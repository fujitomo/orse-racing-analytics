"""
ãƒ‡ãƒ¼ã‚¿å“è³ªãƒã‚§ãƒƒã‚¯ã‚¯ãƒ©ã‚¹
"""
import logging
import time
import pandas as pd
import numpy as np
from typing import Dict, Any, Tuple, List
from datetime import datetime

logger = logging.getLogger(__name__)


class DataQualityChecker:
    """ãƒ‡ãƒ¼ã‚¿å“è³ªãƒã‚§ãƒƒã‚¯ã‚¯ãƒ©ã‚¹ã€‚

    å®Ÿå‹™ãƒ¬ãƒ™ãƒ«ã®ãƒ‡ãƒ¼ã‚¿æ•´å‚™ã«å¿…è¦ãªå“è³ªç®¡ç†æ©Ÿèƒ½ã‚’æä¾›ã™ã‚‹ã€‚
    """
    
    def __init__(self):
        """ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’åˆæœŸåŒ–ã™ã‚‹ã€‚"""
        self.quality_report = {}  # å„å‡¦ç†æ®µéšã®ãƒ‡ãƒ¼ã‚¿å“è³ªãƒ¬ãƒãƒ¼ãƒˆã‚’æ ¼ç´ã™ã‚‹è¾æ›¸
        self.logger = logging.getLogger(__name__)
        
    def check_data_quality(self, df: pd.DataFrame, stage_name: str) -> Dict[str, Any]:
        """åŒ…æ‹¬çš„ãªãƒ‡ãƒ¼ã‚¿å“è³ªãƒã‚§ãƒƒã‚¯ã‚’å®Ÿè¡Œã—ã¾ã™ã€‚

        Args:
            df (pd.DataFrame): ãƒã‚§ãƒƒã‚¯å¯¾è±¡ã® DataFrameã€‚
            stage_name (str): å‡¦ç†æ®µéšåï¼ˆä¾‹: ``BACå‡¦ç†å¾Œ``ï¼‰ã€‚

        Returns:
            Dict[str, Any]: å“è³ªãƒ¬ãƒãƒ¼ãƒˆã‚’æ ¼ç´ã—ãŸè¾æ›¸ã€‚
        """
        self.logger.info(f"ğŸ“Š {stage_name} - ãƒ‡ãƒ¼ã‚¿å“è³ªãƒã‚§ãƒƒã‚¯é–‹å§‹")
        start_time = time.time()
        
        report = {
            'stage': stage_name,  # å‡¦ç†æ®µéšåï¼ˆä¾‹ï¼š'BACå‡¦ç†å¾Œ', 'çµ±åˆå¾Œ'ï¼‰
            'timestamp': datetime.now().isoformat(),  # å“è³ªãƒã‚§ãƒƒã‚¯å®Ÿè¡Œæ™‚åˆ»ï¼ˆISOå½¢å¼ï¼‰
            'total_rows': len(df),  # ãƒ‡ãƒ¼ã‚¿è¡Œæ•°ï¼ˆãƒ¬ã‚³ãƒ¼ãƒ‰æ•°ï¼‰
            'total_columns': len(df.columns),  # ãƒ‡ãƒ¼ã‚¿åˆ—æ•°ï¼ˆã‚«ãƒ©ãƒ æ•°ï¼‰
            'memory_usage_mb': df.memory_usage(deep=True).sum() / 1024 / 1024,  # ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ï¼ˆMBï¼‰
            'missing_values': {},  # æ¬ æå€¤åˆ†æçµæœï¼ˆåˆ—åˆ¥ã®æ¬ ææ•°ãƒ»å‰²åˆï¼‰
            'data_types': {},  # ãƒ‡ãƒ¼ã‚¿å‹æƒ…å ±ï¼ˆåˆ—åã¨ãƒ‡ãƒ¼ã‚¿å‹ã®ãƒãƒƒãƒ”ãƒ³ã‚°ï¼‰
            'duplicates': 0,  # é‡è¤‡è¡Œæ•°
            'outliers': {},  # å¤–ã‚Œå€¤æ¤œå‡ºçµæœï¼ˆåˆ—åˆ¥ã®å¤–ã‚Œå€¤æ•°ï¼‰
            'warnings': [],  # å“è³ªè­¦å‘Šãƒªã‚¹ãƒˆï¼ˆç•°å¸¸å€¤ã€ä¸æ­£ãƒ‡ãƒ¼ã‚¿ãªã©ï¼‰
            'recommendations': []  # æ”¹å–„æ¨å¥¨äº‹é …ãƒªã‚¹ãƒˆ
        }
        
        try:
            # 1. æ¬ æå€¤åˆ†æ
            self.logger.info("   ğŸ” æ¬ æå€¤åˆ†æä¸­...")
            missing_analysis = self._analyze_missing_values(df)
            report['missing_values'] = missing_analysis
            
            # 2. ãƒ‡ãƒ¼ã‚¿å‹ãƒã‚§ãƒƒã‚¯
            self.logger.info("   ğŸ·ï¸ ãƒ‡ãƒ¼ã‚¿å‹ãƒã‚§ãƒƒã‚¯ä¸­...")
            report['data_types'] = self._check_data_types(df)
            
            # 3. é‡è¤‡ãƒã‚§ãƒƒã‚¯
            self.logger.info("   ğŸ”„ é‡è¤‡ãƒã‚§ãƒƒã‚¯ä¸­...")
            report['duplicates'] = int(df.duplicated().sum())
            
            # 4. å¤–ã‚Œå€¤æ¤œå‡ºï¼ˆæ•°å€¤åˆ—ã®ã¿ï¼‰
            self.logger.info("   ğŸ“ˆ å¤–ã‚Œå€¤æ¤œå‡ºä¸­...")
            report['outliers'] = self._detect_outliers(df)
            
            # 5. ãƒ“ã‚¸ãƒã‚¹ãƒ«ãƒ¼ãƒ«æ¤œè¨¼
            self.logger.info("   ğŸ“‹ ãƒ“ã‚¸ãƒã‚¹ãƒ«ãƒ¼ãƒ«æ¤œè¨¼ä¸­...")
            warnings, recommendations = self._validate_business_rules(df)
            report['warnings'] = warnings
            report['recommendations'] = recommendations
            
            execution_time = time.time() - start_time
            report['execution_time_seconds'] = execution_time
            
            self.logger.info(f"âœ… {stage_name} - ãƒ‡ãƒ¼ã‚¿å“è³ªãƒã‚§ãƒƒã‚¯å®Œäº† ({execution_time:.2f}ç§’)")
            
            # ãƒ¬ãƒãƒ¼ãƒˆè¦ç´„ã‚’ãƒ­ã‚°å‡ºåŠ›
            self._log_quality_summary(report)
            
        except Exception as e:
            self.logger.error(f"âŒ ãƒ‡ãƒ¼ã‚¿å“è³ªãƒã‚§ãƒƒã‚¯ã§ã‚¨ãƒ©ãƒ¼: {str(e)}")
            report['error'] = str(e)
        
        self.quality_report[stage_name] = report
        return report
    
    def _analyze_missing_values(self, df: pd.DataFrame) -> Dict[str, Any]:
        """æ¬ æå€¤ã®è©³ç´°åˆ†æã‚’è¡Œã†ã€‚

        Args:
            df (pd.DataFrame): å¯¾è±¡ãƒ‡ãƒ¼ã‚¿ã€‚

        Returns:
            Dict[str, Any]: æ¬ æã‚»ãƒ«ç·æ•°ã‚„åˆ—åˆ¥å†…è¨³ãªã©ã®åˆ†æçµæœã€‚
        """
        missing_counts = df.isnull().sum()
        # æ¬ æå€¤ã®ãƒ‘ãƒ¼ã‚»ãƒ³ãƒ†ãƒ¼ã‚¸
        missing_percentages = (missing_counts / len(df)) * 100
        
        analysis = {
            'total_missing_cells': int(missing_counts.sum()),
            'columns_with_missing': {k: int(v) for k, v in missing_counts[missing_counts > 0].to_dict().items()},
            'missing_percentages': missing_percentages[missing_percentages > 0].to_dict(),
            'critical_columns': []  # 50%ä»¥ä¸Šæ¬ æã®åˆ—
        }
        
        # é‡è¦ãªæ¬ æãƒ‘ã‚¿ãƒ¼ãƒ³ã®ç‰¹å®š
        for col, pct in missing_percentages.items():
            if pct >= 50:
                analysis['critical_columns'].append(col)
        
        return analysis
    
    def _check_data_types(self, df: pd.DataFrame) -> Dict[str, str]:
        """ãƒ‡ãƒ¼ã‚¿å‹ã®å¦¥å½“æ€§ãƒã‚§ãƒƒã‚¯ã‚’è¡Œã†ã€‚

        Args:
            df (pd.DataFrame): å¯¾è±¡ãƒ‡ãƒ¼ã‚¿ã€‚

        Returns:
            Dict[str, str]: åˆ—åã¨ãƒ‡ãƒ¼ã‚¿å‹ã®ãƒãƒƒãƒ”ãƒ³ã‚°ã€‚
        """
        return {col: str(dtype) for col, dtype in df.dtypes.items()}
    
    def _detect_outliers(self, df: pd.DataFrame) -> Dict[str, int]:
        """IQR æ³•ã«ã‚ˆã‚‹å¤–ã‚Œå€¤æ¤œå‡ºã‚’è¡Œã†ã€‚

        Args:
            df (pd.DataFrame): å¯¾è±¡ãƒ‡ãƒ¼ã‚¿ã€‚

        Returns:
            Dict[str, int]: åˆ—åˆ¥ã®å¤–ã‚Œå€¤ä»¶æ•°ã€‚
        """
        outlier_counts = {}
        
        numeric_columns = df.select_dtypes(include=[np.number]).columns
        
        for col in numeric_columns:
            if df[col].notna().sum() > 0:  # æ¬ æå€¤ã§ãªã„å€¤ãŒå­˜åœ¨ã™ã‚‹å ´åˆã®ã¿
                Q1 = df[col].quantile(0.25)
                Q3 = df[col].quantile(0.75)
                IQR = Q3 - Q1
                lower_bound = Q1 - 1.5 * IQR
                upper_bound = Q3 + 1.5 * IQR
                
                outliers = df[(df[col] < lower_bound) | (df[col] > upper_bound)]
                outlier_counts[col] = int(len(outliers))
        
        return outlier_counts
    
    def _validate_business_rules(self, df: pd.DataFrame) -> Tuple[List[str], List[str]]:
        """ç«¶é¦¬ãƒ‡ãƒ¼ã‚¿ç‰¹æœ‰ã®ãƒ“ã‚¸ãƒã‚¹ãƒ«ãƒ¼ãƒ«æ¤œè¨¼ã‚’è¡Œã†ã€‚

        Args:
            df (pd.DataFrame): å¯¾è±¡ãƒ‡ãƒ¼ã‚¿ã€‚

        Returns:
            Tuple[List[str], List[str]]: è­¦å‘Šãƒªã‚¹ãƒˆã¨æ¨å¥¨ãƒªã‚¹ãƒˆã€‚
        """
        warnings = []
        recommendations = []
        
        # ç€é †ã®ãƒã‚§ãƒƒã‚¯
        if 'ç€é †' in df.columns:
            invalid_positions = df[df['ç€é †'] < 0]
            if len(invalid_positions) > 0:
                warnings.append(f"ä¸æ­£ãªç€é †ãƒ‡ãƒ¼ã‚¿: {len(invalid_positions)}ä»¶")
        
        # ã‚¿ã‚¤ãƒ ã®ãƒã‚§ãƒƒã‚¯
        if 'ã‚¿ã‚¤ãƒ ' in df.columns:
            # ç•°å¸¸ã«é€Ÿã„/é…ã„ã‚¿ã‚¤ãƒ ã®æ¤œå‡º
            if df['ã‚¿ã‚¤ãƒ '].notna().sum() > 0:
                median_time = df['ã‚¿ã‚¤ãƒ '].median()
                if median_time and (median_time < 60 or median_time > 300):
                    warnings.append(f"ç•°å¸¸ãªã‚¿ã‚¤ãƒ ä¸­å¤®å€¤: {median_time}ç§’")
        
        # è·é›¢ã®ãƒã‚§ãƒƒã‚¯
        if 'è·é›¢' in df.columns:
            if df['è·é›¢'].notna().sum() > 0:
                min_distance = df['è·é›¢'].min()
                max_distance = df['è·é›¢'].max()
                if min_distance < 1000 or max_distance > 4000:
                    warnings.append(f"ç•°å¸¸ãªè·é›¢ç¯„å›²: {min_distance}m - {max_distance}m")
        
        # æ¨å¥¨äº‹é …
        if len(warnings) == 0:
            recommendations.append("ãƒ‡ãƒ¼ã‚¿å“è³ªã¯è‰¯å¥½ã§ã™")
        else:
            recommendations.append("ãƒ‡ãƒ¼ã‚¿ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°ã‚’æ¤œè¨ã—ã¦ãã ã•ã„")
        
        return warnings, recommendations
    
    def _log_quality_summary(self, report: Dict[str, Any]):
        """å“è³ªãƒ¬ãƒãƒ¼ãƒˆã‚µãƒãƒªãƒ¼ã‚’ãƒ­ã‚°å‡ºåŠ›ã™ã‚‹ã€‚

        Args:
            report (Dict[str, Any]): å“è³ªãƒ¬ãƒãƒ¼ãƒˆè¾æ›¸ã€‚
        """
        self.logger.info(f"ğŸ“Š ã€{report['stage']}ã€‘å“è³ªã‚µãƒãƒªãƒ¼:")
        self.logger.info(f"   ğŸ“ ãƒ‡ãƒ¼ã‚¿è¦æ¨¡: {report['total_rows']:,}è¡Œ x {report['total_columns']}åˆ—")
        self.logger.info(f"   ğŸ’¾ ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡: {report['memory_usage_mb']:.1f}MB")
        self.logger.info(f"   â“ æ¬ æã‚»ãƒ«æ•°: {report['missing_values']['total_missing_cells']:,}")
        self.logger.info(f"   ğŸ”„ é‡è¤‡è¡Œæ•°: {report['duplicates']:,}")
        
        if report['warnings']:
            self.logger.warning(f"   âš ï¸ è­¦å‘Š: {len(report['warnings'])}ä»¶")
            for warning in report['warnings']:
                self.logger.warning(f"      â€¢ {warning}")

