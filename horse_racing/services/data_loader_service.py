"""
ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ã‚µãƒ¼ãƒ“ã‚¹
CSVèª­ã¿è¾¼ã¿ã¨ã‚­ãƒ£ãƒƒã‚·ãƒ¥çµ±åˆã‚’æä¾›
"""

import logging
import pandas as pd
from pathlib import Path
from typing import Optional
from .data_cache_service import get_global_cache

logger = logging.getLogger(__name__)


class DataLoaderService:
    """CSVèª­ã¿è¾¼ã¿ã¨ã‚­ãƒ£ãƒƒã‚·ãƒ¥ç®¡ç†ã‚’æ‹…å½“ã™ã‚‹ã‚µãƒ¼ãƒ“ã‚¹ã‚¯ãƒ©ã‚¹ã€‚"""
    
    def __init__(self):
        """ãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ€ãƒ¼ã‚µãƒ¼ãƒ“ã‚¹ã‚’åˆæœŸåŒ–ã—ã¾ã™ã€‚"""
        self.cache = get_global_cache()
        self.logger = logging.getLogger(__name__)
    
    def load_csv_files(self, input_path: str, encoding: str = 'utf-8', 
                       use_cache: bool = True) -> pd.DataFrame:
        """CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿ã€çµæœã‚’ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã—ã¾ã™ã€‚
        
        Args:
            input_path (str): CSVãƒ•ã‚¡ã‚¤ãƒ«ã€ã¾ãŸã¯ãã‚Œã‚‰ã‚’å«ã‚€ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®ãƒ‘ã‚¹ã€‚
            encoding (str): èª­ã¿è¾¼ã¿æ™‚ã«ä½¿ç”¨ã™ã‚‹æ–‡å­—ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã€‚
            use_cache (bool): ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’åˆ©ç”¨ã™ã‚‹ã‹ã©ã†ã‹ã€‚
            
        Returns:
            pd.DataFrame: å…¥åŠ›ã‚½ãƒ¼ã‚¹ã‚’çµåˆã—ãŸç”Ÿãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã€‚
        """
        # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒã‚§ãƒƒã‚¯
        if use_cache:
            cached_raw = self.cache.get_raw_data()
            if cached_raw is not None:
                self.logger.info("ğŸ’¾ ã‚°ãƒ­ãƒ¼ãƒãƒ«ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‹ã‚‰ç”Ÿãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ä¸­...")
                return cached_raw
        
        self.logger.info("ğŸ“– å…¨CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’åˆå›èª­ã¿è¾¼ã¿ä¸­...")
        input_path_obj = Path(input_path)
        
        if input_path_obj.is_file():
            return self._load_single_file(input_path_obj, encoding)
        else:
            return self._load_directory(input_path_obj, encoding)
    
    def _load_single_file(self, file_path: Path, encoding: str) -> pd.DataFrame:
        """å˜ä¸€CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿ã¾ã™ã€‚
        
        Args:
            file_path (Path): ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã€‚
            encoding (str): æ–‡å­—ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã€‚
            
        Returns:
            pd.DataFrame: èª­ã¿è¾¼ã‚“ã ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã€‚
        """
        df = pd.read_csv(file_path, encoding=encoding)
        self.logger.info(f"ğŸ“Š å˜ä¸€ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿: {len(df):,}è¡Œ")
        self.cache.set_raw_data(df)
        return df
    
    def _load_directory(self, dir_path: Path, encoding: str) -> pd.DataFrame:
        """ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªå†…ã®å…¨CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿çµ±åˆã—ã¾ã™ã€‚
        
        Args:
            dir_path (Path): ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãƒ‘ã‚¹ã€‚
            encoding (str): æ–‡å­—ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã€‚
            
        Returns:
            pd.DataFrame: çµ±åˆã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã€‚
        """
        csv_files = list(dir_path.glob("*.csv"))
        if not csv_files:
            self.logger.error(f"âŒ CSVãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {dir_path}")
            return pd.DataFrame()
        
        self.logger.info(f"ğŸ“Š å…¨CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’çµ±åˆä¸­... ({len(csv_files)}ãƒ•ã‚¡ã‚¤ãƒ«)")
        all_dfs = []
        
        for i, csv_file in enumerate(csv_files):
            try:
                df_temp = pd.read_csv(csv_file, encoding=encoding)
                all_dfs.append(df_temp)
                
                # é€²æ—è¡¨ç¤ºï¼ˆ100ãƒ•ã‚¡ã‚¤ãƒ«ã”ã¨ï¼‰
                if (i + 1) % 100 == 0:
                    self.logger.info(f"   èª­ã¿è¾¼ã¿é€²æ—: {i + 1}/{len(csv_files)}ãƒ•ã‚¡ã‚¤ãƒ«")
                    
            except Exception as e:
                self.logger.warning(f"âš ï¸ ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼ï¼ˆã‚¹ã‚­ãƒƒãƒ—ï¼‰: {csv_file.name} - {str(e)}")
                continue
        
        if all_dfs:
            self.logger.info("ğŸ”„ ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ çµ±åˆä¸­...")
            combined_df = pd.concat(all_dfs, ignore_index=True)
            self.logger.info(f"âœ… çµ±åˆå®Œäº†: {len(combined_df):,}è¡Œã®ãƒ‡ãƒ¼ã‚¿")
            
            # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã«ä¿å­˜
            self.cache.set_raw_data(combined_df)
            self.logger.info("ğŸ’¾ ç”Ÿãƒ‡ãƒ¼ã‚¿ã‚’ã‚°ãƒ­ãƒ¼ãƒãƒ«ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã«ä¿å­˜ã—ã¾ã—ãŸ")
            self.logger.info(f"ğŸ” ã‚­ãƒ£ãƒƒã‚·ãƒ¥ç¢ºèª: raw_data_cached={self.cache.has_raw_data()}")
            return combined_df
        else:
            self.logger.error("âŒ æœ‰åŠ¹ãªCSVãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")
            return pd.DataFrame()
