"""
çµ±ä¸€åˆ†æå™¨ãƒ™ãƒ¼ã‚¹ã‚¯ãƒ©ã‚¹
ã‚ªãƒƒã‚ºæ¯”è¼ƒåˆ†æã¨æœŸé–“åˆ¥åˆ†æã®å…±é€šå‡¦ç†ã‚’æä¾›
"""

import pandas as pd
import numpy as np
from typing import Dict, Any, List, Tuple, Optional
import logging
from pathlib import Path
from abc import ABC, abstractmethod

# æ—¢å­˜ã®åˆ†æå™¨ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
try:
    from ..analyzers.odds_comparison_analyzer import OddsComparisonAnalyzer
    from ..analyzers.race_level_analyzer import REQIAnalyzer
    from ..core.weight_manager import WeightManager
except ImportError:
    OddsComparisonAnalyzer = None
    REQIAnalyzer = None
    WeightManager = None

logger = logging.getLogger(__name__)

class UnifiedAnalyzerBase(ABC):
    """çµ±ä¸€åˆ†æå™¨ã®ãƒ™ãƒ¼ã‚¹ã‚¯ãƒ©ã‚¹"""
    
    def __init__(self, min_races: int = 6, enable_stratified: bool = True):
        """
        åˆæœŸåŒ–
        
        Args:
            min_races: åˆ†æå¯¾è±¡ã¨ã™ã‚‹æœ€ä½å‡ºèµ°å›æ•°
            enable_stratified: å±¤åˆ¥åˆ†æã®æœ‰åŠ¹/ç„¡åŠ¹
        """
        self.min_races = min_races
        self.enable_stratified = enable_stratified
        self.global_weights = None
        self.data = None
        
    def load_data_unified(self, input_path: str, encoding: str = 'utf-8') -> pd.DataFrame:
        """
        çµ±ä¸€ã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
        
        Args:
            input_path: å…¥åŠ›ãƒ‘ã‚¹
            encoding: ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°
            
        Returns:
            èª­ã¿è¾¼ã¾ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ 
        """
        logger.info("ğŸ“– çµ±ä¸€ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿é–‹å§‹...")
        
        # ã‚°ãƒ­ãƒ¼ãƒãƒ«å¤‰æ•°ã‹ã‚‰æ—¢ã«èª­ã¿è¾¼ã¾ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
        import sys
        import os
        
        # analyze_REQIãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’ç›´æ¥ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
        current_dir = os.path.dirname(os.path.dirname(os.path.dirname(__file__)))
        if current_dir not in sys.path:
            sys.path.insert(0, current_dir)
        
        try:
            # ã¾ãšanalyze_REQIãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‹ã‚‰ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’å–å¾—
            import analyze_REQI
            
            # GLOBAL_DATA_CACHEã‚’ç›´æ¥å‚ç…§
            if analyze_REQI.GLOBAL_DATA_CACHE.has_raw_data():
                logger.info("ğŸ’¾ analyze_REQIãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã®ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‹ã‚‰ç”Ÿãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ä¸­...")
                df = analyze_REQI.GLOBAL_DATA_CACHE.get_raw_data()
                logger.info(f"âœ… ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ‡ãƒ¼ã‚¿å–å¾—å®Œäº†: {len(df):,}è¡Œ")
                self.data = df
                return df
            else:
                logger.info("ğŸ” analyze_REQIãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã®ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã¯æœªè¨­å®šã§ã™")
            
            # __main__ ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ã¯å»ƒæ­¢ï¼ˆå–å¾—çµŒè·¯ã‚’çµ±ä¸€ï¼‰
                
        except ImportError as e:
            logger.error(f"âŒ analyze_REQIãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆã«å¤±æ•—: {e}")
            logger.warning("âš ï¸ ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å‡¦ç†ã‚’å®Ÿè¡Œã—ã¾ã™...")
        
        # ã‚°ãƒ­ãƒ¼ãƒãƒ«å¤‰æ•°ãŒãªã„å ´åˆã®ã¿æ–°è¦èª­ã¿è¾¼ã¿ï¼ˆåˆå›èµ·å‹•æ™‚ã®é€šå¸¸ãƒ•ãƒ­ãƒ¼ï¼‰
        # logger.info("â„¹ï¸ ã‚°ãƒ­ãƒ¼ãƒãƒ«å¤‰æ•°ãŒæœªè¨­å®šã®ãŸã‚ã€æ–°è¦èª­ã¿è¾¼ã¿ãƒ«ãƒ¼ãƒˆã«åˆ‡ã‚Šæ›¿ãˆã¾ã™")
        
        # ç›´æ¥CSVã‚’èª­ã¿è¾¼ã¿çµ±åˆï¼ˆ*_formatted_dataset.csv ã‚’å„ªå…ˆã€ãªã‘ã‚Œã° *.csv ã‚’å†å¸°æ¢ç´¢ï¼‰
        try:
            from pathlib import Path
            import pandas as pd
            dataset_dir = Path(input_path)
            if not dataset_dir.exists():
                raise ValueError(f"å…¥åŠ›ãƒ‘ã‚¹ãŒå­˜åœ¨ã—ã¾ã›ã‚“: {input_path}")
            
            csv_files = list(dataset_dir.glob("*_formatted_dataset.csv"))
            if not csv_files:
                # ã‚µãƒ–ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚‚å«ã‚ã¦æ¢ç´¢
                csv_files = list(dataset_dir.rglob("*_formatted_dataset.csv"))
            if not csv_files:
                # æœ€å¾Œã®æ‰‹æ®µã¨ã—ã¦å…¨CSV
                csv_files = list(dataset_dir.rglob("*.csv"))
            
            if not csv_files:
                raise ValueError("ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
            
            dfs = []
            for f in csv_files:
                try:
                    df_part = pd.read_csv(f, encoding=encoding)
                    dfs.append(df_part)
                except Exception as e:
                    logger.warning(f"âš ï¸ èª­ã¿è¾¼ã¿å¤±æ•—ã®ãŸã‚ã‚¹ã‚­ãƒƒãƒ—: {f} - {str(e)}")
            
            if not dfs:
                raise ValueError("èª­è¾¼å¯èƒ½ãªCSVãŒã‚ã‚Šã¾ã›ã‚“")
            
            df = pd.concat(dfs, ignore_index=True)
        except Exception as e:
            logger.error(f"âŒ ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯èª­è¾¼ã‚¨ãƒ©ãƒ¼: {str(e)}")
            raise
        
        if df.empty:
            raise ValueError("ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
        
        logger.info(f"âœ… ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿å®Œäº†: {len(df):,}è¡Œ")
        self.data = df
        return df
    
    def initialize_global_weights(self, df: pd.DataFrame) -> bool:
        """
        ã‚°ãƒ­ãƒ¼ãƒãƒ«é‡ã¿ã®åˆæœŸåŒ–
        
        Args:
            df: ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ 
            
        Returns:
            åˆæœŸåŒ–æˆåŠŸå¯å¦
        """
        logger.info("ğŸ¯ ã‚°ãƒ­ãƒ¼ãƒãƒ«é‡ã¿åˆæœŸåŒ–é–‹å§‹...")
        
        if WeightManager is None:
            logger.warning("WeightManagerãŒåˆ©ç”¨ã§ãã¾ã›ã‚“")
            return False
        
        try:
            import analyze_REQI

            # GLOBAL_DATA_CACHEã‚’ç›´æ¥å‚ç…§
            if analyze_REQI.GLOBAL_DATA_CACHE.has_feature_levels():
                logger.info("ğŸ’¾ analyze_REQIã®ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‹ã‚‰è¨ˆç®—æ¸ˆã¿ç‰¹å¾´é‡ã‚’å–å¾—ä¸­...")
                df_with_features = analyze_REQI.GLOBAL_DATA_CACHE.get_feature_levels()
                logger.info(f"âœ… ã‚°ãƒ­ãƒ¼ãƒãƒ«ç‰¹å¾´é‡å–å¾—å®Œäº†: {len(df_with_features):,}è¡Œ")
            else:
                logger.info("ğŸ§® ç‰¹å¾´é‡ãƒ¬ãƒ™ãƒ«åˆ—ã‚’å†è¨ˆç®—ã—ã¾ã™")
                df_with_features = analyze_REQI.calculate_accurate_feature_levels(df)
                analyze_REQI.GLOBAL_DATA_CACHE.set_combined_data(df)
                analyze_REQI.GLOBAL_DATA_CACHE.set_feature_levels(df_with_features)
                logger.info(f"âœ… ç‰¹å¾´é‡ã‚’ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã«ä¿å­˜: {len(df_with_features):,}è¡Œ")
            
            # ã‚°ãƒ­ãƒ¼ãƒãƒ«é‡ã¿ã‚’åˆæœŸåŒ–
            weights = WeightManager.initialize_from_training_data(df_with_features)
            self.global_weights = weights
            
            logger.info(f"âœ… ã‚°ãƒ­ãƒ¼ãƒãƒ«é‡ã¿è¨­å®šå®Œäº†: {weights}")
            return True
            
        except Exception as e:
            logger.error(f"âŒ ã‚°ãƒ­ãƒ¼ãƒãƒ«é‡ã¿åˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼: {str(e)}")
            return False
    
    def preprocess_data_unified(self, df: pd.DataFrame) -> pd.DataFrame:
        """
        çµ±ä¸€ã•ã‚ŒãŸå‰å‡¦ç†
        
        Args:
            df: ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ 
            
        Returns:
            å‰å‡¦ç†æ¸ˆã¿ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ 
        """
        logger.info("ğŸ”§ çµ±ä¸€å‰å‡¦ç†é–‹å§‹...")
        
        # åŸºæœ¬çš„ãªå‰å‡¦ç†
        processed_df = df.copy()
        
        # å¿…è¦ãªåˆ—ã®å­˜åœ¨ç¢ºèª
        required_cols = ['é¦¬å', 'ç€é †']
        missing_cols = [col for col in required_cols if col not in processed_df.columns]
        if missing_cols:
            logger.warning(f"å¿…è¦ãªåˆ—ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {missing_cols}")
        
        # ãƒ‡ãƒ¼ã‚¿å‹ã®å¤‰æ›
        if 'ç€é †' in processed_df.columns:
            processed_df['ç€é †'] = pd.to_numeric(processed_df['ç€é †'], errors='coerce')
        
        logger.info(f"âœ… å‰å‡¦ç†å®Œäº†: {len(processed_df):,}è¡Œ")
        return processed_df
    
    @abstractmethod
    def analyze(self, df: pd.DataFrame) -> Dict[str, Any]:
        """
        åˆ†æã®å®Ÿè¡Œï¼ˆã‚µãƒ–ã‚¯ãƒ©ã‚¹ã§å®Ÿè£…ï¼‰
        
        Args:
            df: ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ 
            
        Returns:
            åˆ†æçµæœ
        """
        pass
    
    def get_global_weights(self) -> Optional[Dict[str, float]]:
        """
        ã‚°ãƒ­ãƒ¼ãƒãƒ«é‡ã¿ã®å–å¾—
        
        Returns:
            ã‚°ãƒ­ãƒ¼ãƒãƒ«é‡ã¿è¾æ›¸
        """
        return self.global_weights


class OddsComparisonUnifiedAnalyzer(UnifiedAnalyzerBase):
    """ã‚ªãƒƒã‚ºæ¯”è¼ƒåˆ†æç”¨çµ±ä¸€åˆ†æå™¨"""
    
    def __init__(self, min_races: int = 6, enable_stratified: bool = True):
        super().__init__(min_races, enable_stratified)
        self.odds_analyzer = None
        
    def analyze(self, df: pd.DataFrame) -> Dict[str, Any]:
        """
        ã‚ªãƒƒã‚ºæ¯”è¼ƒåˆ†æã®å®Ÿè¡Œ
        
        Args:
            df: ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ 
            
        Returns:
            åˆ†æçµæœ
        """
        logger.info("ğŸ¯ ã‚ªãƒƒã‚ºæ¯”è¼ƒåˆ†æé–‹å§‹...")
        
        if OddsComparisonAnalyzer is None:
            raise ImportError("OddsComparisonAnalyzerãŒåˆ©ç”¨ã§ãã¾ã›ã‚“")
        
        try:
            # OddsComparisonAnalyzerã®ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹åŒ–
            self.odds_analyzer = OddsComparisonAnalyzer(min_races=self.min_races)
            
            # HorseREQIè¨ˆç®—
            horse_stats_df = self.odds_analyzer.calculate_horse_race_level(df)
            logger.info(f"HorseREQIè¨ˆç®—å®Œäº†: {len(horse_stats_df):,}é ­")
            
            # ç›¸é–¢åˆ†æ
            correlation_results = self.odds_analyzer.perform_correlation_analysis(horse_stats_df)
            
            # å›å¸°åˆ†æ
            regression_results = self.odds_analyzer.perform_regression_analysis(horse_stats_df)
            
            # çµæœã‚’ã¾ã¨ã‚ã‚‹
            analysis_results = {
                'data_summary': {
                    'total_records': len(df),
                    'horse_count': len(horse_stats_df),
                    'file_count': len(df)  # æ¦‚ç®—
                },
                'correlations': correlation_results,
                'regression': regression_results
            }
            
            logger.info("âœ… ã‚ªãƒƒã‚ºæ¯”è¼ƒåˆ†æå®Œäº†")
            return analysis_results
            
        except Exception as e:
            logger.error(f"âŒ ã‚ªãƒƒã‚ºæ¯”è¼ƒåˆ†æã‚¨ãƒ©ãƒ¼: {str(e)}")
            raise


class PeriodAnalysisUnifiedAnalyzer(UnifiedAnalyzerBase):
    """æœŸé–“åˆ¥åˆ†æç”¨çµ±ä¸€åˆ†æå™¨"""
    
    def __init__(self, min_races: int = 6, enable_stratified: bool = True):
        super().__init__(min_races, enable_stratified)
        self.race_analyzer = None
        
    def analyze(self, df: pd.DataFrame, periods: List[Tuple[str, int, int]] = None) -> Dict[str, Any]:
        """
        æœŸé–“åˆ¥åˆ†æã®å®Ÿè¡Œ
        
        Args:
            df: ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ 
            periods: æœŸé–“ãƒªã‚¹ãƒˆ [(æœŸé–“å, é–‹å§‹å¹´, çµ‚äº†å¹´), ...]
            
        Returns:
            åˆ†æçµæœ
        """
        logger.info("ğŸ“Š æœŸé–“åˆ¥åˆ†æé–‹å§‹...")
        
        if REQIAnalyzer is None:
            raise ImportError("REQIAnalyzerãŒåˆ©ç”¨ã§ãã¾ã›ã‚“")
        
        try:
            # æœŸé–“ãŒæŒ‡å®šã•ã‚Œã¦ã„ãªã„å ´åˆã¯è‡ªå‹•ç”Ÿæˆ
            if periods is None:
                periods = self._generate_periods(df)
            
            # æœŸé–“åˆ¥åˆ†æã®å®Ÿè¡Œ
            import importlib.util
            import os
            
            # analyze_REQI.pyã®ãƒ‘ã‚¹ã‚’å–å¾—
            current_dir = os.path.dirname(os.path.dirname(os.path.dirname(__file__)))
            module_path = os.path.join(current_dir, 'analyze_REQI.py')
            
            # ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’å‹•çš„ã«ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
            spec = importlib.util.spec_from_file_location("analyze_REQI", module_path)
            module = importlib.util.module_from_spec(spec)
            spec.loader.exec_module(module)
            
            # ä¸€æ™‚çš„ãªè¨­å®šã‚’ä½œæˆï¼ˆãƒ€ãƒŸãƒ¼ãƒ‘ã‚¹ã‚’è¨­å®šï¼‰
            AnalysisConfig = module.AnalysisConfig
            temp_config = AnalysisConfig(
                input_path="export/dataset",  # ãƒ€ãƒŸãƒ¼ãƒ‘ã‚¹ï¼ˆå®Ÿéš›ã¯ä½¿ç”¨ã•ã‚Œãªã„ï¼‰
                min_races=self.min_races,
                output_dir="",  # ä½¿ç”¨ã—ãªã„
                date_str="",
                start_date=None,
                end_date=None
            )
            
            # ä¸€æ™‚çš„ãªåˆ†æå™¨ã‚’ä½œæˆ
            self.race_analyzer = REQIAnalyzer(temp_config, self.enable_stratified)
            
            # ã‚°ãƒ­ãƒ¼ãƒãƒ«ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’è¨­å®šï¼ˆanalyze_by_periods_optimizedãŒä½¿ç”¨ã™ã‚‹ãŸã‚ï¼‰
            import analyze_REQI
            
            # GLOBAL_DATA_CACHEã‚’ç›´æ¥å‚ç…§
            if analyze_REQI.GLOBAL_DATA_CACHE.has_combined_data():
                logger.info("ğŸ’¾ æ—¢å­˜ã®ã‚°ãƒ­ãƒ¼ãƒãƒ«ãƒ‡ãƒ¼ã‚¿ã‚’æ´»ç”¨ä¸­...")
            else:
                analyze_REQI.GLOBAL_DATA_CACHE.set_combined_data(df)
            
            if analyze_REQI.GLOBAL_DATA_CACHE.has_feature_levels():
                logger.info("ğŸ’¾ æ—¢å­˜ã®ã‚°ãƒ­ãƒ¼ãƒãƒ«ç‰¹å¾´é‡ã‚’æ´»ç”¨ä¸­...")
            else:
                analyze_REQI.GLOBAL_DATA_CACHE.set_feature_levels(df)
            
            # æœŸé–“åˆ¥åˆ†æå®Ÿè¡Œ
            all_results = module.analyze_by_periods_optimized(self.race_analyzer, periods, Path("temp"))
            
            logger.info("âœ… æœŸé–“åˆ¥åˆ†æå®Œäº†")
            return all_results
            
        except Exception as e:
            logger.error(f"âŒ æœŸé–“åˆ¥åˆ†æã‚¨ãƒ©ãƒ¼: {str(e)}")
            raise
    
    def _generate_periods(self, df: pd.DataFrame) -> List[Tuple[str, int, int]]:
        """
        æœŸé–“ã®è‡ªå‹•ç”Ÿæˆ
        
        Args:
            df: ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ 
            
        Returns:
            æœŸé–“ãƒªã‚¹ãƒˆ
        """
        if 'å¹´' not in df.columns:
            logger.warning("å¹´åˆ—ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
            return []
        
        min_year = int(df['å¹´'].min())
        max_year = int(df['å¹´'].max())
        
        periods = []
        for start_year in range(min_year, max_year + 1, 3):
            end_year = min(start_year + 2, max_year)
            period_name = f"{start_year}-{end_year}"
            
            # æœŸé–“å†…ã«ãƒ‡ãƒ¼ã‚¿ãŒå­˜åœ¨ã™ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
            period_data = df[(df['å¹´'] >= start_year) & (df['å¹´'] <= end_year)]
            
            if len(period_data) >= self.min_races:
                periods.append((period_name, start_year, end_year))
                logger.info(f"  ğŸ“Š æœŸé–“ {period_name}: {len(period_data):,}ä»¶ã®ãƒ‡ãƒ¼ã‚¿")
            else:
                logger.warning(f"  âš ï¸  æœŸé–“ {period_name}: ãƒ‡ãƒ¼ã‚¿ä¸è¶³ ({len(period_data)}ä»¶)")
        
        return periods


def create_unified_analyzer(analysis_type: str, min_races: int = 6, enable_stratified: bool = True) -> UnifiedAnalyzerBase:
    """
    çµ±ä¸€åˆ†æå™¨ã®ãƒ•ã‚¡ã‚¯ãƒˆãƒªé–¢æ•°
    
    Args:
        analysis_type: åˆ†æã‚¿ã‚¤ãƒ— ('odds' ã¾ãŸã¯ 'period')
        min_races: æœ€å°ãƒ¬ãƒ¼ã‚¹æ•°
        enable_stratified: å±¤åˆ¥åˆ†æã®æœ‰åŠ¹/ç„¡åŠ¹
        
    Returns:
        çµ±ä¸€åˆ†æå™¨ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹
    """
    if analysis_type == 'odds':
        return OddsComparisonUnifiedAnalyzer(min_races, enable_stratified)
    elif analysis_type == 'period':
        return PeriodAnalysisUnifiedAnalyzer(min_races, enable_stratified)
    else:
        raise ValueError(f"ä¸æ˜ãªåˆ†æã‚¿ã‚¤ãƒ—: {analysis_type}")
