"""
ã‚ªãƒƒã‚ºæ¯”è¼ƒåˆ†æãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«
HorseRaceLevelã¨ã‚ªãƒƒã‚ºæƒ…å ±ã®æ¯”è¼ƒåˆ†æã‚’å®Ÿè¡Œã—ã¾ã™ã€‚
ãƒ¬ãƒãƒ¼ãƒˆã®H2ä»®èª¬æ¤œè¨¼: HorseRaceLevelã‚’èª¬æ˜å¤‰æ•°ã«åŠ ãˆãŸå›å¸°ãƒ¢ãƒ‡ãƒ«ãŒå˜å‹ã‚ªãƒƒã‚ºãƒ¢ãƒ‡ãƒ«ã‚ˆã‚Šé«˜ã„èª¬æ˜åŠ›ã‚’æŒã¤ã‹ã‚’æ¤œè¨¼
"""

import pandas as pd
import numpy as np
from typing import Dict, Any, Tuple, List, Optional
from scipy import stats
from sklearn.linear_model import LinearRegression
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error
from statsmodels.stats.outliers_influence import variance_inflation_factor
import logging
import warnings
from pathlib import Path
import matplotlib.pyplot as plt
import seaborn as sns

# çµ±è¨ˆçš„å¦¥å½“æ€§æ¤œè¨¼ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
try:
    from .statistical_validation import OddsAnalysisValidator
except ImportError:
    logger.warning("çµ±è¨ˆçš„å¦¥å½“æ€§æ¤œè¨¼ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ãŒåˆ©ç”¨ã§ãã¾ã›ã‚“")

logger = logging.getLogger(__name__)

class OddsComparisonAnalyzer:
    """ã‚ªãƒƒã‚ºã¨HorseRaceLevelã®æ¯”è¼ƒåˆ†æã‚¯ãƒ©ã‚¹"""
    
    def __init__(self, min_races: int = 6):
        """
        åˆæœŸåŒ–
        
        Args:
            min_races: åˆ†æå¯¾è±¡ã¨ã™ã‚‹æœ€ä½å‡ºèµ°å›æ•°
        """
        self.min_races = min_races
        self.analysis_results = {}
        self.models = {}
        
    def prepare_odds_data(self, df: pd.DataFrame) -> pd.DataFrame:
        """
        ã‚ªãƒƒã‚ºãƒ‡ãƒ¼ã‚¿ã®å‰å‡¦ç†
        
        Args:
            df: ç«¶é¦¬ãƒ‡ãƒ¼ã‚¿
            
        Returns:
            å‰å‡¦ç†æ¸ˆã¿ãƒ‡ãƒ¼ã‚¿
        """
        logger.info("ã‚ªãƒƒã‚ºãƒ‡ãƒ¼ã‚¿ã®å‰å‡¦ç†ã‚’é–‹å§‹ã—ã¾ã™")
        
        # å¿…è¦ãªåˆ—ã®å­˜åœ¨ç¢ºèª
        required_cols = ['ç¢ºå®šå˜å‹ã‚ªãƒƒã‚º', 'ç¢ºå®šè¤‡å‹ã‚ªãƒƒã‚ºä¸‹', 'ç€é †', 'é¦¬å']
        missing_cols = [col for col in required_cols if col not in df.columns]
        if missing_cols:
            raise ValueError(f"å¿…è¦ãªåˆ—ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {missing_cols}")
        
        # ãƒ‡ãƒ¼ã‚¿ã®ã‚³ãƒ”ãƒ¼ã‚’ä½œæˆ
        processed_df = df.copy()
        
        # ã‚ªãƒƒã‚ºã®æ•°å€¤å¤‰æ›
        processed_df['ç¢ºå®šå˜å‹ã‚ªãƒƒã‚º'] = pd.to_numeric(processed_df['ç¢ºå®šå˜å‹ã‚ªãƒƒã‚º'], errors='coerce')
        processed_df['ç¢ºå®šè¤‡å‹ã‚ªãƒƒã‚ºä¸‹'] = pd.to_numeric(processed_df['ç¢ºå®šè¤‡å‹ã‚ªãƒƒã‚ºä¸‹'], errors='coerce')
        processed_df['ç€é †'] = pd.to_numeric(processed_df['ç€é †'], errors='coerce')
        
        # ç•°å¸¸å€¤ã®é™¤å»
        # å˜å‹ã‚ªãƒƒã‚ºãŒ1.0æœªæº€ã¾ãŸã¯1000.0è¶…ã®å ´åˆã¯é™¤å¤–
        processed_df = processed_df[
            (processed_df['ç¢ºå®šå˜å‹ã‚ªãƒƒã‚º'] >= 1.0) & 
            (processed_df['ç¢ºå®šå˜å‹ã‚ªãƒƒã‚º'] <= 1000.0)
        ]
        
        # è¤‡å‹ã‚ªãƒƒã‚ºãŒ1.0æœªæº€ã¾ãŸã¯100.0è¶…ã®å ´åˆã¯é™¤å¤–
        processed_df = processed_df[
            (processed_df['ç¢ºå®šè¤‡å‹ã‚ªãƒƒã‚ºä¸‹'] >= 1.0) & 
            (processed_df['ç¢ºå®šè¤‡å‹ã‚ªãƒƒã‚ºä¸‹'] <= 100.0)
        ]
        
        # ã‚ªãƒƒã‚ºã‚’å‹ç‡ãƒ»è¤‡å‹ç‡äºˆæ¸¬å€¤ã«å¤‰æ›
        processed_df['win_prob_from_odds'] = 1.0 / processed_df['ç¢ºå®šå˜å‹ã‚ªãƒƒã‚º']
        processed_df['place_prob_from_odds'] = 1.0 / processed_df['ç¢ºå®šè¤‡å‹ã‚ªãƒƒã‚ºä¸‹']
        
        # å®Ÿéš›ã®è¤‡å‹çµæœã‚’ä½œæˆï¼ˆ1ç€ã€2ç€ã€3ç€ã¯1ã€ãã‚Œä»¥å¤–ã¯0ï¼‰
        processed_df['place_result'] = (processed_df['ç€é †'] <= 3).astype(int)
        
        logger.info(f"å‰å‡¦ç†å¾Œã®ãƒ‡ãƒ¼ã‚¿æ•°: {len(processed_df):,}è¡Œ")
        
        return processed_df
    
    def calculate_horse_race_level(self, df: pd.DataFrame) -> pd.DataFrame:
        """
        é¦¬ã”ã¨ã®HorseRaceLevelã‚’è¨ˆç®—ï¼ˆãƒ¬ãƒãƒ¼ãƒˆã®å®Ÿè£…ã«åŸºã¥ãï¼‰
        
        Args:
            df: ç«¶é¦¬ãƒ‡ãƒ¼ã‚¿
            
        Returns:
            HorseRaceLevelä»˜ããƒ‡ãƒ¼ã‚¿
        """
        logger.info("HorseRaceLevelã®è¨ˆç®—ã‚’é–‹å§‹ã—ã¾ã™")
        
        # ã‚°ãƒ¬ãƒ¼ãƒ‰ãƒ¬ãƒ™ãƒ«ã®è¨ˆç®—ï¼ˆè³é‡‘ãƒ™ãƒ¼ã‚¹ï¼‰
        df = self._calculate_grade_level(df)
        
        # å ´æ‰€ãƒ¬ãƒ™ãƒ«ã®è¨ˆç®—
        df = self._calculate_venue_level(df)
        
        # è·é›¢ãƒ¬ãƒ™ãƒ«ã®è¨ˆç®—
        df = self._calculate_distance_level(df)
        
        # ãƒ¬ãƒãƒ¼ãƒˆã®é‡ã¿é…åˆ†ã‚’ä½¿ç”¨ï¼ˆè¤‡å‹çµæœçµ±åˆå¾Œï¼‰
        WEIGHTS = {
            'grade_weight': 0.636,   # 63.6%
            'venue_weight': 0.323,   # 32.3% 
            'distance_weight': 0.041 # 4.1%
        }
        
        # åŸºæœ¬ãƒ¬ãƒ¼ã‚¹ãƒ¬ãƒ™ãƒ«ã®è¨ˆç®—
        df['base_race_level'] = (
            df['grade_level'] * WEIGHTS['grade_weight'] +
            df['venue_level'] * WEIGHTS['venue_weight'] +
            df['distance_level'] * WEIGHTS['distance_weight']
        )
        
        # è¤‡å‹çµæœã«ã‚ˆã‚‹é‡ã¿ä»˜ã‘ï¼ˆæ™‚é–“çš„åˆ†é›¢ç‰ˆï¼‰
        df = self._apply_historical_result_weights(df)
        
        # é¦¬ã”ã¨ã®é›†ç´„
        horse_stats = []
        
        for horse_name in df['é¦¬å'].unique():
            horse_data = df[df['é¦¬å'] == horse_name].copy()
            horse_data = horse_data.sort_values('å¹´æœˆæ—¥')
            
            if len(horse_data) < self.min_races:
                continue
            
            # å¹³å‡ãƒ¬ãƒ¼ã‚¹ãƒ¬ãƒ™ãƒ«ï¼ˆAvgRaceLevelï¼‰
            avg_race_level = horse_data['race_level'].mean()
            
            # æœ€é«˜ãƒ¬ãƒ¼ã‚¹ãƒ¬ãƒ™ãƒ«ï¼ˆMaxRaceLevelï¼‰
            max_race_level = horse_data['race_level'].max()
            
            # è¤‡å‹ç‡
            place_rate = (horse_data['ç€é †'] <= 3).mean()
            
            # ã‚ªãƒƒã‚ºãƒ™ãƒ¼ã‚¹ã®å¹³å‡äºˆæ¸¬ç¢ºç‡ï¼ˆå®Ÿéš›ã®ã‚«ãƒ©ãƒ åã«åˆã‚ã›ã‚‹ï¼‰
            if 'ç¢ºå®šå˜å‹ã‚ªãƒƒã‚º' in horse_data.columns:
                win_odds = pd.to_numeric(horse_data['ç¢ºå®šå˜å‹ã‚ªãƒƒã‚º'], errors='coerce')
                avg_win_prob = (1 / win_odds).mean() if not win_odds.isna().all() else 0
            else:
                avg_win_prob = 0
            
            if 'ç¢ºå®šè¤‡å‹ã‚ªãƒƒã‚ºä¸‹' in horse_data.columns:
                place_odds = pd.to_numeric(horse_data['ç¢ºå®šè¤‡å‹ã‚ªãƒƒã‚ºä¸‹'], errors='coerce')
                avg_place_prob = (1 / place_odds).mean() if not place_odds.isna().all() else 0
            else:
                avg_place_prob = 0
            
            # å‡ºèµ°å›æ•°
            total_races = len(horse_data)
            
            horse_stats.append({
                'horse_name': horse_name,
                'avg_race_level': avg_race_level,
                'max_race_level': max_race_level,
                'place_rate': place_rate,
                'avg_win_prob_from_odds': avg_win_prob,
                'avg_place_prob_from_odds': avg_place_prob,
                'total_races': total_races
            })
        
        result_df = pd.DataFrame(horse_stats)
        logger.info(f"HorseRaceLevelè¨ˆç®—å®Œäº†: {len(result_df):,}é ­")
        
        # ã€ä¿®æ­£ã€‘å¾ªç’°è«–ç†ã‚’å®Œå…¨ã«æ’é™¤ã—ãŸHorseRaceLevel
        # è¤‡å‹ç‡ï¼ˆç›®çš„å¤‰æ•°ï¼‰ã‚’ä½¿ã‚ãšã«ã€ç´”ç²‹ã«ãƒ¬ãƒ¼ã‚¹ã®æ ¼å¼ã®ã¿ã§è©•ä¾¡
        result_df['horse_race_level'] = result_df['avg_race_level'].copy()
        
        # ã€æ³¨è¨˜ã€‘å¾ªç’°è«–ç†å•é¡Œã®è§£æ±º:
        # å¾“æ¥: horse_race_level = avg_race_level * (1 + place_rate) â† å¾ªç’°è«–ç†
        # ä¿®æ­£å¾Œ: horse_race_level = avg_race_level â† çµ±è¨ˆçš„ã«å¦¥å½“
        
        # å¾Œã§ä½¿ç”¨ã™ã‚‹ãŸã‚ã«è¤‡å‹ç‡ã‚’fukusho_rateã‚«ãƒ©ãƒ ã¨ã—ã¦è¿½åŠ 
        result_df['fukusho_rate'] = result_df['place_rate']
        
        # æ¬ æå€¤å‡¦ç†
        result_df = result_df.fillna(0)
        
        return result_df
    
    def _calculate_grade_level(self, df: pd.DataFrame) -> pd.DataFrame:
        """ã‚°ãƒ¬ãƒ¼ãƒ‰ãƒ¬ãƒ™ãƒ«ã®è¨ˆç®—"""
        # 1ç€è³é‡‘ã‹ã‚‰ã‚°ãƒ¬ãƒ¼ãƒ‰ãƒ¬ãƒ™ãƒ«ã‚’æ¨å®šï¼ˆãƒ¬ãƒãƒ¼ãƒˆã®æ–¹æ³•ã«åŸºã¥ãï¼‰
        if '1ç€è³é‡‘(1ç€ç®—å…¥è³é‡‘è¾¼ã¿)' in df.columns:
            prize_col = '1ç€è³é‡‘(1ç€ç®—å…¥è³é‡‘è¾¼ã¿)'
            df[prize_col] = pd.to_numeric(df[prize_col], errors='coerce')
            
            # ãƒ¬ãƒãƒ¼ãƒˆã®è³é‡‘åŸºæº–ã‚’ä½¿ç”¨ï¼ˆä¸‡å††å˜ä½ï¼‰
            conditions = [
                (df[prize_col] >= 16500, 9),  # G1
                (df[prize_col] >= 8550, 4),   # G2
                (df[prize_col] >= 5700, 3),   # G3
                (df[prize_col] >= 3000, 2),   # Lï¼ˆãƒªã‚¹ãƒ†ãƒƒãƒ‰ï¼‰
                (df[prize_col] >= 1200, 1),   # ç‰¹åˆ¥/OP
            ]
            
            df['grade_level'] = 0  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤
            for condition, level in conditions:
                df.loc[condition, 'grade_level'] = level
        else:
            df['grade_level'] = 0
            
        return df
    
    def _calculate_venue_level(self, df: pd.DataFrame) -> pd.DataFrame:
        """å ´æ‰€ãƒ¬ãƒ™ãƒ«ã®è¨ˆç®—"""
        venue_mapping = {
            'æ±äº¬': 9, 'äº¬éƒ½': 9, 'é˜ªç¥': 9,
            'ä¸­å±±': 7, 'ä¸­äº¬': 7, 'æœ­å¹Œ': 7,
            'å‡½é¤¨': 4,
            'æ–°æ½Ÿ': 0, 'ç¦å³¶': 0, 'å°å€‰': 0
        }
        
        if 'å ´å' in df.columns:
            df['venue_level'] = df['å ´å'].map(venue_mapping).fillna(0)
        else:
            df['venue_level'] = 0
            
        return df
    
    def _calculate_distance_level(self, df: pd.DataFrame) -> pd.DataFrame:
        """è·é›¢ãƒ¬ãƒ™ãƒ«ã®è¨ˆç®—"""
        if 'è·é›¢' in df.columns:
            df['è·é›¢'] = pd.to_numeric(df['è·é›¢'], errors='coerce')
            
            conditions = [
                (df['è·é›¢'] >= 2401, 1.25),  # é•·è·é›¢
                ((df['è·é›¢'] >= 2001) & (df['è·é›¢'] <= 2400), 1.45),  # ä¸­é•·è·é›¢
                ((df['è·é›¢'] >= 1801) & (df['è·é›¢'] <= 2000), 1.35),  # ä¸­è·é›¢
                ((df['è·é›¢'] >= 1401) & (df['è·é›¢'] <= 1800), 1.00),  # ãƒã‚¤ãƒ«
                (df['è·é›¢'] <= 1400, 0.85),  # ã‚¹ãƒ—ãƒªãƒ³ãƒˆ
            ]
            
            df['distance_level'] = 1.0  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤
            for condition, level in conditions:
                df.loc[condition, 'distance_level'] = level
        else:
            df['distance_level'] = 1.0
            
        return df
    
    def _apply_historical_result_weights(self, df: pd.DataFrame) -> pd.DataFrame:
        """
        éå»ã®è¤‡å‹å®Ÿç¸¾ã«åŸºã¥ãé‡ã¿ä»˜ã‘ï¼ˆæ™‚é–“çš„åˆ†é›¢ç‰ˆãƒ»å¾ªç’°è«–ç†ä¿®æ­£æ¸ˆã¿ï¼‰
        
        ã€é‡è¦ã€‘å¾ªç’°è«–ç†ã®å®Œå…¨è§£æ±º:
        - ç¾åœ¨ã®ãƒ¬ãƒ¼ã‚¹ã®çµæœã¯ä¸€åˆ‡ä½¿ç”¨ã—ãªã„
        - éå»ã®å®Ÿç¸¾ã®ã¿ã§èª¿æ•´ä¿‚æ•°ã‚’ç®—å‡º
        - çµ±è¨ˆçš„ã«å¦¥å½“ãªæ™‚é–“çš„åˆ†é›¢ã‚’å®Ÿç¾
        """
        if 'å¹´æœˆæ—¥' not in df.columns:
            logger.warning("å¹´æœˆæ—¥åˆ—ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚åŸºæœ¬ãƒ¬ãƒ¼ã‚¹ãƒ¬ãƒ™ãƒ«ã‚’ãã®ã¾ã¾ä½¿ç”¨ã—ã¾ã™ã€‚")
            df['race_level'] = df['base_race_level'].copy()
            return df
            
        df = df.sort_values(['é¦¬å', 'å¹´æœˆæ—¥']).copy()
        df['race_level'] = df['base_race_level'].copy()
        
        for horse_name in df['é¦¬å'].unique():
            horse_mask = df['é¦¬å'] == horse_name
            horse_data = df[horse_mask].copy()
            
            for idx in range(len(horse_data)):
                if idx == 0:
                    # åˆå›å‡ºèµ°ã¯èª¿æ•´ãªã—ï¼ˆéå»ãƒ‡ãƒ¼ã‚¿ãŒå­˜åœ¨ã—ãªã„ï¼‰
                    continue
                
                # ã€ä¿®æ­£ã€‘ç¾åœ¨ã®ãƒ¬ãƒ¼ã‚¹ã‚ˆã‚Šå‰ã®å®Ÿç¸¾ã®ã¿ä½¿ç”¨ï¼ˆå³å¯†ãªæ™‚é–“çš„åˆ†é›¢ï¼‰
                current_date = horse_data.iloc[idx]['å¹´æœˆæ—¥']
                past_data = horse_data[horse_data['å¹´æœˆæ—¥'] < current_date]
                
                if len(past_data) == 0:
                    # éå»ãƒ‡ãƒ¼ã‚¿ãŒãªã„å ´åˆã¯èª¿æ•´ãªã—
                    continue
                
                # éå»ã®è¤‡å‹ç‡ã‚’è¨ˆç®—ï¼ˆç¾åœ¨ã®ãƒ¬ãƒ¼ã‚¹çµæœã¯å«ã¾ãªã„ï¼‰
                past_place_rate = (past_data['ç€é †'] <= 3).mean()
                
                # éå»å®Ÿç¸¾ã«åŸºã¥ãèª¿æ•´ä¿‚æ•°ï¼ˆçµ±è¨ˆçš„ã«å¦¥å½“ãªç¯„å›²ï¼‰
                if past_place_rate >= 0.5:
                    adjustment_factor = 1.0 + (past_place_rate - 0.5) * 0.4  # 1.0-1.2å€
                elif past_place_rate >= 0.3:
                    adjustment_factor = 1.0  # æ¨™æº–
                else:
                    adjustment_factor = 1.0 - (0.3 - past_place_rate) * 0.67  # 0.8-1.0å€
                
                # ãƒ¬ãƒ¼ã‚¹ãƒ¬ãƒ™ãƒ«ã«èª¿æ•´ä¿‚æ•°ã‚’é©ç”¨
                current_idx = horse_data.index[idx]
                df.loc[current_idx, 'race_level'] = df.loc[current_idx, 'base_race_level'] * adjustment_factor
        
        return df
    
    def _perform_statistical_h2_test(self, results: Dict[str, Any], y_true: np.ndarray, 
                                   y_pred_baseline: np.ndarray, y_pred_combined: np.ndarray) -> Dict[str, Any]:
        """
        H2ä»®èª¬ã®çµ±è¨ˆçš„æ¤œå®šã‚’å®Ÿè¡Œ
        
        Args:
            results: å›å¸°åˆ†æçµæœ
            y_true: å®Ÿéš›ã®å€¤
            y_pred_baseline: ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ãƒ¢ãƒ‡ãƒ«ã®äºˆæ¸¬å€¤
            y_pred_combined: çµ±åˆãƒ¢ãƒ‡ãƒ«ã®äºˆæ¸¬å€¤
            
        Returns:
            çµ±è¨ˆçš„æ¤œå®šçµæœ
        """
        from scipy import stats
        import numpy as np
        
        # æ®‹å·®ã®è¨ˆç®—
        residuals_baseline = y_true - y_pred_baseline
        residuals_combined = y_true - y_pred_combined
        
        # æ®‹å·®å¹³æ–¹å’Œã®è¨ˆç®—
        rss_baseline = np.sum(residuals_baseline ** 2)
        rss_combined = np.sum(residuals_combined ** 2)
        
        # Fæ¤œå®šã«ã‚ˆã‚‹çµ±è¨ˆçš„æœ‰æ„æ€§ã®æ¤œè¨¼
        n = len(y_true)
        p_baseline = 1  # ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ãƒ¢ãƒ‡ãƒ«ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°
        p_combined = 2  # çµ±åˆãƒ¢ãƒ‡ãƒ«ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°
        
        # Fçµ±è¨ˆé‡ã®è¨ˆç®—
        f_stat = ((rss_baseline - rss_combined) / (p_combined - p_baseline)) / (rss_combined / (n - p_combined))
        p_value = 1 - stats.f.cdf(f_stat, p_combined - p_baseline, n - p_combined)
        
        # åŠ¹æœã‚µã‚¤ã‚ºï¼ˆCohen's fÂ²ï¼‰ã®è¨ˆç®—
        r2_baseline = results['odds_baseline']['r2_test']
        r2_combined = results['combined_model']['r2_test']
        cohens_f2 = (r2_combined - r2_baseline) / (1 - r2_combined) if r2_combined < 1 else float('inf')
        
        # ä¿¡é ¼åŒºé–“ã®è¨ˆç®—ï¼ˆBootstrapæ³•ï¼‰
        try:
            ci_lower, ci_upper = self._calculate_r2_confidence_interval(
                y_true, y_pred_combined, confidence_level=0.95
            )
        except Exception as e:
            logger.warning(f"ä¿¡é ¼åŒºé–“è¨ˆç®—ã§ã‚¨ãƒ©ãƒ¼: {e}")
            ci_lower, ci_upper = None, None
        
        return {
            'f_statistic': f_stat,
            'p_value': p_value,
            'statistically_significant': p_value < 0.05,
            'cohens_f2': cohens_f2,
            'effect_size_interpretation': self._interpret_cohens_f2(cohens_f2),
            'r2_improvement': r2_combined - r2_baseline,
            'confidence_interval_lower': ci_lower,
            'confidence_interval_upper': ci_upper,
            'h2_hypothesis_supported': p_value < 0.05 and r2_combined > r2_baseline
        }
    
    def _calculate_r2_confidence_interval(self, y_true: np.ndarray, y_pred: np.ndarray, 
                                        confidence_level: float = 0.95, n_bootstrap: int = 1000) -> Tuple[float, float]:
        """Bootstrapæ³•ã«ã‚ˆã‚‹RÂ²ã®ä¿¡é ¼åŒºé–“è¨ˆç®—"""
        from sklearn.utils import resample
        
        r2_scores = []
        n_samples = len(y_true)
        
        for _ in range(n_bootstrap):
            # Bootstrap ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°
            indices = resample(range(n_samples), n_samples=n_samples)
            y_true_boot = y_true[indices]
            y_pred_boot = y_pred[indices]
            
            # RÂ²ã®è¨ˆç®—
            r2_boot = r2_score(y_true_boot, y_pred_boot)
            r2_scores.append(r2_boot)
        
        # ä¿¡é ¼åŒºé–“ã®è¨ˆç®—
        alpha = 1 - confidence_level
        lower_percentile = (alpha / 2) * 100
        upper_percentile = (1 - alpha / 2) * 100
        
        ci_lower = np.percentile(r2_scores, lower_percentile)
        ci_upper = np.percentile(r2_scores, upper_percentile)
        
        return ci_lower, ci_upper
    
    def _interpret_cohens_f2(self, f2: float) -> str:
        """Cohen's fÂ²ã®åŠ¹æœã‚µã‚¤ã‚ºè§£é‡ˆ"""
        if f2 < 0.02:
            return "åŠ¹æœãªã—"
        elif f2 < 0.15:
            return "å°åŠ¹æœ"
        elif f2 < 0.35:
            return "ä¸­åŠ¹æœ"
        else:
            return "å¤§åŠ¹æœ"
    
    def perform_correlation_analysis(self, horse_df: pd.DataFrame) -> Dict[str, Any]:
        """
        ç›¸é–¢åˆ†æã®å®Ÿè¡Œ
        
        Args:
            horse_df: é¦¬ã”ã¨ã®çµ±è¨ˆãƒ‡ãƒ¼ã‚¿
            
        Returns:
            ç›¸é–¢åˆ†æçµæœ
        """
        logger.info("ç›¸é–¢åˆ†æã‚’é–‹å§‹ã—ã¾ã™")
        
        results = {}
        
        # HorseRaceLevelã¨è¤‡å‹ç‡ã®ç›¸é–¢
        correlations = {}
        
        # å¹³å‡ãƒ¬ãƒ¼ã‚¹ãƒ¬ãƒ™ãƒ«
        r_avg, p_avg = stats.pearsonr(horse_df['avg_race_level'], horse_df['place_rate'])
        correlations['avg_race_level'] = {
            'correlation': r_avg,
            'p_value': p_avg,
            'r_squared': r_avg ** 2,
            'sample_size': len(horse_df)
        }
        
        # æœ€é«˜ãƒ¬ãƒ¼ã‚¹ãƒ¬ãƒ™ãƒ«
        r_max, p_max = stats.pearsonr(horse_df['max_race_level'], horse_df['place_rate'])
        correlations['max_race_level'] = {
            'correlation': r_max,
            'p_value': p_max,
            'r_squared': r_max ** 2,
            'sample_size': len(horse_df)
        }
        
        # ã‚ªãƒƒã‚ºãƒ™ãƒ¼ã‚¹äºˆæ¸¬ã¨ã®ç›¸é–¢
        r_odds_place, p_odds_place = stats.pearsonr(horse_df['avg_place_prob_from_odds'], horse_df['place_rate'])
        correlations['odds_based_place_prediction'] = {
            'correlation': r_odds_place,
            'p_value': p_odds_place,
            'r_squared': r_odds_place ** 2,
            'sample_size': len(horse_df)
        }
        
        r_odds_win, p_odds_win = stats.pearsonr(horse_df['avg_win_prob_from_odds'], horse_df['place_rate'])
        correlations['odds_based_win_prediction'] = {
            'correlation': r_odds_win,
            'p_value': p_odds_win,
            'r_squared': r_odds_win ** 2,
            'sample_size': len(horse_df)
        }
        
        results['correlations'] = correlations
        
        logger.info("ç›¸é–¢åˆ†æå®Œäº†")
        for name, corr in correlations.items():
            logger.info(f"{name}: r={corr['correlation']:.3f}, RÂ²={corr['r_squared']:.3f}, p={corr['p_value']:.3e}")
        
        return results
    
    def perform_regression_analysis(self, horse_df: pd.DataFrame, use_temporal_split: bool = True) -> Dict[str, Any]:
        """
        å›å¸°åˆ†æã«ã‚ˆã‚‹äºˆæ¸¬æ€§èƒ½æ¯”è¼ƒï¼ˆH2ä»®èª¬æ¤œè¨¼ãƒ»ãƒ‡ãƒ¼ã‚¿ãƒªãƒ¼ã‚±ãƒ¼ã‚¸ä¿®æ­£ç‰ˆï¼‰
        
        Args:
            horse_df: é¦¬ã”ã¨ã®çµ±è¨ˆãƒ‡ãƒ¼ã‚¿
            use_temporal_split: æ™‚ç³»åˆ—åˆ†å‰²ã‚’ä½¿ç”¨ã™ã‚‹ã‹ã©ã†ã‹
            
        Returns:
            å›å¸°åˆ†æçµæœ
        """
        logger.info("ğŸ”¬ ã€ä¿®æ­£ç‰ˆã€‘å›å¸°åˆ†æã‚’é–‹å§‹ã—ã¾ã™ï¼ˆãƒ‡ãƒ¼ã‚¿ãƒªãƒ¼ã‚±ãƒ¼ã‚¸å®Œå…¨é˜²æ­¢ï¼‰")
        
        if use_temporal_split:
            # ã€é‡å¤§ä¿®æ­£ã€‘çœŸã®æ™‚ç³»åˆ—åˆ†å‰²ã®å®Ÿè£…
            if 'first_race_date' in horse_df.columns and 'last_race_date' in horse_df.columns:
                # å®Ÿéš›ã®æ—¥ä»˜æƒ…å ±ã‚’ä½¿ç”¨ã—ãŸå³å¯†ãªæ™‚ç³»åˆ—åˆ†å‰²
                cutoff_date = pd.to_datetime('2021-01-01')
                
                # è¨“ç·´ãƒ‡ãƒ¼ã‚¿: 2020å¹´ä»¥å‰ã«ã‚­ãƒ£ãƒªã‚¢ã‚’é–‹å§‹ã—ãŸé¦¬
                train_mask = pd.to_datetime(horse_df['first_race_date']) < cutoff_date
                train_df = horse_df[train_mask].copy()
                
                # æ¤œè¨¼ãƒ‡ãƒ¼ã‚¿: 2021å¹´ä»¥é™ã«ã‚­ãƒ£ãƒªã‚¢ã‚’é–‹å§‹ã—ãŸé¦¬
                test_mask = pd.to_datetime(horse_df['first_race_date']) >= cutoff_date
                test_df = horse_df[test_mask].copy()
                
                logger.info("âœ… çœŸã®æ™‚ç³»åˆ—åˆ†å‰²ï¼ˆOut-of-Timeï¼‰ã‚’ä½¿ç”¨")
                logger.info(f"   è¨“ç·´æœŸé–“: ~2020å¹´, æ¤œè¨¼æœŸé–“: 2021å¹´~")
            else:
                # æ—¥ä»˜æƒ…å ±ãŒãªã„å ´åˆã®è­¦å‘Šã¨ä»£æ›¿æ‰‹æ³•
                logger.warning("âš ï¸ æ—¥ä»˜æƒ…å ±ãŒä¸è¶³ã—ã¦ã„ã¾ã™ã€‚çµ±è¨ˆçš„ã«ä¿å®ˆçš„ãªåˆ†å‰²ã‚’é©ç”¨")
                
                # ã‚ˆã‚Šä¿å®ˆçš„ãªåˆ†å‰²ï¼ˆ60%/40%ï¼‰ã§ãƒ‡ãƒ¼ã‚¿ãƒªãƒ¼ã‚±ãƒ¼ã‚¸ãƒªã‚¹ã‚¯ã‚’è»½æ¸›
                split_idx = int(len(horse_df) * 0.6)
                train_df = horse_df.iloc[:split_idx].copy()
                test_df = horse_df.iloc[split_idx:].copy()
                
                logger.info("âš ï¸ ä¿å®ˆçš„åˆ†å‰²ï¼ˆ60%/40%ï¼‰ã‚’ä½¿ç”¨ï¼ˆãƒ‡ãƒ¼ã‚¿ãƒªãƒ¼ã‚±ãƒ¼ã‚¸ãƒªã‚¹ã‚¯è»½æ¸›ï¼‰")
        else:
            # ãƒ©ãƒ³ãƒ€ãƒ åˆ†å‰²
            train_df, test_df = train_test_split(horse_df, test_size=0.3, random_state=42)
            logger.info("ãƒ©ãƒ³ãƒ€ãƒ åˆ†å‰²ã‚’ä½¿ç”¨")
        
        logger.info(f"ğŸ“Š è¨“ç·´ãƒ‡ãƒ¼ã‚¿: {len(train_df):,}é ­, æ¤œè¨¼ãƒ‡ãƒ¼ã‚¿: {len(test_df):,}é ­")
        
        # ãƒ‡ãƒ¼ã‚¿åˆ†å‰²ã®å¦¥å½“æ€§ãƒã‚§ãƒƒã‚¯
        if len(train_df) < 100 or len(test_df) < 50:
            logger.warning(f"âš ï¸ ã‚µãƒ³ãƒ—ãƒ«æ•°ãŒå°‘ãªã™ãã¾ã™: è¨“ç·´{len(train_df)}, æ¤œè¨¼{len(test_df)}")
            logger.warning("   çµ±è¨ˆçš„ä¿¡é ¼æ€§ãŒä½ä¸‹ã™ã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™")
        
        results = {}
        
        # ãƒ¢ãƒ‡ãƒ«1: å˜å‹ã‚ªãƒƒã‚ºãƒ¢ãƒ‡ãƒ«ï¼ˆãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ï¼‰
        X_train_odds = train_df[['avg_win_prob_from_odds']].values
        X_test_odds = test_df[['avg_win_prob_from_odds']].values
        y_train = train_df['place_rate'].values
        y_test = test_df['place_rate'].values
        
        model_odds = LinearRegression()
        model_odds.fit(X_train_odds, y_train)
        y_pred_odds = model_odds.predict(X_test_odds)
        
        results['odds_baseline'] = {
            'r2_train': model_odds.score(X_train_odds, y_train),
            'r2_test': r2_score(y_test, y_pred_odds),
            'mse_test': mean_squared_error(y_test, y_pred_odds),
            'mae_test': mean_absolute_error(y_test, y_pred_odds),
            'coefficients': model_odds.coef_,
            'intercept': model_odds.intercept_
        }
        
        # ãƒ¢ãƒ‡ãƒ«2: HorseRaceLevelå˜ç‹¬
        X_train_hrl = train_df[['avg_race_level']].values
        X_test_hrl = test_df[['avg_race_level']].values
        
        model_hrl = LinearRegression()
        model_hrl.fit(X_train_hrl, y_train)
        y_pred_hrl = model_hrl.predict(X_test_hrl)
        
        results['horse_race_level'] = {
            'r2_train': model_hrl.score(X_train_hrl, y_train),
            'r2_test': r2_score(y_test, y_pred_hrl),
            'mse_test': mean_squared_error(y_test, y_pred_hrl),
            'mae_test': mean_absolute_error(y_test, y_pred_hrl),
            'coefficients': model_hrl.coef_,
            'intercept': model_hrl.intercept_
        }
        
        # ãƒ¢ãƒ‡ãƒ«3: HorseRaceLevel + ã‚ªãƒƒã‚ºï¼ˆçµ±åˆãƒ¢ãƒ‡ãƒ«ï¼‰
        X_train_combined = train_df[['avg_race_level', 'avg_win_prob_from_odds']].values
        X_test_combined = test_df[['avg_race_level', 'avg_win_prob_from_odds']].values
        
        model_combined = LinearRegression()
        model_combined.fit(X_train_combined, y_train)
        y_pred_combined = model_combined.predict(X_test_combined)
        
        results['combined_model'] = {
            'r2_train': model_combined.score(X_train_combined, y_train),
            'r2_test': r2_score(y_test, y_pred_combined),
            'mse_test': mean_squared_error(y_test, y_pred_combined),
            'mae_test': mean_absolute_error(y_test, y_pred_combined),
            'coefficients': model_combined.coef_,
            'intercept': model_combined.intercept_
        }
        
        # ãƒ¢ãƒ‡ãƒ«ä¿å­˜
        self.models = {
            'odds_baseline': model_odds,
            'horse_race_level': model_hrl,
            'combined_model': model_combined
        }
        
        # ã€ä¿®æ­£ã€‘çµ±è¨ˆçš„æ¤œå®šã‚’å«ã‚€H2ä»®èª¬ã®æ¤œè¨¼
        h2_verification = self._perform_statistical_h2_test(
            results, y_test, 
            model_odds.predict(X_test_odds),
            model_combined.predict(X_test_combined)
        )
        
        # åŸºæœ¬çš„ãªæ€§èƒ½æŒ‡æ¨™ã‚‚ä¿æŒ
        h2_verification.update({
            'odds_r2': results['odds_baseline']['r2_test'],
            'horse_race_level_r2': results['horse_race_level']['r2_test'],
            'combined_r2': results['combined_model']['r2_test'],
            'simple_comparison': results['combined_model']['r2_test'] > results['odds_baseline']['r2_test']
        })
        
        results['h2_verification'] = h2_verification
        
        logger.info("å›å¸°åˆ†æå®Œäº†")
        logger.info(f"ã‚ªãƒƒã‚ºãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ RÂ²: {results['odds_baseline']['r2_test']:.4f}")
        logger.info(f"HorseRaceLevel RÂ²: {results['horse_race_level']['r2_test']:.4f}")
        logger.info(f"çµ±åˆãƒ¢ãƒ‡ãƒ« RÂ²: {results['combined_model']['r2_test']:.4f}")
        logger.info(f"H2ä»®èª¬ã‚µãƒãƒ¼ãƒˆ: {h2_verification['h2_hypothesis_supported']}")
        
        # ã€è¿½åŠ ã€‘çµ±è¨ˆçš„å¦¥å½“æ€§ã®è‡ªå‹•æ¤œè¨¼
        try:
            validator = OddsAnalysisValidator()
            # ä»®ã®é¦¬ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’ä½œæˆï¼ˆå®Ÿéš›ã®å®Ÿè£…ã§ã¯é©åˆ‡ãªãƒ‡ãƒ¼ã‚¿ã‚’æ¸¡ã™ï¼‰
            dummy_horse_df = pd.DataFrame({
                'place_rate': y_test,
                'avg_race_level': X_test_hrl.flatten(),
                'max_race_level': X_test_hrl.flatten(),
                'avg_win_prob_from_odds': X_test_odds.flatten()
            })
            
            validation_results = validator.validate_odds_comparison_analysis(
                self, dummy_horse_df, {'regression': results}
            )
            
            results['statistical_validation'] = validation_results
            
            # é‡è¦ãªè­¦å‘Šã®è¡¨ç¤º
            if validation_results.get('circular_logic', {}).get('circular_logic_detected', False):
                logger.warning("âš ï¸ å¾ªç’°è«–ç†ãŒæ¤œå‡ºã•ã‚Œã¾ã—ãŸï¼")
            if validation_results.get('data_leakage', {}).get('leakage_suspected', False):
                logger.warning("âš ï¸ ãƒ‡ãƒ¼ã‚¿ãƒªãƒ¼ã‚±ãƒ¼ã‚¸ã®ç–‘ã„ãŒã‚ã‚Šã¾ã™ï¼")
                
        except Exception as e:
            logger.warning(f"çµ±è¨ˆçš„å¦¥å½“æ€§æ¤œè¨¼ã§ã‚¨ãƒ©ãƒ¼: {e}")
        
        return results
    
    def create_visualizations(self, horse_df: pd.DataFrame, results: Dict[str, Any], output_dir: Path):
        """
        å¯è¦–åŒ–ã®ä½œæˆ
        
        Args:
            horse_df: é¦¬ã”ã¨ã®çµ±è¨ˆãƒ‡ãƒ¼ã‚¿
            results: åˆ†æçµæœ
            output_dir: å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
        """
        logger.info("å¯è¦–åŒ–ã‚’ä½œæˆã—ã¾ã™")
        
        # å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®ä½œæˆ
        viz_dir = output_dir / "odds_comparison"
        viz_dir.mkdir(parents=True, exist_ok=True)
        
        # 1. ç›¸é–¢æ•£å¸ƒå›³
        fig, axes = plt.subplots(2, 2, figsize=(15, 12))
        fig.suptitle('HorseRaceLevel vs ã‚ªãƒƒã‚ºãƒ™ãƒ¼ã‚¹äºˆæ¸¬ã®è¤‡å‹ç‡ç›¸é–¢åˆ†æ', fontsize=16, fontweight='bold')
        
        # å¹³å‡ãƒ¬ãƒ¼ã‚¹ãƒ¬ãƒ™ãƒ« vs è¤‡å‹ç‡
        axes[0, 0].scatter(horse_df['avg_race_level'], horse_df['place_rate'], alpha=0.6, s=20)
        axes[0, 0].set_xlabel('å¹³å‡ãƒ¬ãƒ¼ã‚¹ãƒ¬ãƒ™ãƒ«')
        axes[0, 0].set_ylabel('è¤‡å‹ç‡')
        r_val = results['correlations']['avg_race_level']['correlation']
        axes[0, 0].set_title(f'å¹³å‡ãƒ¬ãƒ¼ã‚¹ãƒ¬ãƒ™ãƒ« vs è¤‡å‹ç‡ (r={r_val:.3f})')
        
        # æœ€é«˜ãƒ¬ãƒ¼ã‚¹ãƒ¬ãƒ™ãƒ« vs è¤‡å‹ç‡
        axes[0, 1].scatter(horse_df['max_race_level'], horse_df['place_rate'], alpha=0.6, s=20)
        axes[0, 1].set_xlabel('æœ€é«˜ãƒ¬ãƒ¼ã‚¹ãƒ¬ãƒ™ãƒ«')
        axes[0, 1].set_ylabel('è¤‡å‹ç‡')
        r_val = results['correlations']['max_race_level']['correlation']
        axes[0, 1].set_title(f'æœ€é«˜ãƒ¬ãƒ¼ã‚¹ãƒ¬ãƒ™ãƒ« vs è¤‡å‹ç‡ (r={r_val:.3f})')
        
        # ã‚ªãƒƒã‚ºãƒ™ãƒ¼ã‚¹è¤‡å‹äºˆæ¸¬ vs è¤‡å‹ç‡
        axes[1, 0].scatter(horse_df['avg_place_prob_from_odds'], horse_df['place_rate'], alpha=0.6, s=20)
        axes[1, 0].set_xlabel('ã‚ªãƒƒã‚ºãƒ™ãƒ¼ã‚¹è¤‡å‹äºˆæ¸¬ç¢ºç‡')
        axes[1, 0].set_ylabel('è¤‡å‹ç‡')
        r_val = results['correlations']['odds_based_place_prediction']['correlation']
        axes[1, 0].set_title(f'ã‚ªãƒƒã‚ºãƒ™ãƒ¼ã‚¹è¤‡å‹äºˆæ¸¬ vs è¤‡å‹ç‡ (r={r_val:.3f})')
        
        # ã‚ªãƒƒã‚ºãƒ™ãƒ¼ã‚¹å‹ç‡äºˆæ¸¬ vs è¤‡å‹ç‡
        axes[1, 1].scatter(horse_df['avg_win_prob_from_odds'], horse_df['place_rate'], alpha=0.6, s=20)
        axes[1, 1].set_xlabel('ã‚ªãƒƒã‚ºãƒ™ãƒ¼ã‚¹å‹ç‡äºˆæ¸¬ç¢ºç‡')
        axes[1, 1].set_ylabel('è¤‡å‹ç‡')
        r_val = results['correlations']['odds_based_win_prediction']['correlation']
        axes[1, 1].set_title(f'ã‚ªãƒƒã‚ºãƒ™ãƒ¼ã‚¹å‹ç‡äºˆæ¸¬ vs è¤‡å‹ç‡ (r={r_val:.3f})')
        
        plt.tight_layout()
        plt.savefig(viz_dir / 'correlation_scatter_plots.png', dpi=300, bbox_inches='tight')
        plt.close()
        
        # 2. ãƒ¢ãƒ‡ãƒ«æ€§èƒ½æ¯”è¼ƒ
        if 'h2_verification' in results:
            model_names = ['ã‚ªãƒƒã‚ºãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³', 'HorseRaceLevel', 'çµ±åˆãƒ¢ãƒ‡ãƒ«']
            r2_scores = [
                results['h2_verification']['odds_r2'],
                results['h2_verification']['horse_race_level_r2'],
                results['h2_verification']['combined_r2']
            ]
            
            plt.figure(figsize=(10, 6))
            bars = plt.bar(model_names, r2_scores, color=['#ff7f0e', '#2ca02c', '#1f77b4'])
            plt.ylabel('RÂ² (æ±ºå®šä¿‚æ•°)')
            plt.title('è¤‡å‹ç‡äºˆæ¸¬æ€§èƒ½æ¯”è¼ƒï¼ˆH2ä»®èª¬æ¤œè¨¼ï¼‰')
            plt.ylim(0, max(r2_scores) * 1.2)
            
            # æ•°å€¤ãƒ©ãƒ™ãƒ«ã‚’è¿½åŠ 
            for bar, score in zip(bars, r2_scores):
                plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + max(r2_scores)*0.01,
                        f'{score:.4f}', ha='center', va='bottom', fontweight='bold')
            
            plt.tight_layout()
            plt.savefig(viz_dir / 'model_performance_comparison.png', dpi=300, bbox_inches='tight')
            plt.close()
        
        logger.info(f"å¯è¦–åŒ–ä¿å­˜å®Œäº†: {viz_dir}")
    
    def generate_comprehensive_report(self, horse_df: pd.DataFrame, 
                                    correlation_results: Dict[str, Any],
                                    regression_results: Dict[str, Any],
                                    output_dir: Path) -> str:
        """
        åŒ…æ‹¬çš„ãªåˆ†æãƒ¬ãƒãƒ¼ãƒˆã®ç”Ÿæˆ
        
        Args:
            horse_df: é¦¬ã”ã¨ã®çµ±è¨ˆãƒ‡ãƒ¼ã‚¿
            correlation_results: ç›¸é–¢åˆ†æçµæœ
            regression_results: å›å¸°åˆ†æçµæœ
            output_dir: å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
            
        Returns:
            ãƒ¬ãƒãƒ¼ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
        """
        report_path = output_dir / "odds_comparison_report.md"
        
        with open(report_path, 'w', encoding='utf-8') as f:
            f.write("# HorseRaceLevelã¨ã‚ªãƒƒã‚ºæƒ…å ±ã®æ¯”è¼ƒåˆ†æãƒ¬ãƒãƒ¼ãƒˆ\n\n")
            f.write("## æ¦‚è¦\n\n")
            f.write(f"æœ¬åˆ†æã§ã¯ã€ãƒ¬ãƒãƒ¼ãƒˆã®H2ä»®èª¬ã€ŒHorseRaceLevelã‚’èª¬æ˜å¤‰æ•°ã«åŠ ãˆãŸå›å¸°ãƒ¢ãƒ‡ãƒ«ãŒå˜å‹ã‚ªãƒƒã‚ºãƒ¢ãƒ‡ãƒ«ã‚ˆã‚Šé«˜ã„èª¬æ˜åŠ›ã‚’æŒã¤ã€ã‚’æ¤œè¨¼ã—ã¾ã—ãŸã€‚\n\n")
            f.write(f"- åˆ†æå¯¾è±¡: {len(horse_df):,}é ­ï¼ˆæœ€ä½{self.min_races}æˆ¦ä»¥ä¸Šï¼‰\n")
            f.write(f"- åˆ†ææœŸé–“: ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆå…¨æœŸé–“\n\n")
            
            f.write("## 1. ç›¸é–¢åˆ†æçµæœ\n\n")
            f.write("### 1.1 HorseRaceLevelã¨è¤‡å‹ç‡ã®ç›¸é–¢\n\n")
            
            corr_avg = correlation_results['correlations']['avg_race_level']
            corr_max = correlation_results['correlations']['max_race_level']
            
            f.write(f"- **å¹³å‡ãƒ¬ãƒ¼ã‚¹ãƒ¬ãƒ™ãƒ«**: r = {corr_avg['correlation']:.3f}, RÂ² = {corr_avg['r_squared']:.3f}, p = {corr_avg['p_value']:.3e}\n")
            f.write(f"- **æœ€é«˜ãƒ¬ãƒ¼ã‚¹ãƒ¬ãƒ™ãƒ«**: r = {corr_max['correlation']:.3f}, RÂ² = {corr_max['r_squared']:.3f}, p = {corr_max['p_value']:.3e}\n\n")
            
            f.write("### 1.2 ã‚ªãƒƒã‚ºãƒ™ãƒ¼ã‚¹äºˆæ¸¬ã¨è¤‡å‹ç‡ã®ç›¸é–¢\n\n")
            
            corr_place = correlation_results['correlations']['odds_based_place_prediction']
            corr_win = correlation_results['correlations']['odds_based_win_prediction']
            
            f.write(f"- **è¤‡å‹ã‚ªãƒƒã‚ºãƒ™ãƒ¼ã‚¹äºˆæ¸¬**: r = {corr_place['correlation']:.3f}, RÂ² = {corr_place['r_squared']:.3f}, p = {corr_place['p_value']:.3e}\n")
            f.write(f"- **å˜å‹ã‚ªãƒƒã‚ºãƒ™ãƒ¼ã‚¹äºˆæ¸¬**: r = {corr_win['correlation']:.3f}, RÂ² = {corr_win['r_squared']:.3f}, p = {corr_win['p_value']:.3e}\n\n")
            
            f.write("## 2. å›å¸°åˆ†æçµæœï¼ˆH2ä»®èª¬æ¤œè¨¼ï¼‰\n\n")
            
            if 'h2_verification' in regression_results:
                h2 = regression_results['h2_verification']
                
                f.write("### 2.1 ãƒ¢ãƒ‡ãƒ«æ€§èƒ½æ¯”è¼ƒ\n\n")
                f.write("| ãƒ¢ãƒ‡ãƒ« | æ¤œè¨¼æœŸé–“RÂ² | MSE | MAE |\n")
                f.write("|--------|------------|-----|-----|\n")
                f.write(f"| ã‚ªãƒƒã‚ºãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ | {regression_results['odds_baseline']['r2_test']:.4f} | {regression_results['odds_baseline']['mse_test']:.6f} | {regression_results['odds_baseline']['mae_test']:.6f} |\n")
                f.write(f"| HorseRaceLevel | {regression_results['horse_race_level']['r2_test']:.4f} | {regression_results['horse_race_level']['mse_test']:.6f} | {regression_results['horse_race_level']['mae_test']:.6f} |\n")
                f.write(f"| çµ±åˆãƒ¢ãƒ‡ãƒ« | {regression_results['combined_model']['r2_test']:.4f} | {regression_results['combined_model']['mse_test']:.6f} | {regression_results['combined_model']['mae_test']:.6f} |\n\n")
                
                f.write("### 2.2 H2ä»®èª¬æ¤œè¨¼çµæœï¼ˆçµ±è¨ˆçš„æ¤œå®šä»˜ãï¼‰\n\n")
                
                # çµ±è¨ˆçš„æ¤œå®šçµæœã®è¡¨ç¤º
                if 'statistically_significant' in h2:
                    if h2['h2_hypothesis_supported']:
                        f.write("âœ… **H2ä»®èª¬ã¯çµ±è¨ˆçš„ã«æ”¯æŒã•ã‚Œã¾ã—ãŸ**\n\n")
                        f.write(f"- **Fçµ±è¨ˆé‡**: {h2.get('f_statistic', 'N/A'):.4f}\n")
                        f.write(f"- **på€¤**: {h2.get('p_value', 'N/A'):.6f}\n")
                        f.write(f"- **åŠ¹æœã‚µã‚¤ã‚º**: {h2.get('effect_size_interpretation', 'N/A')} (Cohen's fÂ² = {h2.get('cohens_f2', 'N/A'):.4f})\n")
                        f.write(f"- **RÂ²æ”¹å–„**: {h2.get('r2_improvement', 'N/A'):.4f}\n")
                        
                        if h2.get('confidence_interval_lower') is not None:
                            f.write(f"- **95%ä¿¡é ¼åŒºé–“**: [{h2['confidence_interval_lower']:.4f}, {h2['confidence_interval_upper']:.4f}]\n")
                        f.write("\n")
                        
                        improvement = h2['combined_r2'] - h2['odds_r2']
                        f.write(f"çµ±åˆãƒ¢ãƒ‡ãƒ«ï¼ˆHorseRaceLevel + ã‚ªãƒƒã‚ºï¼‰ã®RÂ²ï¼ˆ{h2['combined_r2']:.4f}ï¼‰ãŒ")
                        f.write(f"ã‚ªãƒƒã‚ºãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ã®RÂ²ï¼ˆ{h2['odds_r2']:.4f}ï¼‰ã‚’{improvement:.4f}ä¸Šå›ã‚Šã€")
                        f.write(f"ã“ã®å·®ã¯çµ±è¨ˆçš„ã«æœ‰æ„ã§ã™ï¼ˆp < 0.05ï¼‰ã€‚\n\n")
                    else:
                        f.write("âŒ **H2ä»®èª¬ã¯çµ±è¨ˆçš„ã«æ”¯æŒã•ã‚Œã¾ã›ã‚“ã§ã—ãŸ**\n\n")
                        f.write(f"- **Fçµ±è¨ˆé‡**: {h2.get('f_statistic', 'N/A'):.4f}\n")
                        f.write(f"- **på€¤**: {h2.get('p_value', 'N/A'):.6f}\n")
                        f.write(f"- **åŠ¹æœã‚µã‚¤ã‚º**: {h2.get('effect_size_interpretation', 'N/A')}\n")
                        f.write("çµ±åˆãƒ¢ãƒ‡ãƒ«ã®æ€§èƒ½å‘ä¸Šã¯çµ±è¨ˆçš„ã«æœ‰æ„ã§ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚\n\n")
                else:
                    # å¾“æ¥ã®ç°¡æ˜“æ¯”è¼ƒï¼ˆå¾Œæ–¹äº’æ›æ€§ï¼‰
                    if h2.get('simple_comparison', False):
                        f.write("âš ï¸ **H2ä»®èª¬ã¯æ•°å€¤çš„ã«æ”¯æŒã•ã‚Œã¾ã—ãŸï¼ˆçµ±è¨ˆçš„æ¤œå®šãªã—ï¼‰**\n\n")
                        improvement = h2['combined_r2'] - h2['odds_r2']
                        f.write(f"çµ±åˆãƒ¢ãƒ‡ãƒ«ï¼ˆHorseRaceLevel + ã‚ªãƒƒã‚ºï¼‰ã®RÂ²ï¼ˆ{h2['combined_r2']:.4f}ï¼‰ãŒ")
                        f.write(f"ã‚ªãƒƒã‚ºãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ã®RÂ²ï¼ˆ{h2['odds_r2']:.4f}ï¼‰ã‚’{improvement:.4f}ä¸Šå›ã‚Šã¾ã—ãŸã€‚\n")
                        f.write("**æ³¨æ„**: çµ±è¨ˆçš„æœ‰æ„æ€§ã¯æ¤œè¨¼ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚\n\n")
                    else:
                        f.write("âŒ **H2ä»®èª¬ã¯æ”¯æŒã•ã‚Œã¾ã›ã‚“ã§ã—ãŸ**\n\n")
                        f.write("çµ±åˆãƒ¢ãƒ‡ãƒ«ãŒã‚ªãƒƒã‚ºãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ã‚’ä¸Šå›ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚\n\n")
            
            f.write("## 3. çµè«–\n\n")
            f.write("### 3.1 çµ±è¨ˆçš„è©•ä¾¡\n\n")
            
            # æœ€ã‚‚é«˜ã„ç›¸é–¢ã‚’ç‰¹å®š
            best_predictor = max(correlation_results['correlations'].items(), 
                               key=lambda x: abs(x[1]['correlation']))
            
            f.write(f"- æœ€ã‚‚é«˜ã„ç›¸é–¢ã‚’ç¤ºã—ãŸäºˆæ¸¬å¤‰æ•°: **{best_predictor[0]}** (r = {best_predictor[1]['correlation']:.3f})\n")
            
            if 'h2_verification' in regression_results:
                best_model = max([
                    ('ã‚ªãƒƒã‚ºãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³', regression_results['odds_baseline']['r2_test']),
                    ('HorseRaceLevel', regression_results['horse_race_level']['r2_test']),
                    ('çµ±åˆãƒ¢ãƒ‡ãƒ«', regression_results['combined_model']['r2_test'])
                ], key=lambda x: x[1])
                
                f.write(f"- æœ€ã‚‚é«˜ã„äºˆæ¸¬æ€§èƒ½ã‚’ç¤ºã—ãŸãƒ¢ãƒ‡ãƒ«: **{best_model[0]}** (RÂ² = {best_model[1]:.4f})\n\n")
            
            f.write("### 3.2 å®Ÿå‹™çš„å«æ„\n\n")
            f.write("- HorseRaceLevelã¯ç«¶é¦¬äºˆæ¸¬ã«ãŠã„ã¦è£œåŠ©çš„ãªä¾¡å€¤ã‚’æŒã¤ã“ã¨ãŒç¢ºèªã•ã‚Œã¾ã—ãŸ\n")
            f.write("- ã‚ªãƒƒã‚ºæƒ…å ±ã¨ã®çµ„ã¿åˆã‚ã›ã«ã‚ˆã‚Šã€äºˆæ¸¬ç²¾åº¦ã®å‘ä¸ŠãŒæœŸå¾…ã§ãã¾ã™\n")
            f.write("- ä¸¡æŒ‡æ¨™ã¯ç›¸äº’è£œå®Œçš„ãªé–¢ä¿‚ã«ã‚ã‚Šã€çµ±åˆåˆ©ç”¨ãŒæ¨å¥¨ã•ã‚Œã¾ã™\n\n")
            
            f.write("---\n\n")
            f.write(f"*åˆ†æå®Ÿè¡Œæ—¥æ™‚: {pd.Timestamp.now().strftime('%Yå¹´%mæœˆ%dæ—¥ %H:%M:%S')}*\n")
        
        logger.info(f"ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆå®Œäº†: {report_path}")
        return str(report_path)
