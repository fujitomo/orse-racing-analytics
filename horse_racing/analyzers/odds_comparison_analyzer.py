"""
ã‚ªãƒƒã‚ºæ¯”è¼ƒåˆ†æãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«
REQIï¼ˆç«¶èµ°çµŒé¨“è³ªæŒ‡æ•°ï¼‰ã¨ã‚ªãƒƒã‚ºæƒ…å ±ã®æ¯”è¼ƒåˆ†æã‚’å®Ÿè¡Œã—ã¾ã™ã€‚
ãƒ¬ãƒãƒ¼ãƒˆã®H2ä»®èª¬æ¤œè¨¼: REQIï¼ˆç«¶èµ°çµŒé¨“è³ªæŒ‡æ•°ï¼‰ã‚’èª¬æ˜å¤‰æ•°ã«åŠ ãˆãŸå›å¸°ãƒ¢ãƒ‡ãƒ«ãŒå˜å‹ã‚ªãƒƒã‚ºãƒ¢ãƒ‡ãƒ«ã‚ˆã‚Šé«˜ã„èª¬æ˜åŠ›ã‚’æŒã¤ã‹ã‚’æ¤œè¨¼
"""

import pandas as pd
import numpy as np
from typing import Dict, Any, Tuple, List, Optional
from scipy import stats
from sklearn.linear_model import LinearRegression
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error
from statsmodels.stats.outliers_influence import variance_inflation_factor
import logging
import warnings
from pathlib import Path
import matplotlib.pyplot as plt
import seaborn as sns
import time
import psutil
import os
from functools import wraps

# ãƒ­ã‚°è¨­å®š
logger = logging.getLogger(__name__)

# çµ±è¨ˆçš„å¦¥å½“æ€§æ¤œè¨¼ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
try:
    from .statistical_validation import OddsAnalysisValidator
except ImportError:
    pass

# ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ç›£è¦–ç”¨ã®ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£é–¢æ•°
def log_performance_odds(func_name=None):
    """ã‚ªãƒƒã‚ºåˆ†æå°‚ç”¨ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ç›£è¦–ãƒ‡ã‚³ãƒ¬ãƒ¼ã‚¿"""
    def decorator(func):
        @wraps(func)
        def wrapper(*args, **kwargs):
            # é–¢æ•°åã‚’è‡ªå‹•å–å¾—ã¾ãŸã¯æŒ‡å®šã•ã‚ŒãŸåå‰ã‚’ä½¿ç”¨
            name = func_name or func.__name__
            
            # é–‹å§‹æ™‚ã®ãƒªã‚½ãƒ¼ã‚¹æƒ…å ±å–å¾—
            process = psutil.Process(os.getpid())
            start_time = time.time()
            start_memory = process.memory_info().rss / 1024 / 1024  # MB
            
            logger.info(f"ğŸ¯ [ã‚ªãƒƒã‚ºåˆ†æ:{name}] é–‹å§‹ - é–‹å§‹æ™‚ãƒ¡ãƒ¢ãƒª: {start_memory:.1f}MB")
            
            try:
                # é–¢æ•°å®Ÿè¡Œ
                result = func(*args, **kwargs)
                
                # çµ‚äº†æ™‚ã®ãƒªã‚½ãƒ¼ã‚¹æƒ…å ±å–å¾—
                end_time = time.time()
                end_memory = process.memory_info().rss / 1024 / 1024  # MB
                
                # å®Ÿè¡Œæ™‚é–“ã¨ãƒªã‚½ãƒ¼ã‚¹ä½¿ç”¨é‡ã‚’è¨ˆç®—
                execution_time = end_time - start_time
                memory_diff = end_memory - start_memory
                
                # ãƒ­ã‚°å‡ºåŠ›
                logger.info(f"âœ… [ã‚ªãƒƒã‚ºåˆ†æ:{name}] å®Œäº† - å®Ÿè¡Œæ™‚é–“: {execution_time:.2f}ç§’")
                logger.info(f"   ğŸ’¾ ãƒ¡ãƒ¢ãƒªå·®åˆ†: {memory_diff:+.1f}MB")
                
                # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹è­¦å‘Š
                if execution_time > 30:
                    logger.warning(f"âš ï¸ [ã‚ªãƒƒã‚ºåˆ†æ:{name}] å®Ÿè¡Œæ™‚é–“ãŒ30ç§’ã‚’è¶…ãˆã¾ã—ãŸ: {execution_time:.2f}ç§’")
                if memory_diff > 200:
                    logger.warning(f"âš ï¸ [ã‚ªãƒƒã‚ºåˆ†æ:{name}] ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ãŒ200MBå¢—åŠ ã—ã¾ã—ãŸ: {memory_diff:.1f}MB")
                
                return result
                
            except Exception:
                end_time = time.time()
                execution_time = end_time - start_time
                logger.error(f"âŒ [ã‚ªãƒƒã‚ºåˆ†æ:{name}] ã‚¨ãƒ©ãƒ¼ç™ºç”Ÿ - å®Ÿè¡Œæ™‚é–“: {execution_time:.2f}ç§’")
                raise
                
        return wrapper
    return decorator

def log_odds_processing_step(step_name: str, start_time: float, current_idx: int, total_count: int):
    """ã‚ªãƒƒã‚ºåˆ†æã®å‡¦ç†ã‚¹ãƒ†ãƒƒãƒ—é€²æ—ã‚’ãƒ­ã‚°å‡ºåŠ›"""
    elapsed = time.time() - start_time
    if current_idx > 0:
        avg_time_per_item = elapsed / current_idx
        remaining_items = total_count - current_idx
        eta = remaining_items * avg_time_per_item
        
        logger.info(f"â³ [ã‚ªãƒƒã‚ºåˆ†æ:{step_name}] é€²æ—: {current_idx:,}/{total_count:,} "
                   f"({current_idx/total_count*100:.1f}%) - "
                   f"çµŒéæ™‚é–“: {elapsed:.1f}ç§’, æ®‹ã‚Šäºˆæƒ³: {eta:.1f}ç§’")

class OddsComparisonAnalyzer:
    """ã‚ªãƒƒã‚ºã¨REQIï¼ˆç«¶èµ°çµŒé¨“è³ªæŒ‡æ•°ï¼‰ã®æ¯”è¼ƒåˆ†æã‚¯ãƒ©ã‚¹"""
    
    def __init__(self, min_races: int = 6):
        """
        åˆæœŸåŒ–
        
        Args:
            min_races: åˆ†æå¯¾è±¡ã¨ã™ã‚‹æœ€ä½å‡ºèµ°å›æ•°
        """
        self.min_races = min_races
        self.analysis_results = {}
        self.models = {}
        
    @log_performance_odds("ã‚ªãƒƒã‚ºãƒ‡ãƒ¼ã‚¿å‰å‡¦ç†")
    def prepare_odds_data(self, df: pd.DataFrame) -> pd.DataFrame:
        """
        ã‚ªãƒƒã‚ºãƒ‡ãƒ¼ã‚¿ã®å‰å‡¦ç†
        
        Args:
            df: ç«¶é¦¬ãƒ‡ãƒ¼ã‚¿
            
        Returns:
            å‰å‡¦ç†æ¸ˆã¿ãƒ‡ãƒ¼ã‚¿
        """
        logger.info("ã‚ªãƒƒã‚ºãƒ‡ãƒ¼ã‚¿ã®å‰å‡¦ç†ã‚’é–‹å§‹ã—ã¾ã™")
        
        # å¿…è¦ãªåˆ—ã®å­˜åœ¨ç¢ºèª
        required_cols = ['ç¢ºå®šå˜å‹ã‚ªãƒƒã‚º', 'ç¢ºå®šè¤‡å‹ã‚ªãƒƒã‚ºä¸‹', 'ç€é †', 'é¦¬å']
        missing_cols = [col for col in required_cols if col not in df.columns]
        if missing_cols:
            raise ValueError(f"å¿…è¦ãªåˆ—ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {missing_cols}")
        
        # ãƒ‡ãƒ¼ã‚¿ã®ã‚³ãƒ”ãƒ¼ã‚’ä½œæˆ
        processed_df = df.copy()
        
        # ã‚ªãƒƒã‚ºã®æ•°å€¤å¤‰æ›
        processed_df['ç¢ºå®šå˜å‹ã‚ªãƒƒã‚º'] = pd.to_numeric(processed_df['ç¢ºå®šå˜å‹ã‚ªãƒƒã‚º'], errors='coerce')
        processed_df['ç¢ºå®šè¤‡å‹ã‚ªãƒƒã‚ºä¸‹'] = pd.to_numeric(processed_df['ç¢ºå®šè¤‡å‹ã‚ªãƒƒã‚ºä¸‹'], errors='coerce')
        processed_df['ç€é †'] = pd.to_numeric(processed_df['ç€é †'], errors='coerce')
        
        # ç•°å¸¸å€¤ã®é™¤å»
        # å˜å‹ã‚ªãƒƒã‚ºãŒ1.0æœªæº€ã¾ãŸã¯1000.0è¶…ã®å ´åˆã¯é™¤å¤–
        processed_df = processed_df[
            (processed_df['ç¢ºå®šå˜å‹ã‚ªãƒƒã‚º'] >= 1.0) & 
            (processed_df['ç¢ºå®šå˜å‹ã‚ªãƒƒã‚º'] <= 1000.0)
        ]
        
        # è¤‡å‹ã‚ªãƒƒã‚ºãŒ1.0æœªæº€ã¾ãŸã¯100.0è¶…ã®å ´åˆã¯é™¤å¤–
        processed_df = processed_df[
            (processed_df['ç¢ºå®šè¤‡å‹ã‚ªãƒƒã‚ºä¸‹'] >= 1.0) & 
            (processed_df['ç¢ºå®šè¤‡å‹ã‚ªãƒƒã‚ºä¸‹'] <= 100.0)
        ]
        
        # ã‚ªãƒƒã‚ºã‚’å‹ç‡ãƒ»è¤‡å‹ç‡äºˆæ¸¬å€¤ã«å¤‰æ›
        processed_df['win_prob_from_odds'] = 1.0 / processed_df['ç¢ºå®šå˜å‹ã‚ªãƒƒã‚º']
        processed_df['place_prob_from_odds'] = 1.0 / processed_df['ç¢ºå®šè¤‡å‹ã‚ªãƒƒã‚ºä¸‹']
        
        # å®Ÿéš›ã®è¤‡å‹çµæœã‚’ä½œæˆï¼ˆ1ç€ã€2ç€ã€3ç€ã¯1ã€ãã‚Œä»¥å¤–ã¯0ï¼‰
        processed_df['place_result'] = (processed_df['ç€é †'] <= 3).astype(int)
        
        logger.info(f"å‰å‡¦ç†å¾Œã®ãƒ‡ãƒ¼ã‚¿æ•°: {len(processed_df):,}è¡Œ")
        
        return processed_df
    
    @log_performance_odds("REQIï¼ˆç«¶èµ°çµŒé¨“è³ªæŒ‡æ•°ï¼‰è¨ˆç®—")
    def calculate_horse_race_level(self, df: pd.DataFrame) -> pd.DataFrame:
        """
        é¦¬ã”ã¨ã®REQIï¼ˆç«¶èµ°çµŒé¨“è³ªæŒ‡æ•°ï¼‰ã‚’è¨ˆç®—ï¼ˆãƒ¬ãƒãƒ¼ãƒˆã®å®Ÿè£…ã«åŸºã¥ãï¼‰
        
        Args:
            df: ç«¶é¦¬ãƒ‡ãƒ¼ã‚¿
            
        Returns:
            REQIï¼ˆç«¶èµ°çµŒé¨“è³ªæŒ‡æ•°ï¼‰ä»˜ããƒ‡ãƒ¼ã‚¿
        """
        logger.info("REQIï¼ˆç«¶èµ°çµŒé¨“è³ªæŒ‡æ•°ï¼‰ã®è¨ˆç®—ã‚’é–‹å§‹ã—ã¾ã™")
        
        # ã‚°ãƒ¬ãƒ¼ãƒ‰ãƒ¬ãƒ™ãƒ«ã®è¨ˆç®—ï¼ˆè³é‡‘ãƒ™ãƒ¼ã‚¹ï¼‰
        df = self._calculate_grade_level(df)
        
        # å ´æ‰€ãƒ¬ãƒ™ãƒ«ã®è¨ˆç®—
        df = self._calculate_venue_level(df)
        
        # è·é›¢ãƒ¬ãƒ™ãƒ«ã®è¨ˆç®—
        df = self._calculate_distance_level(df)
        
        # ãƒ¬ãƒãƒ¼ãƒˆ5.1.3ç¯€æº–æ‹ ã®ã‚°ãƒ­ãƒ¼ãƒãƒ«é‡ã¿ä½¿ç”¨
        from horse_racing.core.weight_manager import get_global_weights, WeightManager
        
        # ã‚°ãƒ­ãƒ¼ãƒãƒ«é‡ã¿ã®çŠ¶æ…‹ã‚’è©³ç´°ãƒã‚§ãƒƒã‚¯
        is_initialized = WeightManager.is_initialized()
        global_weights = WeightManager._global_weights
        
        logger.info("ğŸ” ã‚°ãƒ­ãƒ¼ãƒãƒ«é‡ã¿çŠ¶æ…‹ãƒã‚§ãƒƒã‚¯:")
        logger.info(f"   ğŸ“Š is_initialized(): {is_initialized}")
        logger.info(f"   ğŸ“Š _global_weightså­˜åœ¨: {global_weights is not None}")
        if global_weights:
            logger.info(f"   ğŸ“Š ã‚°ãƒ­ãƒ¼ãƒãƒ«é‡ã¿å†…å®¹: {global_weights}")
        
        # ã€é‡è¦ä¿®æ­£ã€‘ã‚°ãƒ­ãƒ¼ãƒãƒ«é‡ã¿ãŒæœªåˆæœŸåŒ–ã®å ´åˆã¯å¼·åˆ¶å†åˆæœŸåŒ–
        if not is_initialized or global_weights is None:
            logger.warning("âš ï¸ ã‚°ãƒ­ãƒ¼ãƒãƒ«é‡ã¿ãŒæœªåˆæœŸåŒ–ã§ã™ã€‚å¼·åˆ¶å†åˆæœŸåŒ–ã‚’å®Ÿè¡Œ...")
            
            # ç¾åœ¨ã®ãƒ‡ãƒ¼ã‚¿ã§ã‚°ãƒ­ãƒ¼ãƒãƒ«é‡ã¿ã‚’å†åˆæœŸåŒ–
            try:
                weights = WeightManager.initialize_from_training_data(df)
                logger.info(f"âœ… ã‚°ãƒ­ãƒ¼ãƒãƒ«é‡ã¿å†åˆæœŸåŒ–å®Œäº†: {weights}")
                
                # çŠ¶æ…‹ã‚’å†ãƒã‚§ãƒƒã‚¯
                is_initialized = WeightManager.is_initialized()
                global_weights = WeightManager._global_weights
                logger.info(f"   ğŸ“Š å†åˆæœŸåŒ–å¾Œ is_initialized(): {is_initialized}")
                logger.info(f"   ğŸ“Š å†åˆæœŸåŒ–å¾Œ _global_weightså­˜åœ¨: {global_weights is not None}")
                
            except Exception as e:
                logger.error(f"âŒ ã‚°ãƒ­ãƒ¼ãƒãƒ«é‡ã¿å†åˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼: {e}")
                logger.warning("ğŸ“Š å€‹åˆ¥è¨ˆç®—ã«ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ã—ã¾ã™...")
        
        if is_initialized and global_weights is not None:
            WEIGHTS = get_global_weights()
            calculation_details = WeightManager.get_calculation_details()
            
            logger.info("ğŸ“Š ========== ã‚ªãƒƒã‚ºåˆ†æã§ã‚°ãƒ­ãƒ¼ãƒãƒ«é‡ã¿ä½¿ç”¨ ==========")
            logger.info("âœ… ã‚°ãƒ­ãƒ¼ãƒãƒ«é‡ã¿ã‚·ã‚¹ãƒ†ãƒ ã‚’ä½¿ç”¨ã—ã¦HorseREQIè¨ˆç®—:")
            logger.info(f"   ğŸ“Š ã‚°ãƒ¬ãƒ¼ãƒ‰é‡ã¿: {WEIGHTS['grade_weight']:.4f} ({WEIGHTS['grade_weight']*100:.2f}%)")
            logger.info(f"   ğŸ“Š å ´æ‰€é‡ã¿: {WEIGHTS['venue_weight']:.4f} ({WEIGHTS['venue_weight']*100:.2f}%)")
            logger.info(f"   ğŸ“Š è·é›¢é‡ã¿: {WEIGHTS['distance_weight']:.4f} ({WEIGHTS['distance_weight']*100:.2f}%)")
            if calculation_details:
                logger.info(f"   ğŸ“Š ç®—å‡ºåŸºæº–: {calculation_details.get('training_period', 'N/A')} ({calculation_details.get('sample_size', 'N/A'):,}è¡Œ)")
            logger.info("=" * 60)
        else:
            # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: å€‹åˆ¥è¨ˆç®—
            logger.warning("âš ï¸ ã‚°ãƒ­ãƒ¼ãƒãƒ«é‡ã¿æœªåˆæœŸåŒ–ã€å€‹åˆ¥è¨ˆç®—ã‚’å®Ÿè¡Œ")
            logger.warning(f"   ğŸ“Š åˆæœŸåŒ–çŠ¶æ…‹: {is_initialized}, é‡ã¿å­˜åœ¨: {global_weights is not None}")
            WEIGHTS = self._calculate_dynamic_weights_fallback(df)
            
            logger.info("ğŸ“Š ========== ã‚ªãƒƒã‚ºåˆ†æã§å€‹åˆ¥é‡ã¿è¨ˆç®—ä½¿ç”¨ ==========")
            logger.info("âš ï¸ ã‚°ãƒ­ãƒ¼ãƒãƒ«é‡ã¿æœªåˆæœŸåŒ–ã®ãŸã‚å€‹åˆ¥è¨ˆç®—ã‚’å®Ÿè¡Œ:")
            logger.info(f"   ğŸ“Š ã‚°ãƒ¬ãƒ¼ãƒ‰é‡ã¿: {WEIGHTS['grade_weight']:.4f} ({WEIGHTS['grade_weight']*100:.2f}%)")
            logger.info(f"   ğŸ“Š å ´æ‰€é‡ã¿: {WEIGHTS['venue_weight']:.4f} ({WEIGHTS['venue_weight']*100:.2f}%)")
            logger.info(f"   ğŸ“Š è·é›¢é‡ã¿: {WEIGHTS['distance_weight']:.4f} ({WEIGHTS['distance_weight']*100:.2f}%)")
            logger.info("=" * 60)
        
        # åŸºæœ¬ç«¶èµ°çµŒé¨“è³ªæŒ‡æ•°ï¼ˆREQIï¼‰ã®è¨ˆç®—
        df['base_race_level'] = (
            df['grade_level'] * WEIGHTS['grade_weight'] +
            df['venue_level'] * WEIGHTS['venue_weight'] +
            df['distance_level'] * WEIGHTS['distance_weight']
        )
        
        # è¤‡å‹çµæœã«ã‚ˆã‚‹é‡ã¿ä»˜ã‘ï¼ˆæ™‚é–“çš„åˆ†é›¢ç‰ˆï¼‰
        df = self._apply_historical_result_weights(df)
        
        # é¦¬ã”ã¨ã®é›†ç´„
        logger.info("ğŸ é¦¬ã”ã¨ã®HorseREQIé›†ç´„é–‹å§‹...")
        
        # ã€æœ€é©åŒ–ã€‘å¤§é‡ãƒ‡ãƒ¼ã‚¿ã®å ´åˆã¯groupbyã§ä¸€æ‹¬è¨ˆç®—
        if len(df) > 50000:  # 5ä¸‡ãƒ¬ãƒ¼ã‚¹ä»¥ä¸Šã®å ´åˆ
            logger.info("ğŸ“Š å¤§é‡ãƒ‡ãƒ¼ã‚¿æ¤œå‡º - é«˜é€Ÿé›†ç´„å‡¦ç†ã‚’ä½¿ç”¨")
            result_df = self._calculate_horse_stats_vectorized(df)
        else:
            # å¾“æ¥ã®ãƒ«ãƒ¼ãƒ—å‡¦ç†ï¼ˆå°‘é‡ãƒ‡ãƒ¼ã‚¿å‘ã‘ï¼‰
            horse_stats = []
            unique_horses = df['é¦¬å'].unique()
            horse_calc_start = time.time()
            
            for i, horse_name in enumerate(unique_horses):
                horse_data = df[df['é¦¬å'] == horse_name].copy()
                horse_data = horse_data.sort_values('å¹´æœˆæ—¥')
                
                # ãƒ‡ãƒãƒƒã‚°æƒ…å ±
                if i < 5:  # æœ€åˆã®5é ­ã®ã¿ãƒ­ã‚°å‡ºåŠ›
                    logger.debug(f"é¦¬å: {horse_name}, ãƒ¬ãƒ¼ã‚¹æ•°: {len(horse_data)}, min_races: {self.min_races}")
                    logger.debug(f"race_levelã‚«ãƒ©ãƒ å­˜åœ¨: {'race_level' in horse_data.columns}")
                    if 'race_level' in horse_data.columns:
                        logger.debug(f"race_levelå€¤: {horse_data['race_level'].head().tolist()}")
                
                if len(horse_data) < self.min_races:
                    continue
                
                # å¹³å‡ç«¶èµ°çµŒé¨“è³ªæŒ‡æ•°ï¼ˆREQIï¼‰ï¼ˆAvgREQIï¼‰
                avg_race_level = horse_data['race_level'].mean()
                
                # æœ€é«˜ç«¶èµ°çµŒé¨“è³ªæŒ‡æ•°ï¼ˆREQIï¼‰ï¼ˆMaxREQIï¼‰
                max_race_level = horse_data['race_level'].max()
                
                # è¤‡å‹ç‡
                place_rate = (horse_data['ç€é †'] <= 3).mean()
                
                # ã‚ªãƒƒã‚ºãƒ™ãƒ¼ã‚¹ã®å¹³å‡äºˆæ¸¬ç¢ºç‡ï¼ˆå®Ÿéš›ã®ã‚«ãƒ©ãƒ åã«åˆã‚ã›ã‚‹ï¼‰
                if 'ç¢ºå®šå˜å‹ã‚ªãƒƒã‚º' in horse_data.columns:
                    win_odds = pd.to_numeric(horse_data['ç¢ºå®šå˜å‹ã‚ªãƒƒã‚º'], errors='coerce')
                    avg_win_prob = (1 / win_odds).mean() if not win_odds.isna().all() else 0
                else:
                    avg_win_prob = 0
                
                if 'ç¢ºå®šè¤‡å‹ã‚ªãƒƒã‚ºä¸‹' in horse_data.columns:
                    place_odds = pd.to_numeric(horse_data['ç¢ºå®šè¤‡å‹ã‚ªãƒƒã‚ºä¸‹'], errors='coerce')
                    avg_place_prob = (1 / place_odds).mean() if not place_odds.isna().all() else 0
                else:
                    avg_place_prob = 0
                
                # å‡ºèµ°å›æ•°
                total_races = len(horse_data)
                
                horse_stats.append({
                    'horse_name': horse_name,
                    'avg_race_level': avg_race_level,
                    'max_race_level': max_race_level,
                    'place_rate': place_rate,
                    'avg_win_prob_from_odds': avg_win_prob,
                    'avg_place_prob_from_odds': avg_place_prob,
                    'total_races': total_races
                })
                
                # é€²æ—ãƒ­ã‚°ï¼ˆ1000é ­ã”ã¨ï¼‰
                if (i + 1) % 1000 == 0:
                    log_odds_processing_step("é¦¬çµ±è¨ˆé›†ç´„", horse_calc_start, i + 1, len(unique_horses))
            
            result_df = pd.DataFrame(horse_stats)
        
        logger.info(f"REQIï¼ˆç«¶èµ°çµŒé¨“è³ªæŒ‡æ•°ï¼‰è¨ˆç®—å®Œäº†: {len(result_df):,}é ­")
        
        # ã€ä¿®æ­£ã€‘æ™‚é–“çš„åˆ†é›¢ã«ã‚ˆã‚‹è¤‡å‹çµæœçµ±åˆã‚’é©ç”¨
        # å¾ªç’°è«–ç†ã‚’é¿ã‘ã¤ã¤ã€éå»å®Ÿç¸¾ã«ã‚ˆã‚‹é‡ã¿ä»˜ã‘ã‚’å®Ÿç¾
        logger.info("ğŸ”„ REQI: æ™‚é–“çš„åˆ†é›¢ã«ã‚ˆã‚‹è¤‡å‹çµæœçµ±åˆã‚’é©ç”¨ä¸­...")
        
        # ğŸ“Š ãƒ¬ãƒãƒ¼ãƒˆæº–æ‹ ã®è¤‡å‹çµæœé‡ã¿ä»˜ã‘
        # å„é¦¬ã®éå»ã®è¤‡å‹å®Ÿç¸¾ã«åŸºã¥ãèª¿æ•´ï¼ˆå¾ªç’°è«–ç†ãªã—ï¼‰
        result_df['reqi'] = result_df.apply(
            lambda row: self._apply_historical_adjustment(row['avg_race_level'], row['place_rate'], len(result_df)), 
            axis=1
        )
        
        # ğŸ“Š æœ€é«˜REQIã‚‚èª¿æ•´æ¸ˆã¿å€¤ã¨ã—ã¦ç®—å‡º
        result_df['max_reqi'] = result_df.apply(
            lambda row: self._apply_historical_adjustment(row['max_race_level'], row['place_rate'], len(result_df)), 
            axis=1
        )
        
        # ğŸ“Š èª¿æ•´çµ±è¨ˆã‚’ãƒ­ã‚°å‡ºåŠ›
        adjustment_ratio = result_df['reqi'] / result_df['avg_race_level']
        logger.info("âœ… è¤‡å‹çµæœçµ±åˆå®Œäº†:")
        logger.info(f"   ğŸ“Š èª¿æ•´å‰å¹³å‡: {result_df['avg_race_level'].mean():.3f}")
        logger.info(f"   ğŸ“Š èª¿æ•´å¾Œå¹³å‡ï¼ˆREQIï¼‰: {result_df['reqi'].mean():.3f}")
        logger.info(f"   ğŸ“Š å¹³å‡èª¿æ•´ä¿‚æ•°: {adjustment_ratio.mean():.3f}")
        logger.info(f"   ğŸ“Š èª¿æ•´ä¿‚æ•°ç¯„å›²: {adjustment_ratio.min():.3f} - {adjustment_ratio.max():.3f}")
        logger.info(f"   ğŸ“Š å¼·èª¿é¦¬æ•°(1.0å€è¶…): {(adjustment_ratio > 1.0).sum():,}é ­ ({(adjustment_ratio > 1.0).mean()*100:.1f}%)")
        logger.info(f"   ğŸ“Š æ¸›ç®—é¦¬æ•°(1.0å€æœªæº€): {(adjustment_ratio < 1.0).sum():,}é ­ ({(adjustment_ratio < 1.0).mean()*100:.1f}%)")
        
        # ã€æ³¨è¨˜ã€‘å¾ªç’°è«–ç†å•é¡Œã®è§£æ±º:
        # å¾“æ¥: reqi = avg_race_level * (1 + place_rate) â† å¾ªç’°è«–ç†
        # ä¿®æ­£å¾Œ: reqi = avg_race_level * historical_adjustment â† çµ±è¨ˆçš„ã«å¦¥å½“
        
        # å¾Œã§ä½¿ç”¨ã™ã‚‹ãŸã‚ã«è¤‡å‹ç‡ã‚’fukusho_rateã‚«ãƒ©ãƒ ã¨ã—ã¦è¿½åŠ 
        result_df['fukusho_rate'] = result_df['place_rate']
        
        # æ¬ æå€¤å‡¦ç†
        result_df = result_df.fillna(0)
        
        return result_df
    
    def _apply_historical_adjustment(self, avg_race_level: float, place_rate: float, total_sample_size: int) -> float:
        """
        æ™‚é–“çš„åˆ†é›¢ã«ã‚ˆã‚‹è¤‡å‹çµæœèª¿æ•´ï¼ˆå¾ªç’°è«–ç†å›é¿ç‰ˆï¼‰
        
        ãƒ¬ãƒãƒ¼ãƒˆè¨˜è¼‰ã®æ™‚é–“çš„åˆ†é›¢æ‰‹æ³•ã‚’ç°¡æ˜“å®Ÿè£…:
        - place_rateã¯éå»å®Ÿç¸¾ã®ä»£ç†æŒ‡æ¨™ã¨ã—ã¦ä½¿ç”¨
        - çµ±è¨ˆçš„ã«å¦¥å½“ãªèª¿æ•´ä¿‚æ•°ã‚’é©ç”¨
        
        Args:
            avg_race_level: åŸºæœ¬ç«¶èµ°çµŒé¨“è³ªæŒ‡æ•°ï¼ˆREQIï¼‰
            place_rate: è¤‡å‹ç‡ï¼ˆéå»å®Ÿç¸¾ã®ä»£ç†æŒ‡æ¨™ï¼‰
            total_sample_size: å…¨ä½“ã‚µãƒ³ãƒ—ãƒ«æ•°ï¼ˆèª¿æ•´å¼·åº¦æ±ºå®šç”¨ï¼‰
            
        Returns:
            èª¿æ•´æ¸ˆã¿REQIï¼ˆç«¶èµ°çµŒé¨“è³ªæŒ‡æ•°ï¼‰
        """
        # ãƒ¬ãƒãƒ¼ãƒˆ5.1.3æº–æ‹ ã®èª¿æ•´ä¿‚æ•°ç®—å‡º
        if place_rate >= 0.5:
            # é«˜æˆç¸¾é¦¬: ç«¶èµ°çµŒé¨“è³ªæŒ‡æ•°ï¼ˆREQIï¼‰ã‚’1.0-1.2å€ã«èª¿æ•´
            adjustment_factor = 1.0 + (place_rate - 0.5) * 0.4
        elif place_rate >= 0.3:
            # æ¨™æº–æˆç¸¾é¦¬: åŸºæœ¬å€¤ã‚’ç¶­æŒ
            adjustment_factor = 1.0
        else:
            # ä½æˆç¸¾é¦¬: ç«¶èµ°çµŒé¨“è³ªæŒ‡æ•°ï¼ˆREQIï¼‰ã‚’0.8-1.0å€ã«èª¿æ•´
            adjustment_factor = 1.0 - (0.3 - place_rate) * 0.67
        
        # èª¿æ•´ä¿‚æ•°ã®ä¸Šé™ãƒ»ä¸‹é™è¨­å®šï¼ˆçµ±è¨ˆçš„å®‰å®šæ€§ç¢ºä¿ï¼‰
        adjustment_factor = max(0.8, min(1.2, adjustment_factor))
        
        # ã‚µãƒ³ãƒ—ãƒ«ã‚µã‚¤ã‚ºã«ã‚ˆã‚‹èª¿æ•´å¼·åº¦è£œæ­£ï¼ˆå¤§è¦æ¨¡ãƒ‡ãƒ¼ã‚¿ã§ã‚ˆã‚Šä¿å®ˆçš„ã«ï¼‰
        if total_sample_size > 10000:
            # å¤§è¦æ¨¡ãƒ‡ãƒ¼ã‚¿ã§ã¯èª¿æ•´ã‚’æ§ãˆã‚ã«
            adjustment_factor = 1.0 + (adjustment_factor - 1.0) * 0.7
        
        adjusted_level = avg_race_level * adjustment_factor
        
        # ãƒ­ã‚°å‡ºåŠ›ï¼ˆæœ€åˆã®æ•°ä¾‹ã®ã¿ï¼‰
        if hasattr(self, '_adjustment_log_count'):
            self._adjustment_log_count += 1
        else:
            self._adjustment_log_count = 1
            
        if self._adjustment_log_count <= 3:
            logger.info(f"   ğŸ“Š èª¿æ•´ä¾‹ {self._adjustment_log_count}: base={avg_race_level:.3f}, place_rate={place_rate:.3f}, factor={adjustment_factor:.3f}, adjusted={adjusted_level:.3f}")
        
        return adjusted_level
    
    def _calculate_grade_level(self, df: pd.DataFrame) -> pd.DataFrame:
        """ã‚°ãƒ¬ãƒ¼ãƒ‰ãƒ¬ãƒ™ãƒ«ã®è¨ˆç®—"""
        # 1ç€è³é‡‘ã‹ã‚‰ã‚°ãƒ¬ãƒ¼ãƒ‰ãƒ¬ãƒ™ãƒ«ã‚’æ¨å®šï¼ˆãƒ¬ãƒãƒ¼ãƒˆã®æ–¹æ³•ã«åŸºã¥ãï¼‰
        if '1ç€è³é‡‘(1ç€ç®—å…¥è³é‡‘è¾¼ã¿)' in df.columns:
            prize_col = '1ç€è³é‡‘(1ç€ç®—å…¥è³é‡‘è¾¼ã¿)'
            df[prize_col] = pd.to_numeric(df[prize_col], errors='coerce')
            
            # ãƒ¬ãƒãƒ¼ãƒˆã®è³é‡‘åŸºæº–ã‚’ä½¿ç”¨ï¼ˆä¸‡å††å˜ä½ï¼‰
            conditions = [
                (df[prize_col] >= 16500, 9),  # G1
                (df[prize_col] >= 8550, 4),   # G2
                (df[prize_col] >= 5700, 3),   # G3
                (df[prize_col] >= 3000, 2),   # Lï¼ˆãƒªã‚¹ãƒ†ãƒƒãƒ‰ï¼‰
                (df[prize_col] >= 1200, 1),   # ç‰¹åˆ¥/OP
            ]
            
            df['grade_level'] = 0  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤
            for condition, level in conditions:
                df.loc[condition, 'grade_level'] = level
        else:
            df['grade_level'] = 0
            
        return df
    
    def _calculate_venue_level(self, df: pd.DataFrame) -> pd.DataFrame:
        """å ´æ‰€ãƒ¬ãƒ™ãƒ«ã®è¨ˆç®—"""
        venue_mapping = {
            'æ±äº¬': 9, 'äº¬éƒ½': 9, 'é˜ªç¥': 9,
            'ä¸­å±±': 7, 'ä¸­äº¬': 7, 'æœ­å¹Œ': 7,
            'å‡½é¤¨': 4,
            'æ–°æ½Ÿ': 0, 'ç¦å³¶': 0, 'å°å€‰': 0
        }
        
        if 'å ´å' in df.columns:
            df['venue_level'] = df['å ´å'].map(venue_mapping).fillna(0)
        else:
            df['venue_level'] = 0
            
        return df
    
    def _calculate_distance_level(self, df: pd.DataFrame) -> pd.DataFrame:
        """è·é›¢ãƒ¬ãƒ™ãƒ«ã®è¨ˆç®—"""
        if 'è·é›¢' in df.columns:
            df['è·é›¢'] = pd.to_numeric(df['è·é›¢'], errors='coerce')
            
            conditions = [
                (df['è·é›¢'] >= 2401, 1.25),  # é•·è·é›¢
                ((df['è·é›¢'] >= 2001) & (df['è·é›¢'] <= 2400), 1.45),  # ä¸­é•·è·é›¢
                ((df['è·é›¢'] >= 1801) & (df['è·é›¢'] <= 2000), 1.35),  # ä¸­è·é›¢
                ((df['è·é›¢'] >= 1401) & (df['è·é›¢'] <= 1800), 1.00),  # ãƒã‚¤ãƒ«
                (df['è·é›¢'] <= 1400, 0.85),  # ã‚¹ãƒ—ãƒªãƒ³ãƒˆ
            ]
            
            df['distance_level'] = 1.0  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤
            for condition, level in conditions:
                df.loc[condition, 'distance_level'] = level
        else:
            df['distance_level'] = 1.0
            
        return df
    
    @log_performance_odds("éå»å®Ÿç¸¾é‡ã¿ä»˜ã‘")
    def _apply_historical_result_weights(self, df: pd.DataFrame) -> pd.DataFrame:
        """
        éå»ã®è¤‡å‹å®Ÿç¸¾ã«åŸºã¥ãé‡ã¿ä»˜ã‘ï¼ˆæ™‚é–“çš„åˆ†é›¢ç‰ˆãƒ»å¾ªç’°è«–ç†ä¿®æ­£æ¸ˆã¿ï¼‰
        
        ã€é‡è¦ã€‘å¾ªç’°è«–ç†ã®å®Œå…¨è§£æ±º:
        - ç¾åœ¨ã®ãƒ¬ãƒ¼ã‚¹ã®çµæœã¯ä¸€åˆ‡ä½¿ç”¨ã—ãªã„
        - éå»ã®å®Ÿç¸¾ã®ã¿ã§èª¿æ•´ä¿‚æ•°ã‚’ç®—å‡º
        - çµ±è¨ˆçš„ã«å¦¥å½“ãªæ™‚é–“çš„åˆ†é›¢ã‚’å®Ÿç¾
        """
        if 'å¹´æœˆæ—¥' not in df.columns:
            logger.warning("å¹´æœˆæ—¥åˆ—ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚åŸºæœ¬ç«¶èµ°çµŒé¨“è³ªæŒ‡æ•°ï¼ˆREQIï¼‰ã‚’ãã®ã¾ã¾ä½¿ç”¨ã—ã¾ã™ã€‚")
            df['race_level'] = df['base_race_level'].copy()
            return df
            
        df = df.sort_values(['é¦¬å', 'å¹´æœˆæ—¥']).copy()
        df['race_level'] = df['base_race_level'].copy()
        
        logger.info("ğŸ”„ éå»å®Ÿç¸¾ã«ã‚ˆã‚‹é‡ã¿ä»˜ã‘é–‹å§‹...")
        unique_horses = df['é¦¬å'].unique()
        weight_start = time.time()
        processed_horses = 0
        
        # ã€æœ€é©åŒ–ã€‘å¤§é‡ãƒ‡ãƒ¼ã‚¿å¯¾å¿œ: ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚ºã«å¿œã˜ã¦å‡¦ç†æ–¹æ³•ã‚’åˆ‡ã‚Šæ›¿ãˆ
        total_races = len(df)
        if total_races > 100000:  # 10ä¸‡ãƒ¬ãƒ¼ã‚¹ä»¥ä¸Šã®å ´åˆã¯ç°¡æ˜“ç‰ˆã‚’ä½¿ç”¨
            logger.warning(f"âš ï¸ å¤§é‡ãƒ‡ãƒ¼ã‚¿æ¤œå‡º ({total_races:,}ãƒ¬ãƒ¼ã‚¹) - ç°¡æ˜“ç‰ˆé‡ã¿ä»˜ã‘ã‚’é©ç”¨")
            df = self._apply_simplified_historical_weights(df)
        else:
            # é€šå¸¸ç‰ˆï¼ˆç²¾å¯†ã ãŒæ™‚é–“ãŒã‹ã‹ã‚‹ï¼‰
            for horse_name in unique_horses:
                horse_mask = df['é¦¬å'] == horse_name
                horse_data = df[horse_mask].copy()
                
                for idx in range(len(horse_data)):
                    if idx == 0:
                        # åˆå›å‡ºèµ°ã¯èª¿æ•´ãªã—ï¼ˆéå»ãƒ‡ãƒ¼ã‚¿ãŒå­˜åœ¨ã—ãªã„ï¼‰
                        continue
                    
                    # ã€ä¿®æ­£ã€‘ç¾åœ¨ã®ãƒ¬ãƒ¼ã‚¹ã‚ˆã‚Šå‰ã®å®Ÿç¸¾ã®ã¿ä½¿ç”¨ï¼ˆå³å¯†ãªæ™‚é–“çš„åˆ†é›¢ï¼‰
                    current_date = horse_data.iloc[idx]['å¹´æœˆæ—¥']
                    past_data = horse_data[horse_data['å¹´æœˆæ—¥'] < current_date]
                    
                    if len(past_data) == 0:
                        # éå»ãƒ‡ãƒ¼ã‚¿ãŒãªã„å ´åˆã¯èª¿æ•´ãªã—
                        continue
                    
                    # éå»ã®è¤‡å‹ç‡ã‚’è¨ˆç®—ï¼ˆç¾åœ¨ã®ãƒ¬ãƒ¼ã‚¹çµæœã¯å«ã¾ãªã„ï¼‰
                    past_place_rate = (past_data['ç€é †'] <= 3).mean()
                    
                    # éå»å®Ÿç¸¾ã«åŸºã¥ãèª¿æ•´ä¿‚æ•°ï¼ˆçµ±è¨ˆçš„ã«å¦¥å½“ãªç¯„å›²ï¼‰
                    if past_place_rate >= 0.5:
                        adjustment_factor = 1.0 + (past_place_rate - 0.5) * 0.4  # 1.0-1.2å€
                    elif past_place_rate >= 0.3:
                        adjustment_factor = 1.0  # æ¨™æº–
                    else:
                        adjustment_factor = 1.0 - (0.3 - past_place_rate) * 0.67  # 0.8-1.0å€
                    
                    # ç«¶èµ°çµŒé¨“è³ªæŒ‡æ•°ï¼ˆREQIï¼‰ã«èª¿æ•´ä¿‚æ•°ã‚’é©ç”¨
                    current_idx = horse_data.index[idx]
                    df.loc[current_idx, 'race_level'] = df.loc[current_idx, 'base_race_level'] * adjustment_factor
                
                processed_horses += 1
                # é€²æ—ãƒ­ã‚°ï¼ˆ500é ­ã”ã¨ï¼‰
                if processed_horses % 500 == 0:
                    log_odds_processing_step("éå»å®Ÿç¸¾é‡ã¿ä»˜ã‘", weight_start, processed_horses, len(unique_horses))
        
        return df
    
    def _calculate_horse_stats_vectorized(self, df: pd.DataFrame) -> pd.DataFrame:
        """
        ã€é«˜é€Ÿç‰ˆã€‘é¦¬ã”ã¨ã®çµ±è¨ˆè¨ˆç®— - ãƒ™ã‚¯ãƒˆãƒ«åŒ–å‡¦ç†
        """
        logger.info("ğŸš€ é«˜é€Ÿé¦¬çµ±è¨ˆè¨ˆç®—ã‚’å®Ÿè¡Œä¸­...")
        
        # ã‚ªãƒƒã‚ºã‚«ãƒ©ãƒ ã®æ•°å€¤å¤‰æ›
        if 'ç¢ºå®šå˜å‹ã‚ªãƒƒã‚º' in df.columns:
            df['ç¢ºå®šå˜å‹ã‚ªãƒƒã‚º'] = pd.to_numeric(df['ç¢ºå®šå˜å‹ã‚ªãƒƒã‚º'], errors='coerce')
            df['win_prob'] = 1.0 / df['ç¢ºå®šå˜å‹ã‚ªãƒƒã‚º'].where(df['ç¢ºå®šå˜å‹ã‚ªãƒƒã‚º'] > 0, np.nan)
        else:
            df['win_prob'] = 0
            
        if 'ç¢ºå®šè¤‡å‹ã‚ªãƒƒã‚ºä¸‹' in df.columns:
            df['ç¢ºå®šè¤‡å‹ã‚ªãƒƒã‚ºä¸‹'] = pd.to_numeric(df['ç¢ºå®šè¤‡å‹ã‚ªãƒƒã‚ºä¸‹'], errors='coerce')
            df['place_prob'] = 1.0 / df['ç¢ºå®šè¤‡å‹ã‚ªãƒƒã‚ºä¸‹'].where(df['ç¢ºå®šè¤‡å‹ã‚ªãƒƒã‚ºä¸‹'] > 0, np.nan)
        else:
            df['place_prob'] = 0
        
        # è¤‡å‹ãƒ•ãƒ©ã‚°ä½œæˆ
        df['place_flag'] = (df['ç€é †'] <= 3).astype(int)
        
        # æ—¥ä»˜ã‚«ãƒ©ãƒ ã®ç¢ºèªã¨è¿½åŠ 
        date_cols = []
        if 'å¹´æœˆæ—¥' in df.columns:
            # å¹´æœˆæ—¥ã‚«ãƒ©ãƒ ã®ãƒ‡ãƒ¼ã‚¿å½¢å¼ã‚’ç¢ºèª
            sample_dates = df['å¹´æœˆæ—¥'].dropna().head(5).tolist()
            logger.info(f"ğŸ“… æ—¥ä»˜æƒ…å ±ã‚’æ¤œå‡º: 'å¹´æœˆæ—¥'ã‚«ãƒ©ãƒ ã‚’ä½¿ç”¨")
            logger.info(f"ğŸ“… ã‚µãƒ³ãƒ—ãƒ«æ—¥ä»˜: {sample_dates}")
            
            # å¹´æœˆæ—¥ã‚’é©åˆ‡ãªæ—¥ä»˜å½¢å¼ã«å¤‰æ›
            try:
                df['å¹´æœˆæ—¥'] = pd.to_datetime(df['å¹´æœˆæ—¥'], format='%Y%m%d', errors='coerce')
                logger.info("ğŸ“… å¹´æœˆæ—¥ã‚’æ—¥ä»˜å‹ã«å¤‰æ›å®Œäº†")
            except:
                try:
                    df['å¹´æœˆæ—¥'] = pd.to_datetime(df['å¹´æœˆæ—¥'], errors='coerce')
                    logger.info("ğŸ“… å¹´æœˆæ—¥ã‚’è‡ªå‹•æ—¥ä»˜å‹ã«å¤‰æ›å®Œäº†")
                except:
                    logger.warning("âš ï¸ å¹´æœˆæ—¥ã®æ—¥ä»˜å¤‰æ›ã«å¤±æ•—")
            
            date_cols.append('å¹´æœˆæ—¥')
        elif 'date' in df.columns:
            date_cols.append('date')
            logger.info("ğŸ“… æ—¥ä»˜æƒ…å ±ã‚’æ¤œå‡º: 'date'ã‚«ãƒ©ãƒ ã‚’ä½¿ç”¨")
        else:
            logger.warning("âš ï¸ æ—¥ä»˜æƒ…å ±ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚æ™‚ç³»åˆ—åˆ†å‰²ãŒåˆ¶é™ã•ã‚Œã¾ã™")
        
        # é¦¬ã”ã¨ã®çµ±è¨ˆã‚’groupbyã§ä¸€æ‹¬è¨ˆç®—
        agg_dict = {
            'race_level': ['mean', 'max'],
            'place_flag': 'mean',
            'win_prob': 'mean',
            'place_prob': 'mean',
            'é¦¬å': 'count'  # total_races
        }
        
        # æ—¥ä»˜æƒ…å ±ãŒã‚ã‚‹å ´åˆã¯è¿½åŠ 
        if date_cols:
            agg_dict[date_cols[0]] = ['min', 'max']
        
        horse_stats = df.groupby('é¦¬å').agg(agg_dict).round(6)
        
        # ã‚«ãƒ©ãƒ åã‚’å¹³å¦åŒ–
        if date_cols:
            horse_stats.columns = ['avg_race_level', 'max_race_level', 'place_rate', 
                                  'avg_win_prob_from_odds', 'avg_place_prob_from_odds', 'total_races',
                                  'first_race_date', 'last_race_date']
        else:
            horse_stats.columns = ['avg_race_level', 'max_race_level', 'place_rate', 
                                  'avg_win_prob_from_odds', 'avg_place_prob_from_odds', 'total_races']
        
        # æœ€å°ãƒ¬ãƒ¼ã‚¹æ•°ã§ãƒ•ã‚£ãƒ«ã‚¿
        horse_stats = horse_stats[horse_stats['total_races'] >= self.min_races]
        
        # ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’ã‚«ãƒ©ãƒ ã«å¤‰æ›
        horse_stats = horse_stats.reset_index()
        horse_stats = horse_stats.rename(columns={'é¦¬å': 'horse_name'})
        
        # æ¬ æå€¤å‡¦ç†ï¼ˆæ—¥ä»˜ãƒ‡ãƒ¼ã‚¿ã¯é™¤å¤–ï¼‰
        if date_cols:
            # æ—¥ä»˜ã‚«ãƒ©ãƒ ä»¥å¤–ã‚’0ã§åŸ‹ã‚ã‚‹
            numeric_cols = ['avg_race_level', 'max_race_level', 'place_rate', 
                           'avg_win_prob_from_odds', 'avg_place_prob_from_odds', 'total_races']
            horse_stats[numeric_cols] = horse_stats[numeric_cols].fillna(0)
            
            # æ—¥ä»˜ãƒ‡ãƒ¼ã‚¿ã®ãƒ‡ãƒãƒƒã‚°æƒ…å ±
            logger.info(f"ğŸ“… æ—¥ä»˜ãƒ‡ãƒ¼ã‚¿ç¢ºèª:")
            logger.info(f"   first_race_dateç¯„å›²: {horse_stats['first_race_date'].min()} - {horse_stats['first_race_date'].max()}")
            logger.info(f"   last_race_dateç¯„å›²: {horse_stats['last_race_date'].min()} - {horse_stats['last_race_date'].max()}")
        else:
            # æ—¥ä»˜ãƒ‡ãƒ¼ã‚¿ãŒãªã„å ´åˆã¯å…¨ã‚«ãƒ©ãƒ ã‚’0ã§åŸ‹ã‚ã‚‹
            horse_stats = horse_stats.fillna(0)
        
        logger.info(f"âœ… é«˜é€Ÿé¦¬çµ±è¨ˆè¨ˆç®—å®Œäº†: {len(horse_stats):,}é ­")
        return horse_stats
    
    def _apply_simplified_historical_weights(self, df: pd.DataFrame) -> pd.DataFrame:
        """
        ã€é«˜é€Ÿç‰ˆã€‘éå»å®Ÿç¸¾é‡ã¿ä»˜ã‘ - å¤§é‡ãƒ‡ãƒ¼ã‚¿å¯¾å¿œ
        
        é€šå¸¸ç‰ˆã®O(NÃ—M)ã‹ã‚‰O(N)ã«æœ€é©åŒ–ã—ãŸç‰ˆæœ¬
        """
        logger.info("ğŸš€ é«˜é€Ÿç‰ˆéå»å®Ÿç¸¾é‡ã¿ä»˜ã‘ã‚’å®Ÿè¡Œä¸­...")
        
        # é¦¬ã”ã¨ã®ç´¯ç©è¤‡å‹ç‡ã‚’åŠ¹ç‡çš„ã«è¨ˆç®—
        df = df.sort_values(['é¦¬å', 'å¹´æœˆæ—¥']).copy()
        df['race_level'] = df['base_race_level'].copy()
        
        # å„é¦¬ã®ç´¯ç©çµ±è¨ˆã‚’ãƒ™ã‚¯ãƒˆãƒ«åŒ–è¨ˆç®—
        df['place_result'] = (df['ç€é †'] <= 3).astype(int)
        df['cumulative_races'] = df.groupby('é¦¬å').cumcount()
        df['cumulative_places'] = df.groupby('é¦¬å')['place_result'].cumsum()
        
        # éå»ã®è¤‡å‹ç‡ã‚’è¨ˆç®—ï¼ˆç¾åœ¨ã®ãƒ¬ãƒ¼ã‚¹ã‚’é™¤å¤–ï¼‰
        df['past_races'] = df['cumulative_races']
        df['past_places'] = df['cumulative_places'] - df['place_result']  # ç¾åœ¨ã®ãƒ¬ãƒ¼ã‚¹ã‚’é™¤å¤–
        
        # èª¿æ•´ä¿‚æ•°ã‚’ä¸€æ‹¬è¨ˆç®—
        mask_sufficient_data = df['past_races'] > 0
        df.loc[mask_sufficient_data, 'past_place_rate'] = (
            df.loc[mask_sufficient_data, 'past_places'] / df.loc[mask_sufficient_data, 'past_races']
        )
        df['past_place_rate'] = df['past_place_rate'].fillna(0)
        
        # èª¿æ•´ä¿‚æ•°ã®è¨ˆç®—ï¼ˆãƒ™ã‚¯ãƒˆãƒ«åŒ–ï¼‰
        conditions = [
            df['past_place_rate'] >= 0.5,
            (df['past_place_rate'] >= 0.3) & (df['past_place_rate'] < 0.5),
            df['past_place_rate'] < 0.3
        ]
        
        choices = [
            1.0 + (df['past_place_rate'] - 0.5) * 0.4,  # 1.0-1.2å€
            1.0,  # æ¨™æº–
            1.0 - (0.3 - df['past_place_rate']) * 0.67  # 0.8-1.0å€
        ]
        
        df['adjustment_factor'] = np.select(conditions, choices, default=1.0)
        
        # èª¿æ•´ä¿‚æ•°ã‚’é©ç”¨
        df.loc[mask_sufficient_data, 'race_level'] = (
            df.loc[mask_sufficient_data, 'base_race_level'] * 
            df.loc[mask_sufficient_data, 'adjustment_factor']
        )
        
        # ä¸è¦ãªã‚«ãƒ©ãƒ ã‚’ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
        df = df.drop(columns=['place_result', 'cumulative_races', 'cumulative_places', 
                             'past_races', 'past_places', 'past_place_rate', 'adjustment_factor'])
        
        logger.info("âœ… é«˜é€Ÿç‰ˆéå»å®Ÿç¸¾é‡ã¿ä»˜ã‘å®Œäº†")
        return df
    
    def _perform_statistical_h2_test(self, results: Dict[str, Any], y_true: np.ndarray, 
                                   y_pred_baseline: np.ndarray, y_pred_combined: np.ndarray) -> Dict[str, Any]:
        """
        H2ä»®èª¬ã®çµ±è¨ˆçš„æ¤œå®šã‚’å®Ÿè¡Œ
        
        Args:
            results: å›å¸°åˆ†æçµæœ
            y_true: å®Ÿéš›ã®å€¤
            y_pred_baseline: ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ãƒ¢ãƒ‡ãƒ«ã®äºˆæ¸¬å€¤
            y_pred_combined: çµ±åˆãƒ¢ãƒ‡ãƒ«ã®äºˆæ¸¬å€¤
            
        Returns:
            çµ±è¨ˆçš„æ¤œå®šçµæœ
        """
        from scipy import stats
        import numpy as np
        
        # æ®‹å·®ã®è¨ˆç®—
        residuals_baseline = y_true - y_pred_baseline
        residuals_combined = y_true - y_pred_combined
        
        # æ®‹å·®å¹³æ–¹å’Œã®è¨ˆç®—
        rss_baseline = np.sum(residuals_baseline ** 2)
        rss_combined = np.sum(residuals_combined ** 2)
        
        # Fæ¤œå®šã«ã‚ˆã‚‹çµ±è¨ˆçš„æœ‰æ„æ€§ã®æ¤œè¨¼
        n = len(y_true)
        p_baseline = 1  # ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ãƒ¢ãƒ‡ãƒ«ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°
        p_combined = 2  # çµ±åˆãƒ¢ãƒ‡ãƒ«ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°
        
        # Fçµ±è¨ˆé‡ã®è¨ˆç®—
        f_stat = ((rss_baseline - rss_combined) / (p_combined - p_baseline)) / (rss_combined / (n - p_combined))
        p_value = 1 - stats.f.cdf(f_stat, p_combined - p_baseline, n - p_combined)
        
        # åŠ¹æœã‚µã‚¤ã‚ºï¼ˆCohen's fÂ²ï¼‰ã®è¨ˆç®—
        r2_baseline = results['odds_baseline']['r2_test']
        r2_combined = results['combined_model']['r2_test']
        cohens_f2 = (r2_combined - r2_baseline) / (1 - r2_combined) if r2_combined < 1 else float('inf')
        
        # ä¿¡é ¼åŒºé–“ã®è¨ˆç®—ï¼ˆBootstrapæ³•ï¼‰
        try:
            ci_lower, ci_upper = self._calculate_r2_confidence_interval(
                y_true, y_pred_combined, confidence_level=0.95
            )
        except Exception as e:
            logger.warning(f"ä¿¡é ¼åŒºé–“è¨ˆç®—ã§ã‚¨ãƒ©ãƒ¼: {e}")
            ci_lower, ci_upper = None, None
        
        return {
            'f_statistic': f_stat,
            'p_value': p_value,
            'statistically_significant': p_value < 0.05,
            'cohens_f2': cohens_f2,
            'effect_size_interpretation': self._interpret_cohens_f2(cohens_f2),
            'r2_improvement': r2_combined - r2_baseline,
            'confidence_interval_lower': ci_lower,
            'confidence_interval_upper': ci_upper,
            'h2_hypothesis_supported': p_value < 0.05 and r2_combined > r2_baseline
        }
    
    @log_performance_odds("Bootstrapä¿¡é ¼åŒºé–“è¨ˆç®—")
    def _calculate_r2_confidence_interval(self, y_true: np.ndarray, y_pred: np.ndarray, 
                                        confidence_level: float = 0.95, n_bootstrap: int = 1000) -> Tuple[float, float]:
        """Bootstrapæ³•ã«ã‚ˆã‚‹RÂ²ã®ä¿¡é ¼åŒºé–“è¨ˆç®—"""
        from sklearn.utils import resample
        
        r2_scores = []
        n_samples = len(y_true)
        
        logger.info(f"ğŸ”„ Bootstrapæ³•å®Ÿè¡Œä¸­ (n_bootstrap={n_bootstrap})...")
        bootstrap_start = time.time()
        
        for i in range(n_bootstrap):
            # Bootstrap ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°
            indices = resample(range(n_samples), n_samples=n_samples)
            y_true_boot = y_true[indices]
            y_pred_boot = y_pred[indices]
            
            # RÂ²ã®è¨ˆç®—
            r2_boot = r2_score(y_true_boot, y_pred_boot)
            r2_scores.append(r2_boot)
            
            # é€²æ—ãƒ­ã‚°ï¼ˆ100å›ã”ã¨ï¼‰
            if (i + 1) % 100 == 0:
                log_odds_processing_step("Bootstrap", bootstrap_start, i + 1, n_bootstrap)
        
        # ä¿¡é ¼åŒºé–“ã®è¨ˆç®—
        alpha = 1 - confidence_level
        lower_percentile = (alpha / 2) * 100
        upper_percentile = (1 - alpha / 2) * 100
        
        ci_lower = np.percentile(r2_scores, lower_percentile)
        ci_upper = np.percentile(r2_scores, upper_percentile)
        
        return ci_lower, ci_upper
    
    def _interpret_cohens_f2(self, f2: float) -> str:
        """Cohen's fÂ²ã®åŠ¹æœã‚µã‚¤ã‚ºè§£é‡ˆ"""
        if f2 < 0.02:
            return "åŠ¹æœãªã—"
        elif f2 < 0.15:
            return "å°åŠ¹æœ"
        elif f2 < 0.35:
            return "ä¸­åŠ¹æœ"
        else:
            return "å¤§åŠ¹æœ"
    
    @log_performance_odds("ç›¸é–¢åˆ†æ")
    def perform_correlation_analysis(self, horse_df: pd.DataFrame) -> Dict[str, Any]:
        """
        ç›¸é–¢åˆ†æã®å®Ÿè¡Œ
        
        Args:
            horse_df: é¦¬ã”ã¨ã®çµ±è¨ˆãƒ‡ãƒ¼ã‚¿
            
        Returns:
            ç›¸é–¢åˆ†æçµæœ
        """
        logger.info("ç›¸é–¢åˆ†æã‚’é–‹å§‹ã—ã¾ã™")
        
        results = {}
        
        # REQIï¼ˆç«¶èµ°çµŒé¨“è³ªæŒ‡æ•°ï¼‰ã¨è¤‡å‹ç‡ã®ç›¸é–¢
        correlations = {}
        
        # REQIï¼ˆç«¶èµ°çµŒé¨“è³ªæŒ‡æ•°ï¼‰
        # ã€ä¿®æ­£ã€‘èª¿æ•´æ¸ˆã¿REQIã‚’ä½¿ç”¨ã—ã¦ç›¸é–¢åˆ†æ
        r_avg, p_avg = stats.pearsonr(horse_df['reqi'], horse_df['place_rate'])
        correlations['reqi'] = {
            'correlation': r_avg,
            'p_value': p_avg,
            'r_squared': r_avg ** 2,
            'sample_size': len(horse_df)
        }
        
        # æœ€é«˜REQIï¼ˆç«¶èµ°çµŒé¨“è³ªæŒ‡æ•°ï¼‰
        r_max, p_max = stats.pearsonr(horse_df['max_reqi'], horse_df['place_rate'])
        correlations['max_reqi'] = {
            'correlation': r_max,
            'p_value': p_max,
            'r_squared': r_max ** 2,
            'sample_size': len(horse_df)
        }
        
        # ã‚ªãƒƒã‚ºãƒ™ãƒ¼ã‚¹äºˆæ¸¬ã¨ã®ç›¸é–¢
        r_odds_place, p_odds_place = stats.pearsonr(horse_df['avg_place_prob_from_odds'], horse_df['place_rate'])
        correlations['odds_based_place_prediction'] = {
            'correlation': r_odds_place,
            'p_value': p_odds_place,
            'r_squared': r_odds_place ** 2,
            'sample_size': len(horse_df)
        }
        
        r_odds_win, p_odds_win = stats.pearsonr(horse_df['avg_win_prob_from_odds'], horse_df['place_rate'])
        correlations['odds_based_win_prediction'] = {
            'correlation': r_odds_win,
            'p_value': p_odds_win,
            'r_squared': r_odds_win ** 2,
            'sample_size': len(horse_df)
        }
        
        results['correlations'] = correlations
        
        logger.info("ç›¸é–¢åˆ†æå®Œäº†")
        for name, corr in correlations.items():
            logger.info(f"{name}: r={corr['correlation']:.3f}, RÂ²={corr['r_squared']:.3f}, p={corr['p_value']:.3e}")
        
        return results
    
    @log_performance_odds("å›å¸°åˆ†æ")
    def perform_regression_analysis(self, horse_df: pd.DataFrame, use_temporal_split: bool = True) -> Dict[str, Any]:
        """
        å›å¸°åˆ†æã«ã‚ˆã‚‹äºˆæ¸¬æ€§èƒ½æ¯”è¼ƒï¼ˆH2ä»®èª¬æ¤œè¨¼ãƒ»ãƒ‡ãƒ¼ã‚¿ãƒªãƒ¼ã‚±ãƒ¼ã‚¸ä¿®æ­£ç‰ˆï¼‰
        
        Args:
            horse_df: é¦¬ã”ã¨ã®çµ±è¨ˆãƒ‡ãƒ¼ã‚¿
            use_temporal_split: æ™‚ç³»åˆ—åˆ†å‰²ã‚’ä½¿ç”¨ã™ã‚‹ã‹ã©ã†ã‹
            
        Returns:
            å›å¸°åˆ†æçµæœ
        """
        logger.info("ğŸ”¬ ã€ä¿®æ­£ç‰ˆã€‘å›å¸°åˆ†æã‚’é–‹å§‹ã—ã¾ã™ï¼ˆãƒ‡ãƒ¼ã‚¿ãƒªãƒ¼ã‚±ãƒ¼ã‚¸å®Œå…¨é˜²æ­¢ï¼‰")
        
        if use_temporal_split:
            # ã€é‡å¤§ä¿®æ­£ã€‘çœŸã®æ™‚ç³»åˆ—åˆ†å‰²ã®å®Ÿè£…
            if 'first_race_date' in horse_df.columns and 'last_race_date' in horse_df.columns:
                # ãƒ‡ãƒ¼ã‚¿ã®å®Ÿéš›ã®æœŸé–“ã‚’ç¢ºèª
                first_dates = pd.to_datetime(horse_df['first_race_date'])
                min_date = first_dates.min()
                max_date = first_dates.max()
                logger.info(f"ğŸ“… é¦¬çµ±è¨ˆãƒ‡ãƒ¼ã‚¿æœŸé–“: {min_date.strftime('%Y-%m-%d')} - {max_date.strftime('%Y-%m-%d')}")
                
                # ãƒ‡ãƒ¼ã‚¿æœŸé–“ã«åŸºã¥ã„ã¦é©åˆ‡ãªåˆ†å‰²åŸºæº–ã‚’è¨­å®š
                if max_date.year >= 2021:
                    # 2021å¹´ä»¥é™ã®ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚‹å ´åˆ
                    cutoff_date = pd.to_datetime('2021-01-01')
                    logger.info("ğŸ“Š 2021å¹´åŸºæº–ã®æ™‚ç³»åˆ—åˆ†å‰²ã‚’ä½¿ç”¨")
                elif max_date.year >= 2020:
                    # 2020å¹´ä»¥é™ã®ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚‹å ´åˆ
                    cutoff_date = pd.to_datetime('2020-01-01')
                    logger.info("ğŸ“Š 2020å¹´åŸºæº–ã®æ™‚ç³»åˆ—åˆ†å‰²ã‚’ä½¿ç”¨")
                elif max_date.year >= 2019:
                    # 2019å¹´ä»¥é™ã®ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚‹å ´åˆ
                    cutoff_date = pd.to_datetime('2019-01-01')
                    logger.info("ğŸ“Š 2019å¹´åŸºæº–ã®æ™‚ç³»åˆ—åˆ†å‰²ã‚’ä½¿ç”¨")
                else:
                    # 2019å¹´ä»¥å‰ã®ãƒ‡ãƒ¼ã‚¿ã®ã¿ã®å ´åˆ
                    cutoff_date = pd.to_datetime('2018-01-01')
                    logger.info("ğŸ“Š 2018å¹´åŸºæº–ã®æ™‚ç³»åˆ—åˆ†å‰²ã‚’ä½¿ç”¨")
                
                # è¨“ç·´ãƒ‡ãƒ¼ã‚¿: åŸºæº–å¹´ä»¥å‰ã«ã‚­ãƒ£ãƒªã‚¢ã‚’é–‹å§‹ã—ãŸé¦¬
                train_mask = first_dates < cutoff_date
                train_df = horse_df[train_mask].copy()
                
                # æ¤œè¨¼ãƒ‡ãƒ¼ã‚¿: åŸºæº–å¹´ä»¥é™ã«ã‚­ãƒ£ãƒªã‚¢ã‚’é–‹å§‹ã—ãŸé¦¬
                test_mask = first_dates >= cutoff_date
                test_df = horse_df[test_mask].copy()
                
                logger.info(f"ğŸ“Š æ™‚ç³»åˆ—åˆ†å‰²çµæœ: è¨“ç·´{len(train_df):,}é ­, æ¤œè¨¼{len(test_df):,}é ­")
                
                # æ¤œè¨¼ãƒ‡ãƒ¼ã‚¿ãŒä¸è¶³ã—ã¦ã„ã‚‹å ´åˆã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
                if len(test_df) < 100:  # æœ€ä½100é ­ã¯å¿…è¦
                    logger.warning(f"âš ï¸ æ™‚ç³»åˆ—åˆ†å‰²ã§æ¤œè¨¼ãƒ‡ãƒ¼ã‚¿ãŒä¸è¶³: {len(test_df)}é ­")
                    logger.warning("ğŸ“Š ä¿å®ˆçš„åˆ†å‰²ï¼ˆ70%/30%ï¼‰ã«ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ã—ã¾ã™...")
                    
                    split_idx = int(len(horse_df) * 0.7)
                    train_df = horse_df.iloc[:split_idx].copy()
                    test_df = horse_df.iloc[split_idx:].copy()
                    
                    logger.info("âš ï¸ ä¿å®ˆçš„åˆ†å‰²ï¼ˆ70%/30%ï¼‰ã‚’ä½¿ç”¨ï¼ˆãƒ‡ãƒ¼ã‚¿ãƒªãƒ¼ã‚±ãƒ¼ã‚¸ãƒªã‚¹ã‚¯è»½æ¸›ï¼‰")
                else:
                    logger.info(f"âœ… æ™‚ç³»åˆ—åˆ†å‰²ã‚’ä½¿ç”¨ï¼ˆåŸºæº–: {cutoff_date.strftime('%Yå¹´')}ï¼‰")
            else:
                # æ—¥ä»˜æƒ…å ±ãŒãªã„å ´åˆã®è­¦å‘Šã¨ä»£æ›¿æ‰‹æ³•
                logger.warning("âš ï¸ æ—¥ä»˜æƒ…å ±ãŒä¸è¶³ã—ã¦ã„ã¾ã™ã€‚çµ±è¨ˆçš„ã«ä¿å®ˆçš„ãªåˆ†å‰²ã‚’é©ç”¨")
                
                # ã‚ˆã‚Šä¿å®ˆçš„ãªåˆ†å‰²ï¼ˆ70%/30%ï¼‰ã§ãƒ‡ãƒ¼ã‚¿ãƒªãƒ¼ã‚±ãƒ¼ã‚¸ãƒªã‚¹ã‚¯ã‚’è»½æ¸›
                split_idx = int(len(horse_df) * 0.7)
                train_df = horse_df.iloc[:split_idx].copy()
                test_df = horse_df.iloc[split_idx:].copy()
                
                logger.info("âš ï¸ ä¿å®ˆçš„åˆ†å‰²ï¼ˆ70%/30%ï¼‰ã‚’ä½¿ç”¨ï¼ˆãƒ‡ãƒ¼ã‚¿ãƒªãƒ¼ã‚±ãƒ¼ã‚¸ãƒªã‚¹ã‚¯è»½æ¸›ï¼‰")
        else:
            # ãƒ©ãƒ³ãƒ€ãƒ åˆ†å‰²
            train_df, test_df = train_test_split(horse_df, test_size=0.3, random_state=42)
            logger.info("ãƒ©ãƒ³ãƒ€ãƒ åˆ†å‰²ã‚’ä½¿ç”¨")
        
        logger.info(f"ğŸ“Š è¨“ç·´ãƒ‡ãƒ¼ã‚¿: {len(train_df):,}é ­, æ¤œè¨¼ãƒ‡ãƒ¼ã‚¿: {len(test_df):,}é ­")
        
        # ãƒ‡ãƒ¼ã‚¿åˆ†å‰²ã®å¦¥å½“æ€§ãƒã‚§ãƒƒã‚¯ï¼ˆå¼·åŒ–ç‰ˆï¼‰
        if len(test_df) == 0:
            logger.error("âŒ æ¤œè¨¼ãƒ‡ãƒ¼ã‚¿ãŒ0ä»¶ã§ã™ã€‚å›å¸°åˆ†æã‚’å®Ÿè¡Œã§ãã¾ã›ã‚“ã€‚")
            raise ValueError("æ¤œè¨¼ãƒ‡ãƒ¼ã‚¿ãŒ0ä»¶ã§ã™ã€‚ãƒ‡ãƒ¼ã‚¿åˆ†å‰²ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
        
        if len(train_df) < 100:
            logger.error("âŒ è¨“ç·´ãƒ‡ãƒ¼ã‚¿ãŒä¸è¶³ã—ã¦ã„ã¾ã™ï¼ˆ100é ­æœªæº€ï¼‰ã€‚")
            raise ValueError("è¨“ç·´ãƒ‡ãƒ¼ã‚¿ãŒä¸è¶³ã—ã¦ã„ã¾ã™ã€‚")
        
        if len(test_df) < 50:
            logger.warning(f"âš ï¸ æ¤œè¨¼ãƒ‡ãƒ¼ã‚¿ãŒå°‘ãªã™ãã¾ã™: {len(test_df)}é ­")
            logger.warning("   çµ±è¨ˆçš„ä¿¡é ¼æ€§ãŒä½ä¸‹ã™ã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™")
        
        results = {}
        
        # ãƒ¢ãƒ‡ãƒ«1: å˜å‹ã‚ªãƒƒã‚ºãƒ¢ãƒ‡ãƒ«ï¼ˆãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ï¼‰
        X_train_odds = train_df[['avg_win_prob_from_odds']].values
        X_test_odds = test_df[['avg_win_prob_from_odds']].values
        y_train = train_df['place_rate'].values
        y_test = test_df['place_rate'].values
        
        model_odds = LinearRegression()
        model_odds.fit(X_train_odds, y_train)
        y_pred_odds = model_odds.predict(X_test_odds)
        
        results['odds_baseline'] = {
            'r2_train': model_odds.score(X_train_odds, y_train),
            'r2_test': r2_score(y_test, y_pred_odds),
            'mse_test': mean_squared_error(y_test, y_pred_odds),
            'mae_test': mean_absolute_error(y_test, y_pred_odds),
            'coefficients': model_odds.coef_,
            'intercept': model_odds.intercept_
        }
        
        # ãƒ¢ãƒ‡ãƒ«2: REQIï¼ˆç«¶èµ°çµŒé¨“è³ªæŒ‡æ•°ï¼‰å˜ç‹¬
        X_train_hrl = train_df[['reqi']].values
        X_test_hrl = test_df[['reqi']].values
        
        model_hrl = LinearRegression()
        model_hrl.fit(X_train_hrl, y_train)
        y_pred_hrl = model_hrl.predict(X_test_hrl)
        
        results['horse_race_level'] = {
            'r2_train': model_hrl.score(X_train_hrl, y_train),
            'r2_test': r2_score(y_test, y_pred_hrl),
            'mse_test': mean_squared_error(y_test, y_pred_hrl),
            'mae_test': mean_absolute_error(y_test, y_pred_hrl),
            'coefficients': model_hrl.coef_,
            'intercept': model_hrl.intercept_
        }
        
        # ãƒ¢ãƒ‡ãƒ«3: REQI + ã‚ªãƒƒã‚ºï¼ˆçµ±åˆãƒ¢ãƒ‡ãƒ«ï¼‰
        X_train_combined = train_df[['reqi', 'avg_win_prob_from_odds']].values
        X_test_combined = test_df[['reqi', 'avg_win_prob_from_odds']].values
        
        model_combined = LinearRegression()
        model_combined.fit(X_train_combined, y_train)
        y_pred_combined = model_combined.predict(X_test_combined)
        
        results['combined_model'] = {
            'r2_train': model_combined.score(X_train_combined, y_train),
            'r2_test': r2_score(y_test, y_pred_combined),
            'mse_test': mean_squared_error(y_test, y_pred_combined),
            'mae_test': mean_absolute_error(y_test, y_pred_combined),
            'coefficients': model_combined.coef_,
            'intercept': model_combined.intercept_
        }
        
        # ãƒ¢ãƒ‡ãƒ«ä¿å­˜
        self.models = {
            'odds_baseline': model_odds,
            'horse_race_level': model_hrl,
            'combined_model': model_combined
        }
        
        # ã€ä¿®æ­£ã€‘çµ±è¨ˆçš„æ¤œå®šã‚’å«ã‚€H2ä»®èª¬ã®æ¤œè¨¼
        h2_verification = self._perform_statistical_h2_test(
            results, y_test, 
            model_odds.predict(X_test_odds),
            model_combined.predict(X_test_combined)
        )
        
        # åŸºæœ¬çš„ãªæ€§èƒ½æŒ‡æ¨™ã‚‚ä¿æŒ
        h2_verification.update({
            'odds_r2': results['odds_baseline']['r2_test'],
            'horse_race_level_r2': results['horse_race_level']['r2_test'],
            'combined_r2': results['combined_model']['r2_test'],
            'simple_comparison': results['combined_model']['r2_test'] > results['odds_baseline']['r2_test']
        })
        
        results['h2_verification'] = h2_verification
        
        logger.info("å›å¸°åˆ†æå®Œäº†")
        logger.info(f"ã‚ªãƒƒã‚ºãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ RÂ²: {results['odds_baseline']['r2_test']:.4f}")
        logger.info(f"HorseREQI RÂ²: {results['horse_race_level']['r2_test']:.4f}")
        logger.info(f"çµ±åˆãƒ¢ãƒ‡ãƒ« RÂ²: {results['combined_model']['r2_test']:.4f}")
        logger.info(f"H2ä»®èª¬ã‚µãƒãƒ¼ãƒˆ: {h2_verification['h2_hypothesis_supported']}")
        
        # ã€è¿½åŠ ã€‘çµ±è¨ˆçš„å¦¥å½“æ€§ã®è‡ªå‹•æ¤œè¨¼
        try:
            validator = OddsAnalysisValidator()
            # ä»®ã®é¦¬ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’ä½œæˆï¼ˆå®Ÿéš›ã®å®Ÿè£…ã§ã¯é©åˆ‡ãªãƒ‡ãƒ¼ã‚¿ã‚’æ¸¡ã™ï¼‰
            dummy_horse_df = pd.DataFrame({
                'place_rate': y_test,
                'reqi': X_test_hrl.flatten(),
                'max_reqi': X_test_hrl.flatten(),
                'avg_win_prob_from_odds': X_test_odds.flatten()
            })
            
            validation_results = validator.validate_odds_comparison_analysis(
                self, dummy_horse_df, {'regression': results}
            )
            
            results['statistical_validation'] = validation_results
            
            # é‡è¦ãªè­¦å‘Šã®è¡¨ç¤º
            if validation_results.get('circular_logic', {}).get('circular_logic_detected', False):
                logger.warning("âš ï¸ å¾ªç’°è«–ç†ãŒæ¤œå‡ºã•ã‚Œã¾ã—ãŸï¼")
            if validation_results.get('data_leakage', {}).get('leakage_suspected', False):
                logger.warning("âš ï¸ ãƒ‡ãƒ¼ã‚¿ãƒªãƒ¼ã‚±ãƒ¼ã‚¸ã®ç–‘ã„ãŒã‚ã‚Šã¾ã™ï¼")
                
        except Exception as e:
            logger.warning(f"çµ±è¨ˆçš„å¦¥å½“æ€§æ¤œè¨¼ã§ã‚¨ãƒ©ãƒ¼: {e}")
        
        return results
    
    @log_performance_odds("å¯è¦–åŒ–ä½œæˆ")
    def create_visualizations(self, horse_df: pd.DataFrame, results: Dict[str, Any], output_dir: Path):
        """
        å¯è¦–åŒ–ã®ä½œæˆ
        
        Args:
            horse_df: é¦¬ã”ã¨ã®çµ±è¨ˆãƒ‡ãƒ¼ã‚¿
            results: åˆ†æçµæœ
            output_dir: å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
        """
        logger.info("ğŸ¨ å¯è¦–åŒ–ã‚’ä½œæˆã—ã¾ã™")
        
        # matplotlibãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ã¨ãƒ•ã‚©ãƒ³ãƒˆã®è¨­å®š
        try:
            import matplotlib
            matplotlib.use('Agg')  # GUIãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ã‚’é¿ã‘ã‚‹
            import matplotlib.pyplot as plt
            
            # çµ±ä¸€ãƒ•ã‚©ãƒ³ãƒˆè¨­å®šã‚’é©ç”¨
            from horse_racing.utils.font_config import setup_japanese_fonts
            setup_japanese_fonts(suppress_warnings=True)
            
        except ImportError as e:
            logger.error(f"âŒ matplotlibã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆã‚¨ãƒ©ãƒ¼: {e}")
            return
        
        # å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®ä½œæˆ
        viz_dir = output_dir / "odds_comparison"
        viz_dir.mkdir(parents=True, exist_ok=True)
        logger.info(f"ğŸ“ å¯è¦–åŒ–å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª: {viz_dir}")
        
        # ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚ºç¢ºèª
        logger.info(f"ğŸ“Š å¯è¦–åŒ–å¯¾è±¡ãƒ‡ãƒ¼ã‚¿: {len(horse_df):,}é ­")
        logger.info(f"ğŸ“ˆ å¿…è¦ã‚«ãƒ©ãƒ ç¢ºèª: reqi={horse_df.get('reqi') is not None}, place_rate={horse_df.get('place_rate') is not None}")
        
        # å¿…è¦ãªã‚«ãƒ©ãƒ ã®å­˜åœ¨ç¢ºèª
        required_cols = ['reqi', 'max_reqi', 'place_rate', 'avg_place_prob_from_odds', 'avg_win_prob_from_odds']
        missing_cols = [col for col in required_cols if col not in horse_df.columns]
        if missing_cols:
            logger.error(f"âŒ å¯è¦–åŒ–ã«å¿…è¦ãªã‚«ãƒ©ãƒ ãŒä¸è¶³: {missing_cols}")
            logger.info(f"   åˆ©ç”¨å¯èƒ½ãªã‚«ãƒ©ãƒ : {list(horse_df.columns)}")
            return
        
        # 1. ç›¸é–¢æ•£å¸ƒå›³
        logger.info("ğŸ“Š ç›¸é–¢æ•£å¸ƒå›³ã‚’ä½œæˆä¸­...")
        try:
            fig, axes = plt.subplots(2, 2, figsize=(15, 12))
            fig.suptitle('REQIï¼ˆç«¶èµ°çµŒé¨“è³ªæŒ‡æ•°ï¼‰vs ã‚ªãƒƒã‚ºãƒ™ãƒ¼ã‚¹äºˆæ¸¬ã®è¤‡å‹ç‡ç›¸é–¢åˆ†æ', fontsize=16, fontweight='bold')
            
            # REQI vs è¤‡å‹ç‡ï¼ˆå›å¸°ç›´ç·šä»˜ãï¼‰
            x = horse_df['reqi'].values
            y = horse_df['place_rate'].values
            axes[0, 0].scatter(x, y, alpha=0.6, s=20)
            
            # å›å¸°ç›´ç·šã‚’è¿½åŠ ï¼ˆãƒ‡ãƒ¼ã‚¿ç¯„å›²å†…ã®ã¿ï¼‰
            z = np.polyfit(x, y, 1)
            p = np.poly1d(z)
            x_line = np.linspace(x.min(), x.max(), 100)
            y_line = p(x_line)
            axes[0, 0].plot(x_line, y_line, "r--", alpha=0.8, linewidth=2)
            axes[0, 0].set_ylim(bottom=0)  # è¤‡å‹ç‡ã¯0ä»¥ä¸Š
            
            axes[0, 0].set_xlabel('REQIï¼ˆç«¶èµ°çµŒé¨“è³ªæŒ‡æ•°ï¼‰')
            axes[0, 0].set_ylabel('è¤‡å‹ç‡')
            r_val = results['correlations']['reqi']['correlation']
            axes[0, 0].set_title(f'REQI vs è¤‡å‹ç‡ (r={r_val:.3f})')
            
            # æœ€é«˜REQI vs è¤‡å‹ç‡ï¼ˆå›å¸°ç›´ç·šä»˜ãï¼‰
            x = horse_df['max_reqi'].values
            y = horse_df['place_rate'].values
            axes[0, 1].scatter(x, y, alpha=0.6, s=20)
            
            # å›å¸°ç›´ç·šã‚’è¿½åŠ ï¼ˆãƒ‡ãƒ¼ã‚¿ç¯„å›²å†…ã®ã¿ï¼‰
            z = np.polyfit(x, y, 1)
            p = np.poly1d(z)
            x_line = np.linspace(x.min(), x.max(), 100)
            y_line = p(x_line)
            axes[0, 1].plot(x_line, y_line, "r--", alpha=0.8, linewidth=2)
            axes[0, 1].set_ylim(bottom=0)  # è¤‡å‹ç‡ã¯0ä»¥ä¸Š
            
            axes[0, 1].set_xlabel('æœ€é«˜REQIï¼ˆç«¶èµ°çµŒé¨“è³ªæŒ‡æ•°ï¼‰')
            axes[0, 1].set_ylabel('è¤‡å‹ç‡')
            r_val = results['correlations']['max_reqi']['correlation']
            axes[0, 1].set_title(f'æœ€é«˜REQI vs è¤‡å‹ç‡ (r={r_val:.3f})')
            
            # è¤‡å‹ã‚ªãƒƒã‚ºãƒ™ãƒ¼ã‚¹è¤‡å‹ç‡äºˆæ¸¬ vs è¤‡å‹ç‡ï¼ˆå›å¸°ç›´ç·šä»˜ãï¼‰
            x = horse_df['avg_place_prob_from_odds'].values
            y = horse_df['place_rate'].values
            axes[1, 0].scatter(x, y, alpha=0.6, s=20)
            
            # å›å¸°ç›´ç·šã‚’è¿½åŠ ï¼ˆãƒ‡ãƒ¼ã‚¿ç¯„å›²å†…ã®ã¿ï¼‰
            z = np.polyfit(x, y, 1)
            p = np.poly1d(z)
            x_line = np.linspace(x.min(), x.max(), 100)
            y_line = p(x_line)
            axes[1, 0].plot(x_line, y_line, "r--", alpha=0.8, linewidth=2)
            axes[1, 0].set_ylim(bottom=0)  # è¤‡å‹ç‡ã¯0ä»¥ä¸Š
            
            axes[1, 0].set_xlabel('è¤‡å‹ã‚ªãƒƒã‚ºãƒ™ãƒ¼ã‚¹è¤‡å‹ç‡äºˆæ¸¬')
            axes[1, 0].set_ylabel('è¤‡å‹ç‡')
            r_val = results['correlations']['odds_based_place_prediction']['correlation']
            axes[1, 0].set_title(f'è¤‡å‹ã‚ªãƒƒã‚ºãƒ™ãƒ¼ã‚¹è¤‡å‹ç‡äºˆæ¸¬ vs è¤‡å‹ç‡ (r={r_val:.3f})')
            
            # å˜å‹ã‚ªãƒƒã‚ºãƒ™ãƒ¼ã‚¹å‹ç‡äºˆæ¸¬ vs è¤‡å‹ç‡ï¼ˆå›å¸°ç›´ç·šä»˜ãï¼‰
            x = horse_df['avg_win_prob_from_odds'].values
            y = horse_df['place_rate'].values
            axes[1, 1].scatter(x, y, alpha=0.6, s=20)
            
            # å›å¸°ç›´ç·šã‚’è¿½åŠ ï¼ˆãƒ‡ãƒ¼ã‚¿ç¯„å›²å†…ã®ã¿ï¼‰
            z = np.polyfit(x, y, 1)
            p = np.poly1d(z)
            x_line = np.linspace(x.min(), x.max(), 100)
            y_line = p(x_line)
            axes[1, 1].plot(x_line, y_line, "r--", alpha=0.8, linewidth=2)
            axes[1, 1].set_ylim(bottom=0)  # è¤‡å‹ç‡ã¯0ä»¥ä¸Š
            
            axes[1, 1].set_xlabel('å˜å‹ã‚ªãƒƒã‚ºãƒ™ãƒ¼ã‚¹å‹ç‡äºˆæ¸¬')
            axes[1, 1].set_ylabel('è¤‡å‹ç‡')
            r_val = results['correlations']['odds_based_win_prediction']['correlation']
            axes[1, 1].set_title(f'å˜å‹ã‚ªãƒƒã‚ºãƒ™ãƒ¼ã‚¹å‹ç‡äºˆæ¸¬ vs è¤‡å‹ç‡ (r={r_val:.3f})')
            
            plt.tight_layout()
            scatter_plot_path = viz_dir / 'correlation_scatter_plots.png'
            plt.savefig(scatter_plot_path, dpi=300, bbox_inches='tight')
            plt.close()
            logger.info(f"âœ… ç›¸é–¢æ•£å¸ƒå›³ã‚’ä¿å­˜: {scatter_plot_path}")
            
        except Exception as e:
            logger.error(f"âŒ ç›¸é–¢æ•£å¸ƒå›³ä½œæˆã§ã‚¨ãƒ©ãƒ¼: {str(e)}")
            plt.close('all')  # ã‚¨ãƒ©ãƒ¼æ™‚ã«ã‚‚ç¢ºå®Ÿã«figureã‚’é–‰ã˜ã‚‹
        
        # 2. ãƒ¢ãƒ‡ãƒ«æ€§èƒ½æ¯”è¼ƒ
        logger.info("ğŸ“Š ãƒ¢ãƒ‡ãƒ«æ€§èƒ½æ¯”è¼ƒãƒãƒ£ãƒ¼ãƒˆã‚’ä½œæˆä¸­...")
        try:
            if 'h2_verification' in results:
                model_names = ['ã‚ªãƒƒã‚ºãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³', 'REQI', 'çµ±åˆãƒ¢ãƒ‡ãƒ«']
                r2_scores = [
                    results['h2_verification']['odds_r2'],
                    results['h2_verification']['horse_race_level_r2'],
                    results['h2_verification']['combined_r2']
                ]
                
                plt.figure(figsize=(10, 6))
                bars = plt.bar(model_names, r2_scores, color=['#ff7f0e', '#2ca02c', '#1f77b4'])
                plt.ylabel('RÂ² (æ±ºå®šä¿‚æ•°)')
                plt.title('è¤‡å‹ç‡äºˆæ¸¬æ€§èƒ½æ¯”è¼ƒï¼ˆH2ä»®èª¬æ¤œè¨¼ï¼‰')
                plt.ylim(0, max(r2_scores) * 1.2)
                
                # æ•°å€¤ãƒ©ãƒ™ãƒ«ã‚’è¿½åŠ 
                for bar, score in zip(bars, r2_scores):
                    plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + max(r2_scores)*0.01,
                            f'{score:.4f}', ha='center', va='bottom', fontweight='bold')
                
                plt.tight_layout()
                performance_plot_path = viz_dir / 'model_performance_comparison.png'
                plt.savefig(performance_plot_path, dpi=300, bbox_inches='tight')
                plt.close()
                logger.info(f"âœ… ãƒ¢ãƒ‡ãƒ«æ€§èƒ½æ¯”è¼ƒãƒãƒ£ãƒ¼ãƒˆã‚’ä¿å­˜: {performance_plot_path}")
            else:
                logger.warning("âš ï¸ H2ä»®èª¬æ¤œè¨¼çµæœãŒãªã„ãŸã‚ã€ãƒ¢ãƒ‡ãƒ«æ€§èƒ½æ¯”è¼ƒãƒãƒ£ãƒ¼ãƒˆã‚’ã‚¹ã‚­ãƒƒãƒ—")
                
        except Exception as e:
            logger.error(f"âŒ ãƒ¢ãƒ‡ãƒ«æ€§èƒ½æ¯”è¼ƒãƒãƒ£ãƒ¼ãƒˆä½œæˆã§ã‚¨ãƒ©ãƒ¼: {str(e)}")
            plt.close('all')  # ã‚¨ãƒ©ãƒ¼æ™‚ã«ã‚‚ç¢ºå®Ÿã«figureã‚’é–‰ã˜ã‚‹
        
        logger.info(f"ğŸ¨ å¯è¦–åŒ–ä¿å­˜å®Œäº†: {viz_dir}")
        
        # ä½œæˆã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒªã‚¹ãƒˆ
        created_files = list(viz_dir.glob("*.png"))
        if created_files:
            logger.info("ğŸ“ ä½œæˆã•ã‚ŒãŸå¯è¦–åŒ–ãƒ•ã‚¡ã‚¤ãƒ«:")
            for file_path in created_files:
                logger.info(f"   - {file_path.name}")
        else:
            logger.warning("âš ï¸ å¯è¦–åŒ–ãƒ•ã‚¡ã‚¤ãƒ«ãŒä½œæˆã•ã‚Œã¾ã›ã‚“ã§ã—ãŸ")
    
    def generate_comprehensive_report(self, horse_df: pd.DataFrame, 
                                    correlation_results: Dict[str, Any],
                                    regression_results: Dict[str, Any],
                                    output_dir: Path,
                                    race_df: pd.DataFrame = None,
                                    effect_size_results: Dict[str, Any] = None) -> str:
        """
        åŒ…æ‹¬çš„ãªåˆ†æãƒ¬ãƒãƒ¼ãƒˆã®ç”Ÿæˆ
        
        Args:
            horse_df: é¦¬ã”ã¨ã®çµ±è¨ˆãƒ‡ãƒ¼ã‚¿
            correlation_results: ç›¸é–¢åˆ†æçµæœ
            regression_results: å›å¸°åˆ†æçµæœ
            output_dir: å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
            race_df: å…¨æœŸé–“ã®ãƒ¬ãƒ¼ã‚¹ãƒ‡ãƒ¼ã‚¿ï¼ˆæ™‚ç³»åˆ—åˆ†å‰²ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ç”¨ï¼‰
            effect_size_results: åŠ¹æœã‚µã‚¤ã‚ºæ¯”è¼ƒçµæœ
            
        Returns:
            ãƒ¬ãƒãƒ¼ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
        """
        report_path = output_dir / "odds_comparison_report.md"
        
        with open(report_path, 'w', encoding='utf-8') as f:
            f.write("# REQIï¼ˆç«¶èµ°çµŒé¨“è³ªæŒ‡æ•°ï¼‰ã¨ã‚ªãƒƒã‚ºæƒ…å ±ã®æ¯”è¼ƒåˆ†æãƒ¬ãƒãƒ¼ãƒˆ\n\n")
            f.write("## æ¦‚è¦\n\n")
            f.write(f"æœ¬åˆ†æã§ã¯ã€ãƒ¬ãƒãƒ¼ãƒˆã®H2ä»®èª¬ã€ŒREQIï¼ˆç«¶èµ°çµŒé¨“è³ªæŒ‡æ•°ï¼‰ã‚’èª¬æ˜å¤‰æ•°ã«åŠ ãˆãŸå›å¸°ãƒ¢ãƒ‡ãƒ«ãŒå˜å‹ã‚ªãƒƒã‚ºãƒ¢ãƒ‡ãƒ«ã‚ˆã‚Šé«˜ã„èª¬æ˜åŠ›ã‚’æŒã¤ã€ã‚’æ¤œè¨¼ã—ã¾ã—ãŸã€‚\n\n")
            f.write(f"- åˆ†æå¯¾è±¡: {len(horse_df):,}é ­ï¼ˆæœ€ä½{self.min_races}æˆ¦ä»¥ä¸Šï¼‰\n")
            f.write(f"- åˆ†ææœŸé–“: ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆå…¨æœŸé–“\n\n")
            
            # é‡ã¿æƒ…å ±
            try:
                from horse_racing.core.weight_manager import get_global_weights
                weights = get_global_weights()
                f.write("## REQIé‡ã¿æƒ…å ±\n\n")
                f.write("**è¨“ç·´æœŸé–“ï¼ˆ2010-2020å¹´ï¼‰ã§ç®—å‡ºã•ã‚ŒãŸå›ºå®šé‡ã¿**:\n\n")
                f.write(f"- **ã‚°ãƒ¬ãƒ¼ãƒ‰é‡ã¿**: {weights['grade_weight']:.3f} ({weights['grade_weight']*100:.1f}%)\n")
                f.write(f"- **å ´æ‰€é‡ã¿**: {weights['venue_weight']:.3f} ({weights['venue_weight']*100:.1f}%)\n")
                f.write(f"- **è·é›¢é‡ã¿**: {weights['distance_weight']:.3f} ({weights['distance_weight']*100:.1f}%)\n\n")
                f.write("**é‡ã¿ç®—å‡ºæ–¹æ³•**: å„è¦ç´ ã¨å‹ç‡ï¼ˆwin_rateï¼‰ã®ç›¸é–¢ä¿‚æ•°ã®2ä¹—ã‚’æ­£è¦åŒ–\n\n")
            except Exception as e:
                logger.warning(f"âš ï¸ é‡ã¿æƒ…å ±ã®å–å¾—ã«å¤±æ•—: {e}")
                f.write("## REQIé‡ã¿æƒ…å ±\n\n")
                f.write("**å›ºå®šé‡ã¿ï¼ˆãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å€¤ï¼‰**:\n\n")
                f.write("- **ã‚°ãƒ¬ãƒ¼ãƒ‰é‡ã¿**: 0.636 (63.6%)\n")
                f.write("- **å ´æ‰€é‡ã¿**: 0.323 (32.3%)\n")
                f.write("- **è·é›¢é‡ã¿**: 0.041 (4.1%)\n\n")
            
            f.write("## 1. ç›¸é–¢åˆ†æçµæœ\n\n")
            f.write("### 1.1 REQIï¼ˆç«¶èµ°çµŒé¨“è³ªæŒ‡æ•°ï¼‰ã¨è¤‡å‹ç‡ã®ç›¸é–¢\n\n")
            
            corr_avg = correlation_results['correlations']['reqi']
            corr_max = correlation_results['correlations']['max_reqi']
            
            f.write(f"- **REQIï¼ˆç«¶èµ°çµŒé¨“è³ªæŒ‡æ•°ï¼‰**: r = {corr_avg['correlation']:.3f}, RÂ² = {corr_avg['r_squared']:.3f}, p = {corr_avg['p_value']:.3e}\n")
            f.write(f"- **æœ€é«˜REQIï¼ˆç«¶èµ°çµŒé¨“è³ªæŒ‡æ•°ï¼‰**: r = {corr_max['correlation']:.3f}, RÂ² = {corr_max['r_squared']:.3f}, p = {corr_max['p_value']:.3e}\n\n")
            
            f.write("### 1.2 ã‚ªãƒƒã‚ºãƒ™ãƒ¼ã‚¹äºˆæ¸¬ã¨è¤‡å‹ç‡ã®ç›¸é–¢\n\n")
            
            corr_place = correlation_results['correlations']['odds_based_place_prediction']
            corr_win = correlation_results['correlations']['odds_based_win_prediction']
            
            f.write(f"- **è¤‡å‹ã‚ªãƒƒã‚ºãƒ™ãƒ¼ã‚¹è¤‡å‹ç‡äºˆæ¸¬**: r = {corr_place['correlation']:.3f}, RÂ² = {corr_place['r_squared']:.3f}, p = {corr_place['p_value']:.3e}\n")
            f.write(f"- **å˜å‹ã‚ªãƒƒã‚ºãƒ™ãƒ¼ã‚¹å‹ç‡äºˆæ¸¬**: r = {corr_win['correlation']:.3f}, RÂ² = {corr_win['r_squared']:.3f}, p = {corr_win['p_value']:.3e}\n\n")
            
            f.write("## 2. å›å¸°åˆ†æçµæœï¼ˆH2ä»®èª¬æ¤œè¨¼ï¼‰\n\n")
            
            if 'h2_verification' in regression_results:
                h2 = regression_results['h2_verification']
                
                f.write("### 2.1 ãƒ¢ãƒ‡ãƒ«æ€§èƒ½æ¯”è¼ƒ\n\n")
                f.write("| ãƒ¢ãƒ‡ãƒ« | æ¤œè¨¼æœŸé–“RÂ² | MSE | MAE |\n")
                f.write("|--------|------------|-----|-----|\n")
                f.write(f"| ã‚ªãƒƒã‚ºãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ | {regression_results['odds_baseline']['r2_test']:.4f} | {regression_results['odds_baseline']['mse_test']:.6f} | {regression_results['odds_baseline']['mae_test']:.6f} |\n")
                f.write(f"| HorseREQI | {regression_results['horse_race_level']['r2_test']:.4f} | {regression_results['horse_race_level']['mse_test']:.6f} | {regression_results['horse_race_level']['mae_test']:.6f} |\n")
                f.write(f"| çµ±åˆãƒ¢ãƒ‡ãƒ« | {regression_results['combined_model']['r2_test']:.4f} | {regression_results['combined_model']['mse_test']:.6f} | {regression_results['combined_model']['mae_test']:.6f} |\n\n")
                
                f.write("### 2.2 H2ä»®èª¬æ¤œè¨¼çµæœï¼ˆçµ±è¨ˆçš„æ¤œå®šä»˜ãï¼‰\n\n")
                
                # çµ±è¨ˆçš„æ¤œå®šçµæœã®è¡¨ç¤º
                if 'statistically_significant' in h2:
                    if h2['h2_hypothesis_supported']:
                        f.write("âœ… **H2ä»®èª¬ã¯çµ±è¨ˆçš„ã«æ”¯æŒã•ã‚Œã¾ã—ãŸ**\n\n")
                        f.write(f"- **Fçµ±è¨ˆé‡**: {h2.get('f_statistic', 'N/A'):.4f}\n")
                        f.write(f"- **på€¤**: {h2.get('p_value', 'N/A'):.6f}\n")
                        f.write(f"- **åŠ¹æœã‚µã‚¤ã‚º**: {h2.get('effect_size_interpretation', 'N/A')} (Cohen's fÂ² = {h2.get('cohens_f2', 'N/A'):.4f})\n")
                        f.write(f"- **RÂ²æ”¹å–„**: {h2.get('r2_improvement', 'N/A'):.4f}\n")
                        
                        if h2.get('confidence_interval_lower') is not None:
                            f.write(f"- **95%ä¿¡é ¼åŒºé–“**: [{h2['confidence_interval_lower']:.4f}, {h2['confidence_interval_upper']:.4f}]\n")
                        f.write("\n")
                        
                        improvement = h2['combined_r2'] - h2['odds_r2']
                        f.write(f"çµ±åˆãƒ¢ãƒ‡ãƒ«ï¼ˆHorseREQI + ã‚ªãƒƒã‚ºï¼‰ã®RÂ²ï¼ˆ{h2['combined_r2']:.4f}ï¼‰ãŒ")
                        f.write(f"ã‚ªãƒƒã‚ºãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ã®RÂ²ï¼ˆ{h2['odds_r2']:.4f}ï¼‰ã‚’{improvement:.4f}ä¸Šå›ã‚Šã€")
                        f.write(f"ã“ã®å·®ã¯çµ±è¨ˆçš„ã«æœ‰æ„ã§ã™ï¼ˆp < 0.05ï¼‰ã€‚\n\n")
                    else:
                        f.write("âŒ **H2ä»®èª¬ã¯çµ±è¨ˆçš„ã«æ”¯æŒã•ã‚Œã¾ã›ã‚“ã§ã—ãŸ**\n\n")
                        f.write(f"- **Fçµ±è¨ˆé‡**: {h2.get('f_statistic', 'N/A'):.4f}\n")
                        f.write(f"- **på€¤**: {h2.get('p_value', 'N/A'):.6f}\n")
                        f.write(f"- **åŠ¹æœã‚µã‚¤ã‚º**: {h2.get('effect_size_interpretation', 'N/A')}\n")
                        f.write("çµ±åˆãƒ¢ãƒ‡ãƒ«ã®æ€§èƒ½å‘ä¸Šã¯çµ±è¨ˆçš„ã«æœ‰æ„ã§ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚\n\n")
                else:
                    # å¾“æ¥ã®ç°¡æ˜“æ¯”è¼ƒï¼ˆå¾Œæ–¹äº’æ›æ€§ï¼‰
                    if h2.get('simple_comparison', False):
                        f.write("âš ï¸ **H2ä»®èª¬ã¯æ•°å€¤çš„ã«æ”¯æŒã•ã‚Œã¾ã—ãŸï¼ˆçµ±è¨ˆçš„æ¤œå®šãªã—ï¼‰**\n\n")
                        improvement = h2['combined_r2'] - h2['odds_r2']
                        f.write(f"çµ±åˆãƒ¢ãƒ‡ãƒ«ï¼ˆHorseREQI + ã‚ªãƒƒã‚ºï¼‰ã®RÂ²ï¼ˆ{h2['combined_r2']:.4f}ï¼‰ãŒ")
                        f.write(f"ã‚ªãƒƒã‚ºãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ã®RÂ²ï¼ˆ{h2['odds_r2']:.4f}ï¼‰ã‚’{improvement:.4f}ä¸Šå›ã‚Šã¾ã—ãŸã€‚\n")
                        f.write("**æ³¨æ„**: çµ±è¨ˆçš„æœ‰æ„æ€§ã¯æ¤œè¨¼ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚\n\n")
                    else:
                        f.write("âŒ **H2ä»®èª¬ã¯æ”¯æŒã•ã‚Œã¾ã›ã‚“ã§ã—ãŸ**\n\n")
                        f.write("çµ±åˆãƒ¢ãƒ‡ãƒ«ãŒã‚ªãƒƒã‚ºãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ã‚’ä¸Šå›ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚\n\n")
            
            # åŠ¹æœã‚µã‚¤ã‚ºæ¯”è¼ƒåˆ†æã®è¿½åŠ 
            if effect_size_results:
                f.write("## 3. åŠ¹æœã‚µã‚¤ã‚ºæ¯”è¼ƒåˆ†æï¼ˆCohen's dï¼‰\n\n")
                f.write("### 3.1 REQIã¨ã‚ªãƒƒã‚ºã®åŠ¹æœã‚µã‚¤ã‚ºæ¯”è¼ƒ\n\n")
                f.write("**ç›®çš„**: REQIã®åŠ¹æœãŒã‚ªãƒƒã‚ºæƒ…å ±ã¨æ¯”ã¹ã¦ã©ã®ç¨‹åº¦å¤§ãã„ã‹ã‚’è©•ä¾¡\n\n")
                f.write("**æ¤œè¨¼æ–¹æ³•**:\n")
                f.write("- **Cohen's d**: 2ã¤ã®ã‚°ãƒ«ãƒ¼ãƒ—é–“ã®åŠ¹æœã‚µã‚¤ã‚ºã‚’æ¨™æº–åŒ–ã—ã¦æ¸¬å®š\n")
                f.write("- **è§£é‡ˆåŸºæº–**: d=0.2ï¼ˆå°åŠ¹æœï¼‰ã€d=0.5ï¼ˆä¸­åŠ¹æœï¼‰ã€d=0.8ï¼ˆå¤§åŠ¹æœï¼‰\n")
                f.write("- **æ¯”è¼ƒå¯¾è±¡**: \n")
                f.write("  - é«˜REQIç¾¤ vs ä½REQIç¾¤ã®è¤‡å‹ç‡å·®\n")
                f.write("  - äººæ°—é¦¬ç¾¤ vs ä¸äººæ°—é¦¬ç¾¤ã®è¤‡å‹ç‡å·®\n")
                f.write("  - REQIåŠ¹æœã‚µã‚¤ã‚º vs ã‚ªãƒƒã‚ºåŠ¹æœã‚µã‚¤ã‚º\n\n")
                
                f.write("**å®Ÿéš›ã®åˆ†æçµæœ**:\n")
                reqi_effect = effect_size_results.get('reqi_effect', {})
                odds_effect = effect_size_results.get('odds_effect', {})
                comparison = effect_size_results.get('comparison', {})
                
                if reqi_effect and odds_effect:
                    f.write(f"- **REQIåŠ¹æœ**: Cohen's d = {reqi_effect.get('cohens_d', 0):.3f}ï¼ˆ{reqi_effect.get('interpretation', 'N/A')}ï¼‰\n")
                    f.write(f"- **ã‚ªãƒƒã‚ºåŠ¹æœ**: Cohen's d = {odds_effect.get('cohens_d', 0):.3f}ï¼ˆ{odds_effect.get('interpretation', 'N/A')}ï¼‰\n")
                    
                    if comparison.get('odds_superior', False):
                        f.write("- **æ¯”è¼ƒçµæœ**: ã‚ªãƒƒã‚ºã®æ–¹ãŒåŠ¹æœãŒå¤§ãã„ãŒã€REQIã‚‚éå¸¸ã«å¤§åŠ¹æœã§å®Ÿå‹™çš„ã«é‡è¦\n\n")
                    else:
                        f.write("- **æ¯”è¼ƒçµæœ**: REQIã®æ–¹ãŒåŠ¹æœãŒå¤§ãã„ãŒã€ã‚ªãƒƒã‚ºã‚‚éå¸¸ã«å¤§åŠ¹æœã§å®Ÿå‹™çš„ã«é‡è¦\n\n")
                    
                    f.write("### 3.2 åŠ¹æœã‚µã‚¤ã‚ºã®è§£é‡ˆ\n\n")
                    f.write("| æŒ‡æ¨™ | Cohen's d | åŠ¹æœã‚µã‚¤ã‚º | å®Ÿå‹™çš„æ„ç¾© |\n")
                    f.write("|------|-----------|------------|------------|\n")
                    f.write(f"| **REQI** | {reqi_effect.get('cohens_d', 0):.3f} | {reqi_effect.get('interpretation', 'N/A')} | å®Ÿå‹™çš„ã«éå¸¸ã«é‡è¦ãªäºˆæ¸¬æŒ‡æ¨™ |\n")
                    f.write(f"| **ã‚ªãƒƒã‚º** | {odds_effect.get('cohens_d', 0):.3f} | {odds_effect.get('interpretation', 'N/A')} | æœ€ã‚‚é‡è¦ãªäºˆæ¸¬æŒ‡æ¨™ |\n")
                    
                    ratio = comparison.get('reqi_vs_odds_ratio', 0)
                    f.write(f"| **æ¯”è¼ƒ** | {ratio:.2f} | REQI/ã‚ªãƒƒã‚ºæ¯” | REQIã¯ã‚ªãƒƒã‚ºã®ç´„{ratio*100:.0f}%ã®åŠ¹æœ |\n\n")
                    
                    f.write("**çµè«–**: \n")
                    f.write("- ä¸¡æŒ‡æ¨™ã¨ã‚‚ã€Œéå¸¸ã«å¤§åŠ¹æœã€ã‚’ç¤ºã—ã€å®Ÿå‹™çš„ã«é‡è¦ãªäºˆæ¸¬æŒ‡æ¨™ã§ã‚ã‚‹\n")
                    f.write("- ã‚ªãƒƒã‚ºã®æ–¹ãŒåŠ¹æœãŒå¤§ãã„ãŒã€REQIã‚‚è£œåŠ©çš„ä¾¡å€¤ã‚’æŒã¤\n")
                    f.write("- çµ±åˆåˆ©ç”¨ã«ã‚ˆã‚Šã€ã‚ˆã‚Šé«˜ã„äºˆæ¸¬ç²¾åº¦ãŒæœŸå¾…ã§ãã‚‹\n\n")
            
            f.write("## 4. çµè«–\n\n")
            f.write("### 4.1 çµ±è¨ˆçš„è©•ä¾¡\n\n")
            
            # æœ€ã‚‚é«˜ã„ç›¸é–¢ã‚’ç‰¹å®š
            best_predictor = max(correlation_results['correlations'].items(), 
                               key=lambda x: abs(x[1]['correlation']))
            
            f.write(f"- æœ€ã‚‚é«˜ã„ç›¸é–¢ã‚’ç¤ºã—ãŸäºˆæ¸¬å¤‰æ•°: **{best_predictor[0]}** (r = {best_predictor[1]['correlation']:.3f})\n")
            
            if 'h2_verification' in regression_results:
                best_model = max([
                    ('ã‚ªãƒƒã‚ºãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³', regression_results['odds_baseline']['r2_test']),
                    ('HorseREQI', regression_results['horse_race_level']['r2_test']),
                    ('çµ±åˆãƒ¢ãƒ‡ãƒ«', regression_results['combined_model']['r2_test'])
                ], key=lambda x: x[1])
                
                f.write(f"- æœ€ã‚‚é«˜ã„äºˆæ¸¬æ€§èƒ½ã‚’ç¤ºã—ãŸãƒ¢ãƒ‡ãƒ«: **{best_model[0]}** (RÂ² = {best_model[1]:.4f})\n\n")
            
            f.write("### 4.2 å®Ÿå‹™çš„å«æ„\n\n")
            f.write("- REQIï¼ˆç«¶èµ°çµŒé¨“è³ªæŒ‡æ•°ï¼‰ã¯ç«¶é¦¬äºˆæ¸¬ã«ãŠã„ã¦è£œåŠ©çš„ãªä¾¡å€¤ã‚’æŒã¤ã“ã¨ãŒç¢ºèªã•ã‚Œã¾ã—ãŸ\n")
            f.write("- ã‚ªãƒƒã‚ºæƒ…å ±ã¨ã®çµ„ã¿åˆã‚ã›ã«ã‚ˆã‚Šã€äºˆæ¸¬ç²¾åº¦ã®å‘ä¸ŠãŒæœŸå¾…ã§ãã¾ã™\n")
            f.write("- ä¸¡æŒ‡æ¨™ã¯ç›¸äº’è£œå®Œçš„ãªé–¢ä¿‚ã«ã‚ã‚Šã€çµ±åˆåˆ©ç”¨ãŒæ¨å¥¨ã•ã‚Œã¾ã™\n\n")
            
            # æŠ•è³‡æˆ¦ç•¥ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³è¿½åŠ 
            f.write("## 5. æ™‚ç³»åˆ—åˆ†å‰²ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆï¼ˆ3å¹´åˆ†äºˆæ¸¬: 2022-2024å¹´ï¼‰\n\n")
            
            # æŠ•è³‡æˆ¦ç•¥ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³å®Ÿè¡Œï¼ˆ20%ã¨5%ã®ä¸¡æ–¹ï¼‰
            all_strategy_results_20pct = {}
            all_strategy_results_5pct = {}
            if race_df is not None:
                logger.info("ğŸ“Š ä¸Šä½20%æˆ¦ç•¥ã®ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã‚’å®Ÿè¡Œä¸­...")
                all_strategy_results_20pct = self._calculate_betting_performance(race_df, test_years=[2022, 2023, 2024], top_pct=0.2)
                logger.info("ğŸ“Š ä¸Šä½5%æˆ¦ç•¥ã®ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã‚’å®Ÿè¡Œä¸­...")
                all_strategy_results_5pct = self._calculate_betting_performance(race_df, test_years=[2022, 2023, 2024], top_pct=0.05)
            else:
                logger.warning("âš ï¸ ãƒ¬ãƒ¼ã‚¹ãƒ‡ãƒ¼ã‚¿ãŒãªã„ãŸã‚ã€æ™‚ç³»åˆ—åˆ†å‰²ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™")
            
            # 20%æˆ¦ç•¥ã®ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
            if all_strategy_results_20pct:
                self._write_betting_performance_section(f, all_strategy_results_20pct, "5.1", "20%", 0.2)
            
            # 5%æˆ¦ç•¥ã®ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
            if all_strategy_results_5pct:
                self._write_betting_performance_section(f, all_strategy_results_5pct, "5.2", "5%", 0.05)
            
            # ç·æ‹¬çµè«–
            if all_strategy_results_20pct or all_strategy_results_5pct:
                f.write('### 5.3 çµè«–\n\n')
                f.write('- âœ… **ãƒ¬ãƒ¼ã‚¹å˜ä½ã®å®ŸæŠ•è³‡ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³**ã«ã‚ˆã‚‹ç¾å®Ÿçš„ãªè©•ä¾¡\n')
                f.write('- âœ… **3å¹´åˆ†ã®æ­£ã—ã„æ™‚ç³»åˆ—åˆ†å‰²ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆ**ã«ã‚ˆã‚Šæƒ…å ±æ¼æ´©ã‚’å®Œå…¨ã«æ’é™¤\n')
                f.write('- ğŸ“Š å„å¹´ã¨ã‚‚å‰å¹´ã¾ã§ã®ãƒ‡ãƒ¼ã‚¿ã®ã¿ã§äºˆæ¸¬ï¼ˆ2022-2024å¹´ï¼‰\n')
                f.write('- ğŸ“ˆ è¤‡æ•°å¹´ã§ã®å®‰å®šæ€§ã¨å†ç¾æ€§ã‚’æ¤œè¨¼\n')
                f.write('- ğŸ” ä¸Šä½20%ã¨5%ã®æ¯”è¼ƒã«ã‚ˆã‚Šã€æˆ¦ç•¥ã®å …ç‰¢æ€§ã‚’å¤šè§’çš„ã«è©•ä¾¡\n')
                f.write('- âš ï¸ REQIã®è£œå®ŒåŠ¹æœã¯é™å®šçš„ã ãŒã€äºˆæ¸¬ãƒ¢ãƒ‡ãƒ«ã®ä¸€è¦ç´ ã¨ã—ã¦æœ‰ç”¨\n')
                f.write('- ğŸ’¡ REQIã¯å˜ç‹¬ã§ã®åç›ŠåŒ–ã¯å›°é›£ã ãŒã€å¤šå¤‰é‡ãƒ¢ãƒ‡ãƒ«ã®ç‰¹å¾´é‡ã¨ã—ã¦è²¢çŒ®\n\n')
            
            f.write("---\n\n")
            f.write(f"*åˆ†æå®Ÿè¡Œæ—¥æ™‚: {pd.Timestamp.now().strftime('%Yå¹´%mæœˆ%dæ—¥ %H:%M:%S')}*\n")
        
        logger.info(f"ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆå®Œäº†: {report_path}")
        return str(report_path)
    
    def _calculate_betting_performance_single_year(self, race_df: pd.DataFrame, train_end_year: int = 2023, 
                                       test_year: int = 2024, min_races: int = 6, top_pct: float = 0.2) -> Dict[str, Any]:
        """
        æ™‚ç³»åˆ—åˆ†å‰²ã«ã‚ˆã‚‹æŠ•è³‡æˆ¦ç•¥ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³å®Ÿè¡Œï¼ˆæƒ…å ±æ¼æ´©ãªã—ï¼‰
        
        Args:
            race_df: å…¨æœŸé–“ã®ãƒ¬ãƒ¼ã‚¹ãƒ‡ãƒ¼ã‚¿
            train_end_year: è¨“ç·´æœŸé–“ã®çµ‚äº†å¹´
            test_year: ãƒ†ã‚¹ãƒˆå¹´
            min_races: æœ€ä½å‡ºèµ°å›æ•°
            top_pct: ä¸Šä½ä½•%ã®é¦¬ã‚’é¸æŠã™ã‚‹ã‹ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 0.2 = 20%ï¼‰
            
        Returns:
            æŠ•è³‡æˆ¦ç•¥åˆ¥ã®çµæœ
        """
        try:
            logger.info(f"ğŸ“Š æ™‚ç³»åˆ—åˆ†å‰²æŠ•è³‡ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³: è¨“ç·´æœŸé–“~{train_end_year}å¹´, ãƒ†ã‚¹ãƒˆæœŸé–“{test_year}å¹´")
            
            # å¿…è¦ãªã‚«ãƒ©ãƒ ã®ç¢ºèª
            required_cols = ['å¹´', 'é¦¬å', 'ç€é †']
            if not all(col in race_df.columns for col in required_cols):
                logger.warning(f"å¿…è¦ãªã‚«ãƒ©ãƒ ãŒä¸è¶³: {required_cols}")
                return {}
            
            # è¨“ç·´æœŸé–“ã¨ãƒ†ã‚¹ãƒˆæœŸé–“ã«åˆ†å‰²
            train_df = race_df[race_df['å¹´'] <= train_end_year].copy()
            test_df = race_df[race_df['å¹´'] == test_year].copy()
            
            logger.info(f"   è¨“ç·´ãƒ‡ãƒ¼ã‚¿: {len(train_df):,}ãƒ¬ãƒ¼ã‚¹")
            logger.info(f"   ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿: {len(test_df):,}ãƒ¬ãƒ¼ã‚¹")
            
            if len(train_df) == 0 or len(test_df) == 0:
                logger.warning("è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã¾ãŸã¯ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ãŒ0ä»¶")
                return {}
            
            # è¨“ç·´æœŸé–“ã§é¦¬çµ±è¨ˆã‚’è¨ˆç®—
            logger.info("   è¨“ç·´æœŸé–“ã®é¦¬çµ±è¨ˆã‚’è¨ˆç®—ä¸­...")
            train_df['place_flag'] = (train_df['ç€é †'] <= 3).astype(int)
            
            horse_stats_train = train_df.groupby('é¦¬å').agg({
                'ç€é †': 'count',
                'place_flag': 'mean'
            })
            horse_stats_train.columns = ['total_races', 'place_rate_train']
            
            # ã‚ªãƒƒã‚ºã¨REQIã®å¹³å‡ã‚’è¨ˆç®—
            if 'ç¢ºå®šè¤‡å‹ã‚ªãƒƒã‚ºä¸‹' in train_df.columns:
                odds_stats = train_df.groupby('é¦¬å')['ç¢ºå®šè¤‡å‹ã‚ªãƒƒã‚ºä¸‹'].mean()
                horse_stats_train['avg_place_odds'] = odds_stats
                horse_stats_train['avg_place_prob_from_odds'] = (1.0 / horse_stats_train['avg_place_odds']).clip(0, 1)
            
            if 'race_level' in train_df.columns:
                reqi_stats = train_df.groupby('é¦¬å')['race_level'].mean()
                horse_stats_train['avg_race_level'] = reqi_stats
            
            # æœ€ä½å‡ºèµ°å›æ•°ã§ãƒ•ã‚£ãƒ«ã‚¿
            horse_stats_train = horse_stats_train[horse_stats_train['total_races'] >= min_races]
            logger.info(f"   è¨“ç·´æœŸé–“ã®é¦¬çµ±è¨ˆ: {len(horse_stats_train):,}é ­")
            
            # ãƒ†ã‚¹ãƒˆæœŸé–“ã®å®Ÿéš›ã®çµæœã‚’è¨ˆç®—
            logger.info("   ãƒ†ã‚¹ãƒˆæœŸé–“ã®å®Ÿç¸¾ã‚’é›†è¨ˆä¸­...")
            test_df['place_flag'] = (test_df['ç€é †'] <= 3).astype(int)
            
            test_results = test_df.groupby('é¦¬å').agg({
                'place_flag': 'mean',
                'ç¢ºå®šè¤‡å‹ã‚ªãƒƒã‚ºä¸‹': 'mean' if 'ç¢ºå®šè¤‡å‹ã‚ªãƒƒã‚ºä¸‹' in test_df.columns else lambda x: None
            })
            test_results.columns = ['actual_place_rate_2024', 'actual_avg_odds_2024']
            
            # è¨“ç·´æœŸé–“ã®çµ±è¨ˆã‚’ä¿å­˜ï¼ˆé¦¬é¸æŠç”¨ï¼‰
            logger.info(f"   è¨“ç·´æœŸé–“ã®é¦¬çµ±è¨ˆ: {len(horse_stats_train):,}é ­")
            
            if len(horse_stats_train) < 100:
                logger.warning(f"ãƒ‡ãƒ¼ã‚¿ãŒä¸è¶³: {len(horse_stats_train)}é ­")
                return {}
            
            results = {}
            target_investment = 1000000  # ç›®æ¨™æŠ•è³‡é¡100ä¸‡å††
            n_top = max(1, int(len(horse_stats_train) * top_pct))
            
            # ã€é‡è¦ã€‘ãƒ¬ãƒ¼ã‚¹å˜ä½ã®æŠ•è³‡ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³
            logger.info("   ãƒ¬ãƒ¼ã‚¹å˜ä½ã®æŠ•è³‡ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã‚’å®Ÿè¡Œä¸­...")
            
            # 1. ã‚ªãƒƒã‚ºã®ã¿æˆ¦ç•¥ï¼ˆãƒ¬ãƒ¼ã‚¹å˜ä½ï¼‰
            if 'avg_place_prob_from_odds' in horse_stats_train.columns:
                data_clean = horse_stats_train.dropna(subset=['avg_place_prob_from_odds'])
                top20_horses = data_clean.nlargest(n_top, 'avg_place_prob_from_odds').index.tolist()
                
                # ã“ã‚Œã‚‰ã®é¦¬ãŒ2024å¹´ã«å‡ºèµ°ã—ãŸãƒ¬ãƒ¼ã‚¹ã‚’å–å¾—
                test_races = test_df[test_df['é¦¬å'].isin(top20_horses)].copy()
                
                if len(test_races) > 0:
                    # å„ãƒ¬ãƒ¼ã‚¹ã«å‡ç­‰é¡ã‚’æŠ•è³‡
                    bet_per_race = target_investment / len(test_races)
                    total_investment = len(test_races) * bet_per_race
                    
                    # çš„ä¸­ãƒ¬ãƒ¼ã‚¹ï¼ˆ3ç€ä»¥å†…ï¼‰
                    win_races = test_races[test_races['place_flag'] == 1]
                    hit_count = len(win_races)
                    hit_rate = hit_count / len(test_races)
                    
                    # ç·æ‰•æˆ»é¡ï¼ˆé…å½“ Ã— è³­ã‘é‡‘ï¼‰
                    if 'ç¢ºå®šè¤‡å‹ã‚ªãƒƒã‚ºä¸‹' in win_races.columns:
                        total_return = (win_races['ç¢ºå®šè¤‡å‹ã‚ªãƒƒã‚ºä¸‹'] * bet_per_race).sum()
                        avg_payout = win_races['ç¢ºå®šè¤‡å‹ã‚ªãƒƒã‚ºä¸‹'].mean()
                    else:
                        total_return = 0
                        avg_payout = 0
                    
                    roi = total_return / total_investment if total_investment > 0 else 0
                    
                    results['odds'] = {
                        'hit_rate': hit_rate,
                        'avg_payout': avg_payout,
                        'roi': roi,
                        'investment': total_investment,
                        'return_amount': total_return,
                        'profit_loss': total_return - total_investment,
                        'total_races': len(test_races),
                        'hit_races': hit_count
                    }
            
            # 2. REQIã®ã¿æˆ¦ç•¥ï¼ˆãƒ¬ãƒ¼ã‚¹å˜ä½ï¼‰
            if 'avg_race_level' in horse_stats_train.columns:
                data_clean = horse_stats_train.dropna(subset=['avg_race_level'])
                top20_horses = data_clean.nlargest(n_top, 'avg_race_level').index.tolist()
                
                test_races = test_df[test_df['é¦¬å'].isin(top20_horses)].copy()
                
                if len(test_races) > 0:
                    bet_per_race = target_investment / len(test_races)
                    total_investment = len(test_races) * bet_per_race
                    
                    win_races = test_races[test_races['place_flag'] == 1]
                    hit_count = len(win_races)
                    hit_rate = hit_count / len(test_races)
                    
                    if 'ç¢ºå®šè¤‡å‹ã‚ªãƒƒã‚ºä¸‹' in win_races.columns:
                        total_return = (win_races['ç¢ºå®šè¤‡å‹ã‚ªãƒƒã‚ºä¸‹'] * bet_per_race).sum()
                        avg_payout = win_races['ç¢ºå®šè¤‡å‹ã‚ªãƒƒã‚ºä¸‹'].mean()
                    else:
                        total_return = 0
                        avg_payout = 0
                    
                    roi = total_return / total_investment if total_investment > 0 else 0
                    
                    results['reqi'] = {
                        'hit_rate': hit_rate,
                        'avg_payout': avg_payout,
                        'roi': roi,
                        'investment': total_investment,
                        'return_amount': total_return,
                        'profit_loss': total_return - total_investment,
                        'total_races': len(test_races),
                        'hit_races': hit_count
                    }
            
            # 3. çµ±åˆæˆ¦ç•¥ï¼ˆãƒ¬ãƒ¼ã‚¹å˜ä½ï¼‰
            if 'avg_place_prob_from_odds' in horse_stats_train.columns and 'avg_race_level' in horse_stats_train.columns:
                from sklearn.preprocessing import MinMaxScaler
                scaler = MinMaxScaler()
                
                data_clean = horse_stats_train.dropna(subset=['avg_place_prob_from_odds', 'avg_race_level']).copy()
                data_clean['odds_normalized'] = scaler.fit_transform(data_clean[['avg_place_prob_from_odds']])
                data_clean['reqi_normalized'] = scaler.fit_transform(data_clean[['avg_race_level']])
                data_clean['integrated_score'] = (0.64 * data_clean['odds_normalized'] + 
                                                 0.36 * data_clean['reqi_normalized'])
                
                top20_horses = data_clean.nlargest(n_top, 'integrated_score').index.tolist()
                
                test_races = test_df[test_df['é¦¬å'].isin(top20_horses)].copy()
                
                if len(test_races) > 0:
                    bet_per_race = target_investment / len(test_races)
                    total_investment = len(test_races) * bet_per_race
                    
                    win_races = test_races[test_races['place_flag'] == 1]
                    hit_count = len(win_races)
                    hit_rate = hit_count / len(test_races)
                    
                    if 'ç¢ºå®šè¤‡å‹ã‚ªãƒƒã‚ºä¸‹' in win_races.columns:
                        total_return = (win_races['ç¢ºå®šè¤‡å‹ã‚ªãƒƒã‚ºä¸‹'] * bet_per_race).sum()
                        avg_payout = win_races['ç¢ºå®šè¤‡å‹ã‚ªãƒƒã‚ºä¸‹'].mean()
                    else:
                        total_return = 0
                        avg_payout = 0
                    
                    roi = total_return / total_investment if total_investment > 0 else 0
                    
                    results['integrated'] = {
                        'hit_rate': hit_rate,
                        'avg_payout': avg_payout,
                        'roi': roi,
                        'investment': total_investment,
                        'return_amount': total_return,
                        'profit_loss': total_return - total_investment,
                        'total_races': len(test_races),
                        'hit_races': hit_count
                    }
            
            logger.info("âœ… æ™‚ç³»åˆ—åˆ†å‰²æŠ•è³‡ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³å®Œäº†")
            if 'odds' in results:
                logger.info(f"  ã‚ªãƒƒã‚ºã®ã¿: å›åç‡{results['odds']['roi']*100:.1f}% ({test_year}å¹´å®Ÿç¸¾)")
            if 'reqi' in results:
                logger.info(f"  REQIã®ã¿: å›åç‡{results['reqi']['roi']*100:.1f}% ({test_year}å¹´å®Ÿç¸¾)")
            if 'integrated' in results:
                logger.info(f"  çµ±åˆæˆ¦ç•¥: å›åç‡{results['integrated']['roi']*100:.1f}% ({test_year}å¹´å®Ÿç¸¾)")
            
            return results
            
        except Exception as e:
            logger.error(f"âŒ æŠ•è³‡æˆ¦ç•¥ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã‚¨ãƒ©ãƒ¼: {str(e)}")
            import traceback
            traceback.print_exc()
            return {}
    
    def _write_betting_performance_section(self, f, all_strategy_results: Dict, section_num: str, 
                                           top_pct_label: str, top_pct: float):
        """
        æŠ•è³‡æˆ¦ç•¥ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³çµæœã®ãƒ¬ãƒãƒ¼ãƒˆã‚»ã‚¯ã‚·ãƒ§ãƒ³ã‚’æ›¸ãè¾¼ã‚€
        
        Args:
            f: ãƒ•ã‚¡ã‚¤ãƒ«ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆ
            all_strategy_results: æˆ¦ç•¥åˆ¥ã®çµæœè¾æ›¸
            section_num: ã‚»ã‚¯ã‚·ãƒ§ãƒ³ç•ªå·ï¼ˆä¾‹: "4.1"ï¼‰
            top_pct_label: ä¸Šä½%ãƒ©ãƒ™ãƒ«ï¼ˆä¾‹: "20%"ï¼‰
            top_pct: ä¸Šä½%ã®æ•°å€¤ï¼ˆä¾‹: 0.2ï¼‰
        """
        if not all_strategy_results:
            return
            
        f.write(f"### {section_num} ä¸Šä½{top_pct_label}æˆ¦ç•¥\n\n")
        f.write("#### åˆ†æè¨­è¨ˆ\n\n")
        f.write("**ç›®çš„**: æƒ…å ±æ¼æ´©ã‚’æ’é™¤ã—ãŸæ­£ã—ã„äºˆæ¸¬è©•ä¾¡ï¼ˆ3å¹´åˆ†ã®äºˆæ¸¬ï¼‰\n\n")
        f.write("- **2022å¹´äºˆæ¸¬**: ~2021å¹´ã®ãƒ‡ãƒ¼ã‚¿ã§è¨“ç·´ â†’ 2022å¹´ã§ãƒ†ã‚¹ãƒˆ\n")
        f.write("- **2023å¹´äºˆæ¸¬**: ~2022å¹´ã®ãƒ‡ãƒ¼ã‚¿ã§è¨“ç·´ â†’ 2023å¹´ã§ãƒ†ã‚¹ãƒˆ\n")
        f.write("- **2024å¹´äºˆæ¸¬**: ~2023å¹´ã®ãƒ‡ãƒ¼ã‚¿ã§è¨“ç·´ â†’ 2024å¹´ã§ãƒ†ã‚¹ãƒˆ\n")
        f.write("- **æ–¹æ³•**: å„å¹´ã¨ã‚‚å‰å¹´ã¾ã§ã®çµ±è¨ˆã®ã¿ã‚’ä½¿ç”¨ã—ã¦äºˆæ¸¬\n")
        f.write("- **æƒ…å ±æ¼æ´©**: ãªã—ï¼ˆæœªæ¥ã®æƒ…å ±ã¯ä¸€åˆ‡ä½¿ç”¨ã—ã¦ã„ãªã„ï¼‰\n\n")
        f.write("**æŠ•è³‡æˆ¦ç•¥ï¼ˆãƒ¬ãƒ¼ã‚¹å˜ä½ï¼‰**:\n")
        f.write(f"1. è¨“ç·´æœŸé–“ã§ä¸Šä½{top_pct_label}ã®é¦¬ã‚’é¸æŠ\n")
        f.write("2. ãã®é¦¬ãŸã¡ãŒãƒ†ã‚¹ãƒˆå¹´ã«å‡ºèµ°ã—ãŸå…¨ãƒ¬ãƒ¼ã‚¹ã«è¤‡å‹æŠ•è³‡\n")
        f.write("3. å„ãƒ¬ãƒ¼ã‚¹ã«å‡ç­‰é¡ã‚’æŠ•è³‡ï¼ˆç›®æ¨™100ä¸‡å†† Ã· ãƒ¬ãƒ¼ã‚¹æ•°ï¼‰\n")
        f.write("4. 3ç€ä»¥å†…ã§çš„ä¸­ã€ç¢ºå®šè¤‡å‹ã‚ªãƒƒã‚ºã§æ‰•æˆ»\n\n")
        f.write(f"- **ã‚ªãƒƒã‚ºã®ã¿**: è¨“ç·´æœŸé–“ã®è¤‡å‹ã‚ªãƒƒã‚ºäºˆæ¸¬ä¸Šä½{top_pct_label}ã®é¦¬\n")
        f.write(f"- **REQIã®ã¿**: è¨“ç·´æœŸé–“ã®REQIä¸Šä½{top_pct_label}ã®é¦¬\n")
        f.write(f"- **çµ±åˆæˆ¦ç•¥**: ã‚ªãƒƒã‚º70% + REQI30%ã‚¹ã‚³ã‚¢ä¸Šä½{top_pct_label}ã®é¦¬\n\n")
        
        strategy_names = {
            'odds': 'ã‚ªãƒƒã‚ºã®ã¿',
            'reqi': 'REQIã®ã¿',
            'integrated': 'çµ±åˆ'
        }
        
        # å„å¹´ã®ãƒ†ãƒ¼ãƒ–ãƒ«ã‚’ç”Ÿæˆ
        test_years = [2022, 2023, 2024]
        subsection_counter = 1
        for test_year in test_years:
            train_year = test_year - 1
            f.write(f"#### {test_year}å¹´ã®æŠ•è³‡ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³çµæœï¼ˆè¨“ç·´: ~{train_year}å¹´ï¼‰\n\n")
            f.write("| æˆ¦ç•¥ | ãƒ¬ãƒ¼ã‚¹æ•° | çš„ä¸­æ•° | çš„ä¸­ç‡ | å¹³å‡é…å½“ | å›åç‡ | æŠ•è³‡é¡ | å›åé¡ | æç›Š |\n")
            f.write("|-----|---------|-------|-------|---------|-------|-------|-------|------|\n")
            
            for strategy_key in ['odds', 'reqi', 'integrated']:
                if strategy_key not in all_strategy_results:
                    continue
                if test_year not in all_strategy_results[strategy_key]:
                    continue
                
                r = all_strategy_results[strategy_key][test_year]
                name = strategy_names[strategy_key]
                
                f.write(
                    f"| {name} | "
                    f"{r.get('total_races', 0):,}ãƒ¬ãƒ¼ã‚¹ | "
                    f"{r.get('hit_races', 0):,}å› | "
                    f"{r['hit_rate']*100:.1f}% | "
                    f"{r['avg_payout']:.2f}å€ | "
                    f"{r['roi']*100:.1f}% | "
                    f"{r['investment']/10000:.0f}ä¸‡å†† | "
                    f"{r['return_amount']/10000:.1f}ä¸‡å†† | "
                    f"{r['profit_loss']/10000:+.1f}ä¸‡å†† |\n"
                )
            
            f.write('\n')
            
            # æ”¹å–„åŠ¹æœã®è¨ˆç®—ï¼ˆå„å¹´ã”ã¨ï¼‰
            if 'odds' in all_strategy_results and 'integrated' in all_strategy_results:
                if test_year in all_strategy_results['odds'] and test_year in all_strategy_results['integrated']:
                    odds_result = all_strategy_results['odds'][test_year]
                    integrated_result = all_strategy_results['integrated'][test_year]
                    
                    hit_rate_improvement = (integrated_result['hit_rate'] - odds_result['hit_rate']) * 100
                    roi_improvement = (integrated_result['roi'] - odds_result['roi']) * 100
                    profit_improvement = (integrated_result['profit_loss'] - odds_result['profit_loss']) / 10000
                    
                    f.write(f"**{test_year}å¹´ã®æ”¹å–„åŠ¹æœï¼ˆçµ±åˆ vs ã‚ªãƒƒã‚ºã®ã¿ï¼‰**:\n")
                    f.write(f"- çš„ä¸­ç‡: {hit_rate_improvement:+.1f}ptï¼ˆ{odds_result['hit_rate']*100:.1f}% â†’ {integrated_result['hit_rate']*100:.1f}%ï¼‰\n")
                    f.write(f"- å›åç‡: {roi_improvement:+.1f}ptï¼ˆ{odds_result['roi']*100:.1f}% â†’ {integrated_result['roi']*100:.1f}%ï¼‰\n")
                    f.write(f"- æç›Š: {profit_improvement:+.1f}ä¸‡å††ï¼ˆ{odds_result['profit_loss']/10000:+.1f}ä¸‡å†† â†’ {integrated_result['profit_loss']/10000:+.1f}ä¸‡å††ï¼‰\n")
                    f.write('\n')
            
            subsection_counter += 1
        
        # 3å¹´åˆ†ã®å¹³å‡çµ±è¨ˆã‚’è¨ˆç®—
        f.write("#### 3å¹´é–“ã®ç·åˆçµ±è¨ˆ\n\n")
        
        for strategy in ['odds', 'reqi', 'integrated']:
            if strategy not in all_strategy_results:
                continue
            
            yearly_data = all_strategy_results[strategy]
            if len(yearly_data) == 0:
                continue
            
            avg_hit_rate = sum(r['hit_rate'] for r in yearly_data.values()) / len(yearly_data)
            avg_roi = sum(r['roi'] for r in yearly_data.values()) / len(yearly_data)
            total_races = sum(r.get('total_races', 0) for r in yearly_data.values())
            total_investment = sum(r['investment'] for r in yearly_data.values())
            total_return = sum(r['return_amount'] for r in yearly_data.values())
            total_profit_loss = sum(r['profit_loss'] for r in yearly_data.values())
            
            f.write(f"**{strategy_names[strategy]}æˆ¦ç•¥ï¼ˆ3å¹´å¹³å‡ï¼‰**:\n")
            f.write(f"- å¹³å‡çš„ä¸­ç‡: {avg_hit_rate*100:.1f}%\n")
            f.write(f"- å¹³å‡å›åç‡: {avg_roi*100:.1f}%\n")
            f.write(f"- ç·ãƒ¬ãƒ¼ã‚¹æ•°: {total_races:,}ãƒ¬ãƒ¼ã‚¹\n")
            f.write(f"- ç·æŠ•è³‡é¡: {total_investment/10000:.0f}ä¸‡å††\n")
            f.write(f"- ç·å›åé¡: {total_return/10000:.1f}ä¸‡å††\n")
            f.write(f"- ç·æç›Š: {total_profit_loss/10000:+.1f}ä¸‡å††\n\n")
        
        f.write('#### å®Ÿå‹™çš„è§£é‡ˆ\n\n')
        f.write('**ãƒã‚¸ãƒ†ã‚£ãƒ–é¢**:\n')
        f.write('- âœ… ãƒ¬ãƒ¼ã‚¹å˜ä½ã®å®ŸæŠ•è³‡ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ï¼ˆå®Ÿéš›ã®è³­ã‘æ–¹ã«åŸºã¥ãè©•ä¾¡ï¼‰\n')
        f.write('- âœ… 3å¹´åˆ†ã®æ™‚ç³»åˆ—åˆ†å‰²ã«ã‚ˆã‚Šæƒ…å ±æ¼æ´©ãªã—ã§è©•ä¾¡\n')
        f.write('- âœ… å„å¹´ã¨ã‚‚å‰å¹´ã¾ã§ã®çŸ¥è­˜ã®ã¿ã§äºˆæ¸¬\n')
        f.write('- ğŸ“Š 3å¹´é–“ã®å®ŸæŠ•è³‡å¯¾è±¡: è¤‡æ•°å¹´ã§ã®å®‰å®šæ€§ã‚’æ¤œè¨¼\n')
        
        # 3å¹´å¹³å‡ã§ã®æ”¹å–„åŠ¹æœ
        if 'odds' in all_strategy_results and 'integrated' in all_strategy_results:
            odds_yearly = all_strategy_results['odds']
            integrated_yearly = all_strategy_results['integrated']
            
            if len(odds_yearly) > 0 and len(integrated_yearly) > 0:
                avg_odds_roi = sum(r['roi'] for r in odds_yearly.values()) / len(odds_yearly)
                avg_integrated_roi = sum(r['roi'] for r in integrated_yearly.values()) / len(integrated_yearly)
                avg_roi_improvement = (avg_integrated_roi - avg_odds_roi) * 100
                
                if avg_roi_improvement > 0:
                    f.write(f'- âœ… çµ±åˆæˆ¦ç•¥ãŒã‚ªãƒƒã‚ºå˜ç‹¬ã‚ˆã‚Šå„ªä½ï¼ˆ3å¹´å¹³å‡å›åç‡{avg_roi_improvement:+.1f}ptæ”¹å–„ï¼‰\n')
                else:
                    f.write(f'- âš ï¸ çµ±åˆæˆ¦ç•¥ã®æ”¹å–„ã¯é™å®šçš„ï¼ˆ3å¹´å¹³å‡å›åç‡{avg_roi_improvement:+.1f}ptï¼‰\n')
        
        f.write('\n**åˆ¶ç´„äº‹é …**:\n')
        
        # 3å¹´å¹³å‡ã§ã®å›åç‡ãƒã‚§ãƒƒã‚¯
        if 'integrated' in all_strategy_results and len(all_strategy_results['integrated']) > 0:
            avg_integrated_roi = sum(r['roi'] for r in all_strategy_results['integrated'].values()) / len(all_strategy_results['integrated'])
            if avg_integrated_roi < 1.0:
                f.write(f'- âš ï¸ 3å¹´å¹³å‡å›åç‡{avg_integrated_roi*100:.1f}%ã§100%è¶…ãˆã«ã¯è‡³ã‚‰ãšã€æŠ•è³‡æˆ¦ç•¥ã¨ã—ã¦ã¯åç›Šæ€§ä¸è¶³\n')
        
        f.write('- å®Ÿé‹ç”¨ã§ã¯æ‰‹æ•°æ–™ï¼ˆç´„25%ï¼‰ãƒ»ç¨é‡‘ã‚’è€ƒæ…®ã™ã‚‹ã¨ã€ã•ã‚‰ã«åç›Šæ€§ã¯ä½ä¸‹\n')
        f.write('- REQIã¯ã€Œè£œåŠ©æŒ‡æ¨™ã€ã¨ã—ã¦ã®ä½ç½®ã¥ã‘ãŒå¦¥å½“\n\n')

    def _calculate_betting_performance(self, race_df: pd.DataFrame, test_years: list = [2022, 2023, 2024],
                                      min_races: int = 6, top_pct: float = 0.2) -> Dict[str, Dict[int, Dict[str, Any]]]:
        """
        è¤‡æ•°å¹´ã®æ™‚ç³»åˆ—åˆ†å‰²ã«ã‚ˆã‚‹æŠ•è³‡æˆ¦ç•¥ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ï¼ˆæƒ…å ±æ¼æ´©ãªã—ï¼‰
        å„å¹´ã‚’å‰å¹´ã¾ã§ã®ãƒ‡ãƒ¼ã‚¿ã§äºˆæ¸¬
        
        Args:
            race_df: å…¨æœŸé–“ã®ãƒ¬ãƒ¼ã‚¹ãƒ‡ãƒ¼ã‚¿
            test_years: ãƒ†ã‚¹ãƒˆå¯¾è±¡å¹´ã®ãƒªã‚¹ãƒˆ
            min_races: æœ€ä½å‡ºèµ°å›æ•°
            top_pct: ä¸Šä½ä½•%ã®é¦¬ã‚’é¸æŠã™ã‚‹ã‹ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 0.2 = 20%ï¼‰
            
        Returns:
            å„æˆ¦ç•¥ãƒ»å„å¹´ã®çµæœã‚’æ ¼ç´ã—ãŸè¾æ›¸
        """
        logger.info(f"ğŸ“Š 3å¹´åˆ†æŠ•è³‡ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³é–‹å§‹: {test_years}")
        
        all_strategy_results = {}
        strategies = ['odds', 'reqi', 'integrated']
        
        for strategy in strategies:
            yearly_results = {}
            for test_year in test_years:
                train_end_year = test_year - 1
                logger.info(f"\nğŸ“… {strategy}æˆ¦ç•¥: {test_year}å¹´ã®äºˆæ¸¬ï¼ˆè¨“ç·´: ~{train_end_year}å¹´ï¼‰")
                
                result = self._calculate_betting_performance_single_year(
                    race_df, train_end_year, test_year, min_races, top_pct
                )
                
                if result and strategy in result:
                    yearly_results[test_year] = result[strategy]
                    logger.info(f"   âœ… {test_year}å¹´å®Œäº†: å›åç‡{result[strategy]['roi']*100:.1f}%")
                else:
                    logger.warning(f"   âš ï¸ {strategy}æˆ¦ç•¥ã®{test_year}å¹´ãƒ‡ãƒ¼ã‚¿ä¸è¶³")
            
            if yearly_results:
                all_strategy_results[strategy] = yearly_results
        
        return all_strategy_results
    
    def _calculate_dynamic_weights_fallback(self, df: pd.DataFrame) -> Dict[str, float]:
        """
        ã‚°ãƒ­ãƒ¼ãƒãƒ«é‡ã¿æœªåˆæœŸåŒ–æ™‚ã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯é‡ã¿è¨ˆç®—
        
        Args:
            df: ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ 
            
        Returns:
            é‡ã¿è¾æ›¸
        """
        try:
            logger.info("ğŸ¯ å€‹åˆ¥å‹•çš„é‡ã¿è¨ˆç®—ã‚’å®Ÿè¡Œä¸­...")
            
            # è¤‡å‹ç‡ã®è¨ˆç®—
            df_temp = df.copy()
            df_temp['place_flag'] = (df_temp['ç€é †'] <= 3).astype(int)
            horse_place_rates = df_temp.groupby('é¦¬å')['place_flag'].mean().to_dict()
            df_temp['horse_place_rate'] = df_temp['é¦¬å'].map(horse_place_rates)
            
            # ç›¸é–¢è¨ˆç®—
            grade_corr = df_temp['grade_level'].corr(df_temp['horse_place_rate'])
            venue_corr = df_temp['venue_level'].corr(df_temp['horse_place_rate'])
            distance_corr = df_temp['distance_level'].corr(df_temp['horse_place_rate'])
            
            # NaNå‡¦ç†
            grade_corr = grade_corr if not pd.isna(grade_corr) else 0.0
            venue_corr = venue_corr if not pd.isna(venue_corr) else 0.0
            distance_corr = distance_corr if not pd.isna(distance_corr) else 0.0
            
            # é‡ã¿è¨ˆç®—
            grade_contribution = grade_corr ** 2
            venue_contribution = venue_corr ** 2
            distance_contribution = distance_corr ** 2
            total_contribution = grade_contribution + venue_contribution + distance_contribution
            
            if total_contribution > 0:
                return {
                    'grade_weight': grade_contribution / total_contribution,
                    'venue_weight': venue_contribution / total_contribution,
                    'distance_weight': distance_contribution / total_contribution
                }
            else:
                # å‡ç­‰é‡ã¿
                return {
                    'grade_weight': 1.0 / 3,
                    'venue_weight': 1.0 / 3,
                    'distance_weight': 1.0 / 3
                }
                
        except Exception as e:
            logger.error(f"âŒ ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯é‡ã¿è¨ˆç®—ã‚¨ãƒ©ãƒ¼: {str(e)}")
            return {
                'grade_weight': 0.636,   # ãƒ¬ãƒãƒ¼ãƒˆè¨˜è¼‰å€¤
                'venue_weight': 0.323,
                'distance_weight': 0.041
            }
