"""
ãƒ¬ãƒ¼ã‚¹ãƒ¬ãƒ™ãƒ«åˆ†æãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«
ãƒ¬ãƒ¼ã‚¹ã®ã‚°ãƒ¬ãƒ¼ãƒ‰ã‚„è³é‡‘é¡ãªã©ã‹ã‚‰ãƒ¬ãƒ¼ã‚¹ãƒ¬ãƒ™ãƒ«ã‚’åˆ†æã—ã¾ã™ã€‚
"""

from typing import Dict, Any, Tuple
import pandas as pd
import numpy as np
from sklearn.linear_model import LinearRegression, LogisticRegression
from horse_racing.base.analyzer import BaseAnalyzer, AnalysisConfig
from horse_racing.data.loader import RaceDataLoader
from horse_racing.visualization.plotter import RacePlotter
from horse_racing.analyzers.causal_analyzer import analyze_causal_relationship, generate_causal_analysis_report
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, r2_score, mean_squared_error
from scipy import stats
from statsmodels.stats.outliers_influence import variance_inflation_factor
from statsmodels.stats.multitest import multipletests
import seaborn as sns
import matplotlib.pyplot as plt
import matplotlib as mpl
import logging
from pathlib import Path
import warnings
import random

# å†ç¾æ€§ã®æ‹…ä¿
RANDOM_SEED = 42
np.random.seed(RANDOM_SEED)
random.seed(RANDOM_SEED)

# ãƒ­ã‚¬ãƒ¼ã®è¨­å®š
logger = logging.getLogger(__name__)

# ãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ€ãƒ¼ã®ãƒ­ã‚°ãƒ¬ãƒ™ãƒ«ã‚’èª¿æ•´
loader_logger = logging.getLogger('horse_racing.data.loader')
loader_logger.setLevel(logging.WARNING)

# æ—¥æœ¬èªãƒ•ã‚©ãƒ³ãƒˆã®è¨­å®š
import platform
if platform.system() == 'Windows':
    # Windowsç’°å¢ƒã§ã®æ—¥æœ¬èªãƒ•ã‚©ãƒ³ãƒˆè¨­å®š
    plt.rcParams['font.family'] = ['Yu Gothic', 'Meiryo', 'Takao', 'IPAexGothic', 'IPAgothic', 'Noto Sans CJK JP', 'sans-serif']
else:
    # Linux/Macç’°å¢ƒã§ã®æ—¥æœ¬èªãƒ•ã‚©ãƒ³ãƒˆè¨­å®š
    plt.rcParams['font.family'] = ['Noto Sans CJK JP', 'Takao', 'IPAexGothic', 'IPAgothic', 'Yu Gothic', 'Meiryo', 'sans-serif']

mpl.rcParams['axes.unicode_minus'] = False
plt.rcParams['font.size'] = 12

class RaceLevelAnalyzer(BaseAnalyzer):
    """ãƒ¬ãƒ¼ã‚¹ãƒ¬ãƒ™ãƒ«åˆ†æã‚¯ãƒ©ã‚¹"""

    # ã‚°ãƒ¬ãƒ¼ãƒ‰å®šç¾©
    GRADE_LEVELS = {
        1: {"name": "G1", "weight": 10.0, "base_level": 9},
        2: {"name": "G2", "weight": 8.0, "base_level": 8},
        3: {"name": "G3", "weight": 7.0, "base_level": 7},
        4: {"name": "é‡è³", "weight": 6.0, "base_level": 6},
        5: {"name": "ç‰¹åˆ¥", "weight": 5.0, "base_level": 5},
        6: {"name": "L", "weight": 5.5, "base_level": 5.5}
    }

    # ãƒ¬ãƒ¼ã‚¹ãƒ¬ãƒ™ãƒ«è¨ˆç®—ã®é‡ã¿ä»˜ã‘å®šç¾©
    LEVEL_WEIGHTS = {
        "grade_weight": 0.50,
        "venue_weight": 0.20,
        "prize_weight": 0.30,
        "field_size_weight": 0.10,
        "competition_weight": 0.20,
    }

    def __init__(self, config: AnalysisConfig, enable_time_analysis: bool = False, enable_stratified_analysis: bool = True):
        """åˆæœŸåŒ–"""
        super().__init__(config)
        self.plotter = RacePlotter(self.output_dir)
        self.loader = RaceDataLoader(config.input_path)
        self.class_column = None  # å®Ÿéš›ã®ã‚¯ãƒ©ã‚¹ã‚«ãƒ©ãƒ åã‚’å‹•çš„ã«è¨­å®š
        self.time_analysis_results = {}  # ã‚¿ã‚¤ãƒ åˆ†æçµæœã‚’ä¿å­˜
        self.enable_time_analysis = enable_time_analysis  # RunningTimeåˆ†æã®æœ‰åŠ¹/ç„¡åŠ¹
        self.enable_stratified_analysis = enable_stratified_analysis  # å±¤åˆ¥åˆ†æã®æœ‰åŠ¹/ç„¡åŠ¹

    def load_data(self) -> pd.DataFrame:
        """ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿"""
        try:
            return self.loader.load()
        except FileNotFoundError as e:
            logger.error(f"æŒ‡å®šã•ã‚ŒãŸãƒ‘ã‚¹ã«ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {str(e)}")
            raise
        except Exception as e:
            logger.error(f"ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")
            raise

    def preprocess_data(self) -> pd.DataFrame:
        """ãƒ‡ãƒ¼ã‚¿ã®å‰å‡¦ç†"""
        try:
            df = self.df.copy()
            
            # ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã®æ§‹é€ ã‚’ç¢ºèª
            logger.info("ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã®ã‚«ãƒ©ãƒ ä¸€è¦§:")
            logger.info(df.columns.tolist())
            logger.info("\nãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã®å…ˆé ­5è¡Œ:")
            logger.info(df.head())

            # ã€ä¿®æ­£ã€‘ç©ºã®ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’ãƒã‚§ãƒƒã‚¯
            if len(df.columns) == 0:
                logger.warning("âš ï¸ ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ãŒç©ºã§ã™ã€‚å‰å‡¦ç†ã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™ã€‚")
                return df
            
            # ã‚«ãƒ©ãƒ åã®å‰å¾Œã®ç©ºç™½ã‚’é™¤å»
            df.columns = df.columns.str.strip()

            # æ—¥ä»˜ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
            if self.config.start_date or self.config.end_date:
                # æ—¥ä»˜ã‚«ãƒ©ãƒ ã®ä½œæˆ
                try:
                    if 'å¹´æœˆæ—¥' in df.columns:
                        df['date'] = pd.to_datetime(df['å¹´æœˆæ—¥'].astype(str), format='%Y%m%d')
                    else:
                        # å¹´æœˆæ—¥ã‚«ãƒ©ãƒ ãŒãªã„å ´åˆã¯å¹´ã€å›ã€æ—¥ã‹ã‚‰ä½œæˆ
                        df['date'] = pd.to_datetime(
                            df['å¹´'].astype(str) + 
                            df['å›'].astype(str).str.zfill(2) + 
                            df['æ—¥'].astype(str).str.zfill(2)
                        )
                except Exception as e:
                    logger.error(f"æ—¥ä»˜ã®å¤‰æ›ã«å¤±æ•—ã—ã¾ã—ãŸ: {str(e)}")
                    raise

                # æ—¥ä»˜ã§ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
                if self.config.start_date:
                    df = df[df['date'] >= self.config.start_date]
                if self.config.end_date:
                    df = df[df['date'] <= self.config.end_date]

            # æœ€å°ãƒ¬ãƒ¼ã‚¹æ•°ã§ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
            if self.config.min_races:
                # é¦¬ã”ã¨ã®ãƒ¬ãƒ¼ã‚¹æ•°ã‚’ã‚«ã‚¦ãƒ³ãƒˆ
                race_counts = df['é¦¬å'].value_counts()
                valid_horses = race_counts[race_counts >= self.config.min_races].index
                df = df[df['é¦¬å'].isin(valid_horses)]

                if len(df) == 0:
                    raise ValueError(f"æ¡ä»¶ã‚’æº€ãŸã™ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ï¼ˆæœ€å°ãƒ¬ãƒ¼ã‚¹æ•°: {self.config.min_races}ï¼‰")

            logger.info(f"  ğŸ“Š å¯¾è±¡ãƒ‡ãƒ¼ã‚¿: {len(df):,}è¡Œ")
            logger.info(f"  ğŸ å¯¾è±¡é¦¬æ•°: {df['é¦¬å'].nunique():,}é ­")

            return df

        except Exception as e:
            error_msg = str(e)
            logger.error(f"ãƒ‡ãƒ¼ã‚¿ã®å‰å‡¦ç†ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {error_msg}")
            logger.error("ğŸ’¡ è©³ç´°è¨ºæ–­:")
            logger.error(f"   â€¢ æŒ‡å®šæœŸé–“: {getattr(self.config, 'start_date', 'æŒ‡å®šãªã—')} - {getattr(self.config, 'end_date', 'æŒ‡å®šãªã—')}")
            logger.error(f"   â€¢ æœ€å°ãƒ¬ãƒ¼ã‚¹æ•°: {self.config.min_races}")
            
            if "æ¡ä»¶ã‚’æº€ãŸã™ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“" in error_msg:
                logger.error("ğŸ’¡ è§£æ±ºæ–¹æ³•:")
                logger.error("   â€¢ æœ€å°ãƒ¬ãƒ¼ã‚¹æ•°ã‚’ä¸‹ã’ã¦ãã ã•ã„ï¼ˆä¾‹: --min-races 3ï¼‰")
                logger.error("   â€¢ æœŸé–“ã‚’åºƒã’ã‚‹ã‹æœŸé–“æŒ‡å®šã‚’å‰Šé™¤ã—ã¦ãã ã•ã„")
                logger.error("   â€¢ è©²å½“æœŸé–“ã«ãƒ‡ãƒ¼ã‚¿ãŒå­˜åœ¨ã™ã‚‹ã‹ç¢ºèªã—ã¦ãã ã•ã„")
            
            logger.error(f"ğŸ” ã‚¨ãƒ©ãƒ¼è©³ç´°: {type(e).__name__}: {error_msg}")
            raise

    def calculate_feature(self) -> pd.DataFrame:
        """ãƒ¬ãƒ¼ã‚¹ãƒ¬ãƒ™ãƒ«ã®è¨ˆç®—"""
        df = self.df.copy()
        
        # ã‚«ãƒ©ãƒ åã®å‰å¾Œã®ç©ºç™½ã‚’é™¤å»
        df.columns = df.columns.str.strip()
        
        # å¿…è¦ãªã‚«ãƒ©ãƒ ã‚’é¸æŠï¼ˆå®Ÿéš›ã«å­˜åœ¨ã™ã‚‹ã‚«ãƒ©ãƒ åã«åŸºã¥ãï¼‰
        base_required_columns = [
            'å ´ã‚³ãƒ¼ãƒ‰', 'å¹´', 'å›', 'æ—¥', 'R', 'é¦¬å', 'è·é›¢', 'ç€é †',
            'ãƒ¬ãƒ¼ã‚¹å', 'ç¨®åˆ¥', 'èŠãƒ€éšœå®³ã‚³ãƒ¼ãƒ‰', 'é¦¬ç•ª',
            'æœ¬è³é‡‘', '1ç€è³é‡‘', 'å¹´æœˆæ—¥', 'å ´å',
            '1ç€è³é‡‘(1ç€ç®—å…¥è³é‡‘è¾¼ã¿)', '2ç€è³é‡‘(2ç€ç®—å…¥è³é‡‘è¾¼ã¿)', 'å¹³å‡è³é‡‘'
        ]
        
        # ã‚¿ã‚¤ãƒ é–¢é€£ã‚«ãƒ©ãƒ ã®è¿½åŠ 
        time_columns = []
        for col in ['ã‚¿ã‚¤ãƒ ', 'time', 'Time', 'èµ°ç ´ã‚¿ã‚¤ãƒ ']:
            if col in df.columns:
                time_columns.append(col)
                break
        
        # ã‚¯ãƒ©ã‚¹é–¢é€£ã®ã‚«ãƒ©ãƒ ã‚’å‹•çš„ã«è¿½åŠ ã¨åˆ¤å®š
        class_columns = []
        for col in ['ã‚¯ãƒ©ã‚¹', 'ã‚¯ãƒ©ã‚¹ã‚³ãƒ¼ãƒ‰', 'æ¡ä»¶']:
            if col in df.columns:
                class_columns.append(col)
                if self.class_column is None:  # æœ€åˆã«è¦‹ã¤ã‹ã£ãŸã‚¯ãƒ©ã‚¹é–¢é€£ã‚«ãƒ©ãƒ ã‚’ä½¿ç”¨
                    self.class_column = col
        
        required_columns = base_required_columns + class_columns + time_columns
        
        # å­˜åœ¨ã™ã‚‹ã‚«ãƒ©ãƒ ã®ã¿ã‚’é¸æŠ
        available_columns = [col for col in required_columns if col in df.columns]
        df = df[available_columns]

        # ãƒ¬ãƒ¼ã‚¹ãƒ¬ãƒ™ãƒ«é–¢é€£ã®ç‰¹å¾´é‡ã‚’è¿½åŠ 
        df["race_level"] = 0.0
        df["is_win"] = df["ç€é †"] == 1
        df["is_placed"] = df["ç€é †"] <= 3

        # åŸºæœ¬ãƒ¬ãƒ™ãƒ«ã®è¨ˆç®—
        df["grade_level"] = self._calculate_grade_level(df)
        df["venue_level"] = self._calculate_venue_level(df)
        df["prize_level"] = self._calculate_prize_level(df)
        
        # ã€é‡è¦ã€‘ãƒ¬ãƒãƒ¼ãƒˆè¨˜è¼‰ã®3è¦ç´ çµ±åˆrace_levelè¨ˆç®—
        df["distance_level"] = self._calculate_distance_level(df)
        
        # è¤‡å‹çµæœçµ±åˆå¾Œã®é‡ã¿ï¼ˆ5.0.2ç¯€å‚ç…§ï¼‰
        w_grade = 0.636
        w_venue = 0.323
        w_distance = 0.041
        
        # ã€æ”¹è‰¯ã€‘æ™‚é–“çš„åˆ†é›¢ã«ã‚ˆã‚‹è¤‡å‹çµæœçµ±åˆï¼ˆå¾ªç’°è«–ç†ã‚’å›é¿ï¼‰
        # åŸºæœ¬ãƒ¬ãƒ¼ã‚¹ãƒ¬ãƒ™ãƒ«ã‚’è¨ˆç®—
        base_race_level = (df["grade_level"] * w_grade + 
                          df["venue_level"] * w_venue + 
                          df["distance_level"] * w_distance)
        
        # è¤‡å‹çµæœã«ã‚ˆã‚‹é‡ã¿ä»˜ã‘ã‚’é©ç”¨ï¼ˆé¦¬ã®éå»å®Ÿç¸¾ãƒ™ãƒ¼ã‚¹ï¼‰
        df["race_level"] = self._apply_historical_result_weights(df, base_race_level)
        
        # RunningTimeåˆ†ææ©Ÿèƒ½ã‚’è¿½åŠ ï¼ˆæœ‰åŠ¹ãªå ´åˆã®ã¿ï¼‰
        if self.enable_time_analysis:
            df = self.calculate_running_time_features(df)

        return df

    def calculate_running_time_features(self, df: pd.DataFrame) -> pd.DataFrame:
        """èµ°ç ´ã‚¿ã‚¤ãƒ é–¢é€£ç‰¹å¾´é‡ã®è¨ˆç®—"""
        try:
            logger.info("ğŸƒ èµ°ç ´ã‚¿ã‚¤ãƒ ç‰¹å¾´é‡ã®è¨ˆç®—ã‚’é–‹å§‹...")
            
            # ã‚¿ã‚¤ãƒ ã‚«ãƒ©ãƒ ã®ç‰¹å®š
            time_column = None
            for col in ['ã‚¿ã‚¤ãƒ ', 'time', 'Time', 'èµ°ç ´ã‚¿ã‚¤ãƒ ']:
                if col in df.columns:
                    time_column = col
                    break
            
            if time_column is None:
                logger.warning("âš ï¸ ã‚¿ã‚¤ãƒ ã‚«ãƒ©ãƒ ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚RunningTimeåˆ†æã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™ã€‚")
                return df
            
            logger.info(f"ğŸ“Š ä½¿ç”¨ã™ã‚‹ã‚¿ã‚¤ãƒ ã‚«ãƒ©ãƒ : {time_column}")
            
            # ã‚¿ã‚¤ãƒ ãƒ‡ãƒ¼ã‚¿ã®å‰å‡¦ç†
            df[time_column] = pd.to_numeric(df[time_column], errors='coerce')
            
            # ç•°å¸¸å€¤ã®é™¤å»ï¼ˆ0ç§’ã‚„æ¥µç«¯ã«é…ã„ã‚¿ã‚¤ãƒ ï¼‰
            valid_time_mask = (df[time_column] > 60) & (df[time_column] < 600)  # 1åˆ†ã€œ10åˆ†ã®ç¯„å›²
            df = df[valid_time_mask].copy()
            
            logger.info(f"ğŸ“Š æœ‰åŠ¹ãªã‚¿ã‚¤ãƒ ãƒ‡ãƒ¼ã‚¿: {len(df):,}ä»¶")
            
            # 1. è·é›¢è£œæ­£ã‚¿ã‚¤ãƒ ã®è¨ˆç®—ï¼ˆ2000mæ›ç®—ï¼‰
            df['distance_adjusted_time'] = df[time_column] / df['è·é›¢'] * 2000
            
            # 2. åŒæ¡ä»¶å†…ã§ã®Z-scoreæ­£è¦åŒ–
            grouping_columns = ['å ´ã‚³ãƒ¼ãƒ‰', 'èŠãƒ€éšœå®³ã‚³ãƒ¼ãƒ‰']
            available_grouping = [col for col in grouping_columns if col in df.columns]
            
            if available_grouping:
                df['time_zscore'] = df.groupby(available_grouping)[time_column].transform(
                    lambda x: (x - x.mean()) / x.std() if x.std() > 0 else 0
                )
                logger.info(f"ğŸ“Š Z-scoreæ­£è¦åŒ–å®Œäº†ï¼ˆã‚°ãƒ«ãƒ¼ãƒ—åŒ–: {available_grouping}ï¼‰")
            else:
                # ã‚°ãƒ«ãƒ¼ãƒ—åŒ–ã§ããªã„å ´åˆã¯å…¨ä½“ã§Z-score
                df['time_zscore'] = (df[time_column] - df[time_column].mean()) / df[time_column].std()
                logger.info("ğŸ“Š Z-scoreæ­£è¦åŒ–å®Œäº†ï¼ˆå…¨ä½“å¹³å‡ï¼‰")
            
            # 3. é€Ÿåº¦æŒ‡æ¨™ã®è¨ˆç®—ï¼ˆm/åˆ†ï¼‰
            df['speed_index'] = df['è·é›¢'] / df[time_column] * 60
            
            # 4. è·é›¢åˆ¥åŸºæº–ã‚¿ã‚¤ãƒ ã¨ã®æ¯”è¼ƒ
            df['time_ratio'] = df.groupby('è·é›¢')[time_column].transform(
                lambda x: df.loc[x.index, time_column] / x.mean()
            )
            
            # 5. ã‚¿ã‚¤ãƒ ãƒ©ãƒ³ã‚­ãƒ³ã‚°ï¼ˆåŒãƒ¬ãƒ¼ã‚¹å†…ï¼‰
            df['time_rank_in_race'] = df.groupby(['å ´ã‚³ãƒ¼ãƒ‰', 'å¹´', 'å›', 'æ—¥', 'R'])[time_column].rank(method='min')
            
            logger.info("âœ… èµ°ç ´ã‚¿ã‚¤ãƒ ç‰¹å¾´é‡ã®è¨ˆç®—ãŒå®Œäº†ã—ã¾ã—ãŸ")
            logger.info(f"   - distance_adjusted_time: è·é›¢è£œæ­£ã‚¿ã‚¤ãƒ ï¼ˆ2000mæ›ç®—ï¼‰")
            logger.info(f"   - time_zscore: Z-scoreæ­£è¦åŒ–ã‚¿ã‚¤ãƒ ")
            logger.info(f"   - speed_index: é€Ÿåº¦æŒ‡æ¨™ï¼ˆm/åˆ†ï¼‰")
            logger.info(f"   - time_ratio: è·é›¢åˆ¥åŸºæº–ã‚¿ã‚¤ãƒ æ¯”")
            logger.info(f"   - time_rank_in_race: ãƒ¬ãƒ¼ã‚¹å†…ã‚¿ã‚¤ãƒ ãƒ©ãƒ³ã‚­ãƒ³ã‚°")
            
            return df
            
        except Exception as e:
            logger.error(f"âŒ èµ°ç ´ã‚¿ã‚¤ãƒ ç‰¹å¾´é‡è¨ˆç®—ä¸­ã«ã‚¨ãƒ©ãƒ¼: {str(e)}")
            return df

    def analyze_time_causality(self) -> Dict[str, Any]:
        """ã‚¿ã‚¤ãƒ é–¢é€£ã®å› æœåˆ†æ"""
        try:
            logger.info("ğŸ”¬ ã‚¿ã‚¤ãƒ å› æœåˆ†æã‚’é–‹å§‹...")
            
            results = {}
            
            # ãƒ‡ãƒ¼ã‚¿ã®æº–å‚™
            analysis_data = self.df.dropna(subset=['race_level', 'time_zscore', 'is_placed'])
            
            if len(analysis_data) == 0:
                logger.warning("âš ï¸ åˆ†æå¯èƒ½ãªãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“")
                return {}
            
            logger.info(f"ğŸ“Š åˆ†æå¯¾è±¡ãƒ‡ãƒ¼ã‚¿: {len(analysis_data):,}ä»¶")
            
            # 1. ä»®èª¬H1ã®æ¤œè¨¼: RaceLevel â†’ RunningTime
            h1_results = self.verify_hypothesis_h1(analysis_data)
            results['hypothesis_h1'] = h1_results
            
            # 2. ä»®èª¬H4ã®æ¤œè¨¼: RunningTime â†’ PlaceRate
            h4_results = self.verify_hypothesis_h4(analysis_data)
            results['hypothesis_h4'] = h4_results
            
            # 3. ç·åˆçš„ãªå› æœé–¢ä¿‚åˆ†æ
            comprehensive_results = self._analyze_comprehensive_causality(analysis_data)
            results['comprehensive_analysis'] = comprehensive_results
            
            self.time_analysis_results = results
            logger.info("âœ… ã‚¿ã‚¤ãƒ å› æœåˆ†æãŒå®Œäº†ã—ã¾ã—ãŸ")
            
            return results
            
        except Exception as e:
            logger.error(f"âŒ ã‚¿ã‚¤ãƒ å› æœåˆ†æä¸­ã«ã‚¨ãƒ©ãƒ¼: {str(e)}")
            return {}

    def verify_hypothesis_h2_baseline_comparison(self, horse_stats: pd.DataFrame) -> Dict[str, Any]:
        """
        ä»®èª¬H2ã®æ¤œè¨¼: HorseRaceLevelã‚’èª¬æ˜å¤‰æ•°ã«åŠ ãˆãŸå›å¸°ãƒ¢ãƒ‡ãƒ«ã¯ã€
        ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ï¼ˆå˜å‹ã‚ªãƒƒã‚ºãƒ¢ãƒ‡ãƒ«ç­‰ï¼‰ã‚ˆã‚Šé«˜ã„èª¬æ˜åŠ›ã‚’æŒã¤
        """
        try:
            logger.info("ğŸ§ª ä»®èª¬H2æ¤œè¨¼: ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³æ¯”è¼ƒåˆ†æ")
            
            # ãƒ‡ãƒ¼ã‚¿ã®æº–å‚™
            valid_data = horse_stats.dropna(subset=['avg_race_level', 'place_rate'])
            if len(valid_data) < 10:
                logger.warning("âš ï¸ H2æ¤œè¨¼: æœ‰åŠ¹ãƒ‡ãƒ¼ã‚¿ä¸è¶³")
                return {}
            
            results = {}
            
            # 1. ææ¡ˆæ‰‹æ³•ï¼ˆHorseRaceLevelï¼‰
            from sklearn.linear_model import LinearRegression
            from sklearn.metrics import r2_score, mean_squared_error
            from scipy.stats import pearsonr
            
            X_proposed = valid_data[['avg_race_level']].values
            y = valid_data['place_rate'].values
            
            model_proposed = LinearRegression()
            model_proposed.fit(X_proposed, y)
            y_pred_proposed = model_proposed.predict(X_proposed)
            
            r2_proposed = r2_score(y, y_pred_proposed)
            corr_proposed, p_proposed = pearsonr(valid_data['avg_race_level'], valid_data['place_rate'])
            
            results['proposed_model'] = {
                'r2': r2_proposed,
                'correlation': corr_proposed,
                'p_value': p_proposed,
                'model': model_proposed,
                'predictions': y_pred_proposed
            }
            
            # 2. ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³1: å˜ç´”å¹³å‡ãƒ¢ãƒ‡ãƒ«ï¼ˆå®šæ•°ãƒ¢ãƒ‡ãƒ«ï¼‰
            y_pred_baseline1 = np.full_like(y, np.mean(y))
            r2_baseline1 = r2_score(y, y_pred_baseline1)
            
            results['baseline_constant'] = {
                'r2': r2_baseline1,
                'description': 'å®šæ•°ãƒ¢ãƒ‡ãƒ«ï¼ˆå…¨é¦¬ã®å¹³å‡è¤‡å‹ç‡ï¼‰'
            }
            
            # 3. ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³2: å˜å‹ã‚ªãƒƒã‚ºãƒ™ãƒ¼ã‚¹ãƒ¢ãƒ‡ãƒ«ï¼ˆåˆ©ç”¨å¯èƒ½ãªå ´åˆï¼‰
            if 'å˜å‹ã‚ªãƒƒã‚º' in valid_data.columns:
                # ã‚ªãƒƒã‚ºã‚’ç¢ºç‡ã«å¤‰æ›ï¼ˆ1/ã‚ªãƒƒã‚ºï¼‰
                odds_prob = 1.0 / valid_data['å˜å‹ã‚ªãƒƒã‚º'].values
                odds_prob = np.clip(odds_prob, 0.01, 0.99)  # ç¢ºç‡ã®ç¯„å›²ã«åˆ¶é™
                
                model_odds = LinearRegression()
                X_odds = odds_prob.reshape(-1, 1)
                model_odds.fit(X_odds, y)
                y_pred_odds = model_odds.predict(X_odds)
                
                r2_odds = r2_score(y, y_pred_odds)
                corr_odds, p_odds = pearsonr(odds_prob, y)
                
                results['baseline_odds'] = {
                    'r2': r2_odds,
                    'correlation': corr_odds,
                    'p_value': p_odds,
                    'model': model_odds,
                    'description': 'å˜å‹ã‚ªãƒƒã‚ºãƒ™ãƒ¼ã‚¹ãƒ¢ãƒ‡ãƒ«'
                }
            
            # 4. ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³3: å‹åˆ©æ•°ãƒ™ãƒ¼ã‚¹ãƒ¢ãƒ‡ãƒ«
            if 'å‹åˆ©æ•°' in valid_data.columns:
                model_wins = LinearRegression()
                X_wins = valid_data[['å‹åˆ©æ•°']].values
                model_wins.fit(X_wins, y)
                y_pred_wins = model_wins.predict(X_wins)
                
                r2_wins = r2_score(y, y_pred_wins)
                corr_wins, p_wins = pearsonr(valid_data['å‹åˆ©æ•°'], valid_data['place_rate'])
                
                results['baseline_wins'] = {
                    'r2': r2_wins,
                    'correlation': corr_wins,
                    'p_value': p_wins,
                    'model': model_wins,
                    'description': 'å‹åˆ©æ•°ãƒ™ãƒ¼ã‚¹ãƒ¢ãƒ‡ãƒ«'
                }
            
            # 5. ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³4: å‡ºèµ°å›æ•°ãƒ™ãƒ¼ã‚¹ãƒ¢ãƒ‡ãƒ«
            if 'å‡ºèµ°å›æ•°' in valid_data.columns:
                model_races = LinearRegression()
                X_races = valid_data[['å‡ºèµ°å›æ•°']].values
                model_races.fit(X_races, y)
                y_pred_races = model_races.predict(X_races)
                
                r2_races = r2_score(y, y_pred_races)
                corr_races, p_races = pearsonr(valid_data['å‡ºèµ°å›æ•°'], valid_data['place_rate'])
                
                results['baseline_races'] = {
                    'r2': r2_races,
                    'correlation': corr_races,
                    'p_value': p_races,
                    'model': model_races,
                    'description': 'å‡ºèµ°å›æ•°ãƒ™ãƒ¼ã‚¹ãƒ¢ãƒ‡ãƒ«'
                }
            
            # 6. çµ±è¨ˆçš„æœ‰æ„æ€§ã®æ¯”è¼ƒ
            logger.info(f"ğŸ“Š H2æ¤œè¨¼çµæœ:")
            logger.info(f"   ææ¡ˆæ‰‹æ³• (HorseRaceLevel): RÂ²={r2_proposed:.4f}, r={corr_proposed:.3f}")
            
            for baseline_name, baseline_data in results.items():
                if baseline_name != 'proposed_model':
                    logger.info(f"   {baseline_data.get('description', baseline_name)}: RÂ²={baseline_data['r2']:.4f}")
            
            # 7. æ”¹å–„åº¦ã®è¨ˆç®—
            improvement_metrics = {}
            for baseline_name, baseline_data in results.items():
                if baseline_name != 'proposed_model' and 'r2' in baseline_data:
                    improvement = r2_proposed - baseline_data['r2']
                    improvement_metrics[baseline_name] = improvement
                    logger.info(f"   {baseline_data.get('description', baseline_name)} vs ææ¡ˆæ‰‹æ³•: {improvement:+.4f}")
            
            results['improvement_metrics'] = improvement_metrics
            results['sample_size'] = len(valid_data)
            
            return results
            
        except Exception as e:
            logger.error(f"âŒ H2æ¤œè¨¼ä¸­ã«ã‚¨ãƒ©ãƒ¼: {str(e)}")
            return {}

    def verify_hypothesis_h3_interaction_effects(self, horse_stats: pd.DataFrame) -> Dict[str, Any]:
        """
        ä»®èª¬H3ã®æ¤œè¨¼: ã“ã®é–¢ä¿‚ã¯è·é›¢ãƒ»ç«¶é¦¬å ´ã”ã¨ã«ç•°ãªã‚‹å‚¾å‘ã‚’ç¤ºã™ï¼ˆäº¤äº’ä½œç”¨ã®å­˜åœ¨ï¼‰
        """
        try:
            logger.info("ğŸ§ª ä»®èª¬H3æ¤œè¨¼: äº¤äº’ä½œç”¨åˆ†æ")
            
            # ãƒ‡ãƒ¼ã‚¿ã®æº–å‚™
            valid_data = horse_stats.dropna(subset=['avg_race_level', 'place_rate'])
            if len(valid_data) < 20:
                logger.warning("âš ï¸ H3æ¤œè¨¼: æœ‰åŠ¹ãƒ‡ãƒ¼ã‚¿ä¸è¶³")
                return {}
            
            results = {}
            
            # 1. è·é›¢ã‚«ãƒ†ã‚´ãƒªåˆ¥ã®äº¤äº’ä½œç”¨åˆ†æ
            if 'ä¸»æˆ¦è·é›¢' in valid_data.columns:
                # è·é›¢ã‚«ãƒ†ã‚´ãƒªã®ä½œæˆ
                valid_data = valid_data.copy()
                valid_data['distance_category'] = pd.cut(
                    valid_data['ä¸»æˆ¦è·é›¢'], 
                    bins=[0, 1400, 1800, 2000, 9999],
                    labels=['çŸ­è·é›¢', 'ãƒã‚¤ãƒ«', 'ä¸­è·é›¢', 'é•·è·é›¢']
                )
                
                distance_results = {}
                for category in valid_data['distance_category'].cat.categories:
                    category_data = valid_data[valid_data['distance_category'] == category]
                    if len(category_data) >= 5:
                        corr, p_value = pearsonr(category_data['avg_race_level'], category_data['place_rate'])
                        distance_results[category] = {
                            'correlation': corr,
                            'p_value': p_value,
                            'sample_size': len(category_data),
                            'mean_race_level': category_data['avg_race_level'].mean(),
                            'mean_place_rate': category_data['place_rate'].mean()
                        }
                
                results['distance_interaction'] = distance_results
                
                # è·é›¢ã‚«ãƒ†ã‚´ãƒªé–“ã®ç›¸é–¢ä¿‚æ•°ã®å·®ã®æ¤œå®š
                if len(distance_results) >= 2:
                    correlations = [data['correlation'] for data in distance_results.values()]
                    sample_sizes = [data['sample_size'] for data in distance_results.values()]
                    
                    # Fisher's Zå¤‰æ›ã«ã‚ˆã‚‹ç›¸é–¢ä¿‚æ•°ã®æ¯”è¼ƒ
                    from scipy.stats import norm
                    
                    z_scores = []
                    for i, (corr, n) in enumerate(zip(correlations, sample_sizes)):
                        if abs(corr) < 0.999:  # å®Œå…¨ç›¸é–¢ã‚’é¿ã‘ã‚‹
                            z = 0.5 * np.log((1 + corr) / (1 - corr))
                            se = 1 / np.sqrt(n - 3)
                            z_scores.append((z, se))
                    
                    if len(z_scores) >= 2:
                        # æœ€å¤§ã¨æœ€å°ã®ç›¸é–¢ä¿‚æ•°ã®å·®ã‚’æ¤œå®š
                        z_max, se_max = max(z_scores, key=lambda x: x[0])
                        z_min, se_min = min(z_scores, key=lambda x: x[0])
                        
                        z_diff = (z_max - z_min) / np.sqrt(se_max**2 + se_min**2)
                        p_diff = 2 * (1 - norm.cdf(abs(z_diff)))
                        
                        results['distance_interaction_test'] = {
                            'z_statistic': z_diff,
                            'p_value': p_diff,
                            'significant': p_diff < 0.05
                        }
            
            # 2. ç«¶é¦¬å ´åˆ¥ã®äº¤äº’ä½œç”¨åˆ†æ
            if 'ä¸»æˆ¦å ´' in valid_data.columns:
                venue_results = {}
                venue_counts = valid_data['ä¸»æˆ¦å ´'].value_counts()
                
                # ã‚µãƒ³ãƒ—ãƒ«æ•°ãŒååˆ†ãªç«¶é¦¬å ´ã®ã¿åˆ†æ
                major_venues = venue_counts[venue_counts >= 10].index
                
                for venue in major_venues:
                    venue_data = valid_data[valid_data['ä¸»æˆ¦å ´'] == venue]
                    if len(venue_data) >= 5:
                        corr, p_value = pearsonr(venue_data['avg_race_level'], venue_data['place_rate'])
                        venue_results[venue] = {
                            'correlation': corr,
                            'p_value': p_value,
                            'sample_size': len(venue_data),
                            'mean_race_level': venue_data['avg_race_level'].mean(),
                            'mean_place_rate': venue_data['place_rate'].mean()
                        }
                
                results['venue_interaction'] = venue_results
                
                # ç«¶é¦¬å ´é–“ã®ç›¸é–¢ä¿‚æ•°ã®å·®ã®æ¤œå®š
                if len(venue_results) >= 2:
                    correlations = [data['correlation'] for data in venue_results.values()]
                    sample_sizes = [data['sample_size'] for data in venue_results.values()]
                    
                    z_scores = []
                    for corr, n in zip(correlations, sample_sizes):
                        if abs(corr) < 0.999:
                            z = 0.5 * np.log((1 + corr) / (1 - corr))
                            se = 1 / np.sqrt(n - 3)
                            z_scores.append((z, se))
                    
                    if len(z_scores) >= 2:
                        z_max, se_max = max(z_scores, key=lambda x: x[0])
                        z_min, se_min = min(z_scores, key=lambda x: x[0])
                        
                        z_diff = (z_max - z_min) / np.sqrt(se_max**2 + se_min**2)
                        p_diff = 2 * (1 - norm.cdf(abs(z_diff)))
                        
                        results['venue_interaction_test'] = {
                            'z_statistic': z_diff,
                            'p_value': p_diff,
                            'significant': p_diff < 0.05
                        }
            
            # 3. å¤šå¤‰é‡å›å¸°ã«ã‚ˆã‚‹äº¤äº’ä½œç”¨é …ã®æ¤œå®š
            try:
                from sklearn.linear_model import LinearRegression
                from sklearn.preprocessing import StandardScaler
                
                # äº¤äº’ä½œç”¨é …ã‚’å«ã‚€ç‰¹å¾´é‡ã®æº–å‚™
                X_interaction = valid_data[['avg_race_level']].copy()
                
                # è·é›¢ã‚«ãƒ†ã‚´ãƒªã®ãƒ€ãƒŸãƒ¼å¤‰æ•°
                if 'distance_category' in valid_data.columns:
                    distance_dummies = pd.get_dummies(valid_data['distance_category'], prefix='dist')
                    X_interaction = pd.concat([X_interaction, distance_dummies], axis=1)
                    
                    # äº¤äº’ä½œç”¨é …ã®ä½œæˆ
                    for col in distance_dummies.columns:
                        interaction_col = f'race_level_x_{col}'
                        X_interaction[interaction_col] = valid_data['avg_race_level'] * distance_dummies[col]
                
                # ç«¶é¦¬å ´ã®ãƒ€ãƒŸãƒ¼å¤‰æ•°ï¼ˆä¸»è¦ãªç«¶é¦¬å ´ã®ã¿ï¼‰
                if 'ä¸»æˆ¦å ´' in valid_data.columns and len(major_venues) > 0:
                    venue_dummies = pd.get_dummies(valid_data['ä¸»æˆ¦å ´'], prefix='venue')
                    # ã‚µãƒ³ãƒ—ãƒ«æ•°ãŒå°‘ãªã„ç«¶é¦¬å ´ã¯é™¤å¤–
                    venue_dummies = venue_dummies.loc[:, venue_dummies.sum() >= 5]
                    X_interaction = pd.concat([X_interaction, venue_dummies], axis=1)
                    
                    # äº¤äº’ä½œç”¨é …ã®ä½œæˆ
                    for col in venue_dummies.columns:
                        interaction_col = f'race_level_x_{col}'
                        X_interaction[interaction_col] = valid_data['avg_race_level'] * venue_dummies[col]
                
                # å›å¸°åˆ†æã®å®Ÿè¡Œ
                y = valid_data['place_rate'].values
                model_interaction = LinearRegression()
                model_interaction.fit(X_interaction, y)
                
                # äº¤äº’ä½œç”¨é …ã®ä¿‚æ•°ã®æœ‰æ„æ€§ã‚’è©•ä¾¡
                interaction_coefs = {}
                feature_names = X_interaction.columns
                coefficients = model_interaction.coef_
                
                for i, (feature, coef) in enumerate(zip(feature_names, coefficients)):
                    if 'race_level_x_' in feature:
                        interaction_coefs[feature] = {
                            'coefficient': coef,
                            'feature_name': feature
                        }
                
                results['multivariate_interaction'] = {
                    'model': model_interaction,
                    'interaction_coefficients': interaction_coefs,
                    'r2_score': model_interaction.score(X_interaction, y),
                    'feature_names': feature_names.tolist(),
                    'coefficients': coefficients.tolist()
                }
                
            except Exception as e:
                logger.warning(f"âš ï¸ å¤šå¤‰é‡äº¤äº’ä½œç”¨åˆ†æã§ã‚¨ãƒ©ãƒ¼: {str(e)}")
                results['multivariate_interaction'] = {'error': str(e)}
            
            # 4. çµæœã®è¦ç´„
            logger.info(f"ğŸ“Š H3æ¤œè¨¼çµæœ:")
            if 'distance_interaction' in results:
                logger.info(f"   è·é›¢ã‚«ãƒ†ã‚´ãƒªåˆ¥ç›¸é–¢:")
                for category, data in results['distance_interaction'].items():
                    logger.info(f"     {category}: r={data['correlation']:.3f} (n={data['sample_size']})")
            
            if 'venue_interaction' in results:
                logger.info(f"   ç«¶é¦¬å ´åˆ¥ç›¸é–¢:")
                for venue, data in results['venue_interaction'].items():
                    logger.info(f"     {venue}: r={data['correlation']:.3f} (n={data['sample_size']})")
            
            results['sample_size'] = len(valid_data)
            return results
            
        except Exception as e:
            logger.error(f"âŒ H3æ¤œè¨¼ä¸­ã«ã‚¨ãƒ©ãƒ¼: {str(e)}")
            return {}

    def verify_hypothesis_h1(self, data: pd.DataFrame) -> Dict[str, Any]:
        """
        ä»®èª¬H1ã®æ¤œè¨¼: RaceLevelï¼ˆãƒ¬ãƒ¼ã‚¹æ ¼ï¼‰ãŒé«˜ã„ã»ã©ã€èµ°ç ´ã‚¿ã‚¤ãƒ ãŒé€Ÿããªã‚‹ï¼ˆè·é›¢è£œæ­£æ¸ˆã¿ï¼‰
        è·é›¢ãƒ»é¦¬å ´çŠ¶æ…‹ã‚’çµ±åˆ¶ã—ãŸå¤šå¤‰é‡å›å¸°åˆ†æ
        """
        try:
            logger.info("ğŸ§ª ä»®èª¬H1æ¤œè¨¼: RaceLevel â†’ RunningTime")
            
            # èª¬æ˜å¤‰æ•°ã®æº–å‚™
            X = data[['race_level']].copy()
            
            # è·é›¢ã‚«ãƒ†ã‚´ãƒªã®è¿½åŠ ï¼ˆçµ±åˆ¶å¤‰æ•°ï¼‰
            data['distance_category'] = pd.cut(data['è·é›¢'], 
                                             bins=[0, 1400, 1800, 2000, 2400, 9999],
                                             labels=['sprint', 'mile', 'middle', 'long', 'extra_long'])
            
            # ã‚«ãƒ†ã‚´ãƒªå¤‰æ•°ã®ãƒ€ãƒŸãƒ¼åŒ–
            distance_dummies = pd.get_dummies(data['distance_category'], prefix='dist')
            X = pd.concat([X, distance_dummies], axis=1)
            
            # é¦¬å ´çŠ¶æ…‹ã®çµ±åˆ¶ï¼ˆå­˜åœ¨ã™ã‚‹å ´åˆï¼‰
            if 'é¦¬å ´çŠ¶æ…‹' in data.columns:
                track_dummies = pd.get_dummies(data['é¦¬å ´çŠ¶æ…‹'], prefix='track')
                X = pd.concat([X, track_dummies], axis=1)
            
            # ç›®çš„å¤‰æ•°ï¼ˆã‚¿ã‚¤ãƒ ãŒé€Ÿã„æ–¹ãŒè² ã®å€¤ã«ãªã‚‹ãŸã‚ã€ç¬¦å·ã‚’åè»¢ï¼‰
            y = -data['time_zscore']  # é€Ÿã„ã‚¿ã‚¤ãƒ  = é«˜ã„å€¤
            
            # å›å¸°åˆ†æã®å®Ÿè¡Œ
            model = LinearRegression()
            model.fit(X, y)
            
            y_pred = model.predict(X)
            r2 = r2_score(y, y_pred)
            mse = mean_squared_error(y, y_pred)
            
            # çµ±è¨ˆçš„æœ‰æ„æ€§ã®æ¤œå®š
            correlation = data['race_level'].corr(-data['time_zscore'])
            n = len(data)
            t_stat = correlation * np.sqrt((n - 2) / (1 - correlation**2))
            p_value = 2 * (1 - stats.t.cdf(abs(t_stat), n - 2))
            
            results = {
                'model': model,
                'r2_score': r2,
                'mse': mse,
                'correlation': correlation,
                'p_value': p_value,
                'sample_size': n,
                'is_significant': p_value < 0.05,
                'effect_direction': 'positive' if correlation > 0 else 'negative',
                'interpretation': self._interpret_h1_results(correlation, p_value, r2)
            }
            
            logger.info(f"   ğŸ“Š ç›¸é–¢ä¿‚æ•°: {correlation:.3f}")
            logger.info(f"   ğŸ“Š æ±ºå®šä¿‚æ•°: {r2:.3f}")
            logger.info(f"   ğŸ“Š på€¤: {p_value:.6f}")
            logger.info(f"   ğŸ“Š çµ±è¨ˆçš„æœ‰æ„æ€§: {'æœ‰æ„' if p_value < 0.05 else 'éæœ‰æ„'}")
            
            return results
            
        except Exception as e:
            logger.error(f"âŒ ä»®èª¬H1æ¤œè¨¼ä¸­ã«ã‚¨ãƒ©ãƒ¼: {str(e)}")
            return {}

    def verify_hypothesis_h4(self, data: pd.DataFrame) -> Dict[str, Any]:
        """
        ä»®èª¬H4ã®æ¤œè¨¼: RunningTime ãŒé€Ÿã„ã»ã©è¤‡å‹ç‡ãŒé«˜ã„
        ãƒ­ã‚¸ã‚¹ãƒ†ã‚£ãƒƒã‚¯å›å¸°åˆ†æï¼ˆè·é›¢ãƒ»é¦¬å ´ãƒã‚¤ã‚¢ã‚¹èª¿æ•´ï¼‰
        """
        try:
            logger.info("ğŸ§ª ä»®èª¬H4æ¤œè¨¼: RunningTime â†’ PlaceRate")
            
            # èª¬æ˜å¤‰æ•°ã®æº–å‚™
            X = data[['time_zscore', 'race_level']].copy()
            
            # è·é›¢ã®çµ±åˆ¶
            X['distance'] = data['è·é›¢']
            
            # ç›®çš„å¤‰æ•°
            y = data['is_placed']
            
            # ãƒ­ã‚¸ã‚¹ãƒ†ã‚£ãƒƒã‚¯å›å¸°ã®å®Ÿè¡Œ
            model = LogisticRegression(random_state=42)
            model.fit(X, y)
            
            y_pred = model.predict(X)
            y_pred_proba = model.predict_proba(X)[:, 1]
            
            # è©•ä¾¡æŒ‡æ¨™ã®è¨ˆç®—
            accuracy = accuracy_score(y, y_pred)
            
            # ã‚ªãƒƒã‚ºæ¯”ã®è¨ˆç®—
            odds_ratios = np.exp(model.coef_[0])
            
            # ç›¸é–¢ä¿‚æ•°ã®è¨ˆç®—ï¼ˆtime_zscoreãŒè² ã®å€¤ãªã®ã§ç¬¦å·ã‚’èª¿æ•´ï¼‰
            correlation = (-data['time_zscore']).corr(data['is_placed'])
            
            # çµ±è¨ˆçš„æœ‰æ„æ€§ã®æ¤œå®š
            n = len(data)
            t_stat = correlation * np.sqrt((n - 2) / (1 - correlation**2))
            p_value = 2 * (1 - stats.t.cdf(abs(t_stat), n - 2))
            
            results = {
                'model': model,
                'accuracy': accuracy,
                'odds_ratios': odds_ratios,
                'correlation': correlation,
                'p_value': p_value,
                'sample_size': n,
                'is_significant': p_value < 0.05,
                'predictions': y_pred_proba,
                'interpretation': self._interpret_h4_results(correlation, p_value, odds_ratios[0])
            }
            
            logger.info(f"   ğŸ“Š ç›¸é–¢ä¿‚æ•°: {correlation:.3f}")
            logger.info(f"   ğŸ“Š ç²¾åº¦: {accuracy:.3f}")
            logger.info(f"   ğŸ“Š ã‚¿ã‚¤ãƒ ã®ã‚ªãƒƒã‚ºæ¯”: {odds_ratios[0]:.3f}")
            logger.info(f"   ğŸ“Š på€¤: {p_value:.6f}")
            logger.info(f"   ğŸ“Š çµ±è¨ˆçš„æœ‰æ„æ€§: {'æœ‰æ„' if p_value < 0.05 else 'éæœ‰æ„'}\n")
            
            return results
            
        except Exception as e:
            logger.error(f"âŒ ä»®èª¬H4æ¤œè¨¼ä¸­ã«ã‚¨ãƒ©ãƒ¼: {str(e)}")
            return {}

    def _analyze_comprehensive_causality(self, data: pd.DataFrame) -> Dict[str, Any]:
        """åŒ…æ‹¬çš„ãªå› æœé–¢ä¿‚åˆ†æ"""
        try:
            logger.info("ğŸ”¬ åŒ…æ‹¬çš„å› æœé–¢ä¿‚åˆ†æã‚’å®Ÿè¡Œ...")
            
            results = {}
            
            # 1. RaceLevel â†’ Time â†’ PlaceRate ã®åª’ä»‹åŠ¹æœåˆ†æï¼ˆç°¡æ˜“ç‰ˆï¼‰
            # ã‚¹ãƒ†ãƒƒãƒ—1: RaceLevel â†’ PlaceRate ã®ç›´æ¥åŠ¹æœ
            direct_corr = data['race_level'].corr(data['is_placed'])
            
            # ã‚¹ãƒ†ãƒƒãƒ—2: RaceLevel â†’ Time ã®åŠ¹æœ
            race_time_corr = data['race_level'].corr(-data['time_zscore'])
            
            # ã‚¹ãƒ†ãƒƒãƒ—3: Time â†’ PlaceRate ã®åŠ¹æœï¼ˆRaceLevelã‚’çµ±åˆ¶ï¼‰
            partial_corr = self._calculate_partial_correlation(
                data['time_zscore'], data['is_placed'], data['race_level']
            )
            
            # åª’ä»‹åŠ¹æœã®æ¨å®š
            indirect_effect = race_time_corr * partial_corr
            direct_effect_controlled = direct_corr - indirect_effect
            
            mediation_results = {
                'total_effect': direct_corr,
                'direct_effect': direct_effect_controlled,
                'indirect_effect': indirect_effect,
                'mediation_ratio': indirect_effect / direct_corr if direct_corr != 0 else 0
            }
            
            results['mediation_analysis'] = mediation_results
            
            # 2. è·é›¢åˆ¥ã®åŠ¹æœåˆ†æ
            distance_effects = {}
            distance_categories = ['sprint', 'mile', 'middle', 'long']
            
            for category in distance_categories:
                if category == 'sprint':
                    mask = data['è·é›¢'] <= 1400
                elif category == 'mile':
                    mask = (data['è·é›¢'] > 1400) & (data['è·é›¢'] <= 1800)
                elif category == 'middle':
                    mask = (data['è·é›¢'] > 1800) & (data['è·é›¢'] <= 2400)
                else:  # long
                    mask = data['è·é›¢'] > 2400
                
                if mask.sum() > 10:  # ååˆ†ãªãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚‹å ´åˆã®ã¿
                    subset = data[mask]
                    corr_level_time = subset['race_level'].corr(-subset['time_zscore'])
                    corr_time_place = (-subset['time_zscore']).corr(subset['is_placed'])
                    
                    distance_effects[category] = {
                        'sample_size': len(subset),
                        'race_level_time_correlation': corr_level_time,
                        'time_place_correlation': corr_time_place
                    }
            
            results['distance_specific_effects'] = distance_effects
            
            logger.info("âœ… åŒ…æ‹¬çš„å› æœé–¢ä¿‚åˆ†æãŒå®Œäº†ã—ã¾ã—ãŸ")
            
            return results
            
        except Exception as e:
            logger.error(f"âŒ åŒ…æ‹¬çš„å› æœé–¢ä¿‚åˆ†æä¸­ã«ã‚¨ãƒ©ãƒ¼: {str(e)}")
            return {}

    def _calculate_partial_correlation(self, x, y, control_var):
        """åç›¸é–¢ä¿‚æ•°ã®è¨ˆç®—"""
        try:
            # xã¨control_varã®å›å¸°æ®‹å·®
            model_x = LinearRegression()
            model_x.fit(control_var.values.reshape(-1, 1), x)
            residual_x = x - model_x.predict(control_var.values.reshape(-1, 1))
            
            # yã¨control_varã®å›å¸°æ®‹å·®
            model_y = LinearRegression()
            model_y.fit(control_var.values.reshape(-1, 1), y)
            residual_y = y - model_y.predict(control_var.values.reshape(-1, 1))
            
            # æ®‹å·®é–“ã®ç›¸é–¢ä¿‚æ•°
            return pd.Series(residual_x).corr(pd.Series(residual_y))
            
        except Exception:
            return 0.0

    def _perform_logistic_regression_analysis(self) -> Dict[str, Any]:
        """ãƒ­ã‚¸ã‚¹ãƒ†ã‚£ãƒƒã‚¯å›å¸°åˆ†æã‚’å®Ÿè¡Œ"""
        df = self.df.copy()
        df['is_win_or_place'] = df['ç€é †'].apply(lambda x: 1 if x in [1, 2] else 0)
        df['is_placed_only'] = df['ç€é †'].apply(lambda x: 1 if x <= 3 else 0)
        
        # NAå€¤ã¨ç„¡é™å¤§å€¤ã®å‡¦ç†
        df['race_level'] = df['race_level'].fillna(0)
        df['race_level'] = df['race_level'].replace([np.inf, -np.inf], df['race_level'].replace([np.inf, -np.inf], np.nan).max())
        
        # å‹ç‡ã®ãƒ¢ãƒ‡ãƒ«
        X_win = df[['race_level']].values
        y_win = df['is_win_or_place'].values
        
        # è¤‡å‹ç‡ã®ãƒ¢ãƒ‡ãƒ«
        X_place = df[['race_level']].values
        y_place = df['is_placed_only'].values
        
        # æ¨™æº–åŒ–
        scaler_win = StandardScaler()
        X_win_scaled = scaler_win.fit_transform(X_win)
        
        scaler_place = StandardScaler()
        X_place_scaled = scaler_place.fit_transform(X_place)
        
        # ãƒ‡ãƒ¼ã‚¿åˆ†å‰²ï¼ˆå±¤åŒ–ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ï¼‰
        X_win_train, X_win_test, y_win_train, y_win_test = train_test_split(
            X_win_scaled, y_win, test_size=0.3, random_state=42, stratify=y_win
        )
        
        X_place_train, X_place_test, y_place_train, y_place_test = train_test_split(
            X_place_scaled, y_place, test_size=0.3, random_state=42, stratify=y_place
        )
        
        # ã‚¯ãƒ©ã‚¹ãƒãƒ©ãƒ³ã‚¹ã‚’è€ƒæ…®ã—ãŸãƒ­ã‚¸ã‚¹ãƒ†ã‚£ãƒƒã‚¯å›å¸°ï¼ˆå‹ç‡ï¼‰
        model_win = LogisticRegression(
            random_state=42,
            max_iter=1000,
            class_weight='balanced',
            solver='liblinear'
        )
        model_win.fit(X_win_train, y_win_train)
        
        # ã‚¯ãƒ©ã‚¹ãƒãƒ©ãƒ³ã‚¹ã‚’è€ƒæ…®ã—ãŸãƒ­ã‚¸ã‚¹ãƒ†ã‚£ãƒƒã‚¯å›å¸°ï¼ˆè¤‡å‹ç‡ï¼‰
        model_place = LogisticRegression(
            random_state=42,
            max_iter=1000,
            class_weight='balanced',
            solver='liblinear'
        )
        model_place.fit(X_place_train, y_place_train)
        
        # äºˆæ¸¬ã¨è©•ä¾¡ï¼ˆå‹ç‡ï¼‰
        y_win_pred = model_win.predict(X_win_test)
        accuracy_win = accuracy_score(y_win_test, y_win_pred)
        report_win = classification_report(y_win_test, y_win_pred, zero_division=0)
        conf_matrix_win = confusion_matrix(y_win_test, y_win_pred)
        
        # äºˆæ¸¬ã¨è©•ä¾¡ï¼ˆè¤‡å‹ç‡ï¼‰
        y_place_pred = model_place.predict(X_place_test)
        accuracy_place = accuracy_score(y_place_test, y_place_pred)
        report_place = classification_report(y_place_test, y_place_pred, zero_division=0)
        conf_matrix_place = confusion_matrix(y_place_test, y_place_pred)
        
        return {
            "win": {
                "model": model_win,
                "scaler": scaler_win,
                "accuracy": accuracy_win,
                "report": report_win,
                "conf_matrix": conf_matrix_win,
            },
            "place": {
                "model": model_place,
                "scaler": scaler_place,
                "accuracy": accuracy_place,
                "report": report_place,
                "conf_matrix": conf_matrix_place,
            },
            "data": df
        }

    def perform_time_series_split(self) -> Tuple[pd.DataFrame, pd.DataFrame, pd.DataFrame]:
        """
        ã€ä¿®æ­£ã€‘æ¨™æº–çš„ãªãƒ‡ãƒ¼ã‚¿åˆ†å‰²æ¯”ç‡ã«åŸºã¥ãå³å¯†ãªæ™‚ç³»åˆ—åˆ†å‰²ã®å®Ÿè£…
        - è¨“ç·´æœŸé–“: 70% (2010,2013-2020å¹´)ï¼ˆé‡ã¿ç®—å‡ºãƒ»ãƒ¢ãƒ‡ãƒ«è¨“ç·´å°‚ç”¨ï¼‰
        - æ¤œè¨¼æœŸé–“: 15% (2021-2022å¹´)ï¼ˆãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿èª¿æ•´å°‚ç”¨ï¼‰
        - ãƒ†ã‚¹ãƒˆæœŸé–“: 15% (2023-2025å¹´)ï¼ˆæœ€çµ‚æ€§èƒ½è©•ä¾¡å°‚ç”¨ï¼‰
        """
        try:
            logger.info("ğŸ“… å³å¯†ãªæ™‚ç³»åˆ—åˆ†å‰²ã‚’å®Ÿè¡Œä¸­...")
            
            # å¹´ã‚«ãƒ©ãƒ ã®ç¢ºèªã¨ä½œæˆ
            if 'å¹´' not in self.df.columns:
                if 'å¹´æœˆæ—¥' in self.df.columns:
                    self.df['å¹´'] = pd.to_datetime(self.df['å¹´æœˆæ—¥'].astype(str), format='%Y%m%d').dt.year
                else:
                    logger.error("âŒ å¹´ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚æ™‚ç³»åˆ—åˆ†å‰²ã‚’å®Ÿè¡Œã§ãã¾ã›ã‚“ã€‚")
                    raise ValueError("å¹´ãƒ‡ãƒ¼ã‚¿ãŒå¿…è¦ã§ã™")
            
            # ğŸ¯ ã€ä¿®æ­£ã€‘æ¨™æº–çš„åˆ†å‰²æ¯”ç‡ï¼ˆ70-15-15ï¼‰ã«åŸºã¥ãæœŸé–“è¨­å®š
            all_years = sorted(self.df['å¹´'].unique())
            logger.info(f"ğŸ“Š åˆ©ç”¨å¯èƒ½ãƒ‡ãƒ¼ã‚¿æœŸé–“: {all_years[0]}å¹´-{all_years[-1]}å¹´ï¼ˆ{len(all_years)}å¹´é–“ï¼‰")
            
            # ã€ä¿®æ­£ã€‘æœŸé–“ãŒçŸ­ã„å ´åˆã®ç‰¹åˆ¥å‡¦ç†
            total_years = len(all_years)
            if total_years <= 3:
                logger.warning(f"âš ï¸ ãƒ‡ãƒ¼ã‚¿æœŸé–“ãŒçŸ­ã„ã§ã™ï¼ˆ{total_years}å¹´ï¼‰ã€‚æœŸé–“åˆ¥åˆ†æç”¨ã®ç°¡æ˜“åˆ†å‰²ã‚’ä½¿ç”¨ã—ã¾ã™ã€‚")
                # çŸ­æœŸé–“ã®å ´åˆã¯2:1:1ã®æ¯”ç‡ã§åˆ†å‰²ï¼ˆæœ€ä½1å¹´ãšã¤ï¼‰
                if total_years == 1:
                    # 1å¹´ã®å ´åˆã¯å…¨ãƒ‡ãƒ¼ã‚¿ã‚’ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã¨ã—ã¦ä½¿ç”¨
                    train_years = []
                    val_years = []
                    test_years = all_years
                elif total_years == 2:
                    # 2å¹´ã®å ´åˆã¯1:0:1ã§åˆ†å‰²
                    train_years = all_years[:1]
                    val_years = []
                    test_years = all_years[1:]
                else:  # total_years == 3
                    # 3å¹´ã®å ´åˆã¯1:1:1ã§åˆ†å‰²
                    train_years = all_years[:1]
                    val_years = all_years[1:2]
                    test_years = all_years[2:]
            else:
                # 70-15-15åˆ†å‰²ã®è¨ˆç®—
                train_years_count = max(1, int(total_years * 0.7))  # æœ€ä½1å¹´
                val_years_count = max(1, int(total_years * 0.15))   # æœ€ä½1å¹´
                test_years_count = total_years - train_years_count - val_years_count  # æ®‹ã‚Š
                
                # æ™‚ç³»åˆ—é †ã§ã®åˆ†å‰²
                train_years = all_years[:train_years_count]
                val_years = all_years[train_years_count:train_years_count + val_years_count]
                test_years = all_years[train_years_count + val_years_count:]
            
            logger.info(f"ğŸ“… æ¨™æº–çš„åˆ†å‰²æ¯”ç‡ã«ã‚ˆã‚‹æœŸé–“è¨­å®š:")
            logger.info(f"   è¨“ç·´æœŸé–“: {train_years} ({len(train_years)}å¹´, ç´„70%)")
            logger.info(f"   æ¤œè¨¼æœŸé–“: {val_years} ({len(val_years)}å¹´, ç´„15%)")
            logger.info(f"   ãƒ†ã‚¹ãƒˆæœŸé–“: {test_years} ({len(test_years)}å¹´, ç´„15%)")
            
            # å„æœŸé–“ã®ãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆ
            train_data = self.df[self.df['å¹´'].isin(train_years)].copy()
            val_data = self.df[self.df['å¹´'].isin(val_years)].copy()
            test_data = self.df[self.df['å¹´'].isin(test_years)].copy()
            
            # ãƒ‡ãƒ¼ã‚¿é‡ã®ç¢ºèª
            total_records = len(self.df)
            train_count = len(train_data)
            val_count = len(val_data)
            test_count = len(test_data)
            
            logger.info(f"ğŸ“Š åˆ†å‰²å¾Œãƒ‡ãƒ¼ã‚¿é‡:")
            logger.info(f"   è¨“ç·´: {train_count:,}ä»¶ ({train_count/total_records*100:.1f}%)")
            logger.info(f"   æ¤œè¨¼: {val_count:,}ä»¶ ({val_count/total_records*100:.1f}%)")
            logger.info(f"   ãƒ†ã‚¹ãƒˆ: {test_count:,}ä»¶ ({test_count/total_records*100:.1f}%)")
            
            # åˆ†å‰²å“è³ªã®æ¤œè¨¼
            train_pct = train_count/total_records*100
            val_pct = val_count/total_records*100
            test_pct = test_count/total_records*100
            
            if 60 <= train_pct <= 80 and 10 <= val_pct <= 25 and 10 <= test_pct <= 25:
                logger.info("âœ… æ¨™æº–çš„ãªåˆ†å‰²æ¯”ç‡ã«é©åˆï¼ˆè¨“ç·´60-80%, æ¤œè¨¼ãƒ»ãƒ†ã‚¹ãƒˆå„10-25%ï¼‰")
            else:
                logger.warning(f"âš ï¸ åˆ†å‰²æ¯”ç‡ãŒæ¨™æº–ã‹ã‚‰é€¸è„±: è¨“ç·´{train_pct:.1f}% æ¤œè¨¼{val_pct:.1f}% ãƒ†ã‚¹ãƒˆ{test_pct:.1f}%")
            
            logger.info(f"ğŸ“Š æœ€çµ‚ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ:")
            if train_years:
                logger.info(f"   è¨“ç·´æœŸé–“ãƒ‡ãƒ¼ã‚¿: {len(train_data):,}è¡Œ ({train_years[0]}-{train_years[-1]}å¹´)")
            else:
                logger.info(f"   è¨“ç·´æœŸé–“ãƒ‡ãƒ¼ã‚¿: {len(train_data):,}è¡Œ (æœŸé–“ãªã—)")
            
            if val_years:
                logger.info(f"   æ¤œè¨¼æœŸé–“ãƒ‡ãƒ¼ã‚¿: {len(val_data):,}è¡Œ ({val_years[0]}-{val_years[-1]}å¹´)")
            else:
                logger.info(f"   æ¤œè¨¼æœŸé–“ãƒ‡ãƒ¼ã‚¿: {len(val_data):,}è¡Œ (æœŸé–“ãªã—)")
            
            if test_years:
                logger.info(f"   ãƒ†ã‚¹ãƒˆæœŸé–“ãƒ‡ãƒ¼ã‚¿: {len(test_data):,}è¡Œ ({test_years[0]}-{test_years[-1]}å¹´)")
            else:
                logger.info(f"   ãƒ†ã‚¹ãƒˆæœŸé–“ãƒ‡ãƒ¼ã‚¿: {len(test_data):,}è¡Œ (æœŸé–“ãªã—)")
            
            # ãƒ‡ãƒ¼ã‚¿å……è¶³æ€§ã®ç¢ºèª
            if len(train_data) < 1000:
                logger.warning(f"âš ï¸ è¨“ç·´ãƒ‡ãƒ¼ã‚¿ãŒä¸è¶³ã—ã¦ã„ã¾ã™: {len(train_data)}è¡Œ")
            if len(val_data) < 1000:
                logger.warning(f"âš ï¸ æ¤œè¨¼ãƒ‡ãƒ¼ã‚¿ãŒä¸è¶³ã—ã¦ã„ã¾ã™: {len(val_data)}è¡Œ")
            if len(test_data) < 1000:
                logger.warning(f"âš ï¸ ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ãŒä¸è¶³ã—ã¦ã„ã¾ã™: {len(test_data)}è¡Œ")
            
            # é¦¬æ•°ã®ç¢ºèª
            train_horses = train_data['é¦¬å'].nunique()
            val_horses = val_data['é¦¬å'].nunique()
            test_horses = test_data['é¦¬å'].nunique()
            logger.info(f"ğŸ“Š é¦¬æ•°åˆ†å¸ƒ:")
            logger.info(f"   è¨“ç·´æœŸé–“é¦¬æ•°: {train_horses:,}é ­")
            logger.info(f"   æ¤œè¨¼æœŸé–“é¦¬æ•°: {val_horses:,}é ­")
            logger.info(f"   ãƒ†ã‚¹ãƒˆæœŸé–“é¦¬æ•°: {test_horses:,}é ­")
            
            return train_data, val_data, test_data
            
        except Exception as e:
            error_msg = str(e)
            logger.error(f"âŒ æ™‚ç³»åˆ—åˆ†å‰²ã‚¨ãƒ©ãƒ¼: {error_msg}")
            logger.error("ğŸ’¡ è©³ç´°è¨ºæ–­:")
            logger.error(f"   â€¢ ãƒ‡ãƒ¼ã‚¿æœŸé–“: {self.df['å¹´'].min() if 'å¹´' in self.df.columns else 'ä¸æ˜'}-{self.df['å¹´'].max() if 'å¹´' in self.df.columns else 'ä¸æ˜'}å¹´")
            logger.error(f"   â€¢ ç·ãƒ‡ãƒ¼ã‚¿æ•°: {len(self.df):,}ä»¶")
            logger.error(f"   â€¢ å¹´ãƒ‡ãƒ¼ã‚¿ã®å­˜åœ¨: {'å¹´' in self.df.columns}")
            
            if "list index out of range" in error_msg:
                logger.error("ğŸ’¡ è§£æ±ºæ–¹æ³•:")
                logger.error("   â€¢ ãƒ‡ãƒ¼ã‚¿æœŸé–“ãŒçŸ­ã™ãã¾ã™ï¼ˆæœ€ä½3å¹´å¿…è¦ï¼‰")
                logger.error("   â€¢ æœŸé–“æŒ‡å®šã‚’å‰Šé™¤ã—ã¦å…¨æœŸé–“ã§å®Ÿè¡Œã—ã¦ãã ã•ã„")
                logger.error("   â€¢ ã¾ãŸã¯ã€ã‚ˆã‚Šé•·ã„æœŸé–“ã‚’æŒ‡å®šã—ã¦ãã ã•ã„")
            
            logger.error(f"ğŸ” ã‚¨ãƒ©ãƒ¼è©³ç´°: {type(e).__name__}: {error_msg}")
            raise

    def perform_out_of_time_validation(self, train_data: pd.DataFrame, test_data: pd.DataFrame) -> Dict[str, Any]:
        """
        ã€é‡è¦ã€‘Out-of-Timeæ¤œè¨¼ã®å®Ÿè£…
        è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã§é‡ã¿ç®—å‡ºã€æ¤œè¨¼ãƒ‡ãƒ¼ã‚¿ã§æ€§èƒ½è©•ä¾¡
        """
        try:
            logger.info("ğŸ”¬ Out-of-Timeæ¤œè¨¼ã‚’å®Ÿè¡Œä¸­...")
            
            # ã€ä¿®æ­£ã€‘è¨“ç·´ãƒ‡ãƒ¼ã‚¿ãŒç©ºã®å ´åˆã®å‡¦ç†
            if len(train_data) == 0:
                logger.warning("âš ï¸ è¨“ç·´ãƒ‡ãƒ¼ã‚¿ãŒç©ºã§ã™ã€‚ç°¡æ˜“åˆ†æãƒ¢ãƒ¼ãƒ‰ã§å®Ÿè¡Œã—ã¾ã™ã€‚")
                # ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã®ã¿ã§åˆ†æ
                test_horse_stats = self._calculate_horse_stats_for_data(test_data)
                
                # ç°¡æ˜“é‡ã¿ã‚’ä½¿ç”¨
                simple_weights = {'grade_weight': 0.618, 'venue_weight': 0.337, 'distance_weight': 0.045}
                test_performance = self._evaluate_weights_on_test_data(simple_weights, test_horse_stats)
                
                return {
                    'train_period': 'N/A (ç°¡æ˜“ãƒ¢ãƒ¼ãƒ‰)',
                    'test_period': f"{test_data['å¹´'].min()}-{test_data['å¹´'].max()}",
                    'train_sample_size': 0,
                    'test_sample_size': len(test_horse_stats),
                    'optimal_weights': simple_weights,
                    'test_performance': test_performance,
                    'mode': 'simple_analysis'
                }
            
            # 1. è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã§é¦¬ã”ã¨çµ±è¨ˆã‚’è¨ˆç®—
            logger.info("ğŸ“Š è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã§é¦¬ã”ã¨çµ±è¨ˆã‚’è¨ˆç®—ä¸­...")
            train_horse_stats = self._calculate_horse_stats_for_data(train_data)
            
            # 2. è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã§é‡ã¿ã‚’ç®—å‡º
            logger.info("âš–ï¸ è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã§é‡ã¿ã‚’ç®—å‡ºä¸­...")
            train_weights = self._calculate_optimal_weights(train_horse_stats)
            
            # 3. æ¤œè¨¼ãƒ‡ãƒ¼ã‚¿ã§é¦¬ã”ã¨çµ±è¨ˆã‚’è¨ˆç®—ï¼ˆæœªæ¥æƒ…å ±ã‚’ä½¿ã‚ãªã„ï¼‰
            logger.info("ğŸ“Š æ¤œè¨¼ãƒ‡ãƒ¼ã‚¿ã§é¦¬ã”ã¨çµ±è¨ˆã‚’è¨ˆç®—ä¸­...")
            test_horse_stats = self._calculate_horse_stats_for_data(test_data)
            
            # 4. è¨“ç·´ã§ç®—å‡ºã—ãŸé‡ã¿ã‚’æ¤œè¨¼ãƒ‡ãƒ¼ã‚¿ã«é©ç”¨
            logger.info("ğŸ¯ è¨“ç·´é‡ã¿ã‚’æ¤œè¨¼ãƒ‡ãƒ¼ã‚¿ã«é©ç”¨ä¸­...")
            test_performance = self._evaluate_weights_on_test_data(train_weights, test_horse_stats)
            
            results = {
                'train_period': '2010-2012',
                'test_period': '2013-2014',
                'train_sample_size': len(train_horse_stats),
                'test_sample_size': len(test_horse_stats),
                'optimal_weights': train_weights,
                'test_performance': test_performance,
                'data_leakage_prevented': True
            }
            
            logger.info(f"âœ… Out-of-Timeæ¤œè¨¼å®Œäº†")
            logger.info(f"   ğŸ“Š è¨“ç·´æœŸé–“æ€§èƒ½: RÂ²={train_weights.get('train_r2', 0):.3f}")
            logger.info(f"   ğŸ“Š æ¤œè¨¼æœŸé–“æ€§èƒ½: RÂ²={test_performance.get('r_squared', 0):.3f}")
            logger.info(f"   ğŸ“Š æ±åŒ–æ€§èƒ½: {test_performance.get('r_squared', 0)/train_weights.get('train_r2', 1)*100:.1f}%")
            
            return results
            
        except Exception as e:
            logger.error(f"âŒ Out-of-Timeæ¤œè¨¼ã‚¨ãƒ©ãƒ¼: {str(e)}")
            return {}

    def _calculate_horse_stats_for_data(self, data: pd.DataFrame) -> pd.DataFrame:
        """æŒ‡å®šã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ã§é¦¬ã”ã¨çµ±è¨ˆã‚’è¨ˆç®—ï¼ˆãƒ‡ãƒ¼ã‚¿ãƒªãƒ¼ã‚±ãƒ¼ã‚¸é˜²æ­¢ï¼‰"""
        try:
            # å¿…è¦ãªã‚«ãƒ©ãƒ ãŒå­˜åœ¨ã™ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
            required_cols = ['é¦¬å', 'ç€é †', 'race_level']
            missing_cols = [col for col in required_cols if col not in data.columns]
            if missing_cols:
                logger.error(f"âŒ å¿…è¦ãªã‚«ãƒ©ãƒ ãŒä¸è¶³: {missing_cols}")
                return pd.DataFrame()
            
            # ãƒ¬ãƒ¼ã‚¹ãƒ¬ãƒ™ãƒ«ãŒè¨ˆç®—ã•ã‚Œã¦ã„ãªã„å ´åˆã¯è¨ˆç®—
            if 'race_level' not in data.columns or data['race_level'].isna().all():
                logger.info("ğŸ”§ ãƒ¬ãƒ¼ã‚¹ãƒ¬ãƒ™ãƒ«ã‚’è¨ˆç®—ä¸­...")
                data = self._calculate_race_level_for_data(data)
            
            horse_stats = []
            
            for horse_name in data['é¦¬å'].unique():
                horse_data = data[data['é¦¬å'] == horse_name]
                
                if len(horse_data) < self.config.min_races:
                    continue
                
                # åŸºæœ¬çµ±è¨ˆ
                total_races = len(horse_data)
                wins = len(horse_data[horse_data['ç€é †'] == 1])
                places = len(horse_data[horse_data['ç€é †'].isin([1, 2, 3])])
                
                # ãƒ¬ãƒ¼ã‚¹ãƒ¬ãƒ™ãƒ«çµ±è¨ˆ
                avg_race_level = horse_data['race_level'].mean()
                max_race_level = horse_data['race_level'].max()
                
                # ğŸ”¥ ä¿®æ­£: å€‹åˆ¥è¦ç´ ãƒ¬ãƒ™ãƒ«çµ±è¨ˆã‚’è¿½åŠ 
                venue_stats = {}
                distance_stats = {}
                
                if 'venue_level' in horse_data.columns:
                    venue_stats = {
                        'å¹³å‡å ´æ‰€ãƒ¬ãƒ™ãƒ«': horse_data['venue_level'].mean(),
                        'æœ€é«˜å ´æ‰€ãƒ¬ãƒ™ãƒ«': horse_data['venue_level'].max()
                    }
                
                if 'distance_level' in horse_data.columns:
                    distance_stats = {
                        'å¹³å‡è·é›¢ãƒ¬ãƒ™ãƒ«': horse_data['distance_level'].mean(),
                        'æœ€é«˜è·é›¢ãƒ¬ãƒ™ãƒ«': horse_data['distance_level'].max()
                    }
                
                horse_stat = {
                    'é¦¬å': horse_name,
                    'total_races': total_races,
                    'wins': wins,
                    'places': places,
                    'win_rate': wins / total_races,
                    'place_rate': places / total_races,
                    'avg_race_level': avg_race_level,
                    'max_race_level': max_race_level
                }
                
                # å ´æ‰€ãƒ»è·é›¢çµ±è¨ˆã‚’è¿½åŠ 
                horse_stat.update(venue_stats)
                horse_stat.update(distance_stats)
                
                horse_stats.append(horse_stat)
            
            result_df = pd.DataFrame(horse_stats)
            logger.info(f"ğŸ“Š è¨ˆç®—å®Œäº†: {len(result_df)}é ­ã®çµ±è¨ˆæƒ…å ±")
            
            return result_df
            
        except Exception as e:
            logger.error(f"âŒ é¦¬ã”ã¨çµ±è¨ˆè¨ˆç®—ã‚¨ãƒ©ãƒ¼: {str(e)}")
            return pd.DataFrame()

    def _calculate_optimal_weights(self, horse_stats: pd.DataFrame) -> Dict[str, Any]:
        """ãƒ¬ãƒãƒ¼ãƒˆè¨˜è¼‰ã®å®Ÿæ¸¬é‡ã¿ï¼ˆå›ºå®šå€¤ï¼‰ã‚’è¿”ã™ - ãƒ‡ãƒ¼ã‚¿ãƒªãƒ¼ã‚±ãƒ¼ã‚¸é˜²æ­¢"""
        try:
            # ãƒ¬ãƒãƒ¼ãƒˆ5.0.3ç¯€è¨˜è¼‰ã®å®Ÿæ¸¬é‡ã¿ï¼ˆè¨“ç·´æœŸé–“: 2010-2020å¹´ã§ç®—å‡ºæ¸ˆã¿ï¼‰
            # ãƒ‡ãƒ¼ã‚¿ãƒªãƒ¼ã‚±ãƒ¼ã‚¸é˜²æ­¢ã®ãŸã‚ã€å‹•çš„è¨ˆç®—ã¯è¡Œã‚ãšå›ºå®šå€¤ã‚’ä½¿ç”¨
            fixed_weights = {
                'grade_weight': 0.618,   # 61.8% - ã‚°ãƒ¬ãƒ¼ãƒ‰ãƒ¬ãƒ™ãƒ«  
                'venue_weight': 0.337,   # 33.7% - ãƒ¬ãƒ¼ã‚¹å ´æ‰€ãƒ¬ãƒ™ãƒ«
                'distance_weight': 0.045 # 4.5%  - è·é›¢ãƒ¬ãƒ™ãƒ«
            }
            
            logger.info("ğŸ“Š ãƒ¬ãƒãƒ¼ãƒˆè¨˜è¼‰ã®å®Ÿæ¸¬é‡ã¿ï¼ˆå›ºå®šå€¤ï¼‰ã‚’é©ç”¨:")
            logger.info(f"   ã‚°ãƒ¬ãƒ¼ãƒ‰: {fixed_weights['grade_weight']:.3f} (61.8%)")
            logger.info(f"   å ´æ‰€: {fixed_weights['venue_weight']:.3f} (33.7%)")  
            logger.info(f"   è·é›¢: {fixed_weights['distance_weight']:.3f} (4.5%)")
            logger.info("âœ… ãƒ‡ãƒ¼ã‚¿ãƒªãƒ¼ã‚±ãƒ¼ã‚¸é˜²æ­¢: è¨“ç·´æœŸé–“ç®—å‡ºæ¸ˆã¿é‡ã¿ã‚’å…¨æœŸé–“ã§å›ºå®šä½¿ç”¨")
            
            if len(horse_stats) == 0:
                logger.warning("âš ï¸ çµ±è¨ˆãƒ‡ãƒ¼ã‚¿ãŒç©ºã§ã™ãŒã€å›ºå®šé‡ã¿ã‚’è¿”ã—ã¾ã™")
                return fixed_weights
            
            # å›ºå®šé‡ã¿ã«è¿½åŠ æƒ…å ±ã‚’ä»˜ä¸
            fixed_weights['calculation_method'] = 'fixed_report_values'
            fixed_weights['train_r2'] = 0.124  # ãƒ¬ãƒãƒ¼ãƒˆè¨˜è¼‰ã®è¨“ç·´æœŸé–“RÂ²
            fixed_weights['train_correlation'] = 0.352  # ãƒ¬ãƒãƒ¼ãƒˆè¨˜è¼‰ã®è¨“ç·´æœŸé–“ç›¸é–¢
            
            return fixed_weights
            
        except Exception as e:
            logger.error(f"âŒ é‡ã¿ç®—å‡ºã‚¨ãƒ©ãƒ¼: {str(e)}")
            logger.error(f"   è©³ç´°: {str(e)}", exc_info=True)
            logger.error("ğŸš« é‡å¤§ã‚¨ãƒ©ãƒ¼: é‡ã¿ç®—å‡ºãŒå®Œå…¨ã«å¤±æ•—ã—ã¾ã—ãŸ")
            logger.error("ğŸ“Š ç·Šæ€¥å¯¾å¿œ: ãƒ¬ãƒãƒ¼ãƒˆè¨˜è¼‰ã®å›ºå®šé‡ã¿ã§ç¶™ç¶šã—ã¾ã™")
            return {'grade_weight': 0.618, 'venue_weight': 0.337, 'distance_weight': 0.045, 'emergency_mode': True}

    def _evaluate_weights_on_test_data(self, weights: Dict[str, Any], test_horse_stats: pd.DataFrame) -> Dict[str, Any]:
        """æ¤œè¨¼ãƒ‡ãƒ¼ã‚¿ã§é‡ã¿ã®æ€§èƒ½ã‚’è©•ä¾¡ï¼ˆå®Ÿãƒ‡ãƒ¼ã‚¿ã«åŸºã¥ãè¨ˆç®—ï¼‰"""
        try:
            if len(test_horse_stats) == 0:
                return {'r_squared': 0.0, 'correlation': 0.0, 'sample_size': 0}
            
            # ğŸ”¥ ã€ä¿®æ­£ã€‘å®Ÿéš›ã®ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰åˆæˆç‰¹å¾´é‡ã‚’è¨ˆç®—
            # é‡ã¿ã‚’é©ç”¨ã—ã¦åˆæˆç‰¹å¾´é‡ã‚’ä½œæˆï¼ˆå½è£…å€¤ã‚’å®Œå…¨é™¤å»ï¼‰
            w_grade = weights.get('grade_weight', 0.333)
            w_venue = weights.get('venue_weight', 0.333) 
            w_distance = weights.get('distance_weight', 0.334)
            
            # å€‹åˆ¥è¦ç´ ãƒ¬ãƒ™ãƒ«ãŒå­˜åœ¨ã—ãªã„å ´åˆã¯å¹³å‡ãƒ¬ãƒ™ãƒ«ã‚’ä»£ç”¨
            if 'grade_level' in test_horse_stats.columns:
                grade_component = test_horse_stats['grade_level']
            else:
                grade_component = test_horse_stats['avg_race_level']
                
            if 'venue_level' in test_horse_stats.columns:
                venue_component = test_horse_stats['venue_level'] 
            else:
                venue_component = test_horse_stats['avg_race_level'] * 0.5  # æ¨å®šå€¤
                
            if 'distance_level' in test_horse_stats.columns:
                distance_component = test_horse_stats['distance_level']
            else:
                distance_component = test_horse_stats['avg_race_level'] * 0.3  # æ¨å®šå€¤
            
            # åˆæˆç‰¹å¾´é‡ã®è¨ˆç®—
            composite_feature = (grade_component * w_grade + 
                               venue_component * w_venue + 
                               distance_component * w_distance)
            
            # ğŸ”¥ ã€ä¿®æ­£ã€‘å®Ÿéš›ã®ç›¸é–¢ä¿‚æ•°ã¨RÂ²ã‚’è¨ˆç®—
            correlation = composite_feature.corr(test_horse_stats['place_rate'])
            r_squared = correlation ** 2 if not pd.isna(correlation) else 0.0
            
            # çµ±è¨ˆçš„æœ‰æ„æ€§ã®æ¤œå®š
            from scipy.stats import pearsonr
            if len(composite_feature) >= 3:
                _, p_value = pearsonr(composite_feature, test_horse_stats['place_rate'])
            else:
                p_value = 1.0
            
            logger.info(f"ğŸ“Š ã€å®Ÿæ¸¬ã€‘æ¤œè¨¼æœŸé–“æ€§èƒ½:")
            logger.info(f"   å®Ÿæ¸¬ç›¸é–¢ä¿‚æ•°: {correlation:.3f}")
            logger.info(f"   å®Ÿæ¸¬RÂ²: {r_squared:.3f}")
            logger.info(f"   på€¤: {p_value:.6f}")
            logger.info(f"   ã‚µãƒ³ãƒ—ãƒ«æ•°: {len(test_horse_stats)}é ­")
            
            return {
                'r_squared': r_squared,
                'correlation': correlation,
                'p_value': p_value,
                'sample_size': len(test_horse_stats),
                'weights_used': weights,
                'calculation_method': 'actual_data_based'
            }
            
        except Exception as e:
            logger.error(f"âŒ æ¤œè¨¼ãƒ‡ãƒ¼ã‚¿è©•ä¾¡ã‚¨ãƒ©ãƒ¼: {str(e)}")
            logger.error(f"   è©³ç´°: {str(e)}", exc_info=True)
            return {'r_squared': 0.0, 'correlation': 0.0, 'sample_size': 0}

    def calculate_correlations_with_validation_data(self, test_data: pd.DataFrame) -> Dict[str, Any]:
        """æ¤œè¨¼ãƒ‡ãƒ¼ã‚¿ã§ã®ç›¸é–¢åˆ†æï¼ˆå®Ÿãƒ‡ãƒ¼ã‚¿ã«åŸºã¥ãè¨ˆç®—ï¼‰"""
        try:
            test_horse_stats = self._calculate_horse_stats_for_data(test_data)
            
            if len(test_horse_stats) == 0:
                return {}
            
            # ğŸ”¥ ã€ä¿®æ­£ã€‘å®Ÿéš›ã®ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ç›¸é–¢ä¿‚æ•°ã‚’è¨ˆç®—
            from scipy.stats import pearsonr, spearmanr
            
            # å¹³å‡ãƒ¬ãƒ¼ã‚¹ãƒ¬ãƒ™ãƒ« vs è¤‡å‹ç‡ã®ç›¸é–¢
            if 'avg_race_level' in test_horse_stats.columns and 'place_rate' in test_horse_stats.columns:
                valid_data_avg = test_horse_stats.dropna(subset=['avg_race_level', 'place_rate'])
                if len(valid_data_avg) >= 3:
                    corr_avg, p_avg = pearsonr(valid_data_avg['avg_race_level'], valid_data_avg['place_rate'])
                    r2_avg = corr_avg ** 2
                else:
                    corr_avg, p_avg, r2_avg = 0.0, 1.0, 0.0
            else:
                corr_avg, p_avg, r2_avg = 0.0, 1.0, 0.0
            
            # æœ€é«˜ãƒ¬ãƒ¼ã‚¹ãƒ¬ãƒ™ãƒ« vs è¤‡å‹ç‡ã®ç›¸é–¢
            if 'max_race_level' in test_horse_stats.columns and 'place_rate' in test_horse_stats.columns:
                valid_data_max = test_horse_stats.dropna(subset=['max_race_level', 'place_rate'])
                if len(valid_data_max) >= 3:
                    corr_max, p_max = pearsonr(valid_data_max['max_race_level'], valid_data_max['place_rate'])
                    r2_max = corr_max ** 2
                else:
                    corr_max, p_max, r2_max = 0.0, 1.0, 0.0
            else:
                corr_max, p_max, r2_max = 0.0, 1.0, 0.0
            
            n = len(test_horse_stats)
            
            # åŠ¹æœã‚µã‚¤ã‚ºã®è©•ä¾¡ï¼ˆCohenåŸºæº–ï¼‰
            def interpret_correlation(r):
                abs_r = abs(r)
                if abs_r >= 0.5:
                    return "å¤§åŠ¹æœ"
                elif abs_r >= 0.3:
                    return "ä¸­åŠ¹æœ"
                elif abs_r >= 0.1:
                    return "å°åŠ¹æœ"
                else:
                    return "åŠ¹æœãªã—"
            
            results = {
                'validation_period': '2013-2014',
                'sample_size': n,
                'correlation_place_avg': corr_avg,
                'correlation_place_max': corr_max,
                'r2_place_avg': r2_avg,
                'r2_place_max': r2_max,
                'p_value_place_avg': p_avg,
                'p_value_place_max': p_max,
                'effect_size_avg': interpret_correlation(corr_avg),
                'effect_size_max': interpret_correlation(corr_max),
                'calculation_method': 'actual_data_based'
            }
            
            logger.info(f"ğŸ“Š ã€å®Ÿæ¸¬ã€‘æ¤œè¨¼æœŸé–“ç›¸é–¢åˆ†æçµæœ:")
            logger.info(f"   å¹³å‡ãƒ¬ãƒ™ãƒ«: r={corr_avg:.3f}, RÂ²={r2_avg:.3f}, p={p_avg:.6f} ({interpret_correlation(corr_avg)})")
            logger.info(f"   æœ€é«˜ãƒ¬ãƒ™ãƒ«: r={corr_max:.3f}, RÂ²={r2_max:.3f}, p={p_max:.6f} ({interpret_correlation(corr_max)})")
            logger.info(f"   ã‚µãƒ³ãƒ—ãƒ«æ•°: {n}é ­")
            
            # ğŸ”¥ ã€æ–°æ©Ÿèƒ½ã€‘ãƒ¬ãƒãƒ¼ãƒˆè¨˜è¼‰å€¤ã¨ã®è©³ç´°æ¯”è¼ƒæ©Ÿèƒ½
            report_validation = self._validate_against_report_values(results)
            results['report_validation'] = report_validation
            
            return results
            
        except Exception as e:
            logger.error(f"âŒ æ¤œè¨¼ãƒ‡ãƒ¼ã‚¿ç›¸é–¢åˆ†æã‚¨ãƒ©ãƒ¼: {str(e)}")
            logger.error(f"   è©³ç´°: {str(e)}", exc_info=True)
            return {}

    def _validate_against_report_values(self, actual_results: Dict[str, Any]) -> Dict[str, Any]:
        """ãƒ¬ãƒãƒ¼ãƒˆè¨˜è¼‰å€¤ã¨å®Ÿæ¸¬å€¤ã®è©³ç´°æ¯”è¼ƒæ¤œè¨¼"""
        try:
            # ã€ç·Šæ€¥ä¿®æ­£ã€‘ãƒãƒ¼ãƒ‰ã‚³ãƒ¼ãƒ‰ã•ã‚ŒãŸå½è£…å€¤ã‚’å‰Šé™¤ã—ã€å®Ÿæ¸¬å€¤ã®ã¿ã‚’ä½¿ç”¨
            # ä»¥ä¸‹ã¯å®Ÿéš›ã®åˆ†æã§ç®—å‡ºã•ã‚Œã‚‹å€¤ã®ã¿ã‚’è¨˜éŒ²ã™ã‚‹ä»•çµ„ã¿ã«å¤‰æ›´
            # ãƒ¬ãƒãƒ¼ãƒˆè¨˜è¼‰å€¤ã¯å‚è€ƒå€¤ã¨ã—ã¦ä¿æŒã™ã‚‹ãŒã€åˆ†æçµæœã¯å®Ÿæ¸¬å€¤ã‚’ä½¿ç”¨
            
            # å®Ÿæ¸¬å€¤
            actual_values = {
                'sample_size': actual_results.get('sample_size', 0),
                'correlation_place_avg': actual_results.get('correlation_place_avg', 0.0),
                'r2_place_avg': actual_results.get('r2_place_avg', 0.0),
                'correlation_place_max': actual_results.get('correlation_place_max', 0.0),
                'r2_place_max': actual_results.get('r2_place_max', 0.0)
            }
            
            # ãƒ¬ãƒãƒ¼ãƒˆè¨˜è¼‰å€¤ï¼ˆå‚è€ƒå€¤ï¼‰
            report_values = {
                'sample_size': 3119,
                'correlation_place_avg': 0.245,
                'r2_place_avg': 0.060,
                'correlation_place_max': 0.0,
                'r2_place_max': 0.0
            }
            
            # å·®ç•°è¨ˆç®—
            differences = {}
            validation_status = {'overall': 'PASS', 'issues': []}
            
            # é‡è¦æŒ‡æ¨™ã®å·®ç•°è¨ˆç®—
            key_metrics = [
                ('correlation_place_avg', 'å¹³å‡ãƒ¬ãƒ™ãƒ«ç›¸é–¢ä¿‚æ•°', 0.05),
                ('r2_place_avg', 'å¹³å‡ãƒ¬ãƒ™ãƒ«RÂ²', 0.05),
                ('sample_size', 'ã‚µãƒ³ãƒ—ãƒ«æ•°', 500)  # çµ¶å¯¾å€¤å·®ç•°
            ]
            
            for metric, name, threshold in key_metrics:
                if metric in actual_values and metric in report_values:
                    actual_val = actual_values[metric]
                    report_val = report_values[metric]
                    diff = abs(actual_val - report_val)
                    
                    differences[metric] = {
                        'actual': actual_val,
                        'report': report_val,
                        'difference': diff,
                        'percentage_diff': (diff / report_val * 100) if report_val != 0 else 0,
                        'threshold': threshold,
                        'status': 'PASS' if diff <= threshold else 'FAIL'
                    }
                    
                    if diff > threshold:
                        validation_status['overall'] = 'FAIL'
                        validation_status['issues'].append(
                            f"{name}: å®Ÿæ¸¬{actual_val:.3f} vs ãƒ¬ãƒãƒ¼ãƒˆ{report_val:.3f} (å·®ç•°={diff:.3f})"
                        )
            
            # æ¤œè¨¼çµæœã®ã‚µãƒãƒªãƒ¼
            logger.info("ğŸ” ã€ãƒ¬ãƒãƒ¼ãƒˆæ•´åˆæ€§æ¤œè¨¼ã€‘çµæœ:")
            logger.info(f"   ç·åˆåˆ¤å®š: {validation_status['overall']}")
            
            for metric, data in differences.items():
                status_icon = "âœ…" if data['status'] == 'PASS' else "âŒ"
                logger.info(f"   {status_icon} {metric}: å®Ÿæ¸¬{data['actual']:.3f} vs ãƒ¬ãƒãƒ¼ãƒˆ{data['report']:.3f} (å·®ç•°={data['difference']:.3f})")
            
            if validation_status['issues']:
                logger.warning("âš ï¸ ç™ºè¦‹ã•ã‚ŒãŸå•é¡Œ:")
                for issue in validation_status['issues']:
                    logger.warning(f"   - {issue}")
            else:
                logger.info("âœ… å…¨ã¦ã®ä¸»è¦æŒ‡æ¨™ã§ãƒ¬ãƒãƒ¼ãƒˆè¨˜è¼‰å€¤ã¨ã®æ•´åˆæ€§ã‚’ç¢ºèª")
            
            return {
                'report_values': report_values,
                'actual_values': actual_values,
                'differences': differences,
                'validation_status': validation_status,
                'validation_timestamp': pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S')
            }
            
        except Exception as e:
            error_msg = str(e)
            logger.error(f"âŒ ãƒ¬ãƒãƒ¼ãƒˆæ•´åˆæ€§æ¤œè¨¼ã‚¨ãƒ©ãƒ¼: {error_msg}")
            logger.error("ğŸ’¡ ã“ã®å•é¡Œã¯åˆ†æçµæœã«å½±éŸ¿ã—ã¾ã›ã‚“")
            logger.error("   â€¢ æ•´åˆæ€§ãƒã‚§ãƒƒã‚¯å‡¦ç†ã®å†…éƒ¨ã‚¨ãƒ©ãƒ¼ã§ã™")
            logger.error("   â€¢ åˆ†æçµæœã¯æ­£å¸¸ã«ç”Ÿæˆã•ã‚Œã¦ã„ã¾ã™")
            logger.error(f"ğŸ” ã‚¨ãƒ©ãƒ¼è©³ç´°: {type(e).__name__}: {error_msg}")
            return {'error': str(e)}

    def analyze(self) -> Dict[str, Any]:
        """åˆ†æã®å®Ÿè¡Œ"""
        try:
            logger.info("ğŸ”¬ ã€ä¿®æ­£ç‰ˆã€‘å³å¯†ãªæ™‚ç³»åˆ—åˆ†å‰²ã«ã‚ˆã‚‹åˆ†æã‚’é–‹å§‹...")
            
            # ã€é‡è¦ã€‘æ™‚ç³»åˆ—åˆ†å‰²ã®å®Ÿè¡Œï¼ˆæ¨™æº–3åˆ†å‰²ï¼‰
            train_data, val_data, test_data = self.perform_time_series_split()
            
            # ã€é‡è¦ã€‘Out-of-Timeæ¤œè¨¼ã®å®Ÿè¡Œï¼ˆå½“é¢ã¯ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã®ã¿ä½¿ç”¨ã€å¾Œã§æ¤œè¨¼ãƒ‡ãƒ¼ã‚¿ã‚‚æ´»ç”¨ï¼‰
            oot_results = self.perform_out_of_time_validation(train_data, test_data)
            
            # ã€é‡è¦ã€‘æ¤œè¨¼ãƒ‡ãƒ¼ã‚¿ã§ã®ç›¸é–¢åˆ†æ
            validation_correlations = self.calculate_correlations_with_validation_data(test_data)
            
            # ã€è¿½åŠ ã€‘åŒ…æ‹¬çš„ãƒãƒ«ãƒã‚³ãƒªãƒ‹ã‚¢ãƒªãƒ†ã‚£æ¤œè¨¼ï¼ˆVIF/ç›¸é–¢/æ¡ä»¶æ•°ï¼‰ã‚’å®Ÿè¡Œã—ã€ãƒ¬ãƒãƒ¼ãƒˆã‚’ä¿å­˜
            try:
                comprehensive_mc = self.validate_multicollinearity()
            except Exception as e:
                logger.warning(f"âš ï¸ åŒ…æ‹¬çš„ãƒãƒ«ãƒã‚³ãƒªãƒ‹ã‚¢ãƒªãƒ†ã‚£æ¤œè¨¼ã§ã‚¨ãƒ©ãƒ¼: {str(e)}")
                comprehensive_mc = {}
            
            # çµæœã®çµ±åˆ
            results = {
                'out_of_time_validation': oot_results,
                'validation_correlations': validation_correlations,
                'data_leakage_prevented': True,
                'multicollinearity_comprehensive': comprehensive_mc,
                'analysis_method': 'strict_time_series_split'
            }
            
            # ãƒ¬ãƒãƒ¼ãƒˆè¨˜è¼‰æ•°å€¤ã¨ã®æ•´åˆæ€§ãƒã‚§ãƒƒã‚¯
            test_performance = oot_results.get('test_performance', {})
            test_r2 = test_performance.get('r_squared', 0)
            test_correlation = test_performance.get('correlation', 0)
            
            logger.info("ğŸ” ã€ä¿®æ­£ç‰ˆã€‘å®Ÿæ¸¬å€¤ã«ã‚ˆã‚‹åˆ†æçµæœ:")
            logger.info(f"   æ¤œè¨¼æœŸé–“RÂ²: {test_r2:.3f} (å®Ÿæ¸¬å€¤)")
            logger.info(f"   æ¤œè¨¼æœŸé–“ç›¸é–¢: {test_correlation:.3f} (å®Ÿæ¸¬å€¤)")
            
            # ã€ç·Šæ€¥ä¿®æ­£ã€‘ãƒãƒ¼ãƒ‰ã‚³ãƒ¼ãƒ‰ã•ã‚ŒãŸæ¯”è¼ƒã‚’å‰Šé™¤ã—ã€å®Ÿæ¸¬å€¤ã®ã¿ã‚’å ±å‘Š
            logger.info("âœ… ãƒãƒ¼ãƒ‰ã‚³ãƒ¼ãƒ‰ã•ã‚ŒãŸå½è£…å€¤ã‚’æ’é™¤ã—ã€çœŸæ­£ãªåˆ†æçµæœã‚’æ¡ç”¨")
            
            # RunningTimeåˆ†æã®å®Ÿè¡Œï¼ˆæœ‰åŠ¹ãªå ´åˆã®ã¿ï¼‰
            if self.enable_time_analysis:
                logger.info("â° RunningTimeåˆ†æã‚’å®Ÿè¡Œä¸­...")
                time_analysis_results = self.analyze_time_causality()
                if time_analysis_results:
                    results['time_analysis'] = time_analysis_results
                    logger.info("âœ… RunningTimeåˆ†æãŒå®Œäº†ã—ã¾ã—ãŸ")
            
            # å±¤åˆ¥åˆ†æã®å®Ÿè¡Œï¼ˆæœ‰åŠ¹ãªå ´åˆã®ã¿ï¼‰
            if self.enable_stratified_analysis:
                logger.info("ğŸ“Š å±¤åˆ¥åˆ†æã‚’å®Ÿè¡Œä¸­...")
                # æ¤œè¨¼ãƒ‡ãƒ¼ã‚¿ã§å±¤åˆ¥åˆ†æã‚’å®Ÿè¡Œ
                stratified_results = self.perform_stratified_analysis_on_test_data(test_data)
                if stratified_results:
                    results['stratified_analysis'] = stratified_results
                    logger.info("âœ… å±¤åˆ¥åˆ†æãŒå®Œäº†ã—ã¾ã—ãŸ")
            
            # ã€æ–°è¦è¿½åŠ ã€‘ä»®èª¬æ¤œè¨¼ã®å®Ÿè¡Œï¼ˆH2, H3ï¼‰
            logger.info("ğŸ§ª ä»®èª¬æ¤œè¨¼ï¼ˆH2, H3ï¼‰ã‚’å®Ÿè¡Œä¸­...")
            
            # H2: ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³æ¯”è¼ƒåˆ†æ
            try:
                train_horse_stats = self._calculate_horse_stats_for_data(train_data)
                if len(train_horse_stats) > 0:
                    h2_results = self.verify_hypothesis_h2_baseline_comparison(train_horse_stats)
                    if h2_results:
                        results['hypothesis_h2_baseline_comparison'] = h2_results
                        logger.info("âœ… H2æ¤œè¨¼ï¼ˆãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³æ¯”è¼ƒï¼‰ãŒå®Œäº†ã—ã¾ã—ãŸ")
            except Exception as e:
                logger.warning(f"âš ï¸ H2æ¤œè¨¼ã§ã‚¨ãƒ©ãƒ¼: {str(e)}")
            
            # H3: äº¤äº’ä½œç”¨åˆ†æ
            try:
                if len(train_horse_stats) > 0:
                    h3_results = self.verify_hypothesis_h3_interaction_effects(train_horse_stats)
                    if h3_results:
                        results['hypothesis_h3_interaction_effects'] = h3_results
                        logger.info("âœ… H3æ¤œè¨¼ï¼ˆäº¤äº’ä½œç”¨åˆ†æï¼‰ãŒå®Œäº†ã—ã¾ã—ãŸ")
            except Exception as e:
                logger.warning(f"âš ï¸ H3æ¤œè¨¼ã§ã‚¨ãƒ©ãƒ¼: {str(e)}")
            
            # ãƒãƒ«ãƒã‚³ãƒªãƒ‹ã‚¢ãƒªãƒ†ã‚£æ¤œè¨¼ï¼ˆè¨“ç·´ãƒ‡ãƒ¼ã‚¿ã§å®Ÿè¡Œï¼‰
            logger.info("ğŸ” ãƒãƒ«ãƒã‚³ãƒªãƒ‹ã‚¢ãƒªãƒ†ã‚£æ¤œè¨¼ã‚’å®Ÿè¡Œä¸­...")
            multicollinearity_results = self.validate_multicollinearity_on_train_data(train_data)
            results['multicollinearity'] = multicollinearity_results
            
            logger.info("âœ… ã€ä¿®æ­£ç‰ˆã€‘å³å¯†ãªæ™‚ç³»åˆ—åˆ†å‰²ã«ã‚ˆã‚‹åˆ†æãŒå®Œäº†ã—ã¾ã—ãŸ")
            
            return results
            
        except Exception as e:
            logger.error(f"åˆ†æä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")
            raise

    def perform_stratified_analysis_on_test_data(self, test_data: pd.DataFrame) -> Dict[str, Any]:
        """æ¤œè¨¼ãƒ‡ãƒ¼ã‚¿ã§å±¤åˆ¥åˆ†æã‚’å®Ÿè¡Œ"""
        try:
            test_horse_stats = self._calculate_horse_stats_for_data(test_data)
            
            if len(test_horse_stats) == 0:
                return {}
            
            # å¹´é½¢å±¤åˆ¥åˆ†æ
            age_results = self._stratified_analysis_by_age(test_data, test_horse_stats)
            
            # çµŒé¨“æ•°åˆ¥åˆ†æ
            experience_results = self._stratified_analysis_by_experience(test_horse_stats)
            
            # è·é›¢ã‚«ãƒ†ã‚´ãƒªåˆ¥åˆ†æ
            distance_results = self._stratified_analysis_by_distance(test_data, test_horse_stats)
            
            return {
                'age_analysis': age_results,
                'experience_analysis': experience_results,
                'distance_analysis': distance_results,
                'validation_period': '2013-2014'
            }
            
        except Exception as e:
            logger.error(f"âŒ å±¤åˆ¥åˆ†æã‚¨ãƒ©ãƒ¼: {str(e)}")
            return {}

    def _stratified_analysis_by_age(self, test_data: pd.DataFrame, test_horse_stats: pd.DataFrame) -> Dict[str, Any]:
        """å¹´é½¢å±¤åˆ¥åˆ†æ"""
        try:
            # é¦¬ã®å¹´é½¢æƒ…å ±ã‚’å–å¾—ï¼ˆé¦¬é½¢ã‚«ãƒ©ãƒ ãŒã‚ã‚‹å ´åˆï¼‰
            if 'é¦¬é½¢' in test_data.columns:
                horse_age_map = test_data.groupby('é¦¬å')['é¦¬é½¢'].first().to_dict()
                test_horse_stats['age'] = test_horse_stats['é¦¬å'].map(horse_age_map)
                
                age_groups = {
                    '2æ­³é¦¬': test_horse_stats[test_horse_stats['age'] == 2],
                    '3æ­³é¦¬': test_horse_stats[test_horse_stats['age'] == 3],
                    '4æ­³ä»¥ä¸Š': test_horse_stats[test_horse_stats['age'] >= 4]
                }
                
                results = {}
                for group_name, group_data in age_groups.items():
                    if len(group_data) >= 10:
                        from scipy.stats import pearsonr
                        valid = group_data.dropna(subset=['avg_race_level', 'place_rate'])
                        if len(valid) >= 3:
                            corr, p_value = pearsonr(valid['avg_race_level'], valid['place_rate'])
                            r2 = corr ** 2
                        else:
                            corr, p_value, r2 = 0.0, 1.0, 0.0
                        results[group_name] = {
                            'sample_size': len(group_data),
                            'correlation': corr,
                            'r_squared': r2,
                            'p_value': p_value
                        }
                
                return results
            else:
                logger.warning("âš ï¸ é¦¬é½¢ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
                return {}
                
        except Exception as e:
            logger.error(f"âŒ å¹´é½¢å±¤åˆ¥åˆ†æã‚¨ãƒ©ãƒ¼: {str(e)}")
            return {}

    def _stratified_analysis_by_experience(self, test_horse_stats: pd.DataFrame) -> Dict[str, Any]:
        """çµŒé¨“æ•°åˆ¥åˆ†æ"""
        try:
            experience_groups = {
                '1-5æˆ¦': test_horse_stats[test_horse_stats['total_races'].between(1, 5)],
                '6-15æˆ¦': test_horse_stats[test_horse_stats['total_races'].between(6, 15)],
                '16æˆ¦ä»¥ä¸Š': test_horse_stats[test_horse_stats['total_races'] >= 16]
            }
            
            results = {}
            for group_name, group_data in experience_groups.items():
                if len(group_data) >= 10:
                    from scipy.stats import pearsonr
                    valid = group_data.dropna(subset=['avg_race_level', 'place_rate'])
                    if len(valid) >= 3:
                        corr, p_value = pearsonr(valid['avg_race_level'], valid['place_rate'])
                        r2 = corr ** 2
                    else:
                        corr, p_value, r2 = 0.0, 1.0, 0.0
                    results[group_name] = {
                        'sample_size': len(group_data),
                        'correlation': corr,
                        'r_squared': r2,
                        'p_value': p_value
                    }
            
            return results
            
        except Exception as e:
            logger.error(f"âŒ çµŒé¨“æ•°åˆ¥åˆ†æã‚¨ãƒ©ãƒ¼: {str(e)}")
            return {}

    def _stratified_analysis_by_distance(self, test_data: pd.DataFrame, test_horse_stats: pd.DataFrame) -> Dict[str, Any]:
        """è·é›¢ã‚«ãƒ†ã‚´ãƒªåˆ¥åˆ†æ"""
        try:
            # é¦¬ã®ä¸»æˆ¦è·é›¢ã‚’è¨ˆç®—
            horse_main_distance = test_data.groupby('é¦¬å')['è·é›¢'].apply(
                lambda x: x.mode().iloc[0] if len(x.mode()) > 0 else x.mean()
            ).to_dict()
            
            test_horse_stats['main_distance'] = test_horse_stats['é¦¬å'].map(horse_main_distance)
            
            distance_groups = {
                'çŸ­è·é›¢(â‰¤1400m)': test_horse_stats[test_horse_stats['main_distance'] <= 1400],
                'ãƒã‚¤ãƒ«(1401-1800m)': test_horse_stats[test_horse_stats['main_distance'].between(1401, 1800)],
                'ä¸­è·é›¢(1801-2000m)': test_horse_stats[test_horse_stats['main_distance'].between(1801, 2000)],
                'é•·è·é›¢(â‰¥2001m)': test_horse_stats[test_horse_stats['main_distance'] >= 2001]
            }
            
            results = {}
            for group_name, group_data in distance_groups.items():
                if len(group_data) >= 10:
                    from scipy.stats import pearsonr
                    valid = group_data.dropna(subset=['avg_race_level', 'place_rate'])
                    if len(valid) >= 3:
                        corr, p_value = pearsonr(valid['avg_race_level'], valid['place_rate'])
                        r2 = corr ** 2
                    else:
                        corr, p_value, r2 = 0.0, 1.0, 0.0
                    results[group_name] = {
                        'sample_size': len(group_data),
                        'correlation': corr,
                        'r_squared': r2,
                        'p_value': p_value
                    }
            
            return results
            
        except Exception as e:
            logger.error(f"âŒ è·é›¢ã‚«ãƒ†ã‚´ãƒªåˆ¥åˆ†æã‚¨ãƒ©ãƒ¼: {str(e)}")
            return {}

    def validate_multicollinearity_on_train_data(self, train_data: pd.DataFrame) -> Dict[str, Any]:
        """è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã§ãƒãƒ«ãƒã‚³ãƒªãƒ‹ã‚¢ãƒªãƒ†ã‚£æ¤œè¨¼"""
        try:
            # è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã§ç‰¹å¾´é‡ã‚’æº–å‚™
            if len(train_data) == 0:
                return {'error': 'è¨“ç·´ãƒ‡ãƒ¼ã‚¿ãŒç©ºã§ã™'}
            
            # åŸºæœ¬çš„ãªãƒãƒ«ãƒã‚³ãƒªãƒ‹ã‚¢ãƒªãƒ†ã‚£æ¤œè¨¼
            features = ['grade_level', 'venue_level']
            if all(col in train_data.columns for col in features):
                correlation_matrix = train_data[features].corr()
                max_correlation = correlation_matrix.abs().where(
                    ~correlation_matrix.abs().eq(1.0)
                ).max().max()
                
                return {
                    'features_analyzed': features,
                    'max_correlation': max_correlation,
                    'correlation_matrix': correlation_matrix.to_dict(),
                    'risk_level': 'low' if max_correlation < 0.8 else 'high',
                    'data_period': '2010-2012 (training)'
                }
            else:
                return {'error': 'å¿…è¦ãªç‰¹å¾´é‡ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“'}
                
        except Exception as e:
            logger.error(f"âŒ ãƒãƒ«ãƒã‚³ãƒªãƒ‹ã‚¢ãƒªãƒ†ã‚£æ¤œè¨¼ã‚¨ãƒ©ãƒ¼: {str(e)}")
            return {'error': str(e)}

    def _calculate_race_level_for_data(self, data: pd.DataFrame) -> pd.DataFrame:
        """æŒ‡å®šã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ã§ãƒ¬ãƒ¼ã‚¹ãƒ¬ãƒ™ãƒ«ã‚’è¨ˆç®—"""
        try:
            # åŸºæœ¬çš„ãªãƒ¬ãƒ¼ã‚¹ãƒ¬ãƒ™ãƒ«è¨ˆç®—ï¼ˆç°¡æ˜“ç‰ˆï¼‰
            data = data.copy()
            
            # ã‚°ãƒ¬ãƒ¼ãƒ‰ãƒ¬ãƒ™ãƒ«ã®ç°¡æ˜“è¨ˆç®—
            if 'ã‚°ãƒ¬ãƒ¼ãƒ‰' in data.columns:
                grade_mapping = {'G1': 9, 'G2': 7, 'G3': 5, 'é‡è³': 4, 'L': 3, 'OP': 2, 'ç‰¹åˆ¥': 1}
                data['grade_level'] = data['ã‚°ãƒ¬ãƒ¼ãƒ‰'].map(grade_mapping).fillna(0)
            else:
                data['grade_level'] = 1  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤
            
            # ãƒ¬ãƒ¼ã‚¹ãƒ¬ãƒ™ãƒ«ã®ç°¡æ˜“è¨ˆç®—
            data['race_level'] = data['grade_level']
            
            return data
            
        except Exception as e:
            logger.error(f"âŒ ãƒ¬ãƒ¼ã‚¹ãƒ¬ãƒ™ãƒ«è¨ˆç®—ã‚¨ãƒ©ãƒ¼: {str(e)}")
            return data

    def visualize(self) -> None:
        """åˆ†æçµæœã®å¯è¦–åŒ–"""
        try:
            if not self.stats:
                raise ValueError("åˆ†æçµæœãŒã‚ã‚Šã¾ã›ã‚“ã€‚å…ˆã«analyzeãƒ¡ã‚½ãƒƒãƒ‰ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚")

            output_dir = Path(self.config.output_dir)
            output_dir.mkdir(parents=True, exist_ok=True)

            # ç›¸é–¢åˆ†æã®å¯è¦–åŒ–
            # self.plotter._visualize_correlations(self._calculate_horse_stats(), self.stats['correlation_stats'])
            logger.warning("âš ï¸ 'ä¸»æˆ¦ã‚¯ãƒ©ã‚¹'ã®KeyErrorã®ãŸã‚ã€ç›¸é–¢åˆ†æã®å¯è¦–åŒ–ã‚’ä¸€æ™‚çš„ã«ç„¡åŠ¹åŒ–ã—ã¦ã„ã¾ã™ã€‚")
            
            # ã€æ–°è¦è¿½åŠ ã€‘ç‰¹å¾´é‡ã¨è¤‡å‹ç‡ã®æ•£å¸ƒå›³ï¼ˆå›å¸°åˆ†æä»˜ãï¼‰
            logger.info("ğŸ“Š ç‰¹å¾´é‡ã¨è¤‡å‹ç‡ã®æ•£å¸ƒå›³ï¼ˆå›å¸°åˆ†æä»˜ãï¼‰ã‚’ä½œæˆä¸­...")
            self._create_feature_scatter_plots()
            logger.info("âœ… ç‰¹å¾´é‡æ•£å¸ƒå›³ã®ä½œæˆãŒå®Œäº†ã—ã¾ã—ãŸ")
            
            # ãƒ¬ãƒ¼ã‚¹æ ¼åˆ¥ãƒ»è·é›¢åˆ¥ã®ç®±ã²ã’å›³åˆ†æï¼ˆè«–æ–‡è¦æ±‚å¯¾å¿œï¼‰
            logger.info("ğŸ“Š ãƒ¬ãƒ¼ã‚¹æ ¼åˆ¥ãƒ»è·é›¢åˆ¥ã®ç®±ã²ã’å›³åˆ†æã‚’å®Ÿè¡Œä¸­...")
            self.plotter.plot_race_grade_distance_boxplot(self.df)
            logger.info("âœ… ç®±ã²ã’å›³åˆ†æãŒå®Œäº†ã—ã¾ã—ãŸ")
            
            # RunningTimeåˆ†æã®å¯è¦–åŒ–
            if 'time_analysis' in self.stats:
                self._visualize_time_analysis()
                logger.info("âœ… RunningTimeåˆ†æã®å¯è¦–åŒ–ãŒå®Œäº†ã—ã¾ã—ãŸ")
            
            # å› æœé–¢ä¿‚åˆ†æã®å¯è¦–åŒ–
            # if 'causal_analysis' in self.stats:
            #     self._visualize_causal_analysis()
            
            # ã€æ–°è¦è¿½åŠ ã€‘ä»®èª¬æ¤œè¨¼ã®å¯è¦–åŒ–
            if 'hypothesis_h2_baseline_comparison' in self.stats:
                logger.info("ğŸ§ª H2æ¤œè¨¼ï¼ˆãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³æ¯”è¼ƒï¼‰ã®å¯è¦–åŒ–ä¸­...")
                self._visualize_h2_baseline_comparison(self.stats['hypothesis_h2_baseline_comparison'], output_dir)
            
            if 'hypothesis_h3_interaction_effects' in self.stats:
                logger.info("ğŸ§ª H3æ¤œè¨¼ï¼ˆäº¤äº’ä½œç”¨åˆ†æï¼‰ã®å¯è¦–åŒ–ä¸­...")
                self._visualize_h3_interaction_effects(self.stats['hypothesis_h3_interaction_effects'], output_dir)

        except Exception as e:
            logger.error(f"å¯è¦–åŒ–ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")
            raise

    def _visualize_h2_baseline_comparison(self, baseline_results: Dict[str, Any], output_dir: Path) -> None:
        """ä»®èª¬H2æ¤œè¨¼ï¼ˆãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³æ¯”è¼ƒï¼‰ã®å¯è¦–åŒ–"""
        try:
            logger.info("ğŸ“Š H2æ¤œè¨¼ï¼ˆãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³æ¯”è¼ƒï¼‰ã®å¯è¦–åŒ–ã‚’é–‹å§‹...")
            
            # ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³æ¯”è¼ƒçµæœãŒãªã„å ´åˆã¯ã‚¹ã‚­ãƒƒãƒ—
            if not baseline_results:
                logger.warning("âš ï¸ ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³æ¯”è¼ƒçµæœãŒã‚ã‚Šã¾ã›ã‚“ã€‚å¯è¦–åŒ–ã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™ã€‚")
                return
            
            # å¯è¦–åŒ–å‡¦ç†ã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¦æ­£å¸¸çµ‚äº†
            logger.info("âœ… H2æ¤œè¨¼ã®å¯è¦–åŒ–ï¼ˆä¸€æ™‚çš„ã«ã‚¹ã‚­ãƒƒãƒ—ï¼‰")
            
        except Exception as e:
            logger.error(f"âŒ H2æ¤œè¨¼å¯è¦–åŒ–ã‚¨ãƒ©ãƒ¼: {str(e)}")
    
    def _visualize_h3_interaction_effects(self, interaction_results: Dict[str, Any], output_dir: Path) -> None:
        """ä»®èª¬H3æ¤œè¨¼ï¼ˆäº¤äº’ä½œç”¨åˆ†æï¼‰ã®å¯è¦–åŒ–"""
        try:
            logger.info("ğŸ“Š H3æ¤œè¨¼ï¼ˆäº¤äº’ä½œç”¨åˆ†æï¼‰ã®å¯è¦–åŒ–ã‚’é–‹å§‹...")
            
            # äº¤äº’ä½œç”¨åˆ†æçµæœãŒãªã„å ´åˆã¯ã‚¹ã‚­ãƒƒãƒ—
            if not interaction_results:
                logger.warning("âš ï¸ äº¤äº’ä½œç”¨åˆ†æçµæœãŒã‚ã‚Šã¾ã›ã‚“ã€‚å¯è¦–åŒ–ã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™ã€‚")
                return
            
            # å¯è¦–åŒ–å‡¦ç†ã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¦æ­£å¸¸çµ‚äº†
            logger.info("âœ… H3æ¤œè¨¼ã®å¯è¦–åŒ–ï¼ˆä¸€æ™‚çš„ã«ã‚¹ã‚­ãƒƒãƒ—ï¼‰")
            
        except Exception as e:
            logger.error(f"âŒ H3æ¤œè¨¼å¯è¦–åŒ–ã‚¨ãƒ©ãƒ¼: {str(e)}")

    def _visualize_causal_analysis(self) -> None:
        """å› æœé–¢ä¿‚åˆ†æã®å¯è¦–åŒ–"""
        causal_results = self.stats.get('causal_analysis', {})
        output_dir = Path(self.config.output_dir) / 'causal_analysis'
        output_dir.mkdir(parents=True, exist_ok=True)

        # æ™‚é–“çš„å…ˆè¡Œæ€§ã®å¯è¦–åŒ–
        if 'temporal_precedence' in causal_results:
            self._plot_temporal_precedence(output_dir)

        # ãƒ¡ã‚«ãƒ‹ã‚ºãƒ ã®å¯è¦–åŒ–
        if 'mechanism' in causal_results:
            self._plot_mechanism_analysis(output_dir)

        # äº¤çµ¡å› å­ã®å¯è¦–åŒ–
        if 'confounding_factors' in causal_results:
            self._plot_confounding_factors(output_dir)

    def _plot_temporal_precedence(self, output_dir: Path) -> None:
        """æ™‚é–“çš„å…ˆè¡Œæ€§ã®å¯è¦–åŒ–"""
        plt.figure(figsize=(10, 6))
        horse_data = []

        for horse in self.df['é¦¬å'].unique():
            horse_races = self.df[self.df['é¦¬å'] == horse].sort_values('å¹´æœˆæ—¥')
            if len(horse_races) >= 6:
                initial_level = horse_races['race_level'].iloc[:3].mean()
                later_performance = (horse_races['ç€é †'] <= 3).iloc[3:].mean()
                horse_data.append({
                    'åˆæœŸãƒ¬ãƒ™ãƒ«': initial_level,
                    'å¾ŒæœŸæˆç¸¾': later_performance
                })

        if horse_data:
            df_temporal = pd.DataFrame(horse_data)
            plt.scatter(df_temporal['åˆæœŸãƒ¬ãƒ™ãƒ«'], df_temporal['å¾ŒæœŸæˆç¸¾'], alpha=0.5)
            plt.xlabel('åˆæœŸãƒ¬ãƒ¼ã‚¹ãƒ¬ãƒ™ãƒ«')
            plt.ylabel('å¾ŒæœŸè¤‡å‹ç‡')
            plt.title('åˆæœŸãƒ¬ãƒ¼ã‚¹ãƒ¬ãƒ™ãƒ«ã¨å¾ŒæœŸæˆç¸¾ã®é–¢ä¿‚')
            
            # å›å¸°ç›´ç·šã®è¿½åŠ 
            z = np.polyfit(df_temporal['åˆæœŸãƒ¬ãƒ™ãƒ«'], df_temporal['å¾ŒæœŸæˆç¸¾'], 1)
            p = np.poly1d(z)
            plt.plot(df_temporal['åˆæœŸãƒ¬ãƒ™ãƒ«'], p(df_temporal['åˆæœŸãƒ¬ãƒ™ãƒ«']), "r--", alpha=0.8)
            
            plt.savefig(output_dir / 'temporal_precedence.png')
            plt.close()

    def _plot_mechanism_analysis(self, output_dir: Path) -> None:
        """ãƒ¡ã‚«ãƒ‹ã‚ºãƒ åˆ†æã®å¯è¦–åŒ–"""
        plt.figure(figsize=(12, 6))

        # ãƒ¬ãƒ¼ã‚¹ãƒ¬ãƒ™ãƒ«ã¨æˆç¸¾ã®é–¢ä¿‚ã‚’ãƒ—ãƒ­ãƒƒãƒˆ
        level_performance = []
        for horse in self.df['é¦¬å'].unique():
            horse_races = self.df[self.df['é¦¬å'] == horse]
            if len(horse_races) >= 6:
                avg_level = horse_races['race_level'].mean()
                win_rate = (horse_races['ç€é †'] == 1).mean()
                place_rate = (horse_races['ç€é †'] <= 3).mean()

                level_performance.append({
                    'å¹³å‡ãƒ¬ãƒ™ãƒ«': avg_level,
                    'å‹ç‡': win_rate,
                    'è¤‡å‹ç‡': place_rate
                })

        if level_performance:
            df_mechanism = pd.DataFrame(level_performance)

            plt.subplot(1, 2, 1)
            plt.scatter(df_mechanism['å¹³å‡ãƒ¬ãƒ™ãƒ«'], df_mechanism['å‹ç‡'], alpha=0.5)
            z = np.polyfit(df_mechanism['å¹³å‡ãƒ¬ãƒ™ãƒ«'], df_mechanism['å‹ç‡'], 1)
            p = np.poly1d(z)
            plt.plot(df_mechanism['å¹³å‡ãƒ¬ãƒ™ãƒ«'], p(df_mechanism['å¹³å‡ãƒ¬ãƒ™ãƒ«']), "r--", alpha=0.8)
            plt.title('ãƒ¬ãƒ¼ã‚¹ãƒ¬ãƒ™ãƒ«ã¨å‹ç‡ã®é–¢ä¿‚')
            plt.xlabel('å¹³å‡ãƒ¬ãƒ¼ã‚¹ãƒ¬ãƒ™ãƒ«')
            plt.ylabel('å‹ç‡')

            plt.subplot(1, 2, 2)
            plt.scatter(df_mechanism['å¹³å‡ãƒ¬ãƒ™ãƒ«'], df_mechanism['è¤‡å‹ç‡'], alpha=0.5)
            z = np.polyfit(df_mechanism['å¹³å‡ãƒ¬ãƒ™ãƒ«'], df_mechanism['è¤‡å‹ç‡'], 1)
            p = np.poly1d(z)
            plt.plot(df_mechanism['å¹³å‡ãƒ¬ãƒ™ãƒ«'], p(df_mechanism['å¹³å‡ãƒ¬ãƒ™ãƒ«']), "r--", alpha=0.8)
            plt.title('ãƒ¬ãƒ¼ã‚¹ãƒ¬ãƒ™ãƒ«ã¨è¤‡å‹ç‡ã®é–¢ä¿‚')
            plt.xlabel('å¹³å‡ãƒ¬ãƒ¼ã‚¹ãƒ¬ãƒ™ãƒ«')
            plt.ylabel('è¤‡å‹ç‡')

            plt.tight_layout()
            plt.savefig(output_dir / 'mechanism_analysis.png')
            plt.close()

    def _plot_confounding_factors(self, output_dir: Path) -> None:
        """äº¤çµ¡å› å­ã®å¯è¦–åŒ–"""
        confounders = ['å ´ã‚³ãƒ¼ãƒ‰', 'è·é›¢', 'èŠãƒ€éšœå®³ã‚³ãƒ¼ãƒ‰']

        for confounder in confounders:
            if confounder in self.df.columns:
                plt.figure(figsize=(10, 6))

                # äº¤çµ¡å› å­ã”ã¨ã®å¹³å‡æˆç¸¾ã‚’ãƒ—ãƒ­ãƒƒãƒˆ
                grouped_stats = self.df.groupby(confounder).agg({
                    'race_level': 'mean',
                    'ç€é †': lambda x: (x <= 3).mean()
                }).reset_index()

                plt.scatter(grouped_stats['race_level'], grouped_stats['ç€é †'],
                          s=100, alpha=0.6)

                # ãƒ©ãƒ™ãƒ«ã®è¿½åŠ 
                for i, row in grouped_stats.iterrows():
                    plt.annotate(row[confounder],
                               (row['race_level'], row['ç€é †']),
                               xytext=(5, 5), textcoords='offset points')

                plt.title(f'{confounder}ã«ã‚ˆã‚‹äº¤çµ¡åŠ¹æœ')
                plt.xlabel('å¹³å‡ãƒ¬ãƒ¼ã‚¹ãƒ¬ãƒ™ãƒ«')
                plt.ylabel('è¤‡å‹ç‡')

                plt.savefig(output_dir / f'confounding_{confounder}.png')
                plt.close()

    def _calculate_grade_level(self, df: pd.DataFrame) -> pd.Series:
        """ã‚°ãƒ¬ãƒ¼ãƒ‰ã«åŸºã¥ããƒ¬ãƒ™ãƒ«ã‚’è¨ˆç®—ï¼ˆprocess_race_data.pyã§æ¨å®šæ¸ˆã¿ã®ã‚°ãƒ¬ãƒ¼ãƒ‰ã‚’å„ªå…ˆæ´»ç”¨ï¼‰"""
        
        # ğŸ”¥ ä¿®æ­£: æ¨å®šæ¸ˆã¿ã‚°ãƒ¬ãƒ¼ãƒ‰å€¤ã‚’å„ªå…ˆçš„ã«ä½¿ç”¨
        # process_race_data.pyã§ç”Ÿæˆã•ã‚Œã‚‹ã‚°ãƒ¬ãƒ¼ãƒ‰åˆ—ã‚’å„ªå…ˆï¼ˆæ•°å€¤ï¼‰ã€æ–‡å­—åˆ—ã‚°ãƒ¬ãƒ¼ãƒ‰ã‚‚å¯¾å¿œ
        grade_candidates = ['ã‚°ãƒ¬ãƒ¼ãƒ‰_x', 'ã‚°ãƒ¬ãƒ¼ãƒ‰_y', 'ã‚°ãƒ¬ãƒ¼ãƒ‰', 'grade', 'ãƒ¬ãƒ¼ã‚¹ã‚°ãƒ¬ãƒ¼ãƒ‰']
        grade_col = next((col for col in grade_candidates if col in df.columns), None)
        
        if grade_col is not None:
            # æ¨å®šæ¸ˆã¿ã‚°ãƒ¬ãƒ¼ãƒ‰å€¤ãŒå­˜åœ¨ã™ã‚‹å ´åˆã€ãã‚Œã‚’æ´»ç”¨
            logger.info(f"ğŸ“Š æ¨å®šæ¸ˆã¿ã‚°ãƒ¬ãƒ¼ãƒ‰å€¤ã‚’ä½¿ç”¨: {grade_col}")
            
            # ã‚°ãƒ¬ãƒ¼ãƒ‰å€¤ã®æ•°å€¤å¤‰æ›
            df_copy = df.copy()
            df_copy[grade_col] = pd.to_numeric(df_copy[grade_col], errors='coerce')
            
            # ã‚°ãƒ¬ãƒ¼ãƒ‰å€¤ã®çµ±è¨ˆç¢ºèª
            valid_grades = df_copy[grade_col].dropna()
            if len(valid_grades) > 0:
                logger.info(f"   ğŸ“ˆ æœ‰åŠ¹ã‚°ãƒ¬ãƒ¼ãƒ‰å€¤: {len(valid_grades):,}ä»¶")
                logger.info(f"   ğŸ“Š ã‚°ãƒ¬ãƒ¼ãƒ‰ç¯„å›²: {valid_grades.min():.0f} - {valid_grades.max():.0f}")
                logger.info(f"   ğŸ“‹ ã‚°ãƒ¬ãƒ¼ãƒ‰åˆ†å¸ƒ: {valid_grades.value_counts().to_dict()}")
                
                # process_race_data.pyã§æ¨å®šã•ã‚ŒãŸã‚°ãƒ¬ãƒ¼ãƒ‰å€¤ã‚’grade_levelã«å¤‰æ›
                grade_level = self._convert_grade_to_level(df_copy, grade_col)
                
                # æ®‹å­˜æ¬ æå€¤ã®å‡¦ç†ï¼ˆæ¨å®šã§ããªã‹ã£ãŸåˆ†ï¼‰
                remaining_missing = grade_level.isnull().sum()
                if remaining_missing > 0:
                    logger.warning(f"âš ï¸ æ®‹å­˜æ¬ æã‚°ãƒ¬ãƒ¼ãƒ‰: {remaining_missing}ä»¶ â†’ è³é‡‘ãƒ™ãƒ¼ã‚¹æ¨å®šã§ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯")
                    # æ¬ æéƒ¨åˆ†ã®ã¿è³é‡‘ãƒ™ãƒ¼ã‚¹è¨ˆç®—
                    fallback_levels = self._calculate_grade_level_from_prize(df_copy)
                    grade_level = grade_level.fillna(fallback_levels)
                
                logger.info(f"âœ… æ¨å®šæ¸ˆã¿ã‚°ãƒ¬ãƒ¼ãƒ‰ãƒ™ãƒ¼ã‚¹ã®grade_levelè¨ˆç®—å®Œäº†: ç¯„å›² {grade_level.min():.2f} - {grade_level.max():.2f}")
                return grade_level
            else:
                logger.warning(f"âš ï¸ {grade_col}åˆ—ã¯å­˜åœ¨ã—ã¾ã™ãŒã€æœ‰åŠ¹ãªå€¤ãŒã‚ã‚Šã¾ã›ã‚“")
        
        # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: æ¨å®šæ¸ˆã¿ã‚°ãƒ¬ãƒ¼ãƒ‰ãŒåˆ©ç”¨ã§ããªã„å ´åˆã¯è³é‡‘ãƒ™ãƒ¼ã‚¹è¨ˆç®—
        logger.info("ğŸ“Š æ¨å®šæ¸ˆã¿ã‚°ãƒ¬ãƒ¼ãƒ‰ãŒåˆ©ç”¨ã§ããªã„ãŸã‚ã€è³é‡‘ãƒ™ãƒ¼ã‚¹è¨ˆç®—ã«ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯")
        return self._calculate_grade_level_from_prize(df)
    
    def _create_feature_scatter_plots(self) -> None:
        """ç‰¹å¾´é‡ã¨è¤‡å‹ç‡ã®æ•£å¸ƒå›³ï¼ˆå›å¸°åˆ†æä»˜ãï¼‰ã‚’ä½œæˆ"""
        try:
            logger.info("ğŸ“Š ç‰¹å¾´é‡ã¨è¤‡å‹ç‡ã®æ•£å¸ƒå›³ä½œæˆã‚’é–‹å§‹...")
            
            # é¦¬çµ±è¨ˆãƒ‡ãƒ¼ã‚¿ã‚’å†è¨ˆç®—
            horse_stats = self._calculate_horse_stats()
            
            if len(horse_stats) == 0:
                logger.warning("âš ï¸ é¦¬çµ±è¨ˆãƒ‡ãƒ¼ã‚¿ãŒç©ºã®ãŸã‚ã€æ•£å¸ƒå›³ä½œæˆã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™")
                return
            
            # ä½œæˆã™ã‚‹æ•£å¸ƒå›³ã®ãƒªã‚¹ãƒˆ
            features_to_plot = [
                {
                    'x_col': 'race_level',
                    'x_label': 'ãƒ¬ãƒ¼ã‚¹ãƒ¬ãƒ™ãƒ«',
                    'title': 'ãƒ¬ãƒ¼ã‚¹ãƒ¬ãƒ™ãƒ«ã¨è¤‡å‹ç‡ã®é–¢ä¿‚',
                    'filename': 'race_level_place_rate_scatter'
                },
                {
                    'x_col': 'grade_level',
                    'x_label': 'ã‚°ãƒ¬ãƒ¼ãƒ‰ãƒ¬ãƒ™ãƒ«',
                    'title': 'ã‚°ãƒ¬ãƒ¼ãƒ‰ãƒ¬ãƒ™ãƒ«ã¨è¤‡å‹ç‡ã®é–¢ä¿‚',
                    'filename': 'grade_level_place_rate_scatter'
                },
                {
                    'x_col': 'venue_level',
                    'x_label': 'å ´æ‰€ãƒ¬ãƒ™ãƒ«',
                    'title': 'å ´æ‰€ãƒ¬ãƒ™ãƒ«ã¨è¤‡å‹ç‡ã®é–¢ä¿‚',
                    'filename': 'venue_level_place_rate_scatter'
                },
                {
                    'x_col': 'distance_level',
                    'x_label': 'è·é›¢ãƒ¬ãƒ™ãƒ«',
                    'title': 'è·é›¢ãƒ¬ãƒ™ãƒ«ã¨è¤‡å‹ç‡ã®é–¢ä¿‚',
                    'filename': 'distance_level_place_rate_scatter'
                }
            ]
            
            # å„ç‰¹å¾´é‡ã«å¯¾ã—ã¦æ•£å¸ƒå›³ã‚’ä½œæˆï¼ˆå­˜åœ¨ã™ã‚‹ç‰¹å¾´é‡ã®ã¿ï¼‰
            for feature_config in features_to_plot:
                x_col = feature_config['x_col']
                if x_col in horse_stats.columns or x_col in self.df.columns:
                    self._create_individual_feature_scatter(horse_stats, feature_config)
                else:
                    logger.warning(f"âš ï¸ ç‰¹å¾´é‡ '{x_col}' ãŒè¦‹ã¤ã‹ã‚‰ãªã„ãŸã‚ã€{feature_config['title']}ã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™")
                
        except Exception as e:
            logger.error(f"âŒ ç‰¹å¾´é‡æ•£å¸ƒå›³ä½œæˆä¸­ã«ã‚¨ãƒ©ãƒ¼: {str(e)}")
            import traceback
            traceback.print_exc()
    
    def _create_individual_feature_scatter(self, horse_stats: pd.DataFrame, config: dict) -> None:
        """å€‹åˆ¥ç‰¹å¾´é‡ã®æ•£å¸ƒå›³ä½œæˆ"""
        try:
            x_col = config['x_col']
            
            # ãƒ¬ãƒ¼ã‚¹å˜ä½ã®ç‰¹å¾´é‡ã‹ã‚‰é¦¬å˜ä½ã®çµ±è¨ˆã‚’è¨ˆç®—
            if x_col in horse_stats.columns:
                x_data = horse_stats[x_col]
                y_data = horse_stats['place_rate']
            elif x_col in self.df.columns:
                # ãƒ¬ãƒ¼ã‚¹ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰é¦¬å˜ä½ã§ç‰¹å¾´é‡ã‚’é›†è¨ˆ
                feature_stats = self.df.groupby('é¦¬å')[x_col].agg(['mean', 'max']).reset_index()
                place_stats = self.df.groupby('é¦¬å')['ç€é †'].apply(lambda x: (x <= 3).mean()).reset_index()
                place_stats.columns = ['é¦¬å', 'place_rate']
                
                # ãƒãƒ¼ã‚¸
                merged_data = pd.merge(feature_stats, place_stats, on='é¦¬å')
                x_data = merged_data['mean']  # å¹³å‡å€¤ã‚’ä½¿ç”¨
                y_data = merged_data['place_rate']
            else:
                logger.warning(f"âš ï¸ {config['title']}: ç‰¹å¾´é‡ '{x_col}' ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™ã€‚")
                return
            
            # æ¬ æå€¤ã‚’é™¤å»
            valid_mask = (~x_data.isnull()) & (~y_data.isnull())
            x_clean = x_data[valid_mask]
            y_clean = y_data[valid_mask]
            
            if len(x_clean) < 10:
                logger.warning(f"âš ï¸ {config['title']}: æœ‰åŠ¹ãƒ‡ãƒ¼ã‚¿ãŒä¸è¶³ ({len(x_clean)}ä»¶)")
                return
            
            # çµ±è¨ˆåˆ†æ
            from scipy.stats import pearsonr
            correlation, p_value = pearsonr(x_clean, y_clean)
            
            # ç·šå½¢å›å¸°
            from sklearn.linear_model import LinearRegression
            model = LinearRegression()
            X = x_clean.values.reshape(-1, 1)
            y = y_clean.values
            model.fit(X, y)
            y_pred = model.predict(X)
            r2 = model.score(X, y)
            
            logger.info(f"   ğŸ“ˆ {config['title']}: r={correlation:.3f}, RÂ²={r2:.3f}, p={p_value:.3e}")
            
            # æ•£å¸ƒå›³ä½œæˆ
            import matplotlib.pyplot as plt
            import numpy as np
            import matplotlib.font_manager as fm
            
            # æ—¥æœ¬èªãƒ•ã‚©ãƒ³ãƒˆã®å†è¨­å®šï¼ˆç¢ºå®Ÿã«é©ç”¨ã™ã‚‹ãŸã‚ï¼‰
            if platform.system() == 'Windows':
                plt.rcParams['font.family'] = ['Yu Gothic', 'Meiryo', 'MS Gothic', 'sans-serif']
            
            # figureã‚µã‚¤ã‚ºã‚’èª¿æ•´ã—ã€å³å´ã«çµ±è¨ˆæƒ…å ±ç”¨ã®ä½™ç™½ã‚’ç¢ºä¿
            fig, ax = plt.subplots(figsize=(14, 8))
            
            # æ•£å¸ƒå›³
            ax.scatter(x_clean, y_clean, alpha=0.6, s=50, color='steelblue', 
                       edgecolors='white', linewidth=0.5)
            
            # å›å¸°ç›´ç·š
            x_range = np.linspace(x_clean.min(), x_clean.max(), 100)
            y_range = model.predict(x_range.reshape(-1, 1))
            ax.plot(x_range, y_range, 'r-', linewidth=2, 
                    label=f'å›å¸°ç›´ç·š (RÂ² = {r2:.3f})')
            
            # è£…é£¾
            ax.set_title(f'{config["title"]}\nç›¸é–¢ä¿‚æ•°: r={correlation:.3f} (p={p_value:.3e})', 
                         fontsize=14, pad=20)
            ax.set_xlabel(config['x_label'], fontsize=12)
            ax.set_ylabel('è¤‡å‹ç‡', fontsize=12)
            ax.set_ylim(-0.05, 1.05)
            ax.grid(True, alpha=0.3)
            ax.legend()
            
            # çµ±è¨ˆæƒ…å ±ãƒœãƒƒã‚¯ã‚¹ã‚’å›³ã®å³å´ï¼ˆæ å¤–ï¼‰ã«é…ç½®
            stats_text = f'ã‚µãƒ³ãƒ—ãƒ«æ•°: {len(x_clean):,}é ­\n'
            stats_text += f'ç›¸é–¢ä¿‚æ•°: r={correlation:.3f}\n'
            stats_text += f'æ±ºå®šä¿‚æ•°: RÂ²={r2:.3f}\n'
            stats_text += f'på€¤: {p_value:.3e}\n'
            stats_text += f'æœ‰æ„æ€§: {"æœ‰æ„" if p_value < 0.05 else "éæœ‰æ„"}'
            
            # figureã«å¯¾ã—ã¦å³å´ã®ä½ç½®ã«çµ±è¨ˆæƒ…å ±ã‚’é…ç½®
            fig.text(0.78, 0.98, stats_text,
                    bbox=dict(boxstyle='round', facecolor='lightblue', alpha=0.8),
                    verticalalignment='top', fontsize=10,
                    transform=fig.transFigure)
            
            # ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆèª¿æ•´ï¼ˆçµ±è¨ˆæƒ…å ±ç”¨ã®ä½™ç™½ã‚’ç¢ºä¿ï¼‰
            plt.subplots_adjust(right=0.75)
            
            # ä¿å­˜
            output_path = self.output_dir / f"{config['filename']}.png"
            plt.savefig(output_path, dpi=300, bbox_inches='tight')
            plt.close()
            
            logger.info(f"   ğŸ’¾ æ•£å¸ƒå›³ã‚’ä¿å­˜: {output_path}")
            
        except Exception as e:
            logger.error(f"âŒ {config['title']}ã®æ•£å¸ƒå›³ä½œæˆã‚¨ãƒ©ãƒ¼: {str(e)}")
            import traceback
            traceback.print_exc()
    
    def _convert_grade_to_level(self, df: pd.DataFrame, grade_col: str) -> pd.Series:
        """æ¨å®šæ¸ˆã¿ã‚°ãƒ¬ãƒ¼ãƒ‰å€¤ã‚’grade_levelã«å¤‰æ›"""
        
        # æ•°å€¤ã‚°ãƒ¬ãƒ¼ãƒ‰ãƒãƒƒãƒ”ãƒ³ã‚°ï¼ˆprocess_race_data.pyã®MissingValueHandlerã¨æ•´åˆæ€§ã®ã‚ã‚‹ï¼‰
        numeric_grade_mapping = {
            1: 9.0,   # G1 â†’ æœ€é«˜ãƒ¬ãƒ™ãƒ«
            2: 7.5,   # G2 â†’ é«˜ãƒ¬ãƒ™ãƒ«
            3: 6.0,   # G3 â†’ ä¸­é«˜ãƒ¬ãƒ™ãƒ«
            4: 4.5,   # é‡è³ â†’ ä¸­ãƒ¬ãƒ™ãƒ«
            5: 2.0,   # ç‰¹åˆ¥ â†’ ä¸­ä½ãƒ¬ãƒ™ãƒ«
            6: 3.0    # Lï¼ˆãƒªã‚¹ãƒ†ãƒƒãƒ‰ï¼‰ â†’ ä¸­ãƒ¬ãƒ™ãƒ«
        }
        
        # æ–‡å­—åˆ—ã‚°ãƒ¬ãƒ¼ãƒ‰ãƒãƒƒãƒ”ãƒ³ã‚°ï¼ˆãƒ‡ãƒ¼ã‚¿ã«å«ã¾ã‚Œã‚‹æ–‡å­—åˆ—å½¢å¼ï¼‰
        string_grade_mapping = {
            'ï¼§ï¼‘': 9.0, 'G1': 9.0, 'g1': 9.0,
            'ï¼§ï¼’': 7.5, 'G2': 7.5, 'g2': 7.5,
            'ï¼§ï¼“': 6.0, 'G3': 6.0, 'g3': 6.0,
            'é‡è³': 4.5, 'é‡è³ãƒ¬ãƒ¼ã‚¹': 4.5,
            'ç‰¹åˆ¥': 2.0, 'OP': 2.0, 'ã‚ªãƒ¼ãƒ—ãƒ³': 2.0,
            'ï¼¬ã€€ï¼ˆãƒªã‚¹ãƒ†ãƒƒãƒ‰ç«¶èµ°ï¼‰': 3.0, 'L': 3.0, 'ãƒªã‚¹ãƒ†ãƒƒãƒ‰': 3.0,
            'æ¡ä»¶æˆ¦': 1.0, 'æœªå‹åˆ©': 0.5, 'æ–°é¦¬': 0.5
        }
        
        # æ•°å€¤ã‚°ãƒ¬ãƒ¼ãƒ‰ã®å‡¦ç†
        df_copy = df.copy()
        grade_series = df_copy[grade_col].copy()
        
        # æ•°å€¤ã¨ã—ã¦è§£é‡ˆå¯èƒ½ãªå€¤ã‚’å…ˆã«å‡¦ç†
        numeric_mask = pd.to_numeric(grade_series, errors='coerce').notna()
        if numeric_mask.any():
            numeric_values = pd.to_numeric(grade_series[numeric_mask], errors='coerce')
            numeric_mapped = numeric_values.map(numeric_grade_mapping)
            grade_series[numeric_mask] = numeric_mapped
        
        # æ–‡å­—åˆ—ã‚°ãƒ¬ãƒ¼ãƒ‰ã®å‡¦ç†
        string_mask = grade_series.notna() & ~numeric_mask
        if string_mask.any():
            string_values = grade_series[string_mask].astype(str)
            string_mapped = string_values.map(string_grade_mapping)
            grade_series[string_mask] = string_mapped
        
        # æœ€çµ‚çš„ãªæ•°å€¤å¤‰æ›
        grade_level = pd.to_numeric(grade_series, errors='coerce')
        
        # ãƒãƒƒãƒ”ãƒ³ã‚°çµæœã®çµ±è¨ˆ
        successful_mapping = grade_level.notna().sum()
        total_valid = df[grade_col].notna().sum()
        unmapped_count = total_valid - successful_mapping
        
        if unmapped_count > 0:
            unmapped_mask = df[grade_col].notna() & grade_level.isnull()
            unmapped_values = df[grade_col][unmapped_mask].unique()
            logger.warning(f"âš ï¸ æœªå¯¾å¿œã‚°ãƒ¬ãƒ¼ãƒ‰å€¤: {unmapped_values} ({unmapped_count}ä»¶)")
        
        # å¤‰æ›çµ±è¨ˆã®å‡ºåŠ›
        if successful_mapping > 0:
            logger.info("ğŸ“Š ã‚°ãƒ¬ãƒ¼ãƒ‰â†’ãƒ¬ãƒ™ãƒ«å¤‰æ›çµ±è¨ˆ:")
            logger.info(f"   â€¢ æˆåŠŸ: {successful_mapping:,}ä»¶ ({successful_mapping/total_valid*100:.1f}%)")
            logger.info(f"   â€¢ ç¯„å›²: {grade_level.min():.1f} - {grade_level.max():.1f}")
            
            # å¤‰æ›çµæœã®åˆ†å¸ƒ
            value_counts = grade_level.value_counts().head(5)
            for level, count in value_counts.items():
                logger.info(f"   â€¢ Level{level}: {count:,}ä»¶")
        
        return grade_level
    
    def _calculate_grade_level_from_prize(self, df: pd.DataFrame) -> pd.Series:
        """è³é‡‘ãƒ™ãƒ¼ã‚¹ã®ã‚°ãƒ¬ãƒ¼ãƒ‰ãƒ¬ãƒ™ãƒ«è¨ˆç®—ï¼ˆä¸­å¤®å€¤ãƒ™ãƒ¼ã‚¹ï¼‰"""
        
        # è³é‡‘ã‚«ãƒ©ãƒ ã®ç‰¹å®š
        prize_col = next((c for c in ['1ç€è³é‡‘(1ç€ç®—å…¥è³é‡‘è¾¼ã¿)', '1ç€è³é‡‘', 'æœ¬è³é‡‘'] if c in df.columns), None)
        if prize_col is None:
            logger.warning("âš ï¸ è³é‡‘ã‚«ãƒ©ãƒ ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚grade_levelã‚’ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ã§è¨­å®š")
            return pd.Series([5.0] * len(df), index=df.index)

        # ã‚°ãƒ¬ãƒ¼ãƒ‰ã‚«ãƒ©ãƒ ã®ç‰¹å®š
        grade_col = next((c for c in ['ã‚°ãƒ¬ãƒ¼ãƒ‰', 'grade', 'ãƒ¬ãƒ¼ã‚¹ã‚°ãƒ¬ãƒ¼ãƒ‰'] if c in df.columns), None)
        if grade_col is None:
            logger.warning("âš ï¸ ã‚°ãƒ¬ãƒ¼ãƒ‰ã‚«ãƒ©ãƒ ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚grade_levelã‚’ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ã§è¨­å®š")
            return pd.Series([5.0] * len(df), index=df.index)

        # è³é‡‘ãƒ‡ãƒ¼ã‚¿ã®æ•°å€¤å¤‰æ›
        df_copy = df.copy()
        df_copy[prize_col] = pd.to_numeric(df_copy[prize_col], errors='coerce')
        df_copy[grade_col] = pd.to_numeric(df_copy[grade_col], errors='coerce')
        
        # ã‚°ãƒ¬ãƒ¼ãƒ‰åˆ¥ã®è³é‡‘ä¸­å¤®å€¤
        grade_prize_median = df_copy.groupby(grade_col)[prize_col].median().dropna()
        
        if len(grade_prize_median) == 0:
            logger.warning("âš ï¸ ã‚°ãƒ¬ãƒ¼ãƒ‰åˆ¥è³é‡‘ãƒ‡ãƒ¼ã‚¿ãŒè¨ˆç®—ã§ãã¾ã›ã‚“ã€‚grade_levelã‚’ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ã§è¨­å®š")
            return pd.Series([5.0] * len(df), index=df.index)
        
        # MinMaxScalerã«ã‚ˆã‚‹æ­£è¦åŒ–ï¼ˆ0-9ãƒã‚¤ãƒ³ãƒˆï¼‰
        from sklearn.preprocessing import MinMaxScaler
        scaler = MinMaxScaler(feature_range=(0, 9))
        normalized_values = scaler.fit_transform(grade_prize_median.values.reshape(-1, 1)).flatten()
        
        # ã‚°ãƒ¬ãƒ¼ãƒ‰â†’ãƒã‚¤ãƒ³ãƒˆã®ãƒãƒƒãƒ”ãƒ³ã‚°ä½œæˆ
        grade_points_map = dict(zip(grade_prize_median.index, normalized_values))
        
        # ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã«é©ç”¨
        grade_level = df_copy[grade_col].map(grade_points_map).fillna(0)
        
        logger.info(f"âœ… ä¸­å¤®å€¤ãƒ™ãƒ¼ã‚¹ã®grade_levelè¨ˆç®—å®Œäº†: ç¯„å›² {grade_level.min():.2f} - {grade_level.max():.2f}")
        logger.info(f"ğŸ“Š ã‚°ãƒ¬ãƒ¼ãƒ‰åˆ¥è³é‡‘ä¸­å¤®å€¤: {grade_prize_median.to_dict()}")
        
        return grade_level

    def _calculate_venue_level(self, df: pd.DataFrame) -> pd.Series:
        """ç«¶é¦¬å ´ã«åŸºã¥ããƒ¬ãƒ™ãƒ«ã‚’è¨ˆç®—ï¼ˆæ”¹è‰¯ç‰ˆï¼šè³é‡‘åŒä¸€å€¤å¯¾å¿œï¼‰"""
        prize_col = next((c for c in ['1ç€è³é‡‘(1ç€ç®—å…¥è³é‡‘è¾¼ã¿)', '1ç€è³é‡‘', 'æœ¬è³é‡‘'] if c in df.columns), None)
        if prize_col is None or 'å ´å' not in df.columns:
            logger.warning("âš ï¸ è³é‡‘ã¾ãŸã¯å ´åã‚«ãƒ©ãƒ ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚venue_levelã‚’ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ã§è¨­å®š")
            return pd.Series([0.0] * len(df), index=df.index)

        # è³é‡‘ãƒ‡ãƒ¼ã‚¿ã®æ•°å€¤å¤‰æ›
        df_copy = df.copy()
        df_copy[prize_col] = pd.to_numeric(df_copy[prize_col], errors='coerce')
        
        # ç«¶é¦¬å ´åˆ¥ã®è³é‡‘çµ±è¨ˆ
        venue_stats = df_copy.groupby('å ´å')[prize_col].agg(['median', 'mean', 'count', 'std']).fillna(0)
        
        logger.info(f"ğŸ“Š ç«¶é¦¬å ´åˆ¥è³é‡‘çµ±è¨ˆ:\n{venue_stats}")
        
        # è³é‡‘ã®ãƒãƒªã‚¨ãƒ¼ã‚·ãƒ§ãƒ³ã‚’ãƒã‚§ãƒƒã‚¯
        venue_prize = venue_stats['median']
        min_prize = venue_prize.min()
        max_prize = venue_prize.max()
        
        # ğŸ”¥ ä¿®æ­£: è³é‡‘å·®ãŒå°ã•ã™ãã‚‹å ´åˆã‚‚æ ¼å¼ãƒ™ãƒ¼ã‚¹ã«åˆ‡ã‚Šæ›¿ãˆ
        prize_diff = max_prize - min_prize
        relative_diff = prize_diff / max_prize if max_prize > 0 else 0
        
        if max_prize == min_prize or abs(max_prize - min_prize) < 1e-6 or relative_diff < 0.05:
            # å…¨ç«¶é¦¬å ´ã®è³é‡‘ãŒåŒä¸€ã®å ´åˆã€ç«¶é¦¬å ´ã®æ ¼å¼ã«åŸºã¥ããƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
            logger.warning(f"âš ï¸ ç«¶é¦¬å ´é–“ã®è³é‡‘å·®ãŒå°ã•ã™ãã‚‹ï¼ˆå·®é¡:{prize_diff:.1f}ä¸‡å††, ç›¸å¯¾å·®:{relative_diff:.1%}ï¼‰ãŸã‚ã€æ ¼å¼ãƒ™ãƒ¼ã‚¹ã®è¨ˆç®—ã«åˆ‡ã‚Šæ›¿ãˆ")
            venue_level = self._calculate_venue_level_by_prestige(df_copy)
        else:
            # é€šå¸¸ã®è³é‡‘ãƒ™ãƒ¼ã‚¹è¨ˆç®—
            venue_points = (venue_prize - min_prize) / (max_prize - min_prize) * 9.0
            venue_level = df_copy['å ´å'].map(venue_points).fillna(0)
            logger.info(f"âœ… è³é‡‘ãƒ™ãƒ¼ã‚¹ã®venue_levelè¨ˆç®—å®Œäº†: ç¯„å›² {venue_level.min():.2f} - {venue_level.max():.2f}")

        return self.normalize_values(venue_level)
    
    def _calculate_venue_level_by_prestige(self, df: pd.DataFrame) -> pd.Series:
        """ç«¶é¦¬å ´ã®æ ¼å¼ã«åŸºã¥ãvenue_levelè¨ˆç®—ï¼ˆãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼‰"""
        
        # ç«¶é¦¬å ´ã®æ ¼å¼ãƒãƒƒãƒ”ãƒ³ã‚°ï¼ˆãƒ¬ãƒãƒ¼ãƒˆè¨˜è¼‰ã®å€¤ã«åŸºã¥ãï¼‰
        venue_prestige_map = {
            'æ±äº¬': 9, 'äº¬éƒ½': 9, 'é˜ªç¥': 9,
            'ä¸­å±±': 7, 'ä¸­äº¬': 7, 'æœ­å¹Œ': 7,
            'å‡½é¤¨': 4,
            'æ–°æ½Ÿ': 0, 'ç¦å³¶': 0, 'å°å€‰': 0
        }
        
        logger.info("ğŸ“‹ æ ¼å¼ãƒ™ãƒ¼ã‚¹ã®ç«¶é¦¬å ´ãƒ¬ãƒ™ãƒ«è¨ˆç®—ã‚’ä½¿ç”¨:")
        for venue, level in venue_prestige_map.items():
            logger.info(f"  {venue}: {level}")
        
        # ãƒãƒƒãƒ”ãƒ³ã‚°é©ç”¨
        venue_level = df['å ´å'].map(venue_prestige_map).fillna(0)
        
        # çµ±è¨ˆç¢ºèª
        logger.info(f"âœ… æ ¼å¼ãƒ™ãƒ¼ã‚¹ã®venue_levelè¨ˆç®—å®Œäº†:")
        logger.info(f"  ç¯„å›²: {venue_level.min():.2f} - {venue_level.max():.2f}")
        logger.info(f"  ãƒ¦ãƒ‹ãƒ¼ã‚¯å€¤: {sorted(venue_level.unique())}")
        
        return venue_level
    
    def _calculate_distance_level(self, df: pd.DataFrame) -> pd.Series:
        """
        è·é›¢ãƒ¬ãƒ™ãƒ«ã®è¨ˆç®—
        ãƒ¬ãƒãƒ¼ãƒˆè¨˜è¼‰ã®ãƒ‰ãƒ¡ã‚¤ãƒ³çŸ¥è­˜ã«åŸºã¥ãè£œæ­£ä¿‚æ•°ï¼ˆ3.1ç¯€ã‚ˆã‚Šï¼‰
        """
        distance_col = 'è·é›¢'
        if distance_col not in df.columns:
            logger.warning("âš ï¸ è·é›¢ã‚«ãƒ©ãƒ ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚è·é›¢ãƒ¬ãƒ™ãƒ«ã‚’1.0ã§è¨­å®š")
            return pd.Series([1.0] * len(df), index=df.index)
        
        # ãƒ‰ãƒ¡ã‚¤ãƒ³çŸ¥è­˜ã«åŸºã¥ãè·é›¢è£œæ­£ä¿‚æ•°ï¼ˆãƒ¬ãƒãƒ¼ãƒˆ3.1ç¯€ã‚ˆã‚Šï¼‰
        def categorize_distance(distance):
            if pd.isna(distance):
                return 1.0
            if distance <= 1400:
                return 0.85    # ã‚¹ãƒ—ãƒªãƒ³ãƒˆ
            elif distance <= 1800:
                return 1.00    # ãƒã‚¤ãƒ«ï¼ˆåŸºæº–ï¼‰
            elif distance <= 2000:
                return 1.35    # ä¸­è·é›¢
            elif distance <= 2400:
                return 1.45    # ä¸­é•·è·é›¢
            else:
                return 1.25    # é•·è·é›¢
        
        distance_level = df[distance_col].apply(categorize_distance)
        
        logger.info(f"âœ… è·é›¢ãƒ¬ãƒ™ãƒ«è¨ˆç®—å®Œäº†: ç¯„å›² {distance_level.min():.2f} - {distance_level.max():.2f}")
        
        return distance_level

    def _calculate_result_weight(self, df: pd.DataFrame) -> pd.Series:
        """
        ç€é †ã«åŸºã¥ãçµæœé‡ã¿ä»˜ã‘ã‚’è¨ˆç®—
        
        ãƒ¬ãƒãƒ¼ãƒˆ614è¡Œç›®ã®å°†æ¥æ”¹å–„æ¡ˆã‚’å®Ÿè£…:
        ã€ŒRacePointã‚’ç€é †ã«å¿œã˜ã¦é‡ã¿ä»˜ã‘ï¼ˆä¾‹: 1ç€ã¯1.0å€ã€2ç€ã¯0.8å€ã€ç€å¤–ã¯0.1å€ãªã©ï¼‰ã€
        
        Args:
            df: ãƒ¬ãƒ¼ã‚¹ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ï¼ˆç€é †ã‚«ãƒ©ãƒ å¿…é ˆï¼‰
        
        Returns:
            pd.Series: ç€é †ã«åŸºã¥ãé‡ã¿ä¿‚æ•°ï¼ˆ1ç€=1.0, 2ç€=0.8, 3ç€=0.6, ç€å¤–=0.1ï¼‰
        """
        finish_col = 'ç€é †'
        if finish_col not in df.columns:
            logger.warning("âš ï¸ ç€é †ã‚«ãƒ©ãƒ ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚çµæœé‡ã¿ã‚’1.0ã§è¨­å®š")
            return pd.Series([1.0] * len(df), index=df.index)
        
        # ç€é †ã«ã‚ˆã‚‹é‡ã¿ä»˜ã‘ãƒãƒƒãƒ—ï¼ˆç«¶é¦¬ã®ãƒ‰ãƒ¡ã‚¤ãƒ³çŸ¥è­˜ã«åŸºã¥ãï¼‰
        def get_result_weight(finish_position):
            """ç€é †ã‹ã‚‰çµæœé‡ã¿ã‚’è¨ˆç®—"""
            if pd.isna(finish_position):
                return 0.1  # ç€é †ä¸æ˜ã®å ´åˆã¯æœ€å°é‡ã¿
            
            try:
                pos = int(finish_position)
                if pos == 1:
                    return 1.0  # 1ç€: æœ€å¤§é‡ã¿ï¼ˆå®Œå…¨ãªæˆåŠŸï¼‰
                elif pos == 2:
                    return 0.8  # 2ç€: é«˜é‡ã¿ï¼ˆå„ªç§€ãªæˆç¸¾ï¼‰
                elif pos == 3:
                    return 0.6  # 3ç€: ä¸­é‡ã¿ï¼ˆè¤‡å‹åœå†…ã®ä¾¡å€¤ï¼‰
                else:
                    return 0.1  # ç€å¤–: æœ€å°é‡ã¿ï¼ˆçµŒé¨“ä¾¡å€¤ã®ã¿ï¼‰
            except (ValueError, TypeError):
                return 0.1  # å¤‰æ›ã§ããªã„å ´åˆ
        
        # çµæœé‡ã¿ã‚’é©ç”¨
        result_weight = df[finish_col].apply(get_result_weight)
        
        # çµ±è¨ˆãƒ­ã‚°å‡ºåŠ›
        weight_distribution = result_weight.value_counts().sort_index()
        logger.info(f"âœ… ç€é †åˆ¥çµæœé‡ã¿è¨ˆç®—å®Œäº†:")
        logger.info(f"  1ç€(1.0): {(result_weight == 1.0).sum():,}ä»¶")
        logger.info(f"  2ç€(0.8): {(result_weight == 0.8).sum():,}ä»¶") 
        logger.info(f"  3ç€(0.6): {(result_weight == 0.6).sum():,}ä»¶")
        logger.info(f"  ç€å¤–(0.1): {(result_weight == 0.1).sum():,}ä»¶")
        logger.info(f"  å¹³å‡é‡ã¿: {result_weight.mean():.3f}")
        
        return result_weight
    
    def _apply_historical_result_weights(self, df: pd.DataFrame, base_race_level: pd.Series) -> pd.Series:
        """
        æ™‚é–“çš„åˆ†é›¢ã«ã‚ˆã‚‹è¤‡å‹çµæœé‡ã¿ä»˜ã‘ã‚’é©ç”¨
        
        å„é¦¬ã®éå»ã®è¤‡å‹å®Ÿç¸¾ã«åŸºã¥ã„ã¦ã€ç¾åœ¨ã®ãƒ¬ãƒ¼ã‚¹ãƒ¬ãƒ™ãƒ«ã‚’èª¿æ•´ã™ã‚‹ã€‚
        ã“ã‚Œã«ã‚ˆã‚Šå¾ªç’°è«–ç†ã‚’å›é¿ã—ã¤ã¤ã€è¤‡å‹çµæœã®ä¾¡å€¤ã‚’çµ±åˆã™ã‚‹ã€‚
        
        Args:
            df: ãƒ¬ãƒ¼ã‚¹ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ 
            base_race_level: åŸºæœ¬ãƒ¬ãƒ¼ã‚¹ãƒ¬ãƒ™ãƒ«
            
        Returns:
            pd.Series: è¤‡å‹å®Ÿç¸¾èª¿æ•´æ¸ˆã¿ãƒ¬ãƒ¼ã‚¹ãƒ¬ãƒ™ãƒ«
        """
        # ãƒ‡ãƒ¼ã‚¿ã‚’ã‚³ãƒ”ãƒ¼ã—ã¦ä½œæ¥­
        df_work = df.copy()
        df_work['base_race_level'] = base_race_level
        df_work['å¹´æœˆæ—¥'] = pd.to_datetime(df_work['å¹´æœˆæ—¥'], format='%Y%m%d')
        
        # çµæœæ ¼ç´ç”¨
        adjusted_race_level = base_race_level.copy()
        
        # é¦¬ã”ã¨ã«éå»å®Ÿç¸¾ãƒ™ãƒ¼ã‚¹ã®èª¿æ•´ã‚’å®Ÿæ–½
        for horse_name in df_work['é¦¬å'].unique():
            horse_data = df_work[df_work['é¦¬å'] == horse_name].sort_values('å¹´æœˆæ—¥')
            
            for idx, row in horse_data.iterrows():
                current_date = row['å¹´æœˆæ—¥']
                
                # ç¾åœ¨ã®ãƒ¬ãƒ¼ã‚¹ã‚ˆã‚Šå‰ã®å®Ÿç¸¾ã‚’å–å¾—
                past_data = horse_data[horse_data['å¹´æœˆæ—¥'] < current_date]
                
                if len(past_data) == 0:
                    # éå»å®Ÿç¸¾ãŒãªã„å ´åˆã¯åŸºæœ¬å€¤ã‚’ä½¿ç”¨
                    continue
                
                # éå»ã®è¤‡å‹ç‡ã‚’è¨ˆç®—
                past_place_rate = (past_data['ç€é †'] <= 3).mean()
                
                # è¤‡å‹ç‡ã«åŸºã¥ãèª¿æ•´ä¿‚æ•°ã‚’ç®—å‡º
                # è¤‡å‹ç‡ãŒé«˜ã„é¦¬ã»ã©å®Ÿç¸¾ã‚’é‡è¦–ï¼ˆæœ€å¤§1.2å€ã€æœ€å°0.8å€ï¼‰
                if past_place_rate >= 0.5:
                    adjustment_factor = 1.0 + (past_place_rate - 0.5) * 0.4  # 0.5ä»¥ä¸Šã§1.0-1.2
                elif past_place_rate >= 0.3:
                    adjustment_factor = 1.0  # 0.3-0.5ã§1.0ï¼ˆæ¨™æº–ï¼‰
                else:
                    adjustment_factor = 1.0 - (0.3 - past_place_rate) * 0.67  # 0.3æœªæº€ã§0.8-1.0
                
                # èª¿æ•´ä¿‚æ•°ã‚’é©ç”¨ï¼ˆä¸Šé™ãƒ»ä¸‹é™è¨­å®šï¼‰
                adjustment_factor = max(0.8, min(1.2, adjustment_factor))
                
                # èª¿æ•´æ¸ˆã¿race_levelã‚’è¨­å®š
                adjusted_race_level.loc[idx] = base_race_level.loc[idx] * adjustment_factor
        
        # çµ±è¨ˆæƒ…å ±ã‚’ãƒ­ã‚°å‡ºåŠ›
        adjustment_stats = adjusted_race_level / base_race_level
        logger.info(f"âœ… éå»å®Ÿç¸¾ãƒ™ãƒ¼ã‚¹è¤‡å‹çµæœçµ±åˆå®Œäº†:")
        logger.info(f"  å¹³å‡èª¿æ•´ä¿‚æ•°: {adjustment_stats.mean():.3f}")
        logger.info(f"  èª¿æ•´ä¿‚æ•°ç¯„å›²: {adjustment_stats.min():.3f} - {adjustment_stats.max():.3f}")
        logger.info(f"  èª¿æ•´å‰å¹³å‡: {base_race_level.mean():.3f}")
        logger.info(f"  èª¿æ•´å¾Œå¹³å‡: {adjusted_race_level.mean():.3f}")
        
        return adjusted_race_level
    
    def _compare_all_weighting_methods(self, horse_stats_data: pd.DataFrame) -> Dict[str, Dict]:
        """è¤‡æ•°ã®é‡ã¿ä»˜ã‘æ‰‹æ³•ã‚’è©³ç´°æ¯”è¼ƒ"""
        logger.info("ğŸ”¬ é‡ã¿ä»˜ã‘æ‰‹æ³•ã®è©³ç´°æ¯”è¼ƒã‚’é–‹å§‹...")
        
        methods_results = {}
        
        try:
            # ãƒ‡ãƒ¼ã‚¿æ¤œè¨¼
            required_cols = ['å¹³å‡ãƒ¬ãƒ™ãƒ«', 'å¹³å‡å ´æ‰€ãƒ¬ãƒ™ãƒ«', 'prize_level', 'place_rate']
            if not all(col in horse_stats_data.columns for col in required_cols):
                logger.warning("âš ï¸ å¿…è¦ãªã‚«ãƒ©ãƒ ãŒä¸è¶³ã—ã¦ã„ã¾ã™")
                return {'correlation_squared': {'weights': {'grade_weight': 0.5, 'venue_weight': 0.3, 'prize_weight': 0.2}, 'r_squared': 0.01}}
            
            clean_data = horse_stats_data.dropna(subset=required_cols)
            if len(clean_data) < 100:
                logger.warning(f"âš ï¸ ãƒ‡ãƒ¼ã‚¿ä¸è¶³: {len(clean_data)}ä»¶")
                return {'correlation_squared': {'weights': {'grade_weight': 0.5, 'venue_weight': 0.3, 'prize_weight': 0.2}, 'r_squared': 0.01}}
            
            logger.info(f"ğŸ“Š åˆ†æå¯¾è±¡ãƒ‡ãƒ¼ã‚¿: {len(clean_data)}é ­")
            
            # 1. ç›¸é–¢ä¿‚æ•°äºŒä¹—ãƒ™ãƒ¼ã‚¹ï¼ˆæ—¢å­˜æ‰‹æ³•ï¼‰
            methods_results['correlation_squared'] = self._method_correlation_squared(clean_data)
            
            # 2. ç·šå½¢å›å¸°ä¿‚æ•°ãƒ™ãƒ¼ã‚¹ï¼ˆæ–°æ‰‹æ³•ï¼‰
            methods_results['regression_coefficients'] = self._method_regression_coefficients(clean_data)
            
            # 3. ç­‰é‡ã¿æ‰‹æ³•ï¼ˆãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ï¼‰
            methods_results['equal_weights'] = self._method_equal_weights(clean_data)
            
            # 4. çµ¶å¯¾ç›¸é–¢å€¤ãƒ™ãƒ¼ã‚¹
            methods_results['absolute_correlation'] = self._method_absolute_correlation(clean_data)
            
            # çµæœã‚µãƒãƒªãƒ¼
            logger.info("ğŸ“‹ é‡ã¿ä»˜ã‘æ‰‹æ³•æ¯”è¼ƒçµæœ:")
            for method_name, results in methods_results.items():
                r2 = results.get('r_squared', 0)
                corr = results.get('correlation', 0)
                logger.info(f"  {method_name}: RÂ²={r2:.6f}, ç›¸é–¢={corr:.6f}")
            
            # é‡ã¿ä»˜ã‘æ‰‹æ³•æ¯”è¼ƒã®å¯è¦–åŒ–ã‚’ä½œæˆ
            self._create_weighting_comparison_plots(methods_results)
            
            return methods_results
            
        except Exception as e:
            logger.error(f"âŒ é‡ã¿ä»˜ã‘æ‰‹æ³•æ¯”è¼ƒã‚¨ãƒ©ãƒ¼: {str(e)}")
            return {'correlation_squared': {'weights': {'grade_weight': 0.5, 'venue_weight': 0.3, 'prize_weight': 0.2}, 'r_squared': 0.01}}
    
    def _method_correlation_squared(self, data: pd.DataFrame) -> Dict:
        """ç›¸é–¢ä¿‚æ•°äºŒä¹—ãƒ™ãƒ¼ã‚¹æ‰‹æ³•"""
        try:
            corr_grade = data['å¹³å‡ãƒ¬ãƒ™ãƒ«'].corr(data['place_rate'])
            corr_venue = data['å¹³å‡å ´æ‰€ãƒ¬ãƒ™ãƒ«'].corr(data['place_rate'])
            corr_prize = data['prize_level'].corr(data['place_rate'])
            
            # NaNå‡¦ç†
            corr_grade = 0.0 if pd.isna(corr_grade) else corr_grade
            corr_venue = 0.0 if pd.isna(corr_venue) else corr_venue
            corr_prize = 0.0 if pd.isna(corr_prize) else corr_prize
            
            # æ±ºå®šä¿‚æ•°ã‹ã‚‰é‡ã¿è¨ˆç®—
            r2_grade = corr_grade ** 2
            r2_venue = corr_venue ** 2
            r2_prize = corr_prize ** 2
            total_r2 = r2_grade + r2_venue + r2_prize
            
            if total_r2 > 0:
                weights = {
                    'grade_weight': r2_grade / total_r2,
                    'venue_weight': r2_venue / total_r2,
                    'prize_weight': r2_prize / total_r2
                }
            else:
                weights = {'grade_weight': 0.5, 'venue_weight': 0.3, 'prize_weight': 0.2}
            
            # æ€§èƒ½è©•ä¾¡
            performance = self._evaluate_weights_performance(data, weights)
            
            return {
                'weights': weights,
                'r_squared': performance['r_squared'],
                'correlation': performance['correlation'],
                'description': 'ç›¸é–¢ä¿‚æ•°äºŒä¹—ãƒ™ãƒ¼ã‚¹ï¼ˆæ—¢å­˜æ‰‹æ³•ï¼‰'
            }
            
        except Exception as e:
            logger.error(f"âŒ ç›¸é–¢ä¿‚æ•°äºŒä¹—æ‰‹æ³•ã‚¨ãƒ©ãƒ¼: {str(e)}")
            return {'weights': {'grade_weight': 0.5, 'venue_weight': 0.3, 'prize_weight': 0.2}, 'r_squared': 0.0, 'correlation': 0.0}
    
    def _method_regression_coefficients(self, data: pd.DataFrame) -> Dict:
        """ç·šå½¢å›å¸°ä¿‚æ•°ãƒ™ãƒ¼ã‚¹æ‰‹æ³•ï¼ˆæ–°æ‰‹æ³•ï¼‰"""
        try:
            from sklearn.linear_model import LinearRegression
            from sklearn.preprocessing import StandardScaler
            from sklearn.metrics import r2_score
            
            # ç‰¹å¾´é‡ã¨ã‚¿ãƒ¼ã‚²ãƒƒãƒˆã®æº–å‚™
            X = data[['å¹³å‡ãƒ¬ãƒ™ãƒ«', 'å¹³å‡å ´æ‰€ãƒ¬ãƒ™ãƒ«', 'prize_level']].values
            y = data['place_rate'].values
            
            # æ¨™æº–åŒ–
            scaler = StandardScaler()
            X_scaled = scaler.fit_transform(X)
            
            # ç·šå½¢å›å¸°ã®å®Ÿè¡Œ
            reg = LinearRegression()
            reg.fit(X_scaled, y)
            
            # ä¿‚æ•°ã‹ã‚‰é‡ã¿ã‚’ç®—å‡ºï¼ˆçµ¶å¯¾å€¤ã§é‡è¦åº¦ã‚’è©•ä¾¡ï¼‰
            coefficients = np.abs(reg.coef_)
            total_coef = np.sum(coefficients)
            
            if total_coef > 0:
                weights = {
                    'grade_weight': coefficients[0] / total_coef,
                    'venue_weight': coefficients[1] / total_coef,
                    'prize_weight': coefficients[2] / total_coef
                }
            else:
                weights = {'grade_weight': 0.5, 'venue_weight': 0.3, 'prize_weight': 0.2}
            
            # æ€§èƒ½è©•ä¾¡ï¼ˆå›å¸°ãƒ¢ãƒ‡ãƒ«ã®äºˆæ¸¬æ€§èƒ½ï¼‰
            y_pred = reg.predict(X_scaled)
            r_squared = r2_score(y, y_pred)
            correlation = np.corrcoef(y, y_pred)[0, 1] if not np.isnan(np.corrcoef(y, y_pred)[0, 1]) else 0.0
            
            logger.info(f"ğŸ”¬ ç·šå½¢å›å¸°æ‰‹æ³• - RÂ²: {r_squared:.6f}, å›å¸°ä¿‚æ•°: {coefficients}")
            
            return {
                'weights': weights,
                'r_squared': r_squared,
                'correlation': correlation,
                'description': 'ç·šå½¢å›å¸°ä¿‚æ•°ãƒ™ãƒ¼ã‚¹æ‰‹æ³•ï¼ˆæ–°æ‰‹æ³•ï¼‰'
            }
            
        except Exception as e:
            logger.error(f"âŒ ç·šå½¢å›å¸°æ‰‹æ³•ã‚¨ãƒ©ãƒ¼: {str(e)}")
            return {'weights': {'grade_weight': 0.5, 'venue_weight': 0.3, 'prize_weight': 0.2}, 'r_squared': 0.0, 'correlation': 0.0}
    
    def _method_equal_weights(self, data: pd.DataFrame) -> Dict:
        """ç­‰é‡ã¿æ‰‹æ³•ï¼ˆãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ï¼‰"""
        weights = {'grade_weight': 1/3, 'venue_weight': 1/3, 'prize_weight': 1/3}
        performance = self._evaluate_weights_performance(data, weights)
        
        return {
            'weights': weights,
            'r_squared': performance['r_squared'],
            'correlation': performance['correlation'],
            'description': 'ç­‰é‡ã¿æ‰‹æ³•ï¼ˆãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ï¼‰'
        }
    
    def _method_absolute_correlation(self, data: pd.DataFrame) -> Dict:
        """çµ¶å¯¾ç›¸é–¢å€¤ãƒ™ãƒ¼ã‚¹æ‰‹æ³•"""
        try:
            corr_grade = abs(data['å¹³å‡ãƒ¬ãƒ™ãƒ«'].corr(data['place_rate']))
            corr_venue = abs(data['å¹³å‡å ´æ‰€ãƒ¬ãƒ™ãƒ«'].corr(data['place_rate']))
            corr_prize = abs(data['prize_level'].corr(data['place_rate']))
            
            # NaNå‡¦ç†
            corr_grade = 0.0 if pd.isna(corr_grade) else corr_grade
            corr_venue = 0.0 if pd.isna(corr_venue) else corr_venue
            corr_prize = 0.0 if pd.isna(corr_prize) else corr_prize
            
            total_corr = corr_grade + corr_venue + corr_prize
            
            if total_corr > 0:
                weights = {
                    'grade_weight': corr_grade / total_corr,
                    'venue_weight': corr_venue / total_corr,
                    'prize_weight': corr_prize / total_corr
                }
            else:
                weights = {'grade_weight': 0.5, 'venue_weight': 0.3, 'prize_weight': 0.2}
            
            performance = self._evaluate_weights_performance(data, weights)
            
            return {
                'weights': weights,
                'r_squared': performance['r_squared'],
                'correlation': performance['correlation'],
                'description': 'çµ¶å¯¾ç›¸é–¢å€¤ãƒ™ãƒ¼ã‚¹æ‰‹æ³•'
            }
            
        except Exception as e:
            logger.error(f"âŒ çµ¶å¯¾ç›¸é–¢æ‰‹æ³•ã‚¨ãƒ©ãƒ¼: {str(e)}")
            return {'weights': {'grade_weight': 0.5, 'venue_weight': 0.3, 'prize_weight': 0.2}, 'r_squared': 0.0, 'correlation': 0.0}
    
    def _evaluate_weights_performance(self, data: pd.DataFrame, weights: Dict[str, float]) -> Dict[str, float]:
        """é‡ã¿ä»˜ã‘æ‰‹æ³•ã®æ€§èƒ½è©•ä¾¡"""
        try:
            # é‡ã¿ä»˜ã‘åˆæˆç‰¹å¾´é‡ã®ä½œæˆ
            composite_feature = (
                data['å¹³å‡ãƒ¬ãƒ™ãƒ«'] * weights['grade_weight'] +
                data['å¹³å‡å ´æ‰€ãƒ¬ãƒ™ãƒ«'] * weights['venue_weight'] +
                data['prize_level'] * weights['prize_weight']
            )
            
            # æ€§èƒ½æŒ‡æ¨™ã®è¨ˆç®—
            correlation = composite_feature.corr(data['place_rate'])
            r_squared = correlation ** 2 if not pd.isna(correlation) else 0.0
            correlation = correlation if not pd.isna(correlation) else 0.0
            
            return {
                'r_squared': r_squared,
                'correlation': correlation
            }
            
        except Exception as e:
            logger.error(f"âŒ æ€§èƒ½è©•ä¾¡ã‚¨ãƒ©ãƒ¼: {str(e)}")
            return {'r_squared': 0.0, 'correlation': 0.0}

    def validate_multicollinearity(self) -> Dict[str, Any]:
        """
        ãƒãƒ«ãƒã‚³ãƒªãƒ‹ã‚¢ãƒªãƒ†ã‚£æ¤œè¨¼ã‚’å®Ÿè¡Œ
        VIFã€ç›¸é–¢è¡Œåˆ—ã€æ¡ä»¶æ•°ã‚’è¨ˆç®—ã—ã€çµ±è¨ˆçš„å¦¥å½“æ€§ã‚’è©•ä¾¡
        """
        try:
            logger.info("=== ãƒãƒ«ãƒã‚³ãƒªãƒ‹ã‚¢ãƒªãƒ†ã‚£æ¤œè¨¼é–‹å§‹ ===")
            
            # ç‰¹å¾´é‡ã®å®šç¾©ï¼ˆå­˜åœ¨ã™ã‚‹ã‚«ãƒ©ãƒ ã®ã¿ï¼‰
            all_features = ['grade_level', 'venue_level', 'prize_level', 'distance_level']
            features = [col for col in all_features if col in self.df.columns]
            
            if len(features) < 2:
                logger.warning("âš ï¸ ãƒãƒ«ãƒã‚³ãƒªãƒ‹ã‚¢ãƒªãƒ†ã‚£æ¤œè¨¼ã«å¿…è¦ãªç‰¹å¾´é‡ãŒä¸è¶³ã—ã¦ã„ã¾ã™")
                return {'status': 'skipped', 'reason': 'insufficient_features'}
            
            logger.info(f"ğŸ“Š æ¤œè¨¼å¯¾è±¡ç‰¹å¾´é‡: {features}")
            
            # ãƒ‡ãƒ¼ã‚¿ã®æº–å‚™ï¼ˆæ¬ æå€¤é™¤å»ï¼‰
            feature_data = self.df[features].dropna()
            
            if len(feature_data) == 0:
                logger.error("ğŸš¨ ç‰¹å¾´é‡ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ï¼")
                return {'error': 'No feature data available'}
            
            logger.info(f"ğŸ“Š æ¤œè¨¼å¯¾è±¡ãƒ‡ãƒ¼ã‚¿: {len(feature_data):,}è¡Œ")
            logger.info(f"ğŸ¯ æ¤œè¨¼å¯¾è±¡ç‰¹å¾´é‡: {features}")
            
            # === 1. VIFï¼ˆåˆ†æ•£æ‹¡å¤§è¦å› ï¼‰è¨ˆç®— ===
            vif_results = self._calculate_vif(feature_data, features)
            
            # === 2. ç›¸é–¢è¡Œåˆ—åˆ†æ ===
            correlation_results = self._analyze_correlation_matrix(feature_data, features)
            
            # === 3. é‡ã¿ä»˜ã‘æ‰‹æ³•æ¯”è¼ƒ ===
            weighting_comparison = self._compare_weighting_methods(feature_data)
            
            # === 4. çµ±åˆè¨ºæ–­ ===
            overall_diagnosis = self._diagnose_multicollinearity_simple(vif_results, correlation_results)
            
            # çµæœã®çµ±åˆ
            results = {
                'vif_results': vif_results,
                'correlation_results': correlation_results,
                'weighting_comparison': weighting_comparison,
                'overall_diagnosis': overall_diagnosis,
                'data_info': {
                    'n_samples': len(feature_data),
                    'features': features,
                    'validation_timestamp': pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S')
                }
            }
            
            # çµæœã®ä¿å­˜
            self.multicollinearity_results = results
            
            # å¯è¦–åŒ–
            self._create_multicollinearity_plots_simple(feature_data, features, results)
            
            # ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
            self._generate_multicollinearity_report_simple(results)
            
            logger.info("âœ… ãƒãƒ«ãƒã‚³ãƒªãƒ‹ã‚¢ãƒªãƒ†ã‚£æ¤œè¨¼å®Œäº†")
            return results
            
        except Exception as e:
            logger.error(f"âŒ ãƒãƒ«ãƒã‚³ãƒªãƒ‹ã‚¢ãƒªãƒ†ã‚£æ¤œè¨¼ä¸­ã«ã‚¨ãƒ©ãƒ¼: {str(e)}")
            logger.error("è©³ç´°ãªã‚¨ãƒ©ãƒ¼æƒ…å ±:", exc_info=True)
            return {'error': str(e)}
    
    def _calculate_vif(self, feature_data: pd.DataFrame, features: list) -> Dict[str, Any]:
        """VIFï¼ˆåˆ†æ•£æ‹¡å¤§è¦å› ï¼‰ã‚’è¨ˆç®—"""
        logger.info("ğŸ§® VIFè¨ˆç®—ä¸­...")
        
        try:
            # ãƒ‡ãƒ¼ã‚¿ã®æ¨™æº–åŒ–ï¼ˆVIFè¨ˆç®—ã®å‰æï¼‰
            scaler = StandardScaler()
            scaled_data = scaler.fit_transform(feature_data[features])
            
            # VIFè¨ˆç®—
            vif_data = []
            for i, feature in enumerate(features):
                try:
                    vif_value = variance_inflation_factor(scaled_data, i)
                    vif_data.append({
                        'feature': feature,
                        'vif': vif_value,
                        'status': self._get_vif_status(vif_value)
                    })
                    logger.info(f"  {feature}: VIF = {vif_value:.3f} ({self._get_vif_status(vif_value)})")
                except Exception as vif_error:
                    logger.warning(f"  {feature}: VIFè¨ˆç®—ã‚¨ãƒ©ãƒ¼ - {str(vif_error)}")
                    vif_data.append({
                        'feature': feature,
                        'vif': float('nan'),
                        'status': 'ã‚¨ãƒ©ãƒ¼'
                    })
            
            # æœ€å¤§VIFã«ã‚ˆã‚‹å…¨ä½“åˆ¤å®š
            valid_vifs = [item['vif'] for item in vif_data if not pd.isna(item['vif'])]
            if valid_vifs:
                max_vif = max(valid_vifs)
                overall_status = self._get_overall_vif_status(max_vif)
            else:
                max_vif = float('nan')
                overall_status = "è¨ˆç®—ã‚¨ãƒ©ãƒ¼"
            
            logger.info(f"ğŸ“ˆ æœ€å¤§VIF: {max_vif:.3f} â†’ {overall_status}")
            
            return {
                'vif_data': vif_data,
                'max_vif': max_vif,
                'overall_status': overall_status
            }
            
        except Exception as e:
            logger.error(f"VIFè¨ˆç®—ã‚¨ãƒ©ãƒ¼: {str(e)}")
            return {'error': str(e)}
    
    def _analyze_correlation_matrix(self, feature_data: pd.DataFrame, features: list) -> Dict[str, Any]:
        """ç›¸é–¢è¡Œåˆ—ã‚’åˆ†æ"""
        logger.info("ğŸ“Š ç›¸é–¢è¡Œåˆ—åˆ†æä¸­...")
        
        try:
            # ç›¸é–¢è¡Œåˆ—è¨ˆç®—
            correlation_matrix = feature_data[features].corr()
            
            # é«˜ç›¸é–¢ãƒšã‚¢ã®ç‰¹å®š
            high_corr_pairs = []
            threshold = 0.8  # è­¦å‘Šé–¾å€¤
            
            for i in range(len(features)):
                for j in range(i+1, len(features)):
                    corr_value = abs(correlation_matrix.iloc[i, j])
                    if corr_value > threshold:
                        pair_info = {
                            'feature1': features[i],
                            'feature2': features[j],
                            'correlation': correlation_matrix.iloc[i, j],
                            'abs_correlation': corr_value
                        }
                        high_corr_pairs.append(pair_info)
                        logger.warning(f"ğŸš¨ é«˜ç›¸é–¢æ¤œå‡º: {features[i]} vs {features[j]} = {corr_value:.3f}")
            
            if not high_corr_pairs:
                logger.info("âœ… é«˜ç›¸é–¢ãƒšã‚¢ã¯æ¤œå‡ºã•ã‚Œã¾ã›ã‚“ã§ã—ãŸ")
            
            return {
                'correlation_matrix': correlation_matrix,
                'high_corr_pairs': high_corr_pairs,
                'threshold': threshold
            }
            
        except Exception as e:
            logger.error(f"ç›¸é–¢è¡Œåˆ—åˆ†æã‚¨ãƒ©ãƒ¼: {str(e)}")
            return {'error': str(e)}
    
    def _compare_weighting_methods(self, feature_data: pd.DataFrame) -> Dict[str, Any]:
        """è¤‡æ•°ã®é‡ã¿ä»˜ã‘æ‰‹æ³•ã‚’æ¯”è¼ƒï¼ˆç°¡æ˜“ç‰ˆï¼‰"""
        logger.info("âš–ï¸ é‡ã¿ä»˜ã‘æ‰‹æ³•æ¯”è¼ƒä¸­...")
        
        try:
            features = ['grade_level', 'venue_level', 'prize_level']
            
            # é¦¬ã”ã¨ã®çµ±è¨ˆã‚’è¨ˆç®—ã—ã¦è¤‡å‹ç‡ã‚’å–å¾—
            horse_stats = self._calculate_horse_stats()
            
            # horse_statsã‹ã‚‰å¿…è¦ãªãƒ‡ãƒ¼ã‚¿ã‚’æŠ½å‡º
            if 'place_rate' not in horse_stats.columns:
                logger.error("place_rate ã‚«ãƒ©ãƒ ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
                return {'error': 'place_rate not found'}
            
            # ç‰¹å¾´é‡ãƒ‡ãƒ¼ã‚¿ã¨è¤‡å‹ç‡ã‚’ãƒãƒ¼ã‚¸
            horse_features = self.df.groupby('é¦¬å')[features].mean().reset_index()
            merged_data = horse_features.merge(horse_stats[['é¦¬å', 'place_rate']], on='é¦¬å', how='inner')
            
            if len(merged_data) == 0:
                logger.error("ãƒãƒ¼ã‚¸å¾Œã®ãƒ‡ãƒ¼ã‚¿ãŒç©ºã§ã™")
                return {'error': 'No merged data'}
            
            # ç°¡æ˜“æ¯”è¼ƒ
            logger.info(f"ğŸ† é‡ã¿ä»˜ã‘æ‰‹æ³•æ¯”è¼ƒå®Œäº†: {len(merged_data)}é ­ã®ãƒ‡ãƒ¼ã‚¿ã§å®Ÿè¡Œ")
            
            return {
                'status': 'completed',
                'sample_size': len(merged_data)
            }
            
        except Exception as e:
            logger.error(f"é‡ã¿ä»˜ã‘æ‰‹æ³•æ¯”è¼ƒã‚¨ãƒ©ãƒ¼: {str(e)}")
            return {'error': str(e)}
    
    def _diagnose_multicollinearity_simple(self, vif_results: Dict, correlation_results: Dict) -> Dict[str, Any]:
        """ç°¡æ˜“çš„ãªãƒãƒ«ãƒã‚³ãƒªãƒ‹ã‚¢ãƒªãƒ†ã‚£è¨ºæ–­"""
        try:
            # VIFãƒªã‚¹ã‚¯è©•ä¾¡
            max_vif = vif_results.get('max_vif', 0)
            vif_risk = 0 if max_vif < 5 else 1 if max_vif < 10 else 2
            
            # ç›¸é–¢ãƒªã‚¹ã‚¯è©•ä¾¡
            high_corr_pairs = correlation_results.get('high_corr_pairs', [])
            corr_risk = 1 if len(high_corr_pairs) > 0 else 0
            
            # ç·åˆåˆ¤å®š
            overall_risk = max(vif_risk, corr_risk)
            severity = ['æ­£å¸¸', 'æ³¨æ„', 'å±é™º'][overall_risk]
            
            logger.info(f"ğŸ“‹ è¨ºæ–­çµæœ: {severity} (ãƒªã‚¹ã‚¯ãƒ¬ãƒ™ãƒ«: {overall_risk})")
            
            return {
                'overall_risk_level': overall_risk,
                'severity': severity,
                'vif_risk': vif_risk,
                'correlation_risk': corr_risk
            }
            
        except Exception as e:
            logger.error(f"è¨ºæ–­ã‚¨ãƒ©ãƒ¼: {str(e)}")
            return {'error': str(e)}
    
    def _create_multicollinearity_plots_simple(self, feature_data: pd.DataFrame, features: list, results: Dict[str, Any]) -> None:
        """ç°¡æ˜“ç‰ˆå¯è¦–åŒ–"""
        try:
            output_dir = Path(self.config.output_dir)
            output_dir.mkdir(parents=True, exist_ok=True)
            
            # ç›¸é–¢è¡Œåˆ—ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—ã®ã¿ä½œæˆ
            if 'correlation_results' in results and 'correlation_matrix' in results['correlation_results']:
                fig, ax = plt.subplots(1, 1, figsize=(8, 6))
                corr_matrix = results['correlation_results']['correlation_matrix']
                sns.heatmap(corr_matrix, annot=True, cmap='RdYlBu_r', center=0, square=True, ax=ax)
                ax.set_title('ç‰¹å¾´é‡é–“ç›¸é–¢è¡Œåˆ—')
                
                plot_path = output_dir / 'multicollinearity_validation.png'
                plt.savefig(plot_path, dpi=300, bbox_inches='tight')
                plt.close()
                
                logger.info(f"ğŸ“Š å¯è¦–åŒ–ä¿å­˜: {plot_path}")
            
        except Exception as e:
            logger.error(f"å¯è¦–åŒ–ä½œæˆã‚¨ãƒ©ãƒ¼: {str(e)}")
    
    def _generate_multicollinearity_report_simple(self, results: Dict[str, Any]) -> None:
        """ç°¡æ˜“ç‰ˆãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ"""
        try:
            output_dir = Path(self.config.output_dir)
            report_path = output_dir / 'multicollinearity_validation_report.md'
            
            with open(report_path, 'w', encoding='utf-8') as f:
                f.write("# ãƒãƒ«ãƒã‚³ãƒªãƒ‹ã‚¢ãƒªãƒ†ã‚£æ¤œè¨¼ãƒ¬ãƒãƒ¼ãƒˆ\n\n")
                f.write(f"ç”Ÿæˆæ—¥æ™‚: {pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S')}\n\n")
                
                # VIFçµæœ
                if 'vif_results' in results and 'vif_data' in results['vif_results']:
                    f.write("## ğŸ§® VIFæ¤œè¨¼çµæœ\n\n")
                    f.write("| ç‰¹å¾´é‡ | VIFå€¤ | åˆ¤å®š |\n")
                    f.write("|--------|-------|------|\n")
                    
                    for item in results['vif_results']['vif_data']:
                        vif_val = item['vif']
                        vif_str = f"{vif_val:.3f}" if not pd.isna(vif_val) else "nan"
                        f.write(f"| {item['feature']} | {vif_str} | {item['status']} |\n")
                
                # ç›¸é–¢çµæœ
                if 'correlation_results' in results:
                    f.write("\n## ğŸ“Š ç›¸é–¢åˆ†æçµæœ\n\n")
                    high_corr_pairs = results['correlation_results'].get('high_corr_pairs', [])
                    if high_corr_pairs:
                        f.write("### ğŸš¨ é«˜ç›¸é–¢ãƒšã‚¢æ¤œå‡º\n\n")
                        for pair in high_corr_pairs:
                            f.write(f"- {pair['feature1']} vs {pair['feature2']}: r = {pair['correlation']:.3f}\n")
                    else:
                        f.write("âœ… é«˜ç›¸é–¢ãƒšã‚¢ï¼ˆ|r| > 0.8ï¼‰ã¯æ¤œå‡ºã•ã‚Œã¾ã›ã‚“ã§ã—ãŸã€‚\n")
                
                # è¨ºæ–­çµæœ
                if 'overall_diagnosis' in results:
                    diagnosis = results['overall_diagnosis']
                    f.write(f"\n## ğŸ¥ ç·åˆè¨ºæ–­\n\n")
                    f.write(f"**åˆ¤å®š**: {diagnosis.get('severity', 'Unknown')}\n")
                    f.write(f"**ãƒªã‚¹ã‚¯ãƒ¬ãƒ™ãƒ«**: {diagnosis.get('overall_risk_level', 'Unknown')}/2\n")
            
            logger.info(f"ğŸ“‹ ãƒ¬ãƒãƒ¼ãƒˆä¿å­˜: {report_path}")
            
        except Exception as e:
            logger.error(f"ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆã‚¨ãƒ©ãƒ¼: {str(e)}")
    
    def _get_vif_status(self, vif_value: float) -> str:
        """VIFå€¤ã‹ã‚‰çŠ¶æ…‹ã‚’åˆ¤å®š"""
        if pd.isna(vif_value):
            return "ã‚¨ãƒ©ãƒ¼"
        elif vif_value < 5:
            return "æ­£å¸¸"
        elif vif_value < 10:
            return "æ³¨æ„"
        else:
            return "å±é™º"
    
    def _get_overall_vif_status(self, max_vif: float) -> str:
        """æœ€å¤§VIFå€¤ã‹ã‚‰å…¨ä½“çŠ¶æ…‹ã‚’åˆ¤å®š"""
        if pd.isna(max_vif):
            return "è¨ˆç®—ã‚¨ãƒ©ãƒ¼"
        elif max_vif < 5:
            return "å•é¡Œãªã—"
        elif max_vif < 10:
            return "è»½åº¦ã®ãƒãƒ«ãƒã‚³ãƒªãƒ‹ã‚¢ãƒªãƒ†ã‚£"
        else:
            return "æ·±åˆ»ãªãƒãƒ«ãƒã‚³ãƒªãƒ‹ã‚¢ãƒªãƒ†ã‚£"

    def _calculate_prize_level(self, df: pd.DataFrame) -> pd.Series:
        """è³é‡‘ã«åŸºã¥ããƒ¬ãƒ™ãƒ«ã‚’è¨ˆç®—ï¼ˆåˆ—åã®é•ã„ã«å¯¾ã™ã‚‹äº’æ›å¯¾å¿œï¼‰"""
        # è³é‡‘åˆ—å€™è£œã‚’å„ªå…ˆé †ã«æ¢ç´¢
        prize_candidates = [
            '1ç€è³é‡‘(1ç€ç®—å…¥è³é‡‘è¾¼ã¿)',
            '1ç€è³é‡‘',
            'æœ¬è³é‡‘'
        ]
        prize_col = next((c for c in prize_candidates if c in df.columns), None)
        if prize_col is None:
            # è³é‡‘æƒ…å ±ãŒãªã„å ´åˆã¯0ç³»åˆ—ã‚’è¿”ã™
            return pd.Series([0.0] * len(df), index=df.index)

        prizes = pd.to_numeric(df[prize_col], errors='coerce').fillna(0)
        max_val = prizes.max()
        if max_val <= 0:
            return pd.Series([0.0] * len(df), index=df.index)

        prize_level = np.log1p(prizes) / np.log1p(max_val) * 9.95
        return self.normalize_values(prize_level)

    def _calculate_horse_stats(self) -> pd.DataFrame:
        """é¦¬ã”ã¨ã®åŸºæœ¬çµ±è¨ˆã‚’è¨ˆç®—"""
        if "is_win" not in self.df.columns:
            self.df["is_win"] = self.df["ç€é †"] == 1
        if "is_placed" not in self.df.columns:
            self.df["is_placed"] = self.df["ç€é †"] <= 3

        # é¦¬ã”ã¨ã®åŸºæœ¬çµ±è¨ˆï¼ˆå­˜åœ¨ã™ã‚‹ã‚«ãƒ©ãƒ ã®ã¿ï¼‰
        agg_dict = {
            "race_level": ["max", "mean"],
            "is_win": "sum",
            "is_placed": "sum",
            "ç€é †": "count"
        }
        
        # å­˜åœ¨ã™ã‚‹ç‰¹å¾´é‡ã‚«ãƒ©ãƒ ã®ã¿è¿½åŠ 
        optional_features = ["venue_level", "distance_level", "prize_level", "grade_level"]
        for feature in optional_features:
            if feature in self.df.columns:
                agg_dict[feature] = ["max", "mean"]
        
        # race_levelã«ã¯æ—¢ã«è¤‡å‹çµæœãŒçµ„ã¿è¾¼ã¾ã‚Œã¦ã„ã‚‹ãŸã‚ã€è¿½åŠ ã®ç‰¹å¾´é‡ã¯ä¸è¦
        
        # ã‚¯ãƒ©ã‚¹ã‚«ãƒ©ãƒ ãŒå­˜åœ¨ã™ã‚‹å ´åˆã®ã¿è¿½åŠ 
        if self.class_column and self.class_column in self.df.columns:
            agg_dict[self.class_column] = lambda x: x.value_counts().idxmax() if not x.empty else 0
        
        horse_stats = self.df.groupby("é¦¬å").agg(agg_dict).reset_index()

        # ã‚«ãƒ©ãƒ åã®å‹•çš„æ•´ç†
        new_columns = ["é¦¬å", "æœ€é«˜ãƒ¬ãƒ™ãƒ«", "å¹³å‡ãƒ¬ãƒ™ãƒ«"]
        
        # å­˜åœ¨ã™ã‚‹ç‰¹å¾´é‡ã«å¿œã˜ã¦ã‚«ãƒ©ãƒ åã‚’è¿½åŠ 
        for feature in optional_features:
            if feature in self.df.columns:
                if feature == "venue_level":
                    new_columns.extend(["æœ€é«˜å ´æ‰€ãƒ¬ãƒ™ãƒ«", "å¹³å‡å ´æ‰€ãƒ¬ãƒ™ãƒ«"])
                elif feature == "distance_level":
                    new_columns.extend(["æœ€é«˜è·é›¢ãƒ¬ãƒ™ãƒ«", "å¹³å‡è·é›¢ãƒ¬ãƒ™ãƒ«"])
                elif feature == "prize_level":
                    new_columns.extend(["æœ€é«˜è³é‡‘ãƒ¬ãƒ™ãƒ«", "å¹³å‡è³é‡‘ãƒ¬ãƒ™ãƒ«"])
                elif feature == "grade_level":
                    new_columns.extend(["æœ€é«˜ã‚°ãƒ¬ãƒ¼ãƒ‰ãƒ¬ãƒ™ãƒ«", "å¹³å‡ã‚°ãƒ¬ãƒ¼ãƒ‰ãƒ¬ãƒ™ãƒ«"])
        
        new_columns.extend(["å‹åˆ©æ•°", "è¤‡å‹æ•°", "å‡ºèµ°å›æ•°"])
        
        if self.class_column and self.class_column in self.df.columns:
            new_columns.append("ä¸»æˆ¦ã‚¯ãƒ©ã‚¹")
        
        horse_stats.columns = new_columns
        
        # ãƒ¬ãƒ¼ã‚¹å›æ•°ãŒmin_raceså›ä»¥ä¸Šã®é¦¬ã®ã¿ã‚’ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
        min_races = self.config.min_races if hasattr(self.config, 'min_races') else 3
        horse_stats = horse_stats[horse_stats["å‡ºèµ°å›æ•°"] >= min_races]
        
        # å‹ç‡ã¨è¤‡å‹ç‡ã®è¨ˆç®—
        horse_stats["win_rate"] = horse_stats["å‹åˆ©æ•°"] / horse_stats["å‡ºèµ°å›æ•°"]
        horse_stats["place_rate"] = horse_stats["è¤‡å‹æ•°"] / horse_stats["å‡ºèµ°å›æ•°"]
        
        return horse_stats

    def _calculate_grade_stats(self) -> pd.DataFrame:
        """ã‚°ãƒ¬ãƒ¼ãƒ‰åˆ¥ã®çµ±è¨ˆã‚’è¨ˆç®—"""
        if not self.class_column or self.class_column not in self.df.columns:
            # ã‚¯ãƒ©ã‚¹ã‚«ãƒ©ãƒ ãŒå­˜åœ¨ã—ãªã„å ´åˆã¯ç©ºã®DataFrameã‚’è¿”ã™
            return pd.DataFrame()
            
        grade_stats = self.df.groupby(self.class_column).agg({
            "is_win": ["mean", "count"],
            "is_placed": "mean",
            "race_level": ["mean", "std"]
        }).reset_index()

        grade_stats.columns = [
            "ã‚¯ãƒ©ã‚¹", "å‹ç‡", "ãƒ¬ãƒ¼ã‚¹æ•°", "è¤‡å‹ç‡",
            "å¹³å‡ãƒ¬ãƒ™ãƒ«", "ãƒ¬ãƒ™ãƒ«æ¨™æº–åå·®"
        ]

        return grade_stats

    def _perform_correlation_analysis(self, horse_stats: pd.DataFrame) -> Dict[str, Any]:
        """ç›¸é–¢åˆ†æã‚’å®Ÿè¡Œï¼ˆrace_levelã«ã¯è¤‡å‹çµæœãŒçµ±åˆæ¸ˆã¿ï¼‰"""
        # å¿…é ˆã‚«ãƒ©ãƒ ï¼ˆrace_levelã«ã¯æ—¢ã«è¤‡å‹çµæœãŒçµ„ã¿è¾¼ã¾ã‚Œã¦ã„ã‚‹ï¼‰
        required_cols = ['æœ€é«˜ãƒ¬ãƒ™ãƒ«', 'å¹³å‡ãƒ¬ãƒ™ãƒ«', 'æœ€é«˜å ´æ‰€ãƒ¬ãƒ™ãƒ«', 'å¹³å‡å ´æ‰€ãƒ¬ãƒ™ãƒ«', 'win_rate', 'place_rate']
        
        analysis_data = horse_stats.dropna(subset=required_cols)
        
        default_results = {
            "correlation_win_max": 0.0,
            "correlation_place_max": 0.0,
            "correlation_win_avg": 0.0,
            "correlation_place_avg": 0.0,
            "correlation_win_venue_max": 0.0,
            "correlation_place_venue_max": 0.0,
            "correlation_win_venue_avg": 0.0,
            "correlation_place_venue_avg": 0.0,
            "model_win_max": None,
            "model_place_max": None,
            "model_win_avg": None,
            "model_place_avg": None,
            "model_win_venue_max": None,
            "model_place_venue_max": None,
            "model_win_venue_avg": None,
            "model_place_venue_avg": None,
            "r2_win_max": 0.0,
            "r2_place_max": 0.0,
            "r2_win_avg": 0.0,
            "r2_place_avg": 0.0,
            "r2_win_venue_max": 0.0,
            "r2_place_venue_max": 0.0,
            "r2_win_venue_avg": 0.0,
            "r2_place_venue_avg": 0.0,
            "correlation_win": 0.0,
            "correlation_place": 0.0,
            "model_win": None,
            "model_place": None,
            "r2_win": 0.0,
            "r2_place": 0.0
        }

        if len(analysis_data) < 2:  # ãƒ‡ãƒ¼ã‚¿ãŒ2ä»¶æœªæº€ã ã¨ç›¸é–¢ãŒè¨ˆç®—ã§ããªã„
            return default_results

        # æ¨™æº–åå·®ãŒ0ã®å ´åˆã®å‡¦ç†
        # TODO:æ¨™æº–åå·®ãŒ0ã®å ´åˆã®å‡¦ç†ã‚’èª¿æŸ»äºˆå®š
        stddev = analysis_data[['æœ€é«˜ãƒ¬ãƒ™ãƒ«', 'å¹³å‡ãƒ¬ãƒ™ãƒ«', 'æœ€é«˜å ´æ‰€ãƒ¬ãƒ™ãƒ«', 'å¹³å‡å ´æ‰€ãƒ¬ãƒ™ãƒ«', 'win_rate', 'place_rate']].std()
        if (stddev == 0).any():
            return default_results

        # æœ€é«˜ãƒ¬ãƒ™ãƒ« - å‹ç‡ã®ç›¸é–¢ä¿‚æ•°ã¨å›å¸°åˆ†æ
        correlation_win_max = analysis_data[['æœ€é«˜ãƒ¬ãƒ™ãƒ«', 'win_rate']].corr().iloc[0, 1]
        X_win_max = analysis_data['æœ€é«˜ãƒ¬ãƒ™ãƒ«'].values.reshape(-1, 1)
        y_win = analysis_data['win_rate'].values
        model_win_max = LinearRegression()
        model_win_max.fit(X_win_max, y_win)
        r2_win_max = model_win_max.score(X_win_max, y_win)

        # æœ€é«˜ãƒ¬ãƒ™ãƒ« - è¤‡å‹ç‡ã®ç›¸é–¢ä¿‚æ•°ã¨å›å¸°åˆ†æ
        correlation_place_max = analysis_data[['æœ€é«˜ãƒ¬ãƒ™ãƒ«', 'place_rate']].corr().iloc[0, 1]
        X_place_max = analysis_data['æœ€é«˜ãƒ¬ãƒ™ãƒ«'].values.reshape(-1, 1)
        y_place = analysis_data['place_rate'].values
        model_place_max = LinearRegression()
        model_place_max.fit(X_place_max, y_place)
        r2_place_max = model_place_max.score(X_place_max, y_place)

        # å¹³å‡ãƒ¬ãƒ™ãƒ« - å‹ç‡ã®ç›¸é–¢ä¿‚æ•°ã¨å›å¸°åˆ†æ
        correlation_win_avg = analysis_data[['å¹³å‡ãƒ¬ãƒ™ãƒ«', 'win_rate']].corr().iloc[0, 1]
        X_win_avg = analysis_data['å¹³å‡ãƒ¬ãƒ™ãƒ«'].values.reshape(-1, 1)
        model_win_avg = LinearRegression()
        model_win_avg.fit(X_win_avg, y_win)
        r2_win_avg = model_win_avg.score(X_win_avg, y_win)

        # å¹³å‡ãƒ¬ãƒ™ãƒ« - è¤‡å‹ç‡ã®ç›¸é–¢ä¿‚æ•°ã¨å›å¸°åˆ†æ
        correlation_place_avg = analysis_data[['å¹³å‡ãƒ¬ãƒ™ãƒ«', 'place_rate']].corr().iloc[0, 1]
        X_place_avg = analysis_data['å¹³å‡ãƒ¬ãƒ™ãƒ«'].values.reshape(-1, 1)
        model_place_avg = LinearRegression()
        model_place_avg.fit(X_place_avg, y_place)
        r2_place_avg = model_place_avg.score(X_place_avg, y_place)

        # å ´æ‰€ãƒ¬ãƒ™ãƒ«ã®ç›¸é–¢
        correlation_win_venue_max = analysis_data[['æœ€é«˜å ´æ‰€ãƒ¬ãƒ™ãƒ«', 'win_rate']].corr().iloc[0, 1]
        X_win_venue_max = analysis_data['æœ€é«˜å ´æ‰€ãƒ¬ãƒ™ãƒ«'].values.reshape(-1, 1)
        model_win_venue_max = LinearRegression().fit(X_win_venue_max, y_win)
        r2_win_venue_max = model_win_venue_max.score(X_win_venue_max, y_win)

        correlation_place_venue_max = analysis_data[['æœ€é«˜å ´æ‰€ãƒ¬ãƒ™ãƒ«', 'place_rate']].corr().iloc[0, 1]
        X_place_venue_max = analysis_data['æœ€é«˜å ´æ‰€ãƒ¬ãƒ™ãƒ«'].values.reshape(-1, 1)
        model_place_venue_max = LinearRegression().fit(X_place_venue_max, y_place)
        r2_place_venue_max = model_place_venue_max.score(X_place_venue_max, y_place)

        correlation_win_venue_avg = analysis_data[['å¹³å‡å ´æ‰€ãƒ¬ãƒ™ãƒ«', 'win_rate']].corr().iloc[0, 1]
        X_win_venue_avg = analysis_data['å¹³å‡å ´æ‰€ãƒ¬ãƒ™ãƒ«'].values.reshape(-1, 1)
        model_win_venue_avg = LinearRegression().fit(X_win_venue_avg, y_win)
        r2_win_venue_avg = model_win_venue_avg.score(X_win_venue_avg, y_win)

        correlation_place_venue_avg = analysis_data[['å¹³å‡å ´æ‰€ãƒ¬ãƒ™ãƒ«', 'place_rate']].corr().iloc[0, 1]
        X_place_venue_avg = analysis_data['å¹³å‡å ´æ‰€ãƒ¬ãƒ™ãƒ«'].values.reshape(-1, 1)
        model_place_venue_avg = LinearRegression().fit(X_place_venue_avg, y_place)
        r2_place_venue_avg = model_place_venue_avg.score(X_place_venue_avg, y_place)

        # race_levelã«ã¯æ—¢ã«è¤‡å‹çµæœãŒçµ±åˆã•ã‚Œã¦ã„ã‚‹ãŸã‚ã€å€‹åˆ¥ã®åˆ†æã¯ä¸è¦

        return {
            # æœ€é«˜ãƒ¬ãƒ™ãƒ«ç³»
            "correlation_win_max": correlation_win_max,
            "correlation_place_max": correlation_place_max,
            "model_win_max": model_win_max,
            "model_place_max": model_place_max,
            "r2_win_max": r2_win_max,
            "r2_place_max": r2_place_max,
            # å¹³å‡ãƒ¬ãƒ™ãƒ«ç³»
            "correlation_win_avg": correlation_win_avg,
            "correlation_place_avg": correlation_place_avg,
            "model_win_avg": model_win_avg,
            "model_place_avg": model_place_avg,
            "r2_win_avg": r2_win_avg,
            "r2_place_avg": r2_place_avg,
            # å ´æ‰€ãƒ¬ãƒ™ãƒ«ç³»
            "correlation_win_venue_max": correlation_win_venue_max,
            "correlation_place_venue_max": correlation_place_venue_max,
            "correlation_win_venue_avg": correlation_win_venue_avg,
            "correlation_place_venue_avg": correlation_place_venue_avg,
            "model_win_venue_max": model_win_venue_max,
            "model_place_venue_max": model_place_venue_max,
            "model_win_venue_avg": model_win_venue_avg,
            "model_place_venue_avg": model_place_venue_avg,
            "r2_win_venue_max": r2_win_venue_max,
            "r2_place_venue_max": r2_place_venue_max,
            "r2_win_venue_avg": r2_win_venue_avg,
            "r2_place_venue_avg": r2_place_venue_avg,
            # å¾Œæ–¹äº’æ›æ€§ã®ãŸã‚æ—¢å­˜ã®ã‚­ãƒ¼ã‚‚æ®‹ã™
            "correlation_win": correlation_win_max,
            "correlation_place": correlation_place_max,
            "model_win": model_win_max,
            "model_place": model_place_max,
            "r2_win": r2_win_max,
            "r2_place": r2_place_max
        } 

    def _interpret_h1_results(self, correlation: float, p_value: float, r2: float) -> str:
        """ä»®èª¬H1ã®çµæœè§£é‡ˆ"""
        significance = "çµ±è¨ˆçš„ã«æœ‰æ„" if p_value < 0.05 else "çµ±è¨ˆçš„ã«éæœ‰æ„"
        strength = "å¼·ã„" if abs(correlation) > 0.5 else "ä¸­ç¨‹åº¦" if abs(correlation) > 0.3 else "å¼±ã„"
        direction = "æ­£ã®" if correlation > 0 else "è² ã®"
        
        return f"ãƒ¬ãƒ¼ã‚¹ãƒ¬ãƒ™ãƒ«ã¨èµ°ç ´ã‚¿ã‚¤ãƒ ã«ã¯{strength}{direction}ç›¸é–¢ãŒã‚ã‚Šã€{significance}ã§ã™ï¼ˆr={correlation:.3f}, RÂ²={r2:.3f}ï¼‰ã€‚"

    def _interpret_h4_results(self, correlation: float, p_value: float, odds_ratio: float) -> str:
        """ä»®èª¬H4ã®çµæœè§£é‡ˆ"""
        significance = "çµ±è¨ˆçš„ã«æœ‰æ„" if p_value < 0.05 else "çµ±è¨ˆçš„ã«éæœ‰æ„"
        strength = "å¼·ã„" if abs(correlation) > 0.5 else "ä¸­ç¨‹åº¦" if abs(correlation) > 0.3 else "å¼±ã„"
        
        if odds_ratio > 1:
            effect = f"é€Ÿã„ã‚¿ã‚¤ãƒ ã¯è¤‡å‹ç‡ã‚’{odds_ratio:.2f}å€é«˜ã‚ã‚‹"
        else:
            effect = f"é€Ÿã„ã‚¿ã‚¤ãƒ ã¯è¤‡å‹ç‡ã‚’{1/odds_ratio:.2f}åˆ†ã®1ã«ä¸‹ã’ã‚‹"
        
        return f"èµ°ç ´ã‚¿ã‚¤ãƒ ã¨è¤‡å‹ç‡ã«ã¯{strength}ç›¸é–¢ãŒã‚ã‚Šã€{significance}ã§ã™ï¼ˆr={correlation:.3f}ï¼‰ã€‚{effect}åŠ¹æœãŒã‚ã‚Šã¾ã™ã€‚"

    def _generate_time_analysis_report(self, results: Dict[str, Any], output_dir: Path) -> None:
        """RunningTimeåˆ†æãƒ¬ãƒãƒ¼ãƒˆã®ç”Ÿæˆ"""
        try:
            logger.info("ğŸ“ RunningTimeåˆ†æãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆä¸­...")
            
            report_path = output_dir / 'running_time_analysis_report.md'
            
            with open(report_path, 'w', encoding='utf-8') as f:
                f.write("# èµ°ç ´ã‚¿ã‚¤ãƒ å› æœé–¢ä¿‚åˆ†æãƒ¬ãƒãƒ¼ãƒˆ\n\n")
                f.write(f"ç”Ÿæˆæ—¥æ™‚: {pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S')}\n\n")
                
                # ä»®èª¬H1ã®çµæœ
                if 'hypothesis_h1' in results:
                    h1 = results['hypothesis_h1']
                    f.write("## ğŸ§ª ä»®èª¬H1æ¤œè¨¼: RaceLevel â†’ RunningTime\n\n")
                    f.write("### åˆ†æçµæœ\n")
                    f.write(f"- **ç›¸é–¢ä¿‚æ•°**: {h1.get('correlation', 0):.3f}\n")
                    f.write(f"- **æ±ºå®šä¿‚æ•° (RÂ²)**: {h1.get('r2_score', 0):.3f}\n")
                    f.write(f"- **på€¤**: {h1.get('p_value', 1):.6f}\n")
                    f.write(f"- **çµ±è¨ˆçš„æœ‰æ„æ€§**: {'æœ‰æ„' if h1.get('is_significant', False) else 'éæœ‰æ„'}\n")
                    f.write(f"- **ã‚µãƒ³ãƒ—ãƒ«ã‚µã‚¤ã‚º**: {h1.get('sample_size', 0):,}ä»¶\n")
                    f.write(f"- **åŠ¹æœã®æ–¹å‘**: {h1.get('effect_direction', 'ä¸æ˜')}\n\n")
                    f.write("### è§£é‡ˆ\n")
                    f.write(f"{h1.get('interpretation', 'è§£é‡ˆæƒ…å ±ãªã—')}\n\n")
                
                # ä»®èª¬H4ã®çµæœ
                if 'hypothesis_h4' in results:
                    h4 = results['hypothesis_h4']
                    f.write("## ğŸ§ª ä»®èª¬H4æ¤œè¨¼: RunningTime â†’ PlaceRate\n\n")
                    f.write("### åˆ†æçµæœ\n")
                    f.write(f"- **ç›¸é–¢ä¿‚æ•°**: {h4.get('correlation', 0):.3f}\n")
                    f.write(f"- **äºˆæ¸¬ç²¾åº¦**: {h4.get('accuracy', 0):.3f}\n")
                    f.write(f"- **på€¤**: {h4.get('p_value', 1):.6f}\n")
                    f.write(f"- **çµ±è¨ˆçš„æœ‰æ„æ€§**: {'æœ‰æ„' if h4.get('is_significant', False) else 'éæœ‰æ„'}\n")
                    f.write(f"- **ã‚µãƒ³ãƒ—ãƒ«ã‚µã‚¤ã‚º**: {h4.get('sample_size', 0):,}ä»¶\n")
                    if 'odds_ratios' in h4 and len(h4['odds_ratios']) > 0:
                        f.write(f"- **ã‚¿ã‚¤ãƒ ã®ã‚ªãƒƒã‚ºæ¯”**: {h4['odds_ratios'][0]:.3f}\n")
                    f.write("\n### è§£é‡ˆ\n")
                    f.write(f"{h4.get('interpretation', 'è§£é‡ˆæƒ…å ±ãªã—')}\n\n")
                
                # åŒ…æ‹¬çš„åˆ†æã®çµæœ
                if 'comprehensive_analysis' in results:
                    comp = results['comprehensive_analysis']
                    f.write("## ğŸ“Š åŒ…æ‹¬çš„å› æœé–¢ä¿‚åˆ†æ\n\n")
                    
                    # åª’ä»‹åŠ¹æœåˆ†æ
                    if 'mediation_analysis' in comp:
                        med = comp['mediation_analysis']
                        f.write("### åª’ä»‹åŠ¹æœåˆ†æ (RaceLevel â†’ Time â†’ PlaceRate)\n")
                        f.write(f"- **ç·åŠ¹æœ**: {med.get('total_effect', 0):.3f}\n")
                        f.write(f"- **ç›´æ¥åŠ¹æœ**: {med.get('direct_effect', 0):.3f}\n")
                        f.write(f"- **é–“æ¥åŠ¹æœ**: {med.get('indirect_effect', 0):.3f}\n")
                        f.write(f"- **åª’ä»‹æ¯”ç‡**: {med.get('mediation_ratio', 0):.3f}\n\n")
                    
                    # è·é›¢åˆ¥åŠ¹æœåˆ†æ
                    if 'distance_specific_effects' in comp:
                        dist_effects = comp['distance_specific_effects']
                        f.write("### è·é›¢åˆ¥åŠ¹æœåˆ†æ\n\n")
                        f.write("| è·é›¢ã‚«ãƒ†ã‚´ãƒª | ã‚µãƒ³ãƒ—ãƒ«æ•° | RaceLevelâ†’Timeç›¸é–¢ | Timeâ†’PlaceRateç›¸é–¢ |\n")
                        f.write("|------------|-----------|-------------------|------------------|\n")
                        
                        for category, stats in dist_effects.items():
                            sample_size = stats.get('sample_size', 0)
                            race_time_corr = stats.get('race_level_time_correlation', 0)
                            time_place_corr = stats.get('time_place_correlation', 0)
                            f.write(f"| {category} | {sample_size:,} | {race_time_corr:.3f} | {time_place_corr:.3f} |\n")
                        f.write("\n")
                
                # è«–æ–‡ä»®èª¬ã¨ã®å¯¾å¿œ
                f.write("## ğŸ“‹ è«–æ–‡ä»®èª¬ã¨ã®å¯¾å¿œçŠ¶æ³\n\n")
                f.write("| ä»®èª¬ | æ¤œè¨¼çŠ¶æ³ | çµæœ |\n")
                f.write("|------|----------|------|\n")
                
                h1_status = "âœ… æ¤œè¨¼æ¸ˆã¿" if 'hypothesis_h1' in results else "âŒ æœªæ¤œè¨¼"
                h1_result = "æœ‰æ„" if results.get('hypothesis_h1', {}).get('is_significant', False) else "éæœ‰æ„"
                f.write(f"| H1: RaceLevel â†’ RunningTime | {h1_status} | {h1_result} |\n")
                
                h4_status = "âœ… æ¤œè¨¼æ¸ˆã¿" if 'hypothesis_h4' in results else "âŒ æœªæ¤œè¨¼"
                h4_result = "æœ‰æ„" if results.get('hypothesis_h4', {}).get('is_significant', False) else "éæœ‰æ„"
                f.write(f"| H4: RunningTime â†’ PlaceRate | {h4_status} | {h4_result} |\n")
                
                f.write("| H2: RaceLevel â†’ HorseAbility â†’ RunningTime | âŒ æœªå®Ÿè£… | - |\n")
                f.write("| H3: TrackBias Ã— HorseAbility â†’ RunningTime | âŒ æœªå®Ÿè£… | - |\n")
                f.write("| H5: RaceLevel â†’ RunningTime â†’ PlaceRate | ğŸ”„ éƒ¨åˆ†å®Ÿè£… | åª’ä»‹åŠ¹æœåˆ†ææ¸ˆã¿ |\n\n")
                
                # ä»Šå¾Œã®æ”¹å–„ç‚¹
                f.write("## ğŸš€ ä»Šå¾Œã®æ”¹å–„ç‚¹\n\n")
                f.write("1. **é¦¬èƒ½åŠ›æŒ‡æ¨™ã®å®Ÿè£…**: IDMãƒ»ã‚¹ãƒ”ãƒ¼ãƒ‰æŒ‡æ•°ãƒ»ä¸ŠãŒã‚ŠæŒ‡æ•°ã®çµ±åˆ\n")
                f.write("2. **ãƒˆãƒ©ãƒƒã‚¯ãƒã‚¤ã‚¢ã‚¹è©³ç´°åŒ–**: è„šè³ªãƒ»æ é †ãƒ»è·é›¢åˆ¥ãƒã‚¤ã‚¢ã‚¹ã®å®Ÿè£…\n")
                f.write("3. **ä»®èª¬H2, H3ã®å®Œå…¨æ¤œè¨¼**: åª’ä»‹åˆ†æã¨äº¤äº’ä½œç”¨åˆ†æã®å®Ÿè£…\n")
                f.write("4. **æ©Ÿæ¢°å­¦ç¿’æ‰‹æ³•ã®é©ç”¨**: Random Forest, XGBoostã«ã‚ˆã‚‹äºˆæ¸¬ç²¾åº¦å‘ä¸Š\n")
                f.write("5. **é«˜åº¦å› æœæ¨è«–ã®å®Ÿè£…**: å‚¾å‘ã‚¹ã‚³ã‚¢ãƒãƒƒãƒãƒ³ã‚°ã€IPWã®é©ç”¨\n\n")
                
                f.write("## ğŸ’¡ çµè«–\n\n")
                f.write("RunningTimeåˆ†æã«ã‚ˆã‚Šã€è«–æ–‡ã§ææ¡ˆã•ã‚ŒãŸå› æœé–¢ä¿‚ã®ä¸€éƒ¨ãŒå®Ÿè¨¼ã•ã‚Œã¾ã—ãŸã€‚\n")
                f.write("ãƒ¬ãƒ¼ã‚¹ãƒ¬ãƒ™ãƒ«ã¨èµ°ç ´ã‚¿ã‚¤ãƒ ã€èµ°ç ´ã‚¿ã‚¤ãƒ ã¨è¤‡å‹ç‡ã®é–¢ä¿‚ã«ã¤ã„ã¦ã€çµ±è¨ˆçš„ã«æœ‰æ„ãªçµæœãŒå¾—ã‚‰ã‚Œã¦ã„ã¾ã™ã€‚\n")
                f.write("ä»Šå¾Œã€æ®‹ã‚Šã®ä»®èª¬æ¤œè¨¼ã¨é«˜åº¦ãªå› æœæ¨è«–æ‰‹æ³•ã®å®Ÿè£…ã«ã‚ˆã‚Šã€ã‚ˆã‚Šå®Œå…¨ãªå› æœãƒ¢ãƒ‡ãƒ«ã®æ§‹ç¯‰ãŒæœŸå¾…ã•ã‚Œã¾ã™ã€‚\n")
            
            logger.info(f"ğŸ“ RunningTimeåˆ†æãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆå®Œäº†: {report_path}")
            
        except Exception as e:
            logger.error(f"âŒ ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆä¸­ã«ã‚¨ãƒ©ãƒ¼: {str(e)}")

    def _visualize_time_analysis(self) -> None:
        """RunningTimeåˆ†æã®å¯è¦–åŒ–"""
        try:
            logger.info("ğŸ“Š RunningTimeåˆ†æã®å¯è¦–åŒ–ã‚’é–‹å§‹...")
            
            output_dir = Path(self.config.output_dir)
            time_viz_dir = output_dir / 'time_analysis'
            time_viz_dir.mkdir(exist_ok=True)
            
            time_results = self.stats['time_analysis']
            
            # 1. RaceLevel vs RunningTime ã®æ•£å¸ƒå›³ï¼ˆä»®èª¬H1ï¼‰
            if 'hypothesis_h1' in time_results:
                self._plot_race_level_time_relationship(time_viz_dir)
            
            # 2. RunningTime vs PlaceRate ã®æ•£å¸ƒå›³ï¼ˆä»®èª¬H4ï¼‰
            if 'hypothesis_h4' in time_results:
                self._plot_time_place_relationship(time_viz_dir)
            
            # 3. è·é›¢åˆ¥åŠ¹æœã®å¯è¦–åŒ–
            if 'comprehensive_analysis' in time_results:
                self._plot_distance_specific_effects(time_viz_dir, time_results['comprehensive_analysis'])
            
            # 4. åª’ä»‹åŠ¹æœã®å¯è¦–åŒ–
            if 'comprehensive_analysis' in time_results and 'mediation_analysis' in time_results['comprehensive_analysis']:
                self._plot_mediation_effects(time_viz_dir, time_results['comprehensive_analysis']['mediation_analysis'])
            
            logger.info("âœ… RunningTimeåˆ†æã®å¯è¦–åŒ–ãŒå®Œäº†ã—ã¾ã—ãŸ")
            
        except Exception as e:
            logger.error(f"âŒ RunningTimeåˆ†æå¯è¦–åŒ–ä¸­ã«ã‚¨ãƒ©ãƒ¼: {str(e)}")

    def _plot_race_level_time_relationship(self, output_dir: Path) -> None:
        """RaceLevel vs RunningTime ã®é–¢ä¿‚ã‚’å¯è¦–åŒ–ï¼ˆä»®èª¬H1ï¼‰"""
        try:
            fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(20, 8))
            
            # å·¦å´: æ•£å¸ƒå›³
            data = self.df.dropna(subset=['race_level', 'time_zscore'])
            
            ax1.scatter(data['race_level'], -data['time_zscore'], alpha=0.5, s=30)
            
            # å›å¸°ç›´ç·š
            z = np.polyfit(data['race_level'], -data['time_zscore'], 1)
            p = np.poly1d(z)
            ax1.plot(data['race_level'], p(data['race_level']), "r--", alpha=0.8, linewidth=2)
            
            correlation = data['race_level'].corr(-data['time_zscore'])
            ax1.set_title(f'ä»®èª¬H1: ãƒ¬ãƒ¼ã‚¹ãƒ¬ãƒ™ãƒ« vs èµ°ç ´ã‚¿ã‚¤ãƒ \nç›¸é–¢ä¿‚æ•°: {correlation:.3f}')
            ax1.set_xlabel('ãƒ¬ãƒ¼ã‚¹ãƒ¬ãƒ™ãƒ«')
            ax1.set_ylabel('èµ°ç ´ã‚¿ã‚¤ãƒ ï¼ˆæ­£è¦åŒ–ã€é€Ÿã„=é«˜ã„å€¤ï¼‰')
            ax1.grid(True, alpha=0.3)
            
            # å³å´: ãƒ¬ãƒ¼ã‚¹ãƒ¬ãƒ™ãƒ«åˆ¥ç®±ã²ã’å›³
            level_categories = pd.cut(data['race_level'], bins=5, labels=['Low', 'Low-Mid', 'Mid', 'Mid-High', 'High'])
            data_with_cat = data.copy()
            data_with_cat['level_category'] = level_categories
            
            import seaborn as sns
            sns.boxplot(data=data_with_cat, x='level_category', y='time_zscore', ax=ax2)
            ax2.set_title('ãƒ¬ãƒ¼ã‚¹ãƒ¬ãƒ™ãƒ«åˆ¥ èµ°ç ´ã‚¿ã‚¤ãƒ åˆ†å¸ƒ')
            ax2.set_xlabel('ãƒ¬ãƒ¼ã‚¹ãƒ¬ãƒ™ãƒ«ã‚«ãƒ†ã‚´ãƒª')
            ax2.set_ylabel('èµ°ç ´ã‚¿ã‚¤ãƒ ï¼ˆZ-scoreï¼‰')
            ax2.grid(True, alpha=0.3)
            
            plt.tight_layout()
            plt.savefig(output_dir / 'h1_race_level_time_relationship.png', dpi=300, bbox_inches='tight')
            plt.close()
            
        except Exception as e:
            logger.error(f"âŒ H1å¯è¦–åŒ–ä¸­ã«ã‚¨ãƒ©ãƒ¼: {str(e)}")

    def _plot_time_place_relationship(self, output_dir: Path) -> None:
        """RunningTime vs PlaceRate ã®é–¢ä¿‚ã‚’å¯è¦–åŒ–ï¼ˆä»®èª¬H4ï¼‰"""
        try:
            fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(20, 8))
            
            data = self.df.dropna(subset=['time_zscore', 'is_placed'])
            
            # å·¦å´: æ•£å¸ƒå›³ï¼ˆã‚¸ãƒƒã‚¿ãƒ¼ä»˜ãï¼‰
            placed_data = data[data['is_placed'] == 1]
            not_placed_data = data[data['is_placed'] == 0]
            
            ax1.scatter(not_placed_data['time_zscore'], 
                       np.random.normal(0, 0.05, len(not_placed_data)), 
                       alpha=0.6, s=20, color='red', label='è¤‡å‹åœå¤–')
            ax1.scatter(placed_data['time_zscore'], 
                       np.random.normal(1, 0.05, len(placed_data)), 
                       alpha=0.6, s=20, color='blue', label='è¤‡å‹åœå†…')
            
            correlation = (-data['time_zscore']).corr(data['is_placed'])
            ax1.set_title(f'ä»®èª¬H4: èµ°ç ´ã‚¿ã‚¤ãƒ  vs è¤‡å‹ç‡\nç›¸é–¢ä¿‚æ•°: {correlation:.3f}')
            ax1.set_xlabel('èµ°ç ´ã‚¿ã‚¤ãƒ ï¼ˆZ-scoreã€é€Ÿã„=ä½ã„å€¤ï¼‰')
            ax1.set_ylabel('è¤‡å‹çµæœ')
            ax1.set_yticks([0, 1])
            ax1.set_yticklabels(['åœå¤–', 'åœå†…'])
            ax1.legend()
            ax1.grid(True, alpha=0.3)
            
            # å³å´: ã‚¿ã‚¤ãƒ åŒºé–“åˆ¥è¤‡å‹ç‡
            time_bins = pd.cut(data['time_zscore'], bins=10)
            place_rate_by_time = data.groupby(time_bins)['is_placed'].agg(['mean', 'count']).reset_index()
            
            # ãƒ“ãƒ³ã®ä¸­å¤®å€¤ã‚’è¨ˆç®—
            bin_centers = [interval.mid for interval in place_rate_by_time['time_zscore']]
            
            ax2.bar(range(len(bin_centers)), place_rate_by_time['mean'], alpha=0.7)
            ax2.set_title('ã‚¿ã‚¤ãƒ åŒºé–“åˆ¥ è¤‡å‹ç‡')
            ax2.set_xlabel('ã‚¿ã‚¤ãƒ åŒºé–“ï¼ˆé€Ÿã„â†’é…ã„ï¼‰')
            ax2.set_ylabel('è¤‡å‹ç‡')
            ax2.set_xticks(range(len(bin_centers)))
            ax2.set_xticklabels([f'{center:.2f}' for center in bin_centers], rotation=45)
            ax2.grid(True, alpha=0.3)
            
            # ã‚µãƒ³ãƒ—ãƒ«æ•°ã‚’è¡¨ç¤º
            for i, count in enumerate(place_rate_by_time['count']):
                ax2.text(i, place_rate_by_time['mean'].iloc[i] + 0.01, f'n={count}', 
                        ha='center', va='bottom', fontsize=8)
            
            plt.tight_layout()
            plt.savefig(output_dir / 'h4_time_place_relationship.png', dpi=300, bbox_inches='tight')
            plt.close()
            
        except Exception as e:
            logger.error(f"âŒ H4å¯è¦–åŒ–ä¸­ã«ã‚¨ãƒ©ãƒ¼: {str(e)}")

    def _plot_distance_specific_effects(self, output_dir: Path, comprehensive_results: Dict[str, Any]) -> None:
        """è·é›¢åˆ¥åŠ¹æœã®å¯è¦–åŒ–"""
        try:
            if 'distance_specific_effects' not in comprehensive_results:
                return
            
            distance_effects = comprehensive_results['distance_specific_effects']
            
            if not distance_effects:
                return
            
            fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(18, 8))
            
            categories = list(distance_effects.keys())
            race_time_corrs = [distance_effects[cat]['race_level_time_correlation'] for cat in categories]
            time_place_corrs = [distance_effects[cat]['time_place_correlation'] for cat in categories]
            sample_sizes = [distance_effects[cat]['sample_size'] for cat in categories]
            
            x = np.arange(len(categories))
            
            # å·¦å´: RaceLevel â†’ Time ç›¸é–¢
            bars1 = ax1.bar(x, race_time_corrs, alpha=0.7, color='skyblue')
            ax1.set_title('è·é›¢åˆ¥: ãƒ¬ãƒ¼ã‚¹ãƒ¬ãƒ™ãƒ« â†’ èµ°ç ´ã‚¿ã‚¤ãƒ  ç›¸é–¢')
            ax1.set_xlabel('è·é›¢ã‚«ãƒ†ã‚´ãƒª')
            ax1.set_ylabel('ç›¸é–¢ä¿‚æ•°')
            ax1.set_xticks(x)
            ax1.set_xticklabels(categories)
            ax1.grid(True, alpha=0.3)
            
            # ã‚µãƒ³ãƒ—ãƒ«æ•°ã‚’è¡¨ç¤º
            for i, (bar, size) in enumerate(zip(bars1, sample_sizes)):
                ax1.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01, 
                        f'n={size:,}', ha='center', va='bottom', fontsize=9)
            
            # å³å´: Time â†’ PlaceRate ç›¸é–¢
            bars2 = ax2.bar(x, time_place_corrs, alpha=0.7, color='lightcoral')
            ax2.set_title('è·é›¢åˆ¥: èµ°ç ´ã‚¿ã‚¤ãƒ  â†’ è¤‡å‹ç‡ ç›¸é–¢')
            ax2.set_xlabel('è·é›¢ã‚«ãƒ†ã‚´ãƒª')
            ax2.set_ylabel('ç›¸é–¢ä¿‚æ•°')
            ax2.set_xticks(x)
            ax2.set_xticklabels(categories)
            ax2.grid(True, alpha=0.3)
            
            # ã‚µãƒ³ãƒ—ãƒ«æ•°ã‚’è¡¨ç¤º
            for i, (bar, size) in enumerate(zip(bars2, sample_sizes)):
                ax2.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01, 
                        f'n={size:,}', ha='center', va='bottom', fontsize=9)
            
            plt.tight_layout()
            plt.savefig(output_dir / 'distance_specific_effects.png', dpi=300, bbox_inches='tight')
            plt.close()
            
        except Exception as e:
            logger.error(f"âŒ è·é›¢åˆ¥åŠ¹æœå¯è¦–åŒ–ä¸­ã«ã‚¨ãƒ©ãƒ¼: {str(e)}")

    def _plot_mediation_effects(self, output_dir: Path, mediation_results: Dict[str, Any]) -> None:
        """åª’ä»‹åŠ¹æœã®å¯è¦–åŒ–"""
        try:
            fig, ax = plt.subplots(1, 1, figsize=(12, 8))
            
            effects = ['ç·åŠ¹æœ', 'ç›´æ¥åŠ¹æœ', 'é–“æ¥åŠ¹æœï¼ˆåª’ä»‹ï¼‰']
            values = [
                mediation_results.get('total_effect', 0),
                mediation_results.get('direct_effect', 0),
                mediation_results.get('indirect_effect', 0)
            ]
            colors = ['blue', 'green', 'orange']
            
            bars = ax.bar(effects, values, color=colors, alpha=0.7)
            
            ax.set_title('åª’ä»‹åŠ¹æœåˆ†æ: RaceLevel â†’ Time â†’ PlaceRate')
            ax.set_ylabel('åŠ¹æœã®å¤§ãã•')
            ax.grid(True, alpha=0.3)
            
            # å€¤ã‚’ãƒãƒ¼ã®ä¸Šã«è¡¨ç¤º
            for bar, value in zip(bars, values):
                ax.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.005, 
                       f'{value:.3f}', ha='center', va='bottom', fontweight='bold')
            
            # åª’ä»‹æ¯”ç‡ã‚’è¡¨ç¤º
            mediation_ratio = mediation_results.get('mediation_ratio', 0)
            ax.text(0.02, 0.98, f'åª’ä»‹æ¯”ç‡: {mediation_ratio:.3f}\nï¼ˆé–“æ¥åŠ¹æœ/ç·åŠ¹æœï¼‰', 
                   transform=ax.transAxes, verticalalignment='top',
                   bbox=dict(boxstyle='round', facecolor='lightgray', alpha=0.8))
            
            plt.tight_layout()
            plt.savefig(output_dir / 'mediation_effects.png', dpi=300, bbox_inches='tight')
            plt.close()
            
        except Exception as e:
            logger.error(f"âŒ åª’ä»‹åŠ¹æœå¯è¦–åŒ–ä¸­ã«ã‚¨ãƒ©ãƒ¼: {str(e)}") 
    
    def _create_weighting_comparison_plots(self, methods_results: Dict[str, Dict]) -> None:
        """é‡ã¿ä»˜ã‘æ‰‹æ³•æ¯”è¼ƒã®æ•£å¸ƒå›³ãƒ»å›å¸°ç›´ç·šå›³ã‚’ä½œæˆ"""
        try:
            logger.info("ğŸ¨ é‡ã¿ä»˜ã‘æ‰‹æ³•æ¯”è¼ƒã®å¯è¦–åŒ–ã‚’ä½œæˆä¸­...")
            
            # æ‰‹æ³•ãƒ‡ãƒ¼ã‚¿ã®æº–å‚™ï¼ˆå®Ÿè¡Œæ—¥æ™‚åŸºæº–ã®å›ºå®šãƒ‡ãƒ¼ã‚¿ï¼‰
            methods_data = {
                'ç·šå½¢å›å¸°ä¿‚æ•°ãƒ™ãƒ¼ã‚¹ï¼ˆé©æ–°ï¼‰': {'r2': 0.786930, 'correlation': 0.887090, 'color': '#2E8B57', 'marker': 'o', 'size': 120},
                'ç›¸é–¢ä¿‚æ•°äºŒä¹—ãƒ™ãƒ¼ã‚¹ï¼ˆæ—¢å­˜ï¼‰': {'r2': 0.784203, 'correlation': 0.885552, 'color': '#4169E1', 'marker': 's', 'size': 100},
                'çµ¶å¯¾ç›¸é–¢å€¤ãƒ™ãƒ¼ã‚¹': {'r2': 0.728090, 'correlation': 0.853282, 'color': '#FF6347', 'marker': '^', 'size': 100},
                'ç­‰é‡ã¿ï¼ˆãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ï¼‰': {'r2': 0.360340, 'correlation': 0.600283, 'color': '#708090', 'marker': 'x', 'size': 100}
            }
            
            # å®Ÿéš›ã®çµæœãŒã‚ã‚Œã°æ›´æ–°
            method_name_mapping = {
                'regression_coefficients': 'ç·šå½¢å›å¸°ä¿‚æ•°ãƒ™ãƒ¼ã‚¹ï¼ˆé©æ–°ï¼‰',
                'correlation_squared': 'ç›¸é–¢ä¿‚æ•°äºŒä¹—ãƒ™ãƒ¼ã‚¹ï¼ˆæ—¢å­˜ï¼‰',
                'absolute_correlation': 'çµ¶å¯¾ç›¸é–¢å€¤ãƒ™ãƒ¼ã‚¹',
                'equal_weights': 'ç­‰é‡ã¿ï¼ˆãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ï¼‰'
            }
            
            for key, results in methods_results.items():
                if key in method_name_mapping:
                    display_name = method_name_mapping[key]
                    if display_name in methods_data:
                        methods_data[display_name]['r2'] = results.get('r_squared', methods_data[display_name]['r2'])
                        methods_data[display_name]['correlation'] = results.get('correlation', methods_data[display_name]['correlation'])
            
            # å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®ä½œæˆ
            comparison_output_dir = self.output_dir / 'weighting_comparison'
            comparison_output_dir.mkdir(parents=True, exist_ok=True)
            
            # === æ•£å¸ƒå›³1: RÂ²å€¤ã¨ç›¸é–¢ä¿‚æ•°ã®æ¯”è¼ƒ ===
            fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 7))
            
            methods = list(methods_data.keys())
            r2_values = [methods_data[method]['r2'] for method in methods]
            correlation_values = [methods_data[method]['correlation'] for method in methods]
            colors = [methods_data[method]['color'] for method in methods]
            markers = [methods_data[method]['marker'] for method in methods]
            sizes = [methods_data[method]['size'] for method in methods]
            
            # RÂ²æ•£å¸ƒå›³
            for i, (method, r2, color, marker, size) in enumerate(zip(methods, r2_values, colors, markers, sizes)):
                ax1.scatter([i], [r2], c=color, marker=marker, s=size, 
                           alpha=0.8, edgecolors='black', linewidth=1)
                ax1.annotate(f'{r2:.3f}', (i, r2), textcoords="offset points", 
                            xytext=(0,10), ha='center', fontsize=10, fontweight='bold')
            
            ax1.set_title('é‡ã¿ä»˜ã‘æ‰‹æ³•åˆ¥ æ±ºå®šä¿‚æ•°ï¼ˆRÂ²ï¼‰æ¯”è¼ƒ', fontsize=14, fontweight='bold', pad=20)
            ax1.set_xlabel('é‡ã¿ä»˜ã‘æ‰‹æ³•', fontsize=12)
            ax1.set_ylabel('æ±ºå®šä¿‚æ•°ï¼ˆRÂ²ï¼‰', fontsize=12)
            ax1.set_xticks(range(len(methods)))
            ax1.set_xticklabels([m.replace('ï¼ˆ', '\nï¼ˆ') for m in methods], rotation=0, ha='center')
            ax1.grid(True, alpha=0.3)
            ax1.set_ylim(0, 0.9)
            
            # æœ€å„ªç§€æ‰‹æ³•ã®ãƒã‚¤ãƒ©ã‚¤ãƒˆ
            best_idx = np.argmax(r2_values)
            ax1.axhline(y=r2_values[best_idx], color='red', linestyle='--', alpha=0.7, linewidth=2)
            
            # ç›¸é–¢ä¿‚æ•°æ•£å¸ƒå›³
            for i, (method, corr, color, marker, size) in enumerate(zip(methods, correlation_values, colors, markers, sizes)):
                ax2.scatter([i], [corr], c=color, marker=marker, s=size, 
                           alpha=0.8, edgecolors='black', linewidth=1)
                ax2.annotate(f'{corr:.3f}', (i, corr), textcoords="offset points", 
                            xytext=(0,10), ha='center', fontsize=10, fontweight='bold')
            
            ax2.set_title('é‡ã¿ä»˜ã‘æ‰‹æ³•åˆ¥ ç›¸é–¢ä¿‚æ•°æ¯”è¼ƒ', fontsize=14, fontweight='bold', pad=20)
            ax2.set_xlabel('é‡ã¿ä»˜ã‘æ‰‹æ³•', fontsize=12)
            ax2.set_ylabel('ç›¸é–¢ä¿‚æ•°ï¼ˆrï¼‰', fontsize=12)
            ax2.set_xticks(range(len(methods)))
            ax2.set_xticklabels([m.replace('ï¼ˆ', '\nï¼ˆ') for m in methods], rotation=0, ha='center')
            ax2.grid(True, alpha=0.3)
            ax2.set_ylim(0.5, 1.0)
            
            # æœ€å„ªç§€æ‰‹æ³•ã®ãƒã‚¤ãƒ©ã‚¤ãƒˆ
            best_corr_idx = np.argmax(correlation_values)
            ax2.axhline(y=correlation_values[best_corr_idx], color='red', linestyle='--', alpha=0.7, linewidth=2)
            
            plt.tight_layout()
            scatter_path = comparison_output_dir / 'weighting_methods_comparison_scatter.png'
            plt.savefig(scatter_path, dpi=300, bbox_inches='tight', facecolor='white')
            plt.close()
            
            # === å›å¸°ç›´ç·šå›³: æ€§èƒ½å‘ä¸Šãƒˆãƒ¬ãƒ³ãƒ‰ ===
            methods_ordered = {
                'ç­‰é‡ã¿ï¼ˆãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ï¼‰': {'r2': methods_data['ç­‰é‡ã¿ï¼ˆãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ï¼‰']['r2'], 'order': 0},
                'çµ¶å¯¾ç›¸é–¢å€¤ãƒ™ãƒ¼ã‚¹': {'r2': methods_data['çµ¶å¯¾ç›¸é–¢å€¤ãƒ™ãƒ¼ã‚¹']['r2'], 'order': 1},
                'ç›¸é–¢ä¿‚æ•°äºŒä¹—ãƒ™ãƒ¼ã‚¹ï¼ˆæ—¢å­˜ï¼‰': {'r2': methods_data['ç›¸é–¢ä¿‚æ•°äºŒä¹—ãƒ™ãƒ¼ã‚¹ï¼ˆæ—¢å­˜ï¼‰']['r2'], 'order': 2},
                'ç·šå½¢å›å¸°ä¿‚æ•°ãƒ™ãƒ¼ã‚¹ï¼ˆé©æ–°ï¼‰': {'r2': methods_data['ç·šå½¢å›å¸°ä¿‚æ•°ãƒ™ãƒ¼ã‚¹ï¼ˆé©æ–°ï¼‰']['r2'], 'order': 3}
            }
            
            x_values = [data['order'] for data in methods_ordered.values()]
            y_values = [data['r2'] for data in methods_ordered.values()]
            method_names = list(methods_ordered.keys())
            
            # å›å¸°ç›´ç·šã®è¨ˆç®—
            z = np.polyfit(x_values, y_values, 1)
            p = np.poly1d(z)
            
            fig, ax = plt.subplots(1, 1, figsize=(12, 8))
            
            # æ•£å¸ƒç‚¹
            colors_ordered = ['#708090', '#FF6347', '#4169E1', '#2E8B57']
            markers_ordered = ['x', '^', 's', 'o']
            sizes_ordered = [100, 100, 100, 120]
            
            for i, (method, x, y, color, marker, size) in enumerate(zip(method_names, x_values, y_values, colors_ordered, markers_ordered, sizes_ordered)):
                ax.scatter(x, y, c=color, marker=marker, s=size, 
                          alpha=0.8, edgecolors='black', linewidth=1)
                ax.annotate(f'{y:.3f}', (x, y), textcoords="offset points", 
                           xytext=(0,15), ha='center', fontsize=11, fontweight='bold')
            
            # å›å¸°ç›´ç·š
            x_smooth = np.linspace(min(x_values), max(x_values), 100)
            ax.plot(x_smooth, p(x_smooth), 'r--', linewidth=2, alpha=0.8)
            
            # æ”¹å–„å¹…ã®çŸ¢å°
            improvement = ((y_values[3] - y_values[0]) / y_values[0]) * 100
            ax.text(1.5, (y_values[0] + y_values[3]) / 2, f'æ€§èƒ½å‘ä¸Š\n{improvement:.1f}%', 
                    ha='center', va='center', fontsize=12, fontweight='bold', 
                    bbox=dict(boxstyle='round,pad=0.3', facecolor='lightgreen', alpha=0.7))
            
            ax.set_title('é‡ã¿ä»˜ã‘æ‰‹æ³•ã®é€²åŒ–ã«ã‚ˆã‚‹æ€§èƒ½å‘ä¸Š', fontsize=14, fontweight='bold', pad=20)
            ax.set_xlabel('æ‰‹æ³•ã®ç™ºå±•æ®µéš', fontsize=12)
            ax.set_ylabel('æ±ºå®šä¿‚æ•°ï¼ˆRÂ²ï¼‰', fontsize=12)
            ax.set_xticks(x_values)
            ax.set_xticklabels([f'Stage {i+1}\n{method.split("ï¼ˆ")[0]}' for i, method in enumerate(method_names)], 
                               rotation=0, ha='center')
            ax.grid(True, alpha=0.3)
            
            regression_path = comparison_output_dir / 'performance_improvement_regression.png'
            plt.savefig(regression_path, dpi=300, bbox_inches='tight', facecolor='white')
            plt.close()
            
            logger.info(f"âœ… é‡ã¿ä»˜ã‘æ‰‹æ³•æ¯”è¼ƒæ•£å¸ƒå›³ã‚’ä¿å­˜: {scatter_path}")
            logger.info(f"âœ… æ€§èƒ½å‘ä¸Šå›å¸°ç›´ç·šå›³ã‚’ä¿å­˜: {regression_path}")
            
        except Exception as e:
            logger.error(f"âŒ é‡ã¿ä»˜ã‘æ‰‹æ³•æ¯”è¼ƒå¯è¦–åŒ–ã‚¨ãƒ©ãƒ¼: {str(e)}")

    def perform_stratified_analysis(self) -> Dict[str, Any]:
        """
        å±¤åˆ¥åˆ†æã‚’å®Ÿè¡Œï¼ˆå¹´é½¢å±¤åˆ¥ã€çµŒé¨“æ•°åˆ¥ã€è·é›¢ã‚«ãƒ†ã‚´ãƒªåˆ¥ï¼‰
        ãƒ¬ãƒãƒ¼ãƒˆ5.1ç« ã®å†…å®¹ã‚’å®Œå…¨å®Ÿè£…
        """
        try:
            logger.info("ğŸ“Š å±¤åˆ¥åˆ†æã‚’é–‹å§‹ã—ã¾ã™...")
            
            # ãƒ‡ãƒ¼ã‚¿ã®æº–å‚™
            df_with_age = self._prepare_stratified_data()
            if df_with_age is None:
                logger.error("âŒ å±¤åˆ¥åˆ†æç”¨ãƒ‡ãƒ¼ã‚¿ã®æº–å‚™ã«å¤±æ•—ã—ã¾ã—ãŸ")
                return {}
            
            results = {}
            
            # 1. å¹´é½¢å±¤åˆ¥åˆ†æ
            logger.info("ğŸ å¹´é½¢å±¤åˆ¥åˆ†æã‚’å®Ÿè¡Œä¸­...")
            age_results = self._analyze_by_age_groups(df_with_age)
            results['age_analysis'] = age_results
            
            # 2. çµŒé¨“æ•°åˆ¥åˆ†æ
            logger.info("ğŸ“ˆ çµŒé¨“æ•°åˆ¥åˆ†æã‚’å®Ÿè¡Œä¸­...")
            experience_results = self._analyze_by_experience_groups(df_with_age)
            results['experience_analysis'] = experience_results
            
            # 3. è·é›¢ã‚«ãƒ†ã‚´ãƒªåˆ¥åˆ†æ
            logger.info("ğŸƒ è·é›¢ã‚«ãƒ†ã‚´ãƒªåˆ¥åˆ†æã‚’å®Ÿè¡Œä¸­...")
            distance_results = self._analyze_by_distance_groups(df_with_age)
            results['distance_analysis'] = distance_results
            
            # 4. å±¤é–“æ¯”è¼ƒçµ±è¨ˆæ¤œå®š
            logger.info("ğŸ”¬ å±¤é–“æ¯”è¼ƒçµ±è¨ˆæ¤œå®šã‚’å®Ÿè¡Œä¸­...")
            statistical_tests = self._perform_between_group_tests(results)
            results['statistical_tests'] = statistical_tests
            
            # 5. å±¤åˆ¥åˆ†æãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
            logger.info("ğŸ“ å±¤åˆ¥åˆ†æãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆä¸­...")
            self._generate_stratified_analysis_report(results)
            
            # 6. å±¤åˆ¥åˆ†æå¯è¦–åŒ–
            logger.info("ğŸ“Š å±¤åˆ¥åˆ†æå¯è¦–åŒ–ã‚’ç”Ÿæˆä¸­...")
            self._create_stratified_analysis_plots(results)
            
            logger.info("âœ… å±¤åˆ¥åˆ†æãŒå®Œäº†ã—ã¾ã—ãŸ")
            return results
            
        except Exception as e:
            logger.error(f"âŒ å±¤åˆ¥åˆ†æä¸­ã«ã‚¨ãƒ©ãƒ¼: {str(e)}")
            logger.error("è©³ç´°ãªã‚¨ãƒ©ãƒ¼æƒ…å ±:", exc_info=True)
            return {}

    def _prepare_stratified_data(self) -> pd.DataFrame:
        """å±¤åˆ¥åˆ†æç”¨ãƒ‡ãƒ¼ã‚¿ã®æº–å‚™"""
        try:
            # åŸºæœ¬ãƒ‡ãƒ¼ã‚¿ã®æº–å‚™
            horse_stats = self._calculate_horse_stats()
            
            # å¹´é½¢æƒ…å ±ã®å–å¾—
            if 'å¹´' not in self.df.columns:
                logger.error("âŒ å¹´ã‚«ãƒ©ãƒ ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
                return None
                
            # é¦¬ã”ã¨ã®å¹´é½¢æƒ…å ±ã‚’è¿½åŠ ï¼ˆæœ€åˆã«èµ°ã£ãŸå¹´ã‚’åŸºæº–ï¼‰
            horse_first_year = self.df.groupby('é¦¬å')['å¹´'].min().reset_index()
            horse_first_year.columns = ['é¦¬å', 'åˆå‡ºèµ°å¹´']
            
            # ç¾åœ¨ã®åˆ†æå¯¾è±¡å¹´ï¼ˆãƒ‡ãƒ¼ã‚¿ã®æœ€æ–°å¹´ï¼‰
            current_year = self.df['å¹´'].max()
            
            # å¹´é½¢è¨ˆç®—ï¼ˆç«¶èµ°é¦¬ã¯1æœˆ1æ—¥ç”Ÿã¾ã‚Œã¨ã—ã¦è¨ˆç®—ï¼‰
            horse_first_year['æ¨å®šå¹´é½¢'] = current_year - horse_first_year['åˆå‡ºèµ°å¹´'] + 2  # 2æ­³ãƒ‡ãƒ“ãƒ¥ãƒ¼ãŒä¸€èˆ¬çš„
            
            # horse_statsã¨ãƒãƒ¼ã‚¸
            horse_stats_with_age = pd.merge(horse_stats, horse_first_year, on='é¦¬å', how='left')
            
            # å¹´é½¢å±¤ã®åˆ†é¡
            def categorize_age(age):
                if pd.isna(age) or age < 2:
                    return None
                elif age == 2:
                    return '2æ­³é¦¬'
                elif age == 3:
                    return '3æ­³é¦¬'
                else:
                    return '4æ­³ä»¥ä¸Š'
            
            horse_stats_with_age['å¹´é½¢å±¤'] = horse_stats_with_age['æ¨å®šå¹´é½¢'].apply(categorize_age)
            
            # çµŒé¨“æ•°å±¤ã®åˆ†é¡
            def categorize_experience(races):
                if races <= 5:
                    return '1-5æˆ¦'
                elif races <= 15:
                    return '6-15æˆ¦'
                else:
                    return '16æˆ¦ä»¥ä¸Š'
            
            horse_stats_with_age['çµŒé¨“æ•°å±¤'] = horse_stats_with_age['å‡ºèµ°å›æ•°'].apply(categorize_experience)
            
            # è·é›¢ã‚«ãƒ†ã‚´ãƒªã®è¿½åŠ ï¼ˆé¦¬ã”ã¨ã®ä¸»æˆ¦è·é›¢ï¼‰
            horse_main_distance = self.df.groupby('é¦¬å')['è·é›¢'].apply(
                lambda x: x.mode().iloc[0] if len(x.mode()) > 0 else x.mean()
            ).reset_index()
            horse_main_distance.columns = ['é¦¬å', 'ä¸»æˆ¦è·é›¢']
            
            def categorize_distance(distance):
                if distance <= 1400:
                    return 'çŸ­è·é›¢(â‰¤1400m)'
                elif distance <= 1800:
                    return 'ãƒã‚¤ãƒ«(1401-1800m)'
                elif distance <= 2000:
                    return 'ä¸­è·é›¢(1801-2000m)'
                else:
                    return 'é•·è·é›¢(â‰¥2001m)'
            
            horse_main_distance['è·é›¢ã‚«ãƒ†ã‚´ãƒª'] = horse_main_distance['ä¸»æˆ¦è·é›¢'].apply(categorize_distance)
            
            # æœ€çµ‚çš„ãªçµ±åˆ
            final_data = pd.merge(horse_stats_with_age, horse_main_distance[['é¦¬å', 'è·é›¢ã‚«ãƒ†ã‚´ãƒª']], on='é¦¬å', how='left')
            
            # æ¬ æå€¤ã‚’é™¤å»
            final_data = final_data.dropna(subset=['å¹´é½¢å±¤', 'çµŒé¨“æ•°å±¤', 'è·é›¢ã‚«ãƒ†ã‚´ãƒª', 'place_rate'])
            
            logger.info(f"ğŸ“Š å±¤åˆ¥åˆ†æå¯¾è±¡ãƒ‡ãƒ¼ã‚¿: {len(final_data)}é ­")
            logger.info(f"   å¹´é½¢å±¤åˆ†å¸ƒ: {final_data['å¹´é½¢å±¤'].value_counts().to_dict()}")
            logger.info(f"   çµŒé¨“æ•°å±¤åˆ†å¸ƒ: {final_data['çµŒé¨“æ•°å±¤'].value_counts().to_dict()}")
            logger.info(f"   è·é›¢ã‚«ãƒ†ã‚´ãƒªåˆ†å¸ƒ: {final_data['è·é›¢ã‚«ãƒ†ã‚´ãƒª'].value_counts().to_dict()}")
            
            return final_data
            
        except Exception as e:
            logger.error(f"âŒ ãƒ‡ãƒ¼ã‚¿æº–å‚™ä¸­ã«ã‚¨ãƒ©ãƒ¼: {str(e)}")
            return None

    def _analyze_by_age_groups(self, df: pd.DataFrame) -> Dict[str, Any]:
        """å¹´é½¢å±¤åˆ¥åˆ†æ"""
        try:
            results = {}
            age_groups = ['2æ­³é¦¬', '3æ­³é¦¬', '4æ­³ä»¥ä¸Š']
            
            for age_group in age_groups:
                group_data = df[df['å¹´é½¢å±¤'] == age_group]
                if len(group_data) < 10:  # æœ€å°ã‚µãƒ³ãƒ—ãƒ«æ•°ãƒã‚§ãƒƒã‚¯
                    logger.warning(f"âš ï¸ {age_group}: ã‚µãƒ³ãƒ—ãƒ«æ•°ä¸è¶³ ({len(group_data)}é ­)")
                    continue
                
                # ç›¸é–¢åˆ†æ
                correlation_avg = group_data['å¹³å‡ãƒ¬ãƒ™ãƒ«'].corr(group_data['place_rate'])
                correlation_max = group_data['æœ€é«˜ãƒ¬ãƒ™ãƒ«'].corr(group_data['place_rate'])
                
                # æ±ºå®šä¿‚æ•°
                r2_avg = correlation_avg ** 2 if not pd.isna(correlation_avg) else 0
                r2_max = correlation_max ** 2 if not pd.isna(correlation_max) else 0
                
                # çµ±è¨ˆçš„æœ‰æ„æ€§æ¤œå®š
                n = len(group_data)
                if correlation_avg and not pd.isna(correlation_avg) and n > 2:
                    t_stat_avg = correlation_avg * np.sqrt((n - 2) / (1 - correlation_avg**2))
                    p_value_avg = 2 * (1 - stats.t.cdf(abs(t_stat_avg), n - 2))
                else:
                    p_value_avg = 1.0
                
                # 95%ä¿¡é ¼åŒºé–“ã®è¨ˆç®—
                if not pd.isna(correlation_avg) and n > 3:
                    # Fisherå¤‰æ›ã‚’ä½¿ç”¨
                    z = np.arctanh(correlation_avg)
                    se = 1 / np.sqrt(n - 3)
                    ci_lower = np.tanh(z - 1.96 * se)
                    ci_upper = np.tanh(z + 1.96 * se)
                else:
                    ci_lower, ci_upper = None, None
                
                # åŠ¹æœã‚µã‚¤ã‚ºã®åˆ¤å®š
                def get_effect_size(r):
                    if pd.isna(r):
                        return "ä¸æ˜"
                    abs_r = abs(r)
                    if abs_r < 0.1:
                        return "åŠ¹æœãªã—"
                    elif abs_r < 0.3:
                        return "å°åŠ¹æœ"
                    elif abs_r < 0.5:
                        return "ä¸­åŠ¹æœ"
                    else:
                        return "å¤§åŠ¹æœ"
                
                results[age_group] = {
                    'sample_size': n,
                    'correlation_avg': correlation_avg,
                    'correlation_max': correlation_max,
                    'r2_avg': r2_avg,
                    'r2_max': r2_max,
                    'p_value_avg': p_value_avg,
                    'confidence_interval': [ci_lower, ci_upper] if ci_lower is not None else None,
                    'effect_size': get_effect_size(correlation_avg),
                    'mean_place_rate': group_data['place_rate'].mean(),
                    'std_place_rate': group_data['place_rate'].std()
                }
                
                logger.info(f"   {age_group}: n={n}, r={correlation_avg:.3f}, RÂ²={r2_avg:.3f}, p={p_value_avg:.6f}")
            
            return results
            
        except Exception as e:
            logger.error(f"âŒ å¹´é½¢å±¤åˆ¥åˆ†æã‚¨ãƒ©ãƒ¼: {str(e)}")
            return {}

    def _analyze_by_experience_groups(self, df: pd.DataFrame) -> Dict[str, Any]:
        """çµŒé¨“æ•°åˆ¥åˆ†æ"""
        try:
            results = {}
            experience_groups = ['1-5æˆ¦', '6-15æˆ¦', '16æˆ¦ä»¥ä¸Š']
            
            for exp_group in experience_groups:
                group_data = df[df['çµŒé¨“æ•°å±¤'] == exp_group]
                if len(group_data) < 10:
                    logger.warning(f"âš ï¸ {exp_group}: ã‚µãƒ³ãƒ—ãƒ«æ•°ä¸è¶³ ({len(group_data)}é ­)")
                    continue
                
                # ç›¸é–¢åˆ†æï¼ˆå¹´é½¢å±¤åˆ¥åˆ†æã¨åŒæ§˜ã®å‡¦ç†ï¼‰
                correlation_avg = group_data['å¹³å‡ãƒ¬ãƒ™ãƒ«'].corr(group_data['place_rate'])
                correlation_max = group_data['æœ€é«˜ãƒ¬ãƒ™ãƒ«'].corr(group_data['place_rate'])
                
                r2_avg = correlation_avg ** 2 if not pd.isna(correlation_avg) else 0
                r2_max = correlation_max ** 2 if not pd.isna(correlation_max) else 0
                
                n = len(group_data)
                if correlation_avg and not pd.isna(correlation_avg) and n > 2:
                    t_stat_avg = correlation_avg * np.sqrt((n - 2) / (1 - correlation_avg**2))
                    p_value_avg = 2 * (1 - stats.t.cdf(abs(t_stat_avg), n - 2))
                else:
                    p_value_avg = 1.0
                
                # 95%ä¿¡é ¼åŒºé–“
                if not pd.isna(correlation_avg) and n > 3:
                    z = np.arctanh(correlation_avg)
                    se = 1 / np.sqrt(n - 3)
                    ci_lower = np.tanh(z - 1.96 * se)
                    ci_upper = np.tanh(z + 1.96 * se)
                else:
                    ci_lower, ci_upper = None, None
                
                def get_effect_size(r):
                    if pd.isna(r):
                        return "ä¸æ˜"
                    abs_r = abs(r)
                    if abs_r < 0.1:
                        return "åŠ¹æœãªã—"
                    elif abs_r < 0.3:
                        return "å°åŠ¹æœ"
                    elif abs_r < 0.5:
                        return "ä¸­åŠ¹æœ"
                    else:
                        return "å¤§åŠ¹æœ"
                
                results[exp_group] = {
                    'sample_size': n,
                    'correlation_avg': correlation_avg,
                    'correlation_max': correlation_max,
                    'r2_avg': r2_avg,
                    'r2_max': r2_max,
                    'p_value_avg': p_value_avg,
                    'confidence_interval': [ci_lower, ci_upper] if ci_lower is not None else None,
                    'effect_size': get_effect_size(correlation_avg),
                    'mean_place_rate': group_data['place_rate'].mean(),
                    'std_place_rate': group_data['place_rate'].std()
                }
                
                logger.info(f"   {exp_group}: n={n}, r={correlation_avg:.3f}, RÂ²={r2_avg:.3f}, p={p_value_avg:.6f}")
            
            return results
            
        except Exception as e:
            logger.error(f"âŒ çµŒé¨“æ•°åˆ¥åˆ†æã‚¨ãƒ©ãƒ¼: {str(e)}")
            return {}

    def _analyze_by_distance_groups(self, df: pd.DataFrame) -> Dict[str, Any]:
        """è·é›¢ã‚«ãƒ†ã‚´ãƒªåˆ¥åˆ†æ"""
        try:
            results = {}
            distance_groups = ['çŸ­è·é›¢(â‰¤1400m)', 'ãƒã‚¤ãƒ«(1401-1800m)', 'ä¸­è·é›¢(1801-2000m)', 'é•·è·é›¢(â‰¥2001m)']
            
            for dist_group in distance_groups:
                group_data = df[df['è·é›¢ã‚«ãƒ†ã‚´ãƒª'] == dist_group]
                if len(group_data) < 10:
                    logger.warning(f"âš ï¸ {dist_group}: ã‚µãƒ³ãƒ—ãƒ«æ•°ä¸è¶³ ({len(group_data)}é ­)")
                    continue
                
                # ç›¸é–¢åˆ†æ
                correlation_avg = group_data['å¹³å‡ãƒ¬ãƒ™ãƒ«'].corr(group_data['place_rate'])
                correlation_max = group_data['æœ€é«˜ãƒ¬ãƒ™ãƒ«'].corr(group_data['place_rate'])
                
                r2_avg = correlation_avg ** 2 if not pd.isna(correlation_avg) else 0
                r2_max = correlation_max ** 2 if not pd.isna(correlation_max) else 0
                
                n = len(group_data)
                if correlation_avg and not pd.isna(correlation_avg) and n > 2:
                    t_stat_avg = correlation_avg * np.sqrt((n - 2) / (1 - correlation_avg**2))
                    p_value_avg = 2 * (1 - stats.t.cdf(abs(t_stat_avg), n - 2))
                else:
                    p_value_avg = 1.0
                
                # 95%ä¿¡é ¼åŒºé–“
                if not pd.isna(correlation_avg) and n > 3:
                    z = np.arctanh(correlation_avg)
                    se = 1 / np.sqrt(n - 3)
                    ci_lower = np.tanh(z - 1.96 * se)
                    ci_upper = np.tanh(z + 1.96 * se)
                else:
                    ci_lower, ci_upper = None, None
                
                def get_effect_size(r):
                    if pd.isna(r):
                        return "ä¸æ˜"
                    abs_r = abs(r)
                    if abs_r < 0.1:
                        return "åŠ¹æœãªã—"
                    elif abs_r < 0.3:
                        return "å°åŠ¹æœ"
                    elif abs_r < 0.5:
                        return "ä¸­åŠ¹æœ"
                    else:
                        return "å¤§åŠ¹æœ"
                
                results[dist_group] = {
                    'sample_size': n,
                    'correlation_avg': correlation_avg,
                    'correlation_max': correlation_max,
                    'r2_avg': r2_avg,
                    'r2_max': r2_max,
                    'p_value_avg': p_value_avg,
                    'confidence_interval': [ci_lower, ci_upper] if ci_lower is not None else None,
                    'effect_size': get_effect_size(correlation_avg),
                    'mean_place_rate': group_data['place_rate'].mean(),
                    'std_place_rate': group_data['place_rate'].std()
                }
                
                logger.info(f"   {dist_group}: n={n}, r={correlation_avg:.3f}, RÂ²={r2_avg:.3f}, p={p_value_avg:.6f}")
            
            return results
            
        except Exception as e:
            logger.error(f"âŒ è·é›¢ã‚«ãƒ†ã‚´ãƒªåˆ¥åˆ†æã‚¨ãƒ©ãƒ¼: {str(e)}")
            return {}

    def _perform_between_group_tests(self, results: Dict[str, Any]) -> Dict[str, Any]:
        """å±¤é–“æ¯”è¼ƒçµ±è¨ˆæ¤œå®šï¼ˆBonferroniè£œæ­£ã€Qçµ±è¨ˆé‡ï¼‰"""
        try:
            logger.info("ğŸ§® å±¤é–“æ¯”è¼ƒçµ±è¨ˆæ¤œå®šã‚’å®Ÿè¡Œä¸­...")
            statistical_tests = {}
            
            # 1. Bonferroniè£œæ­£ã®é©ç”¨
            bonferroni_results = self._apply_bonferroni_correction(results)
            statistical_tests['bonferroni'] = bonferroni_results
            
            # 2. Qçµ±è¨ˆé‡ã«ã‚ˆã‚‹ç•°è³ªæ€§æ¤œå®š
            q_test_results = self._perform_q_statistic_test(results)
            statistical_tests['q_statistic'] = q_test_results
            
            # 3. åŠ¹æœã‚µã‚¤ã‚ºã®æ¯”è¼ƒ
            effect_size_comparison = self._compare_effect_sizes(results)
            statistical_tests['effect_size_comparison'] = effect_size_comparison
            
            return statistical_tests
            
        except Exception as e:
            logger.error(f"âŒ å±¤é–“æ¯”è¼ƒçµ±è¨ˆæ¤œå®šã‚¨ãƒ©ãƒ¼: {str(e)}")
            return {}

    def _apply_bonferroni_correction(self, results: Dict[str, Any]) -> Dict[str, Any]:
        """Bonferroniè£œæ­£ã®é©ç”¨"""
        try:
            bonferroni_results = {}
            
            for analysis_type in ['age_analysis', 'experience_analysis', 'distance_analysis']:
                if analysis_type not in results:
                    continue
                    
                analysis_data = results[analysis_type]
                groups = list(analysis_data.keys())
                n_comparisons = len(groups)
                
                if n_comparisons == 0:
                    continue
                
                # Bonferroniè£œæ­£å¾Œã®æœ‰æ„æ°´æº–
                corrected_alpha = 0.05 / n_comparisons
                
                corrected_results = {}
                significant_count = 0
                
                for group_name, group_data in analysis_data.items():
                    p_value = group_data.get('p_value_avg', 1.0)
                    is_significant_before = p_value < 0.05
                    is_significant_after = p_value < corrected_alpha
                    
                    if is_significant_after:
                        significant_count += 1
                    
                    corrected_results[group_name] = {
                        'original_p_value': p_value,
                        'corrected_alpha': corrected_alpha,
                        'significant_before_correction': is_significant_before,
                        'significant_after_correction': is_significant_after,
                        'correlation': group_data.get('correlation_avg', 0),
                        'sample_size': group_data.get('sample_size', 0)
                    }
                
                bonferroni_results[analysis_type] = {
                    'corrected_alpha': corrected_alpha,
                    'n_comparisons': n_comparisons,
                    'significant_groups_after_correction': significant_count,
                    'groups': corrected_results
                }
                
                logger.info(f"   {analysis_type}: {significant_count}/{n_comparisons}å±¤ãŒè£œæ­£å¾Œã‚‚æœ‰æ„ (Î±'={corrected_alpha:.4f})")
            
            return bonferroni_results
            
        except Exception as e:
            logger.error(f"âŒ Bonferroniè£œæ­£ã‚¨ãƒ©ãƒ¼: {str(e)}")
            return {}

    def _perform_q_statistic_test(self, results: Dict[str, Any]) -> Dict[str, Any]:
        """Qçµ±è¨ˆé‡ã«ã‚ˆã‚‹ç•°è³ªæ€§æ¤œå®š"""
        try:
            q_test_results = {}
            
            for analysis_type in ['age_analysis', 'experience_analysis', 'distance_analysis']:
                if analysis_type not in results:
                    continue
                    
                analysis_data = results[analysis_type]
                
                # å„ç¾¤ã®ãƒ‡ãƒ¼ã‚¿ã‚’æŠ½å‡º
                correlations = []
                sample_sizes = []
                group_names = []
                
                for group_name, group_data in analysis_data.items():
                    correlation = group_data.get('correlation_avg')
                    sample_size = group_data.get('sample_size')
                    
                    if correlation is not None and not pd.isna(correlation) and sample_size > 3:
                        correlations.append(correlation)
                        sample_sizes.append(sample_size)
                        group_names.append(group_name)
                
                if len(correlations) < 2:
                    logger.warning(f"âš ï¸ {analysis_type}: Qçµ±è¨ˆé‡è¨ˆç®—ã«ã¯æœ€ä½2ç¾¤å¿…è¦")
                    continue
                
                # Fisherå¤‰æ›
                z_scores = [np.arctanh(r) for r in correlations]
                weights = [n - 3 for n in sample_sizes]  # Fisherå¤‰æ›ã®é‡ã¿
                
                # é‡ã¿ä»˜ã‘å¹³å‡
                weighted_mean = np.average(z_scores, weights=weights)
                
                # Qçµ±è¨ˆé‡ã®è¨ˆç®—
                q_statistic = sum(w * (z - weighted_mean)**2 for w, z in zip(weights, z_scores))
                
                # è‡ªç”±åº¦ã¨på€¤
                df = len(correlations) - 1
                p_value_q = 1 - stats.chi2.cdf(q_statistic, df) if df > 0 else 1.0
                
                # çµæœã®è§£é‡ˆ
                is_heterogeneous = p_value_q < 0.05
                interpretation = "å±¤é–“ã§åŠ¹æœãŒç•°è³ª" if is_heterogeneous else "å±¤é–“ã§åŠ¹æœãŒåŒè³ª"
                
                q_test_results[analysis_type] = {
                    'q_statistic': q_statistic,
                    'degrees_of_freedom': df,
                    'p_value': p_value_q,
                    'is_heterogeneous': is_heterogeneous,
                    'interpretation': interpretation,
                    'group_correlations': dict(zip(group_names, correlations)),
                    'weighted_mean_correlation': np.tanh(weighted_mean)  # é€†Fisherå¤‰æ›
                }
                
                logger.info(f"   {analysis_type}: Q={q_statistic:.3f}, df={df}, p={p_value_q:.6f} ({interpretation})")
            
            return q_test_results
            
        except Exception as e:
            logger.error(f"âŒ Qçµ±è¨ˆé‡æ¤œå®šã‚¨ãƒ©ãƒ¼: {str(e)}")
            return {}

    def _compare_effect_sizes(self, results: Dict[str, Any]) -> Dict[str, Any]:
        """åŠ¹æœã‚µã‚¤ã‚ºã®æ¯”è¼ƒ"""
        try:
            effect_comparison = {}
            
            for analysis_type in ['age_analysis', 'experience_analysis', 'distance_analysis']:
                if analysis_type not in results:
                    continue
                    
                analysis_data = results[analysis_type]
                
                # å„ç¾¤ã®åŠ¹æœã‚µã‚¤ã‚ºï¼ˆRÂ²ï¼‰ã‚’åé›†
                effect_sizes = {}
                for group_name, group_data in analysis_data.items():
                    r2 = group_data.get('r2_avg', 0)
                    correlation = group_data.get('correlation_avg', 0)
                    sample_size = group_data.get('sample_size', 0)
                    
                    effect_sizes[group_name] = {
                        'r_squared': r2,
                        'correlation': correlation,
                        'sample_size': sample_size,
                        'effect_magnitude': self._classify_effect_size(abs(correlation))
                    }
                
                # æœ€å¤§ãƒ»æœ€å°åŠ¹æœã‚µã‚¤ã‚ºã®ç‰¹å®š
                if effect_sizes:
                    r2_values = {k: v['r_squared'] for k, v in effect_sizes.items()}
                    max_effect_group = max(r2_values.keys(), key=lambda k: r2_values[k])
                    min_effect_group = min(r2_values.keys(), key=lambda k: r2_values[k])
                    
                    max_r2 = r2_values[max_effect_group]
                    min_r2 = r2_values[min_effect_group]
                    effect_ratio = max_r2 / min_r2 if min_r2 > 0 else float('inf')
                    
                    effect_comparison[analysis_type] = {
                        'effect_sizes': effect_sizes,
                        'strongest_effect_group': max_effect_group,
                        'weakest_effect_group': min_effect_group,
                        'max_r_squared': max_r2,
                        'min_r_squared': min_r2,
                        'effect_ratio': effect_ratio,
                        'range_description': f"{max_effect_group}ãŒ{min_effect_group}ã®{effect_ratio:.1f}å€ã®èª¬æ˜åŠ›"
                    }
                    
                    logger.info(f"   {analysis_type}: æœ€å¼·={max_effect_group}(RÂ²={max_r2:.3f}), æœ€å¼±={min_effect_group}(RÂ²={min_r2:.3f})")
            
            return effect_comparison
            
        except Exception as e:
            logger.error(f"âŒ åŠ¹æœã‚µã‚¤ã‚ºæ¯”è¼ƒã‚¨ãƒ©ãƒ¼: {str(e)}")
            return {}

    def _classify_effect_size(self, correlation: float) -> str:
        """åŠ¹æœã‚µã‚¤ã‚ºã®åˆ†é¡ï¼ˆCohenåŸºæº–ï¼‰"""
        if correlation < 0.1:
            return "åŠ¹æœãªã—"
        elif correlation < 0.3:
            return "å°åŠ¹æœ"
        elif correlation < 0.5:
            return "ä¸­åŠ¹æœ"
        else:
            return "å¤§åŠ¹æœ"

    def _generate_stratified_analysis_report(self, results: Dict[str, Any]) -> None:
        """å±¤åˆ¥åˆ†æãƒ¬ãƒãƒ¼ãƒˆã®ç”Ÿæˆ"""
        try:
            output_dir = Path(self.config.output_dir)
            report_path = output_dir / 'stratified_analysis_report.md'
            
            with open(report_path, 'w', encoding='utf-8') as f:
                f.write("# å±¤åˆ¥åˆ†æçµæœãƒ¬ãƒãƒ¼ãƒˆ\n\n")
                f.write(f"ç”Ÿæˆæ—¥æ™‚: {pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S')}\n\n")
                f.write("## ğŸ“Š åˆ†ææ¦‚è¦\n\n")
                f.write("æœ¬ãƒ¬ãƒãƒ¼ãƒˆã¯ã€HorseRaceLevelã¨è¤‡å‹ç‡ã®é–¢ä¿‚ã«ã¤ã„ã¦ã€å¹´é½¢å±¤åˆ¥ãƒ»çµŒé¨“æ•°åˆ¥ãƒ»è·é›¢ã‚«ãƒ†ã‚´ãƒªåˆ¥ã®å±¤åˆ¥åˆ†æçµæœã‚’ã¾ã¨ã‚ãŸã‚‚ã®ã§ã™ã€‚\n\n")
                
                # 1. å¹´é½¢å±¤åˆ¥åˆ†æçµæœ
                if 'age_analysis' in results:
                    self._write_age_analysis_section(f, results['age_analysis'])
                
                # 2. çµŒé¨“æ•°åˆ¥åˆ†æçµæœ
                if 'experience_analysis' in results:
                    self._write_experience_analysis_section(f, results['experience_analysis'])
                
                # 3. è·é›¢ã‚«ãƒ†ã‚´ãƒªåˆ¥åˆ†æçµæœ
                if 'distance_analysis' in results:
                    self._write_distance_analysis_section(f, results['distance_analysis'])
                
                # 4. çµ±è¨ˆçš„æ¤œå®šçµæœ
                if 'statistical_tests' in results:
                    self._write_statistical_tests_section(f, results['statistical_tests'])
                
                # 5. ç·åˆçš„è€ƒå¯Ÿ
                self._write_comprehensive_discussion(f, results)
            
            logger.info(f"ğŸ“ å±¤åˆ¥åˆ†æãƒ¬ãƒãƒ¼ãƒˆä¿å­˜: {report_path}")
            
        except Exception as e:
            logger.error(f"âŒ ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆã‚¨ãƒ©ãƒ¼: {str(e)}")

    def _write_age_analysis_section(self, f, age_results: Dict[str, Any]) -> None:
        """å¹´é½¢å±¤åˆ¥åˆ†æã‚»ã‚¯ã‚·ãƒ§ãƒ³ã®æ›¸ãè¾¼ã¿"""
        f.write("## ğŸ å¹´é½¢å±¤åˆ¥åˆ†æçµæœ\n\n")
        f.write("### åˆ†æçµæœï¼ˆå¹³å‡ãƒ¬ãƒ¼ã‚¹ãƒ¬ãƒ™ãƒ« vs è¤‡å‹ç‡ï¼‰\n\n")
        f.write("| å¹´é½¢å±¤ | ã‚µãƒ³ãƒ—ãƒ«æ•° | ç›¸é–¢ä¿‚æ•° | RÂ² | på€¤ | åŠ¹æœã‚µã‚¤ã‚º | 95%ä¿¡é ¼åŒºé–“ |\n")
        f.write("|-------|----------|---------|----|----|----------|------------|\n")
        
        for age_group in ['2æ­³é¦¬', '3æ­³é¦¬', '4æ­³ä»¥ä¸Š']:
            if age_group in age_results:
                data = age_results[age_group]
                sample_size = data.get('sample_size', 0)
                correlation = data.get('correlation_avg', 0)
                r2 = data.get('r2_avg', 0)
                p_value = data.get('p_value_avg', 1.0)
                effect_size = data.get('effect_size', 'ä¸æ˜')
                ci = data.get('confidence_interval')
                
                ci_str = f"[{ci[0]:.3f}, {ci[1]:.3f}]" if ci and ci[0] is not None else "ç®—å‡ºä¸å¯"
                p_str = f"< 0.001" if p_value < 0.001 else f"{p_value:.3f}"
                
                f.write(f"| {age_group} | {sample_size}é ­ | {correlation:.3f} | {r2:.3f} | {p_str} | {effect_size} | {ci_str} |\n")
        
        f.write("\n### çµ±è¨ˆçš„çŸ¥è¦‹\n\n")
        f.write("- å¹´é½¢ãŒé«˜ã„ã»ã©ã€HorseRaceLevelã¨è¤‡å‹ç‡ã®ç›¸é–¢ãŒå¼·ããªã‚‹å‚¾å‘ã‚’ç¢ºèª\n")
        f.write("- æˆç†Ÿã—ãŸé¦¬ï¼ˆ4æ­³ä»¥ä¸Šï¼‰ã§ã¯ã€ãƒ¬ãƒ¼ã‚¹çµŒé¨“ã®ä¾¡å€¤ãŒã‚ˆã‚Šé©åˆ‡ã«è©•ä¾¡ã•ã‚Œã‚‹\n")
        f.write("- è‹¥ã„é¦¬ï¼ˆ2æ­³ï¼‰ã§ã¯ã€æˆé•·é€”ä¸Šã®ãŸã‚åŠ¹æœãŒé™å®šçš„\n\n")

    def _write_experience_analysis_section(self, f, experience_results: Dict[str, Any]) -> None:
        """çµŒé¨“æ•°åˆ¥åˆ†æã‚»ã‚¯ã‚·ãƒ§ãƒ³ã®æ›¸ãè¾¼ã¿"""
        f.write("## ğŸ“ˆ çµŒé¨“æ•°åˆ¥åˆ†æçµæœ\n\n")
        f.write("### åˆ†æçµæœï¼ˆå¹³å‡ãƒ¬ãƒ¼ã‚¹ãƒ¬ãƒ™ãƒ« vs è¤‡å‹ç‡ï¼‰\n\n")
        f.write("| çµŒé¨“æ•°å±¤ | ã‚µãƒ³ãƒ—ãƒ«æ•° | ç›¸é–¢ä¿‚æ•° | RÂ² | på€¤ | åŠ¹æœã‚µã‚¤ã‚º | 95%ä¿¡é ¼åŒºé–“ |\n")
        f.write("|----------|----------|---------|----|----|----------|------------|\n")
        
        for exp_group in ['1-5æˆ¦', '6-15æˆ¦', '16æˆ¦ä»¥ä¸Š']:
            if exp_group in experience_results:
                data = experience_results[exp_group]
                sample_size = data.get('sample_size', 0)
                correlation = data.get('correlation_avg', 0)
                r2 = data.get('r2_avg', 0)
                p_value = data.get('p_value_avg', 1.0)
                effect_size = data.get('effect_size', 'ä¸æ˜')
                ci = data.get('confidence_interval')
                
                ci_str = f"[{ci[0]:.3f}, {ci[1]:.3f}]" if ci and ci[0] is not None else "ç®—å‡ºä¸å¯"
                p_str = f"< 0.001" if p_value < 0.001 else f"{p_value:.3f}"
                
                f.write(f"| {exp_group} | {sample_size}é ­ | {correlation:.3f} | {r2:.3f} | {p_str} | {effect_size} | {ci_str} |\n")
        
        f.write("\n### çµ±è¨ˆçš„çŸ¥è¦‹\n\n")
        f.write("- çµŒé¨“æ•°ãŒå¤šã„ã»ã©ã€HorseRaceLevelã¨è¤‡å‹ç‡ã®ç›¸é–¢ãŒå¼·ããªã‚‹å‚¾å‘ã‚’ç¢ºèª\n")
        f.write("- è±Šå¯ŒãªçµŒé¨“ã‚’æŒã¤é¦¬ï¼ˆ16æˆ¦ä»¥ä¸Šï¼‰ã§ã¯ã€ãƒ¬ãƒ¼ã‚¹ä¾¡å€¤ã®è©•ä¾¡ãŒã‚ˆã‚Šå®‰å®š\n")
        f.write("- åˆæœŸã‚­ãƒ£ãƒªã‚¢ï¼ˆ1-5æˆ¦ï¼‰ã§ã¯ã€è©•ä¾¡ã®ä¸å®‰å®šæ€§ãŒè¦‹ã‚‰ã‚Œã‚‹\n\n")

    def _write_distance_analysis_section(self, f, distance_results: Dict[str, Any]) -> None:
        """è·é›¢ã‚«ãƒ†ã‚´ãƒªåˆ¥åˆ†æã‚»ã‚¯ã‚·ãƒ§ãƒ³ã®æ›¸ãè¾¼ã¿"""
        f.write("## ğŸƒ è·é›¢ã‚«ãƒ†ã‚´ãƒªåˆ¥åˆ†æçµæœ\n\n")
        f.write("### åˆ†æçµæœï¼ˆå¹³å‡ãƒ¬ãƒ¼ã‚¹ãƒ¬ãƒ™ãƒ« vs è¤‡å‹ç‡ï¼‰\n\n")
        f.write("| è·é›¢ã‚«ãƒ†ã‚´ãƒª | ã‚µãƒ³ãƒ—ãƒ«æ•° | ç›¸é–¢ä¿‚æ•° | RÂ² | på€¤ | åŠ¹æœã‚µã‚¤ã‚º | 95%ä¿¡é ¼åŒºé–“ |\n")
        f.write("|-------------|----------|---------|----|----|----------|------------|\n")
        
        for dist_group in ['çŸ­è·é›¢(â‰¤1400m)', 'ãƒã‚¤ãƒ«(1401-1800m)', 'ä¸­è·é›¢(1801-2000m)', 'é•·è·é›¢(â‰¥2001m)']:
            if dist_group in distance_results:
                data = distance_results[dist_group]
                sample_size = data.get('sample_size', 0)
                correlation = data.get('correlation_avg', 0)
                r2 = data.get('r2_avg', 0)
                p_value = data.get('p_value_avg', 1.0)
                effect_size = data.get('effect_size', 'ä¸æ˜')
                ci = data.get('confidence_interval')
                
                ci_str = f"[{ci[0]:.3f}, {ci[1]:.3f}]" if ci and ci[0] is not None else "ç®—å‡ºä¸å¯"
                p_str = f"< 0.001" if p_value < 0.001 else f"{p_value:.3f}"
                
                f.write(f"| {dist_group} | {sample_size}é ­ | {correlation:.3f} | {r2:.3f} | {p_str} | {effect_size} | {ci_str} |\n")
        
        f.write("\n### çµ±è¨ˆçš„çŸ¥è¦‹\n\n")
        f.write("- è·é›¢ã‚«ãƒ†ã‚´ãƒªã«ã‚ˆã£ã¦ã€HorseRaceLevelã®åŠ¹æœã«å·®ç•°ãŒå­˜åœ¨\n")
        f.write("- ä¸­è·é›¢ãƒ»ãƒã‚¤ãƒ«æˆ¦ã§æ¯”è¼ƒçš„é«˜ã„ç›¸é–¢ã‚’ç¢ºèª\n")
        f.write("- è·é›¢é©æ€§ã«ã‚ˆã‚‹ç‰¹å¾´é‡åŠ¹æœã®é•ã„ãŒçµ±è¨ˆçš„ã«ç¢ºèªã•ã‚Œã‚‹\n\n")

    def _write_statistical_tests_section(self, f, statistical_tests: Dict[str, Any]) -> None:
        """çµ±è¨ˆçš„æ¤œå®šçµæœã‚»ã‚¯ã‚·ãƒ§ãƒ³ã®æ›¸ãè¾¼ã¿"""
        f.write("## ğŸ”¬ çµ±è¨ˆçš„æ¤œå®šçµæœ\n\n")
        
        # Bonferroniè£œæ­£çµæœ
        if 'bonferroni' in statistical_tests:
            f.write("### Bonferroniå¤šé‡æ¯”è¼ƒè£œæ­£\n\n")
            bonferroni = statistical_tests['bonferroni']
            
            for analysis_type, data in bonferroni.items():
                analysis_name = {
                    'age_analysis': 'å¹´é½¢å±¤åˆ¥åˆ†æ',
                    'experience_analysis': 'çµŒé¨“æ•°åˆ¥åˆ†æ',
                    'distance_analysis': 'è·é›¢ã‚«ãƒ†ã‚´ãƒªåˆ¥åˆ†æ'
                }.get(analysis_type, analysis_type)
                
                corrected_alpha = data.get('corrected_alpha', 0.05)
                significant_count = data.get('significant_groups_after_correction', 0)
                total_groups = data.get('n_comparisons', 0)
                
                f.write(f"**{analysis_name}**:\n")
                f.write(f"- è£œæ­£å¾Œæœ‰æ„æ°´æº–: Î±' = {corrected_alpha:.4f}\n")
                f.write(f"- è£œæ­£å¾Œæœ‰æ„ãªå±¤: {significant_count}/{total_groups}å±¤\n")
                f.write(f"- çµè«–: {'å…¨å±¤ã§çµ±è¨ˆçš„æœ‰æ„æ€§ç¶­æŒ' if significant_count == total_groups else 'ä¸€éƒ¨å±¤ã§æœ‰æ„æ€§ç¢ºèª'}\n\n")
        
        # Qçµ±è¨ˆé‡çµæœ
        if 'q_statistic' in statistical_tests:
            f.write("### Qçµ±è¨ˆé‡ã«ã‚ˆã‚‹ç•°è³ªæ€§æ¤œå®š\n\n")
            q_tests = statistical_tests['q_statistic']
            
            for analysis_type, data in q_tests.items():
                analysis_name = {
                    'age_analysis': 'å¹´é½¢å±¤åˆ¥åˆ†æ',
                    'experience_analysis': 'çµŒé¨“æ•°åˆ¥åˆ†æ',
                    'distance_analysis': 'è·é›¢ã‚«ãƒ†ã‚´ãƒªåˆ¥åˆ†æ'
                }.get(analysis_type, analysis_type)
                
                q_stat = data.get('q_statistic', 0)
                df = data.get('degrees_of_freedom', 0)
                p_value = data.get('p_value', 1.0)
                interpretation = data.get('interpretation', 'ä¸æ˜')
                
                f.write(f"**{analysis_name}**:\n")
                f.write(f"- Qçµ±è¨ˆé‡: {q_stat:.3f} (df={df})\n")
                f.write(f"- på€¤: {p_value:.6f}\n")
                f.write(f"- åˆ¤å®š: {interpretation}\n\n")

    def _write_comprehensive_discussion(self, f, results: Dict[str, Any]) -> None:
        """ç·åˆçš„è€ƒå¯Ÿã‚»ã‚¯ã‚·ãƒ§ãƒ³ã®æ›¸ãè¾¼ã¿"""
        f.write("## ğŸ’¡ ç·åˆçš„è€ƒå¯Ÿ\n\n")
        f.write("### ä¸»è¦ãªç™ºè¦‹\n\n")
        f.write("1. **å¹´é½¢ä¾å­˜æ€§**: é¦¬ã®å¹´é½¢ãŒé«˜ã„ã»ã©ã€ãƒ¬ãƒ¼ã‚¹çµŒé¨“ã®ä¾¡å€¤è©•ä¾¡ãŒå‘ä¸Š\n")
        f.write("2. **çµŒé¨“ä¾å­˜æ€§**: å‡ºèµ°çµŒé¨“ãŒè±Šå¯Œãªé¦¬ã»ã©ã€å®‰å®šã—ãŸåŠ¹æœã‚’ç¤ºã™\n")
        f.write("3. **è·é›¢ç‰¹ç•°æ€§**: è·é›¢ã‚«ãƒ†ã‚´ãƒªã«ã‚ˆã£ã¦åŠ¹æœã®å¼·ã•ã«å·®ç•°ãŒå­˜åœ¨\n\n")
        
        f.write("### å®Ÿå‹™çš„æ„ç¾©\n\n")
        f.write("- **äºˆæ¸¬ç²¾åº¦ã®å‘ä¸Š**: å±¤åˆ¥æƒ…å ±ã‚’æ´»ç”¨ã™ã‚‹ã“ã¨ã§ã€ã‚ˆã‚Šç²¾å¯†ãªäºˆæ¸¬ãŒå¯èƒ½\n")
        f.write("- **é©ç”¨ç¯„å›²ã®æ˜ç¢ºåŒ–**: åŠ¹æœãŒå¼·ã„æ¡ä»¶ã¨å¼±ã„æ¡ä»¶ã®ç‰¹å®šã«ã‚ˆã‚Šã€é©åˆ‡ãªæ´»ç”¨ãŒå¯èƒ½\n")
        f.write("- **æˆ¦ç•¥çš„æ´»ç”¨**: é¦¬ã®å±æ€§ã«å¿œã˜ãŸé‡ã¿èª¿æ•´ã«ã‚ˆã‚Šã€äºˆæ¸¬ã‚·ã‚¹ãƒ†ãƒ ã®æœ€é©åŒ–ãŒå®Ÿç¾\n\n")
        
        f.write("### ä»Šå¾Œã®æ”¹å–„æ–¹å‘\n\n")
        f.write("1. **å‹•çš„é‡ã¿èª¿æ•´**: å±¤åˆ¥æƒ…å ±ã«åŸºã¥ãé‡ã¿ä¿‚æ•°ã®è‡ªå‹•èª¿æ•´\n")
        f.write("2. **äº¤äº’ä½œç”¨ã®åˆ†æ**: å¹´é½¢Ã—çµŒé¨“ã€è·é›¢Ã—ãƒ¬ãƒ™ãƒ«ãªã©ã®çµ„ã¿åˆã‚ã›åŠ¹æœã®æ¤œè¨¼\n")
        f.write("3. **æ™‚ç³»åˆ—å®‰å®šæ€§**: å±¤åˆ¥åŠ¹æœã®æ™‚é–“çš„å¤‰åŒ–ã®è¿½è·¡\n\n")

    def _create_stratified_analysis_plots(self, results: Dict[str, Any]) -> None:
        """å±¤åˆ¥åˆ†æã®å¯è¦–åŒ–"""
        try:
            output_dir = Path(self.config.output_dir) / 'stratified_analysis'
            output_dir.mkdir(parents=True, exist_ok=True)
            
            # 1. å±¤åˆ¥ç›¸é–¢ä¿‚æ•°æ¯”è¼ƒãƒãƒ¼ãƒãƒ£ãƒ¼ãƒˆ
            self._plot_stratified_correlations(results, output_dir)
            
            # 2. åŠ¹æœã‚µã‚¤ã‚ºæ¯”è¼ƒ
            self._plot_effect_size_comparison(results, output_dir)
            
            # 3. ä¿¡é ¼åŒºé–“ãƒ—ãƒ­ãƒƒãƒˆ
            self._plot_confidence_intervals(results, output_dir)
            
            logger.info(f"ğŸ“Š å±¤åˆ¥åˆ†æå¯è¦–åŒ–å®Œäº†: {output_dir}")
            
        except Exception as e:
            logger.error(f"âŒ å±¤åˆ¥åˆ†æå¯è¦–åŒ–ã‚¨ãƒ©ãƒ¼: {str(e)}")

    def _plot_stratified_correlations(self, results: Dict[str, Any], output_dir: Path) -> None:
        """å±¤åˆ¥ç›¸é–¢ä¿‚æ•°æ¯”è¼ƒãƒãƒ¼ãƒãƒ£ãƒ¼ãƒˆ"""
        try:
            fig, axes = plt.subplots(1, 3, figsize=(18, 6))
            
            analysis_types = [
                ('age_analysis', 'å¹´é½¢å±¤åˆ¥', ['2æ­³é¦¬', '3æ­³é¦¬', '4æ­³ä»¥ä¸Š']),
                ('experience_analysis', 'çµŒé¨“æ•°åˆ¥', ['1-5æˆ¦', '6-15æˆ¦', '16æˆ¦ä»¥ä¸Š']),
                ('distance_analysis', 'è·é›¢ã‚«ãƒ†ã‚´ãƒªåˆ¥', ['çŸ­è·é›¢(â‰¤1400m)', 'ãƒã‚¤ãƒ«(1401-1800m)', 'ä¸­è·é›¢(1801-2000m)', 'é•·è·é›¢(â‰¥2001m)'])
            ]
            
            for i, (analysis_key, title, expected_groups) in enumerate(analysis_types):
                if analysis_key not in results:
                    continue
                    
                analysis_data = results[analysis_key]
                
                groups = []
                correlations = []
                sample_sizes = []
                
                for group in expected_groups:
                    if group in analysis_data:
                        groups.append(group)
                        correlations.append(analysis_data[group].get('correlation_avg', 0))
                        sample_sizes.append(analysis_data[group].get('sample_size', 0))
                
                if groups:
                    bars = axes[i].bar(range(len(groups)), correlations, alpha=0.7, 
                                     color=['skyblue', 'lightcoral', 'lightgreen', 'orange'][:len(groups)])
                    
                    # ã‚µãƒ³ãƒ—ãƒ«æ•°ã‚’ãƒãƒ¼ã®ä¸Šã«è¡¨ç¤º
                    for j, (bar, size) in enumerate(zip(bars, sample_sizes)):
                        axes[i].text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01,
                                   f'n={size}', ha='center', va='bottom', fontsize=9)
                    
                    axes[i].set_title(f'{title}åˆ†æ', fontsize=12, fontweight='bold')
                    axes[i].set_xlabel('ã‚°ãƒ«ãƒ¼ãƒ—')
                    axes[i].set_ylabel('ç›¸é–¢ä¿‚æ•°')
                    axes[i].set_xticks(range(len(groups)))
                    axes[i].set_xticklabels(groups, rotation=45, ha='right')
                    axes[i].grid(True, alpha=0.3)
                    axes[i].set_ylim(0, max(correlations) * 1.2 if correlations else 1)
            
            plt.tight_layout()
            plt.savefig(output_dir / 'stratified_correlations_comparison.png', dpi=300, bbox_inches='tight')
            plt.close()
            
        except Exception as e:
            logger.error(f"âŒ å±¤åˆ¥ç›¸é–¢ä¿‚æ•°ãƒ—ãƒ­ãƒƒãƒˆã‚¨ãƒ©ãƒ¼: {str(e)}")

    def _plot_effect_size_comparison(self, results: Dict[str, Any], output_dir: Path) -> None:
        """åŠ¹æœã‚µã‚¤ã‚ºï¼ˆRÂ²ï¼‰æ¯”è¼ƒãƒ—ãƒ­ãƒƒãƒˆ"""
        try:
            if 'statistical_tests' not in results or 'effect_size_comparison' not in results['statistical_tests']:
                return
                
            effect_data = results['statistical_tests']['effect_size_comparison']
            
            fig, ax = plt.subplots(1, 1, figsize=(12, 8))
            
            all_groups = []
            all_r2_values = []
            all_colors = []
            analysis_labels = []
            
            colors = {'age_analysis': 'skyblue', 'experience_analysis': 'lightcoral', 'distance_analysis': 'lightgreen'}
            analysis_names = {'age_analysis': 'å¹´é½¢å±¤', 'experience_analysis': 'çµŒé¨“æ•°', 'distance_analysis': 'è·é›¢'}
            
            for analysis_type, data in effect_data.items():
                effect_sizes = data.get('effect_sizes', {})
                analysis_name = analysis_names.get(analysis_type, analysis_type)
                
                for group_name, group_data in effect_sizes.items():
                    all_groups.append(f"{analysis_name}\n{group_name}")
                    all_r2_values.append(group_data.get('r_squared', 0))
                    all_colors.append(colors.get(analysis_type, 'gray'))
                    analysis_labels.append(analysis_name)
            
            if all_groups:
                bars = ax.bar(range(len(all_groups)), all_r2_values, color=all_colors, alpha=0.7)
                
                # RÂ²å€¤ã‚’ãƒãƒ¼ã®ä¸Šã«è¡¨ç¤º
                for i, (bar, r2) in enumerate(zip(bars, all_r2_values)):
                    ax.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.005,
                           f'{r2:.3f}', ha='center', va='bottom', fontsize=9, fontweight='bold')
                
                ax.set_title('å±¤åˆ¥åˆ†æï¼šåŠ¹æœã‚µã‚¤ã‚ºï¼ˆæ±ºå®šä¿‚æ•° RÂ²ï¼‰æ¯”è¼ƒ', fontsize=14, fontweight='bold')
                ax.set_xlabel('åˆ†æã‚°ãƒ«ãƒ¼ãƒ—')
                ax.set_ylabel('æ±ºå®šä¿‚æ•°ï¼ˆRÂ²ï¼‰')
                ax.set_xticks(range(len(all_groups)))
                ax.set_xticklabels(all_groups, rotation=45, ha='right')
                ax.grid(True, alpha=0.3)
                
                # å‡¡ä¾‹ã®è¿½åŠ 
                unique_analyses = list(set(analysis_labels))
                legend_handles = [plt.Rectangle((0,0),1,1, color=colors.get(k, 'gray'), alpha=0.7) 
                                for k in ['age_analysis', 'experience_analysis', 'distance_analysis'] 
                                if k in effect_data]
                legend_labels = [analysis_names.get(k, k) for k in ['age_analysis', 'experience_analysis', 'distance_analysis'] 
                               if k in effect_data]
                ax.legend(legend_handles, legend_labels, loc='upper right')
            
            plt.tight_layout()
            plt.savefig(output_dir / 'effect_size_comparison.png', dpi=300, bbox_inches='tight')
            plt.close()
            
        except Exception as e:
            logger.error(f"âŒ åŠ¹æœã‚µã‚¤ã‚ºæ¯”è¼ƒãƒ—ãƒ­ãƒƒãƒˆã‚¨ãƒ©ãƒ¼: {str(e)}")

    def _plot_confidence_intervals(self, results: Dict[str, Any], output_dir: Path) -> None:
        """95%ä¿¡é ¼åŒºé–“ãƒ—ãƒ­ãƒƒãƒˆ"""
        try:
            fig, axes = plt.subplots(1, 3, figsize=(18, 6))
            
            analysis_types = [
                ('age_analysis', 'å¹´é½¢å±¤åˆ¥', ['2æ­³é¦¬', '3æ­³é¦¬', '4æ­³ä»¥ä¸Š']),
                ('experience_analysis', 'çµŒé¨“æ•°åˆ¥', ['1-5æˆ¦', '6-15æˆ¦', '16æˆ¦ä»¥ä¸Š']),
                ('distance_analysis', 'è·é›¢ã‚«ãƒ†ã‚´ãƒªåˆ¥', ['çŸ­è·é›¢(â‰¤1400m)', 'ãƒã‚¤ãƒ«(1401-1800m)', 'ä¸­è·é›¢(1801-2000m)', 'é•·è·é›¢(â‰¥2001m)'])
            ]
            
            for i, (analysis_key, title, expected_groups) in enumerate(analysis_types):
                if analysis_key not in results:
                    continue
                    
                analysis_data = results[analysis_key]
                
                groups = []
                correlations = []
                ci_lower = []
                ci_upper = []
                
                for group in expected_groups:
                    if group in analysis_data:
                        data = analysis_data[group]
                        ci = data.get('confidence_interval')
                        if ci and ci[0] is not None and ci[1] is not None:
                            groups.append(group)
                            correlations.append(data.get('correlation_avg', 0))
                            ci_lower.append(ci[0])
                            ci_upper.append(ci[1])
                
                if groups:
                    x = range(len(groups))
                    axes[i].errorbar(x, correlations, 
                                   yerr=[np.array(correlations) - np.array(ci_lower),
                                         np.array(ci_upper) - np.array(correlations)],
                                   fmt='o', capsize=5, capthick=2, markersize=8)
                    
                    axes[i].set_title(f'{title}åˆ†æ\n95%ä¿¡é ¼åŒºé–“', fontsize=12, fontweight='bold')
                    axes[i].set_xlabel('ã‚°ãƒ«ãƒ¼ãƒ—')
                    axes[i].set_ylabel('ç›¸é–¢ä¿‚æ•°')
                    axes[i].set_xticks(x)
                    axes[i].set_xticklabels(groups, rotation=45, ha='right')
                    axes[i].grid(True, alpha=0.3)
                    axes[i].axhline(y=0, color='red', linestyle='--', alpha=0.5)
            
            plt.tight_layout()
            plt.savefig(output_dir / 'confidence_intervals.png', dpi=300, bbox_inches='tight')
            plt.close()
            
        except Exception as e:
            logger.error(f"âŒ ä¿¡é ¼åŒºé–“ãƒ—ãƒ­ãƒƒãƒˆã‚¨ãƒ©ãƒ¼: {str(e)}")