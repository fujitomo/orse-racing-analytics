import os
import glob
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from datetime import datetime
import japanize_matplotlib
from scipy import stats
import warnings
warnings.filterwarnings('ignore')

class InterpretableTrackAnalyzer:
    """
    è§£é‡ˆæ€§é‡è¦–ã®ç«¶é¦¬å ´é©æ€§åˆ†æã‚·ã‚¹ãƒ†ãƒ 
    
    èª²é¡Œèªè­˜:
    - æ©Ÿæ¢°å­¦ç¿’ã®äºˆæ¸¬ç²¾åº¦ã‚ˆã‚Šã‚‚ã€Œãªãœï¼Ÿã€ã‚’é‡è¦–
    - ç«¶é¦¬é–¢ä¿‚è€…ãŒç´å¾—ã§ãã‚‹èª¬æ˜ã‚’æä¾›
    - å®Ÿç”¨çš„ãªactionable insightsã‚’ç”Ÿæˆ
    """
    
    def __init__(self, data_folder="export/with_bias", output_folder="results/interpretable_analysis"):
        self.data_folder = data_folder
        self.output_folder = output_folder
        self.df = None
        self._setup_japanese_font()
        
    def _setup_japanese_font(self):
        """æ—¥æœ¬èªãƒ•ã‚©ãƒ³ãƒˆè¨­å®š"""
        import matplotlib.font_manager as fm
        import platform
        
        try:
            if platform.system() == 'Windows':
                windows_fonts_dir = r'C:\Windows\Fonts'
                font_candidates = [
                    (os.path.join(windows_fonts_dir, 'YuGothM.ttc'), 'Yu Gothic Medium'),
                    (os.path.join(windows_fonts_dir, 'msgothic.ttc'), 'MS Gothic'),
                    (os.path.join(windows_fonts_dir, 'meiryo.ttc'), 'Meiryo'),
                ]
                
                self.font_prop = None
                for font_path, font_name in font_candidates:
                    if os.path.exists(font_path):
                        self.font_prop = fm.FontProperties(fname=font_path)
                        print(f"ãƒ•ã‚©ãƒ³ãƒˆè¨­å®š: {font_name}")
                        break
                        
                if self.font_prop is None:
                    self.font_prop = fm.FontProperties()
            else:
                self.font_prop = fm.FontProperties()
        except Exception as e:
            self.font_prop = fm.FontProperties()
            print(f"ãƒ•ã‚©ãƒ³ãƒˆè¨­å®šã‚¨ãƒ©ãƒ¼: {e}")
    
    def load_and_preprocess_data(self):
        """ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ã¨åŸºæœ¬å‰å‡¦ç†"""
        print("ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿é–‹å§‹...")
        
        sed_files = glob.glob(os.path.join(self.data_folder, "SED*_formatted_with_bias.csv"))
        
        if not sed_files:
            print(f"ã‚¨ãƒ©ãƒ¼: SEDãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
            return False
            
        print(f"è¦‹ã¤ã‹ã£ãŸãƒ•ã‚¡ã‚¤ãƒ«: {len(sed_files)}å€‹")
        
        data_list = []
        for file_path in sed_files[:50]:  # 50ãƒ•ã‚¡ã‚¤ãƒ«é™å®š
            try:
                for encoding in ['utf-8', 'shift-jis', 'cp932']:
                    try:
                        df = pd.read_csv(file_path, encoding=encoding)
                        data_list.append(df)
                        break
                    except UnicodeDecodeError:
                        continue
            except Exception as e:
                print(f"èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {file_path}")
        
        if not data_list:
            return False
            
        self.df = pd.concat(data_list, ignore_index=True)
        print(f"ç·ãƒ‡ãƒ¼ã‚¿æ•°: {len(self.df)}è¡Œ")
        
        return self._preprocess_for_interpretation()
    
    def _preprocess_for_interpretation(self):
        """è§£é‡ˆæ€§é‡è¦–ã®å‰å‡¦ç†"""
        print("è§£é‡ˆæ€§é‡è¦–ã®å‰å‡¦ç†å®Ÿè¡Œä¸­...")
        
        # å¿…é ˆã‚«ãƒ©ãƒ ç¢ºèª
        required_columns = ['å ´å', 'å¹´', 'é¦¬ç•ª', 'ç€é †', 'IDM', 'ç´ ç‚¹']
        missing = [col for col in required_columns if col not in self.df.columns]
        if missing:
            print(f"ã‚¨ãƒ©ãƒ¼: å¿…è¦ã‚«ãƒ©ãƒ ä¸è¶³ {missing}")
            return False
        
        # åŸºæœ¬çš„ãªæ•°å€¤å¤‰æ›
        for col in ['å¹´', 'é¦¬ç•ª', 'ç€é †', 'IDM', 'ç´ ç‚¹', 'è·é›¢']:
            if col in self.df.columns:
                self.df[col] = pd.to_numeric(self.df[col], errors='coerce')
        
        # å‹åˆ©ãƒ•ãƒ©ã‚°
        self.df['å‹åˆ©'] = (self.df['ç€é †'] == 1).astype(int)
        
        # **è§£é‡ˆã—ã‚„ã™ã„ã‚«ãƒ†ã‚´ãƒªå¤‰æ•°ä½œæˆ**
        self._create_interpretable_categories()
        
        # ãƒ‡ãƒ¼ã‚¿ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°
        before_count = len(self.df)
        self.df = self.df.dropna(subset=['å¹´', 'é¦¬ç•ª', 'ç€é †', 'å ´å'])
        after_count = len(self.df)
        
        print(f"ãƒ‡ãƒ¼ã‚¿ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°: {before_count}è¡Œ â†’ {after_count}è¡Œ")
        print(f"åˆ†æå¯¾è±¡ç«¶é¦¬å ´: {sorted(self.df['å ´å'].unique())}")
        
        return True
    
    def _create_interpretable_categories(self):
        """è§£é‡ˆã—ã‚„ã™ã„ã‚«ãƒ†ã‚´ãƒªå¤‰æ•°ã‚’ä½œæˆ"""
        
        # 1. èƒ½åŠ›ãƒ©ãƒ³ã‚¯ï¼ˆ5æ®µéšï¼‰
        self.df['èƒ½åŠ›ãƒ©ãƒ³ã‚¯'] = pd.qcut(
            self.df['IDM'].fillna(self.df['IDM'].median()),
            q=5, 
            labels=['E', 'D', 'C', 'B', 'A']
        )
        
        # 2. é¦¬ç•ªã‚°ãƒ«ãƒ¼ãƒ—ï¼ˆè§£é‡ˆã—ã‚„ã™ãï¼‰
        def categorize_horse_number(num):
            if pd.isna(num):
                return 'ä¸æ˜'
            elif num <= 3:
                return 'å†…æ (1-3)'
            elif num <= 6:
                return 'ä¸­æ (4-6)'
            elif num <= 12:
                return 'å¤–æ (7-12)'
            else:
                return 'å¤§å¤–(13-)'
        
        self.df['æ é †ã‚«ãƒ†ã‚´ãƒª'] = self.df['é¦¬ç•ª'].apply(categorize_horse_number)
        
        # 3. è·é›¢ã‚«ãƒ†ã‚´ãƒª
        def categorize_distance(dist):
            if pd.isna(dist):
                return 'ä¸æ˜'
            elif dist <= 1200:
                return 'ã‚¹ãƒ—ãƒªãƒ³ãƒˆ(-1200m)'
            elif dist <= 1600:
                return 'ãƒã‚¤ãƒ«(1201-1600m)'
            elif dist <= 2000:
                return 'ä¸­è·é›¢(1601-2000m)'
            else:
                return 'é•·è·é›¢(2001m-)'
        
        self.df['è·é›¢ã‚«ãƒ†ã‚´ãƒª'] = self.df['è·é›¢'].apply(categorize_distance)
        
        # 4. ç«¶é¦¬å ´ã‚¿ã‚¤ãƒ—ï¼ˆå®Ÿãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ï¼‰
        track_types = {
            'ä¸­å±±': 'ãƒ‘ãƒ¯ãƒ¼å‹',
            'é˜ªç¥': 'ãƒ‘ãƒ¯ãƒ¼å‹', 
            'ä¸­äº¬': 'ãƒ†ã‚¯ãƒ‹ã‚«ãƒ«å‹',
            'æ±äº¬': 'ã‚¹ãƒ”ãƒ¼ãƒ‰å‹',
            'äº¬éƒ½': 'ãƒãƒ©ãƒ³ã‚¹å‹',
            'æ–°æ½Ÿ': 'ã‚¹ãƒ”ãƒ¼ãƒ‰å‹',
            'ç¦å³¶': 'ãƒãƒ©ãƒ³ã‚¹å‹',
            'å‡½é¤¨': 'ã‚¹ãƒ”ãƒ¼ãƒ‰å‹',
            'å°å€‰': 'ãƒãƒ©ãƒ³ã‚¹å‹',
            'æœ­å¹Œ': 'ã‚¹ãƒ”ãƒ¼ãƒ‰å‹'
        }
        
        self.df['ç«¶é¦¬å ´ã‚¿ã‚¤ãƒ—'] = self.df['å ´å'].map(track_types).fillna('ãã®ä»–')
        
        print("è§£é‡ˆå¯èƒ½ã‚«ãƒ†ã‚´ãƒªä½œæˆå®Œäº†")
    
    def analyze_win_rate_by_conditions(self):
        """æ¡ä»¶åˆ¥å‹ç‡åˆ†æï¼ˆè§£é‡ˆæ€§é‡è¦–ï¼‰"""
        print("\n=== æ¡ä»¶åˆ¥å‹ç‡åˆ†æé–‹å§‹ ===")
        
        if not os.path.exists(self.output_folder):
            os.makedirs(self.output_folder)
        
        # 1. åŸºæœ¬çš„ãªå‹ç‡åˆ†æ
        basic_analysis = self._basic_win_rate_analysis()
        
        # 2. ç«¶é¦¬å ´Ã—èƒ½åŠ›Ã—æ é †ã®3æ¬¡å…ƒåˆ†æ
        advanced_analysis = self._three_dimensional_analysis()
        
        # 3. çµ±è¨ˆçš„æœ‰æ„æ€§æ¤œå®š
        significance_test = self._statistical_significance_test()
        
        # 4. å¯è¦–åŒ–
        self._create_interpretable_visualizations(basic_analysis, advanced_analysis)
        
        # 5. å®Ÿç”¨ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
        self._generate_actionable_report(basic_analysis, advanced_analysis, significance_test)
        
        return {
            'basic': basic_analysis,
            'advanced': advanced_analysis,
            'significance': significance_test
        }
    
    def _basic_win_rate_analysis(self):
        """åŸºæœ¬å‹ç‡åˆ†æ"""
        print("åŸºæœ¬å‹ç‡åˆ†æä¸­...")
        
        results = {}
        
        # å…¨ä½“å‹ç‡
        overall_win_rate = self.df['å‹åˆ©'].mean()
        results['overall'] = {
            'win_rate': overall_win_rate,
            'sample_size': len(self.df)
        }
        
        # ç«¶é¦¬å ´åˆ¥å‹ç‡
        track_analysis = self.df.groupby('å ´å').agg({
            'å‹åˆ©': ['count', 'sum', 'mean'],
            'ç€é †': 'mean'
        }).round(4)
        
        track_analysis.columns = ['ãƒ¬ãƒ¼ã‚¹æ•°', 'å‹åˆ©æ•°', 'å‹ç‡', 'å¹³å‡ç€é †']
        results['by_track'] = track_analysis
        
        # èƒ½åŠ›ãƒ©ãƒ³ã‚¯åˆ¥å‹ç‡
        ability_analysis = self.df.groupby('èƒ½åŠ›ãƒ©ãƒ³ã‚¯').agg({
            'å‹åˆ©': ['count', 'sum', 'mean'],
            'ç€é †': 'mean'
        }).round(4)
        
        ability_analysis.columns = ['ãƒ¬ãƒ¼ã‚¹æ•°', 'å‹åˆ©æ•°', 'å‹ç‡', 'å¹³å‡ç€é †']
        results['by_ability'] = ability_analysis
        
        # æ é †åˆ¥å‹ç‡
        gate_analysis = self.df.groupby('æ é †ã‚«ãƒ†ã‚´ãƒª').agg({
            'å‹åˆ©': ['count', 'sum', 'mean'],
            'ç€é †': 'mean'
        }).round(4)
        
        gate_analysis.columns = ['ãƒ¬ãƒ¼ã‚¹æ•°', 'å‹åˆ©æ•°', 'å‹ç‡', 'å¹³å‡ç€é †']
        results['by_gate'] = gate_analysis
        
        return results
    
    def _three_dimensional_analysis(self):
        """3æ¬¡å…ƒã‚¯ãƒ­ã‚¹åˆ†æï¼ˆç«¶é¦¬å ´Ã—èƒ½åŠ›Ã—æ é †ï¼‰"""
        print("3æ¬¡å…ƒã‚¯ãƒ­ã‚¹åˆ†æä¸­...")
        
        # 3æ¬¡å…ƒã‚¯ãƒ­ã‚¹é›†è¨ˆ
        cross_table = self.df.groupby(['å ´å', 'èƒ½åŠ›ãƒ©ãƒ³ã‚¯', 'æ é †ã‚«ãƒ†ã‚´ãƒª']).agg({
            'å‹åˆ©': ['count', 'sum', 'mean'],
            'ç€é †': 'mean'
        }).round(4)
        
        cross_table.columns = ['ãƒ¬ãƒ¼ã‚¹æ•°', 'å‹åˆ©æ•°', 'å‹ç‡', 'å¹³å‡ç€é †']
        
        # ã‚µãƒ³ãƒ—ãƒ«ã‚µã‚¤ã‚ºãƒ•ã‚£ãƒ«ã‚¿ï¼ˆæœ€ä½20ãƒ¬ãƒ¼ã‚¹ï¼‰
        filtered_table = cross_table[cross_table['ãƒ¬ãƒ¼ã‚¹æ•°'] >= 20].copy()
        
        # å‹ç‡ã®å·®åˆ†åˆ†æ
        overall_win_rate = self.df['å‹åˆ©'].mean()
        filtered_table['å‹ç‡å·®'] = filtered_table['å‹ç‡'] - overall_win_rate
        filtered_table['å‹ç‡å€ç‡'] = filtered_table['å‹ç‡'] / overall_win_rate
        
        return {
            'cross_table': cross_table,
            'filtered_table': filtered_table,
            'top_combinations': filtered_table.nlargest(10, 'å‹ç‡'),
            'worst_combinations': filtered_table.nsmallest(10, 'å‹ç‡')
        }
    
    def _statistical_significance_test(self):
        """çµ±è¨ˆçš„æœ‰æ„æ€§æ¤œå®š"""
        print("çµ±è¨ˆçš„æ¤œå®šå®Ÿè¡Œä¸­...")
        
        results = {}
        
        # ç«¶é¦¬å ´é–“ã®å‹ç‡å·®æ¤œå®š
        track_groups = []
        track_names = []
        
        for track in self.df['å ´å'].unique():
            track_data = self.df[self.df['å ´å'] == track]['å‹åˆ©'].values
            if len(track_data) >= 50:  # æœ€ä½ã‚µãƒ³ãƒ—ãƒ«ã‚µã‚¤ã‚º
                track_groups.append(track_data)
                track_names.append(track)
        
        if len(track_groups) >= 2:
            # ã‚«ã‚¤äºŒä¹—æ¤œå®š
            from scipy.stats import chi2_contingency
            
            contingency_table = []
            for track in track_names:
                track_df = self.df[self.df['å ´å'] == track]
                wins = track_df['å‹åˆ©'].sum()
                losses = len(track_df) - wins
                contingency_table.append([wins, losses])
            
            chi2, p_value, dof, expected = chi2_contingency(contingency_table)
            
            results['track_difference'] = {
                'chi2_statistic': chi2,
                'p_value': p_value,
                'significant': p_value < 0.05,
                'tracks_tested': track_names
            }
        
        # èƒ½åŠ›ãƒ©ãƒ³ã‚¯é–“ã®å‹ç‡å·®æ¤œå®š
        ability_groups = []
        ability_names = []
        
        for ability in ['E', 'D', 'C', 'B', 'A']:
            ability_data = self.df[self.df['èƒ½åŠ›ãƒ©ãƒ³ã‚¯'] == ability]['å‹åˆ©'].values
            if len(ability_data) >= 30:
                ability_groups.append(ability_data)
                ability_names.append(ability)
        
        if len(ability_groups) >= 2:
            # ä¸€å…ƒé…ç½®åˆ†æ•£åˆ†æ
            from scipy.stats import f_oneway
            f_stat, p_value = f_oneway(*ability_groups)
            
            results['ability_difference'] = {
                'f_statistic': f_stat,
                'p_value': p_value,
                'significant': p_value < 0.05,
                'abilities_tested': ability_names
            }
        
        return results
    
    def _create_interpretable_visualizations(self, basic_analysis, advanced_analysis):
        """è§£é‡ˆã—ã‚„ã™ã„å¯è¦–åŒ–"""
        print("è§£é‡ˆé‡è¦–ã®å¯è¦–åŒ–ä½œæˆä¸­...")
        
        # 1. åŸºæœ¬å‹ç‡æ¯”è¼ƒ
        fig, axes = plt.subplots(2, 2, figsize=(16, 12))
        fig.suptitle('ç«¶é¦¬å ´Ã—é¦¬èƒ½åŠ› è§£é‡ˆæ€§é‡è¦–åˆ†æ', fontproperties=self.font_prop, fontsize=16)
        
        # ç«¶é¦¬å ´åˆ¥å‹ç‡
        ax1 = axes[0, 0]
        track_data = basic_analysis['by_track'].sort_values('å‹ç‡', ascending=True)
        bars1 = ax1.barh(range(len(track_data)), track_data['å‹ç‡'], alpha=0.7)
        ax1.set_yticks(range(len(track_data)))
        ax1.set_yticklabels(track_data.index, fontproperties=self.font_prop)
        ax1.set_xlabel('å‹ç‡', fontproperties=self.font_prop)
        ax1.set_title('ç«¶é¦¬å ´åˆ¥å‹ç‡', fontproperties=self.font_prop, fontsize=12)
        
        # å…¨ä½“å¹³å‡ç·š
        overall_rate = basic_analysis['overall']['win_rate']
        ax1.axvline(overall_rate, color='red', linestyle='--', label=f'å…¨ä½“å¹³å‡: {overall_rate:.3f}')
        ax1.legend(prop=self.font_prop)
        
        # èƒ½åŠ›ãƒ©ãƒ³ã‚¯åˆ¥å‹ç‡
        ax2 = axes[0, 1]
        ability_data = basic_analysis['by_ability']
        bars2 = ax2.bar(ability_data.index, ability_data['å‹ç‡'], alpha=0.7)
        ax2.set_xlabel('èƒ½åŠ›ãƒ©ãƒ³ã‚¯', fontproperties=self.font_prop)
        ax2.set_ylabel('å‹ç‡', fontproperties=self.font_prop)
        ax2.set_title('èƒ½åŠ›ãƒ©ãƒ³ã‚¯åˆ¥å‹ç‡', fontproperties=self.font_prop, fontsize=12)
        ax2.axhline(overall_rate, color='red', linestyle='--')
        
        # æ é †ã‚«ãƒ†ã‚´ãƒªåˆ¥å‹ç‡
        ax3 = axes[1, 0]
        gate_data = basic_analysis['by_gate']
        bars3 = ax3.bar(range(len(gate_data)), gate_data['å‹ç‡'], alpha=0.7)
        ax3.set_xticks(range(len(gate_data)))
        ax3.set_xticklabels(gate_data.index, rotation=45, fontproperties=self.font_prop)
        ax3.set_ylabel('å‹ç‡', fontproperties=self.font_prop)
        ax3.set_title('æ é †ã‚«ãƒ†ã‚´ãƒªåˆ¥å‹ç‡', fontproperties=self.font_prop, fontsize=12)
        ax3.axhline(overall_rate, color='red', linestyle='--')
        
        # TOP10çµ„ã¿åˆã‚ã›
        ax4 = axes[1, 1]
        top_combinations = advanced_analysis['top_combinations'].head(8)
        
        # ãƒ©ãƒ™ãƒ«ä½œæˆ
        labels = []
        for idx, row in top_combinations.iterrows():
            track, ability, gate = idx
            label = f"{track}\n{ability}ãƒ©ãƒ³ã‚¯\n{gate}"
            labels.append(label)
        
        bars4 = ax4.bar(range(len(top_combinations)), top_combinations['å‹ç‡'], alpha=0.7)
        ax4.set_xticks(range(len(top_combinations)))
        ax4.set_xticklabels(labels, rotation=45, fontproperties=self.font_prop, fontsize=8)
        ax4.set_ylabel('å‹ç‡', fontproperties=self.font_prop)
        ax4.set_title('é«˜å‹ç‡çµ„ã¿åˆã‚ã›TOP8', fontproperties=self.font_prop, fontsize=12)
        ax4.axhline(overall_rate, color='red', linestyle='--')
        
        plt.tight_layout()
        plt.savefig(os.path.join(self.output_folder, 'è§£é‡ˆæ€§é‡è¦–åˆ†æ.png'), dpi=300, bbox_inches='tight')
        plt.close()
        
        # 2. ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—ï¼ˆç«¶é¦¬å ´Ã—èƒ½åŠ›ãƒ©ãƒ³ã‚¯ï¼‰
        self._create_heatmap_analysis(advanced_analysis)
        
    def _create_heatmap_analysis(self, advanced_analysis):
        """ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—åˆ†æ"""
        
        # ç«¶é¦¬å ´Ã—èƒ½åŠ›ãƒ©ãƒ³ã‚¯ ã®ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—
        heatmap_data = self.df.groupby(['å ´å', 'èƒ½åŠ›ãƒ©ãƒ³ã‚¯'])['å‹åˆ©'].mean().unstack(fill_value=0)
        
        plt.figure(figsize=(12, 8))
        sns.heatmap(heatmap_data, annot=True, cmap='RdYlBu_r', fmt='.3f', 
                   cbar_kws={'label': 'å‹ç‡'})
        plt.title('ç«¶é¦¬å ´Ã—èƒ½åŠ›ãƒ©ãƒ³ã‚¯åˆ¥å‹ç‡ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—', fontproperties=self.font_prop, fontsize=14)
        plt.xlabel('èƒ½åŠ›ãƒ©ãƒ³ã‚¯', fontproperties=self.font_prop)
        plt.ylabel('ç«¶é¦¬å ´', fontproperties=self.font_prop)
        
        # è»¸ãƒ©ãƒ™ãƒ«ã®ãƒ•ã‚©ãƒ³ãƒˆè¨­å®š
        ax = plt.gca()
        for label in ax.get_xticklabels():
            label.set_fontproperties(self.font_prop)
        for label in ax.get_yticklabels():
            label.set_fontproperties(self.font_prop)
        
        plt.tight_layout()
        plt.savefig(os.path.join(self.output_folder, 'å‹ç‡ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—.png'), dpi=300, bbox_inches='tight')
        plt.close()
        
    def _generate_actionable_report(self, basic_analysis, advanced_analysis, significance_test):
        """å®Ÿç”¨çš„ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ"""
        
        report_path = os.path.join(self.output_folder, 'è§£é‡ˆæ€§é‡è¦–ãƒ¬ãƒãƒ¼ãƒˆ.md')
        
        with open(report_path, 'w', encoding='utf-8-sig') as f:
            f.write("# ç«¶é¦¬å ´Ã—é¦¬èƒ½åŠ›é©æ€§ è§£é‡ˆæ€§é‡è¦–åˆ†æãƒ¬ãƒãƒ¼ãƒˆ\n\n")
            f.write(f"ç”Ÿæˆæ—¥æ™‚: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n\n")
            
            f.write("## ğŸ¯ åˆ†æã®ç‹™ã„\n\n")
            f.write("æ©Ÿæ¢°å­¦ç¿’ã®äºˆæ¸¬ç²¾åº¦ã§ã¯ãªãã€**ãªãœãã®çµ„ã¿åˆã‚ã›ã§å‹ã¡ã‚„ã™ã„ã®ã‹**ã‚’\n")
            f.write("ç«¶é¦¬é–¢ä¿‚è€…ãŒç´å¾—ã§ãã‚‹å½¢ã§èª¬æ˜ã™ã‚‹ã“ã¨ã‚’é‡è¦–ã—ã¾ã—ãŸã€‚\n\n")
            
            f.write("## ğŸ“Š åŸºæœ¬çµ±è¨ˆ\n\n")
            overall_rate = basic_analysis['overall']['win_rate']
            overall_races = basic_analysis['overall']['sample_size']
            f.write(f"- **å…¨ä½“å‹ç‡**: {overall_rate:.3f} ({overall_races:,}ãƒ¬ãƒ¼ã‚¹)\n")
            f.write(f"- **åˆ†ææœŸé–“**: {self.df['å¹´'].min():.0f}å¹´ - {self.df['å¹´'].max():.0f}å¹´\n")
            f.write(f"- **å¯¾è±¡ç«¶é¦¬å ´**: {len(self.df['å ´å'].unique())}å ´\n\n")
            
            f.write("## ğŸ† æœ€ã‚‚å‹ã¡ã‚„ã™ã„çµ„ã¿åˆã‚ã› TOP10\n\n")
            f.write("| é †ä½ | ç«¶é¦¬å ´ | èƒ½åŠ›ãƒ©ãƒ³ã‚¯ | æ é † | å‹ç‡ | ãƒ¬ãƒ¼ã‚¹æ•° | å…¨ä½“æ¯” |\n")
            f.write("|------|--------|------------|------|------|----------|--------|\n")
            
            top_10 = advanced_analysis['top_combinations'].head(10)
            for i, (idx, row) in enumerate(top_10.iterrows(), 1):
                track, ability, gate = idx
                win_rate = row['å‹ç‡']
                race_count = int(row['ãƒ¬ãƒ¼ã‚¹æ•°'])
                ratio = row['å‹ç‡å€ç‡']
                f.write(f"| {i} | {track} | {ability} | {gate} | {win_rate:.3f} | {race_count} | {ratio:.2f}å€ |\n")
            
            f.write("\n## âš ï¸ æœ€ã‚‚å‹ã¡ã«ãã„çµ„ã¿åˆã‚ã› TOP5\n\n")
            f.write("| é †ä½ | ç«¶é¦¬å ´ | èƒ½åŠ›ãƒ©ãƒ³ã‚¯ | æ é † | å‹ç‡ | ãƒ¬ãƒ¼ã‚¹æ•° | å…¨ä½“æ¯” |\n")
            f.write("|------|--------|------------|------|------|----------|--------|\n")
            
            worst_5 = advanced_analysis['worst_combinations'].head(5)
            for i, (idx, row) in enumerate(worst_5.iterrows(), 1):
                track, ability, gate = idx
                win_rate = row['å‹ç‡']
                race_count = int(row['ãƒ¬ãƒ¼ã‚¹æ•°'])
                ratio = row['å‹ç‡å€ç‡']
                f.write(f"| {i} | {track} | {ability} | {gate} | {win_rate:.3f} | {race_count} | {ratio:.2f}å€ |\n")
            
            f.write("\n## ğŸ”¬ çµ±è¨ˆçš„æ¤œå®šçµæœ\n\n")
            
            if 'track_difference' in significance_test:
                track_test = significance_test['track_difference']
                f.write(f"### ç«¶é¦¬å ´é–“ã®å‹ç‡å·®\n")
                f.write(f"- **ã‚«ã‚¤äºŒä¹—çµ±è¨ˆé‡**: {track_test['chi2_statistic']:.4f}\n")
                f.write(f"- **på€¤**: {track_test['p_value']:.6f}\n")
                f.write(f"- **çµ±è¨ˆçš„æœ‰æ„**: {'Yes' if track_test['significant'] else 'No'}\n")
                f.write(f"- **çµè«–**: ç«¶é¦¬å ´ã«ã‚ˆã‚‹å‹ç‡å·®ã¯{'ã‚ã‚‹' if track_test['significant'] else 'ãªã„'}\n\n")
            
            if 'ability_difference' in significance_test:
                ability_test = significance_test['ability_difference']
                f.write(f"### èƒ½åŠ›ãƒ©ãƒ³ã‚¯é–“ã®å‹ç‡å·®\n")
                f.write(f"- **Fçµ±è¨ˆé‡**: {ability_test['f_statistic']:.4f}\n")
                f.write(f"- **på€¤**: {ability_test['p_value']:.6f}\n")
                f.write(f"- **çµ±è¨ˆçš„æœ‰æ„**: {'Yes' if ability_test['significant'] else 'No'}\n")
                f.write(f"- **çµè«–**: èƒ½åŠ›ã«ã‚ˆã‚‹å‹ç‡å·®ã¯{'æ˜ç¢ºã«ã‚ã‚‹' if ability_test['significant'] else 'ãªã„'}\n\n")
            
            f.write("## ğŸ’¡ å®Ÿç”¨çš„ãªçŸ¥è¦‹\n\n")
            
            # ç«¶é¦¬å ´åˆ¥ã®ç‰¹å¾´
            track_analysis = basic_analysis['by_track'].sort_values('å‹ç‡', ascending=False)
            best_track = track_analysis.index[0]
            worst_track = track_analysis.index[-1]
            
            f.write(f"### ç«¶é¦¬å ´ã®ç‰¹å¾´\n")
            f.write(f"- **æœ€ã‚‚å‹ã¡ã‚„ã™ã„ç«¶é¦¬å ´**: {best_track} (å‹ç‡: {track_analysis.loc[best_track, 'å‹ç‡']:.3f})\n")
            f.write(f"- **æœ€ã‚‚å‹ã¡ã«ãã„ç«¶é¦¬å ´**: {worst_track} (å‹ç‡: {track_analysis.loc[worst_track, 'å‹ç‡']:.3f})\n\n")
            
            # èƒ½åŠ›ãƒ©ãƒ³ã‚¯ã®åŠ¹æœ
            ability_analysis = basic_analysis['by_ability'].sort_values('å‹ç‡', ascending=False)
            f.write(f"### èƒ½åŠ›ãƒ©ãƒ³ã‚¯ã®åŠ¹æœ\n")
            for rank in ability_analysis.index:
                rate = ability_analysis.loc[rank, 'å‹ç‡']
                count = int(ability_analysis.loc[rank, 'ãƒ¬ãƒ¼ã‚¹æ•°'])
                f.write(f"- **{rank}ãƒ©ãƒ³ã‚¯**: å‹ç‡{rate:.3f} ({count:,}ãƒ¬ãƒ¼ã‚¹)\n")
            
            f.write(f"\n### å®Ÿè·µçš„ã‚¢ãƒ‰ãƒã‚¤ã‚¹\n")
            f.write(f"1. **é«˜å‹ç‡ã®çµ„ã¿åˆã‚ã›**ã‚’ç‹™ã†éš›ã¯ã€æœ€ä½20ãƒ¬ãƒ¼ã‚¹ä»¥ä¸Šã®å®Ÿç¸¾ãŒã‚ã‚‹æ¡ä»¶ã‚’é¸ã¶\n")
            f.write(f"2. **èƒ½åŠ›Aãƒ©ãƒ³ã‚¯**ã®é¦¬ã§ã‚‚ç«¶é¦¬å ´ã¨æ é †ã«ã‚ˆã£ã¦å‹ç‡ãŒå¤§ããå¤‰ã‚ã‚‹\n")
            f.write(f"3. **{best_track}ç«¶é¦¬å ´**ã¯å…¨ä½“çš„ã«å‹ã¡ã‚„ã™ã„å‚¾å‘\n")
            f.write(f"4. **æ é †ã®å½±éŸ¿**ã¯ç«¶é¦¬å ´ã«ã‚ˆã£ã¦ç•°ãªã‚‹ãŸã‚ã€çµ„ã¿åˆã‚ã›ã§åˆ¤æ–­ã™ã¹ã\n\n")
        
        print(f"å®Ÿç”¨ãƒ¬ãƒãƒ¼ãƒˆä¿å­˜: {report_path}")

def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•°"""
    analyzer = InterpretableTrackAnalyzer()
    
    # ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
    if not analyzer.load_and_preprocess_data():
        print("ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸã€‚")
        return
    
    # è§£é‡ˆæ€§é‡è¦–ã®åˆ†æå®Ÿè¡Œ
    results = analyzer.analyze_win_rate_by_conditions()
    
    print(f"\n=== è§£é‡ˆæ€§é‡è¦–åˆ†æå®Œäº† ===")
    print(f"çµæœä¿å­˜å…ˆ: {analyzer.output_folder}")
    print("\nä¸»ãªçŸ¥è¦‹:")
    print(f"- å…¨ä½“å‹ç‡: {results['basic']['overall']['win_rate']:.3f}")
    
    if 'track_difference' in results['significance']:
        track_sig = results['significance']['track_difference']['significant']
        print(f"- ç«¶é¦¬å ´ã«ã‚ˆã‚‹å‹ç‡å·®: {'çµ±è¨ˆçš„ã«æœ‰æ„' if track_sig else 'æœ‰æ„å·®ãªã—'}")
    
    if 'ability_difference' in results['significance']:
        ability_sig = results['significance']['ability_difference']['significant']
        print(f"- èƒ½åŠ›ã«ã‚ˆã‚‹å‹ç‡å·®: {'çµ±è¨ˆçš„ã«æœ‰æ„' if ability_sig else 'æœ‰æ„å·®ãªã—'}")

if __name__ == "__main__":
    main() 