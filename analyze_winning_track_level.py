#!/usr/bin/env python
"""
ç«¶é¦¬å ´ãƒ¬ãƒ™ãƒ«åˆ¥å‹ç‡åˆ†æã‚³ãƒãƒ³ãƒ‰ãƒ©ã‚¤ãƒ³ãƒ„ãƒ¼ãƒ«
é¦¬ã”ã¨ã®é‡ã¿ä»˜ã‘ãƒã‚¤ãƒ³ãƒˆã¨å‹ç‡ã®é–¢ä¿‚ã‚’3å¹´ã”ã¨ã«åˆ†æã—ã¾ã™ã€‚
è¤‡å‹ã—ãŸå ´åˆã®ã¿ãƒã‚¤ãƒ³ãƒˆã‚’åŠ ç®—ã™ã‚‹ä»•æ§˜ã«å¤‰æ›´ã€‚
"""

import argparse
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from pathlib import Path
from datetime import datetime
import logging
import sys
import japanize_matplotlib
from scipy import stats
from scipy.stats import pearsonr, spearmanr
from sklearn.linear_model import LinearRegression, LogisticRegression
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import r2_score
import warnings
import copy
import random
warnings.filterwarnings('ignore')

# ãƒ¡ã‚¤ãƒ³ãƒ­ã‚¬ãƒ¼ã®è¨­å®š
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

class TrackWinRateAnalyzer:
    """ç«¶é¦¬å ´åˆ¥å‹ç‡åˆ†æã‚¯ãƒ©ã‚¹ï¼ˆé¦¬ã”ã¨é‡ã¿ä»˜ã‘ãƒ»3å¹´é–“éš”åˆ†æãƒ»è¤‡å‹æ™‚ã®ã¿ãƒã‚¤ãƒ³ãƒˆåŠ ç®—ï¼‰"""
    
    def __init__(self, config):
        """åˆæœŸåŒ–"""
        self.config = config
        self.df = None
        self.track_hierarchy = {}
        self.original_track_hierarchy = {}  # ã‚ªãƒªã‚¸ãƒŠãƒ«ã®é‡ã¿ä»˜ã‘ã‚’ä¿å­˜
        self.is_random_weights = config.get('random_weights', False)  # ãƒ©ãƒ³ãƒ€ãƒ é‡ã¿ä»˜ã‘ãƒ•ãƒ©ã‚°
        
        # æ—¥æœ¬èªãƒ•ã‚©ãƒ³ãƒˆè¨­å®š
        self._setup_japanese_font()
        
        # ç«¶é¦¬å ´éšå±¤ã®è¨­å®š
        self._setup_track_hierarchy()
        
        # ãƒ©ãƒ³ãƒ€ãƒ é‡ã¿ä»˜ã‘ã®å ´åˆã¯é‡ã¿ã‚’å¤‰æ›´
        if self.is_random_weights:
            self._apply_random_weights()
    
    def _setup_japanese_font(self):
        """æ—¥æœ¬èªãƒ•ã‚©ãƒ³ãƒˆè¨­å®š"""
        plt.rcParams['font.family'] = 'MS Gothic'
        plt.rcParams['axes.unicode_minus'] = False
        plt.rcParams['font.size'] = 10
    
    def _setup_track_hierarchy(self):
        """ç«¶é¦¬å ´ã®éšå±¤å®šç¾©ã¨é‡ã¿ä»˜ã‘ãƒã‚¤ãƒ³ãƒˆã‚·ã‚¹ãƒ†ãƒ """
        self.track_hierarchy = {
            # ä¸­å¤®ç«¶é¦¬ - é‡ã¿ä»˜ã‘ãƒã‚¤ãƒ³ãƒˆã‚·ã‚¹ãƒ†ãƒ 
            'æ±äº¬': {
                'level': 10, 'type': 'ä¸­å¤®', 'category': 'æœ€é«˜æ ¼å¼',
                'weight_points': 100,  # æœ€é«˜æ ¼å¼G1å¤šæ•°é–‹å‚¬
                'grade_weight': 10,    # G1ãƒ¬ãƒ¼ã‚¹ä¾¡å€¤
                'prestige_weight': 10, # å¨ä¿¡åº¦
                'facility_weight': 10  # è¨­å‚™ãƒ»è¦æ¨¡
            },
            'ä¸­å±±': {
                'level': 10, 'type': 'ä¸­å¤®', 'category': 'æœ€é«˜æ ¼å¼',
                'weight_points': 95,
                'grade_weight': 9.5,
                'prestige_weight': 9.5,
                'facility_weight': 9.5
            },
            'äº¬éƒ½': {
                'level': 9, 'type': 'ä¸­å¤®', 'category': 'é–¢è¥¿ä¸»è¦',
                'weight_points': 90,
                'grade_weight': 9,
                'prestige_weight': 9,
                'facility_weight': 9
            },
            'é˜ªç¥': {
                'level': 9, 'type': 'ä¸­å¤®', 'category': 'é–¢è¥¿ä¸»è¦',
                'weight_points': 85,
                'grade_weight': 8.5,
                'prestige_weight': 8.5,
                'facility_weight': 8.5
            },
            'ä¸­äº¬': {
                'level': 7, 'type': 'ä¸­å¤®', 'category': 'ä¸­å¤®åœ°æ–¹',
                'weight_points': 70,
                'grade_weight': 7,
                'prestige_weight': 7,
                'facility_weight': 7
            },
            'æ–°æ½Ÿ': {
                'level': 6, 'type': 'ä¸­å¤®', 'category': 'ä¸­å¤®åœ°æ–¹',
                'weight_points': 60,
                'grade_weight': 6,
                'prestige_weight': 6,
                'facility_weight': 6
            },
            'å°å€‰': {
                'level': 6, 'type': 'ä¸­å¤®', 'category': 'ä¸­å¤®åœ°æ–¹',
                'weight_points': 58,
                'grade_weight': 5.8,
                'prestige_weight': 5.8,
                'facility_weight': 5.8
            },
            'ç¦å³¶': {
                'level': 5, 'type': 'ä¸­å¤®', 'category': 'ä¸­å¤®åœ°æ–¹',
                'weight_points': 50,
                'grade_weight': 5,
                'prestige_weight': 5,
                'facility_weight': 5
            },
            'å‡½é¤¨': {
                'level': 5, 'type': 'ä¸­å¤®', 'category': 'ä¸­å¤®åœ°æ–¹',
                'weight_points': 48,
                'grade_weight': 4.8,
                'prestige_weight': 4.8,
                'facility_weight': 4.8
            },
            'æœ­å¹Œ': {
                'level': 5, 'type': 'ä¸­å¤®', 'category': 'ä¸­å¤®åœ°æ–¹',
                'weight_points': 45,
                'grade_weight': 4.5,
                'prestige_weight': 4.5,
                'facility_weight': 4.5
            },
            
            # åœ°æ–¹ç«¶é¦¬ - NARé‡è³ä¾¡å€¤ã‚’è€ƒæ…®
            'å¤§äº•': {
                'level': 4, 'type': 'åœ°æ–¹', 'category': 'é¦–éƒ½åœä¸»è¦',
                'weight_points': 40,  # æ±äº¬å¤§è³å…¸ç­‰G1é–‹å‚¬
                'grade_weight': 4,
                'prestige_weight': 4,
                'facility_weight': 4
            },
            'å·å´': {
                'level': 4, 'type': 'åœ°æ–¹', 'category': 'é¦–éƒ½åœä¸»è¦',
                'weight_points': 38,  # å·å´è¨˜å¿µç­‰G1é–‹å‚¬
                'grade_weight': 3.8,
                'prestige_weight': 3.8,
                'facility_weight': 3.8
            },
            'èˆ¹æ©‹': {
                'level': 3, 'type': 'åœ°æ–¹', 'category': 'é¦–éƒ½åœåœ°æ–¹',
                'weight_points': 30,  # ã‹ã—ã‚è¨˜å¿µç­‰G1é–‹å‚¬
                'grade_weight': 3,
                'prestige_weight': 3,
                'facility_weight': 3
            },
            'æµ¦å’Œ': {
                'level': 3, 'type': 'åœ°æ–¹', 'category': 'é¦–éƒ½åœåœ°æ–¹',
                'weight_points': 28,
                'grade_weight': 2.8,
                'prestige_weight': 2.8,
                'facility_weight': 2.8
            },
            'åœ’ç”°': {
                'level': 3, 'type': 'åœ°æ–¹', 'category': 'é–¢è¥¿åœ°æ–¹',
                'weight_points': 25,
                'grade_weight': 2.5,
                'prestige_weight': 2.5,
                'facility_weight': 2.5
            },
            'å§«è·¯': {
                'level': 2, 'type': 'åœ°æ–¹', 'category': 'é–¢è¥¿åœ°æ–¹',
                'weight_points': 20,
                'grade_weight': 2,
                'prestige_weight': 2,
                'facility_weight': 2
            },
            'åå¤å±‹': {
                'level': 3, 'type': 'åœ°æ–¹', 'category': 'ä¸­éƒ¨åœ°æ–¹',
                'weight_points': 28,
                'grade_weight': 2.8,
                'prestige_weight': 2.8,
                'facility_weight': 2.8
            },
            'ç¬ æ¾': {
                'level': 2, 'type': 'åœ°æ–¹', 'category': 'ä¸­éƒ¨åœ°æ–¹',
                'weight_points': 18,
                'grade_weight': 1.8,
                'prestige_weight': 1.8,
                'facility_weight': 1.8
            },
            'é‡‘æ²¢': {
                'level': 2, 'type': 'åœ°æ–¹', 'category': 'åŒ—é™¸åœ°æ–¹',
                'weight_points': 15,
                'grade_weight': 1.5,
                'prestige_weight': 1.5,
                'facility_weight': 1.5
            },
            'ä½è³€': {
                'level': 2, 'type': 'åœ°æ–¹', 'category': 'ä¹å·åœ°æ–¹',
                'weight_points': 15,
                'grade_weight': 1.5,
                'prestige_weight': 1.5,
                'facility_weight': 1.5
            },
            'é«˜çŸ¥': {
                'level': 2, 'type': 'åœ°æ–¹', 'category': 'å››å›½åœ°æ–¹',
                'weight_points': 12,
                'grade_weight': 1.2,
                'prestige_weight': 1.2,
                'facility_weight': 1.2
            },
            'é–€åˆ¥': {
                'level': 3, 'type': 'åœ°æ–¹', 'category': 'åŒ—æµ·é“åœ°æ–¹',
                'weight_points': 25,  # ç”Ÿç”£åœ°ä¾¡å€¤åŠ ç®—
                'grade_weight': 2.5,
                'prestige_weight': 2.5,
                'facility_weight': 2.5
            },
            'ç››å²¡': {
                'level': 2, 'type': 'åœ°æ–¹', 'category': 'æ±åŒ—åœ°æ–¹',
                'weight_points': 12,
                'grade_weight': 1.2,
                'prestige_weight': 1.2,
                'facility_weight': 1.2
            },
            'æ°´æ²¢': {
                'level': 2, 'type': 'åœ°æ–¹', 'category': 'æ±åŒ—åœ°æ–¹',
                'weight_points': 10,
                'grade_weight': 1,
                'prestige_weight': 1,
                'facility_weight': 1
            },
            'å®‡éƒ½å®®': {
                'level': 2, 'type': 'åœ°æ–¹', 'category': 'é–¢æ±åœ°æ–¹',
                'weight_points': 10,
                'grade_weight': 1,
                'prestige_weight': 1,
                'facility_weight': 1
            },
            'è¶³åˆ©': {
                'level': 1, 'type': 'åœ°æ–¹', 'category': 'é–¢æ±åœ°æ–¹',
                'weight_points': 5,
                'grade_weight': 0.5,
                'prestige_weight': 0.5,
                'facility_weight': 0.5
            },
            'é«˜å´': {
                'level': 1, 'type': 'åœ°æ–¹', 'category': 'é–¢æ±åœ°æ–¹',
                'weight_points': 5,
                'grade_weight': 0.5,
                'prestige_weight': 0.5,
                'facility_weight': 0.5
            },
            'ç¦å±±': {
                'level': 1, 'type': 'åœ°æ–¹', 'category': 'ä¸­å›½åœ°æ–¹',
                'weight_points': 3,
                'grade_weight': 0.3,
                'prestige_weight': 0.3,
                'facility_weight': 0.3
            },
            'ç›Šç”°': {
                'level': 1, 'type': 'åœ°æ–¹', 'category': 'ä¸­å›½åœ°æ–¹',
                'weight_points': 2,
                'grade_weight': 0.2,
                'prestige_weight': 0.2,
                'facility_weight': 0.2
            }
        }
    
    def _apply_random_weights(self):
        """ç«¶é¦¬å ´ã®é‡ã¿ä»˜ã‘ã‚’ãƒ©ãƒ³ãƒ€ãƒ ã«å¤‰æ›´"""
        import random
        
        logger.info("ğŸ² ç«¶é¦¬å ´é‡ã¿ä»˜ã‘ã‚’ãƒ©ãƒ³ãƒ€ãƒ ã«å¤‰æ›´ä¸­...")
        
        # ã‚ªãƒªã‚¸ãƒŠãƒ«ã®é‡ã¿ä»˜ã‘ã‚’ä¿å­˜
        self.original_track_hierarchy = copy.deepcopy(self.track_hierarchy)
        
        # å…¨ç«¶é¦¬å ´ã®ãƒªã‚¹ãƒˆã‚’å–å¾—
        track_names = list(self.track_hierarchy.keys())
        
        # ã‚ªãƒªã‚¸ãƒŠãƒ«ã®é‡ã¿ä»˜ã‘ãƒã‚¤ãƒ³ãƒˆã‚’å–å¾—ã—ã¦ã‚·ãƒ£ãƒƒãƒ•ãƒ«
        original_points = [info['weight_points'] for info in self.track_hierarchy.values()]
        random.shuffle(original_points)
        
        # ã‚·ãƒ£ãƒƒãƒ•ãƒ«ã•ã‚ŒãŸãƒã‚¤ãƒ³ãƒˆã‚’å„ç«¶é¦¬å ´ã«å†å‰²ã‚Šå½“ã¦
        for i, track_name in enumerate(track_names):
            new_weight = original_points[i]
            self.track_hierarchy[track_name]['weight_points'] = new_weight
            
            # ä»–ã®é‡ã¿ã‚‚æ¯”ä¾‹ã—ã¦èª¿æ•´
            ratio = new_weight / self.original_track_hierarchy[track_name]['weight_points']
            self.track_hierarchy[track_name]['grade_weight'] = round(
                self.original_track_hierarchy[track_name]['grade_weight'] * ratio, 2)
            self.track_hierarchy[track_name]['prestige_weight'] = round(
                self.original_track_hierarchy[track_name]['prestige_weight'] * ratio, 2)
            self.track_hierarchy[track_name]['facility_weight'] = round(
                self.original_track_hierarchy[track_name]['facility_weight'] * ratio, 2)
        
        # ãƒ©ãƒ³ãƒ€ãƒ åŒ–ã®çµæœã‚’ãƒ­ã‚°å‡ºåŠ›
        logger.info("ğŸ² ãƒ©ãƒ³ãƒ€ãƒ é‡ã¿ä»˜ã‘çµæœï¼ˆæŠœç²‹ï¼‰:")
        for track_name in ['æ±äº¬', 'ä¸­å±±', 'å¤§äº•', 'å·å´']:
            if track_name in self.track_hierarchy:
                original = self.original_track_hierarchy[track_name]['weight_points']
                new = self.track_hierarchy[track_name]['weight_points']
                logger.info(f"  {track_name}: {original} â†’ {new}")
    
    def load_data(self):
        """ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿"""
        logger.info("ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿é–‹å§‹...")
        
        input_path = Path(self.config['input_path'])
        
        if input_path.is_file():
            df = self._read_csv_file(input_path)
        elif input_path.is_dir():
            csv_files = list(input_path.glob("*.csv"))
            if not csv_files:
                raise FileNotFoundError(f"CSVãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {input_path}")
            
            df_list = []
            for file_path in csv_files:
                try:
                    df_temp = self._read_csv_file(file_path)
                    df_list.append(df_temp)
                except Exception as e:
                    logger.warning(f"ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {file_path} - {e}")
            
            if not df_list:
                raise ValueError("æœ‰åŠ¹ãªCSVãƒ•ã‚¡ã‚¤ãƒ«ãŒã‚ã‚Šã¾ã›ã‚“")
            
            df = pd.concat(df_list, ignore_index=True)
        else:
            raise FileNotFoundError(f"æŒ‡å®šã•ã‚ŒãŸãƒ‘ã‚¹ãŒå­˜åœ¨ã—ã¾ã›ã‚“: {input_path}")
        
        logger.info(f"ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿å®Œäº†: {len(df)}è¡Œ")
        return df
    
    def _read_csv_file(self, file_path):
        """CSVãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿ï¼ˆã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°è‡ªå‹•åˆ¤å®šï¼‰"""
        encodings = ['utf-8', 'shift-jis', 'cp932', 'euc-jp']
        
        for encoding in encodings:
            try:
                return pd.read_csv(file_path, encoding=encoding)
            except UnicodeDecodeError:
                continue
        
        raise ValueError(f"ãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã‚ã¾ã›ã‚“ã§ã—ãŸ: {file_path}")
    
    def preprocess_data(self):
        """ãƒ‡ãƒ¼ã‚¿å‰å‡¦ç†"""
        logger.info("ãƒ‡ãƒ¼ã‚¿å‰å‡¦ç†é–‹å§‹...")
        
        # å¿…è¦ã‚«ãƒ©ãƒ ã®ç¢ºèª
        required_columns = ['é¦¬å', 'å ´å', 'ç€é †']
        missing_columns = [col for col in required_columns if col not in self.df.columns]
        if missing_columns:
            raise ValueError(f"å¿…è¦ãªã‚«ãƒ©ãƒ ãŒä¸è¶³ã—ã¦ã„ã¾ã™: {missing_columns}")
        
        # æ•°å€¤å¤‰æ›
        self.df['ç€é †'] = pd.to_numeric(self.df['ç€é †'], errors='coerce')
        
        # å‹åˆ©ãƒ»è¤‡å‹ãƒ•ãƒ©ã‚°
        self.df['å‹åˆ©'] = (self.df['ç€é †'] == 1).astype(int)
        self.df['è¤‡å‹'] = (self.df['ç€é †'] <= 3).astype(int)
        
        # ç«¶é¦¬å ´æƒ…å ±ã®è¿½åŠ 
        self.df['ç«¶é¦¬å ´ãƒ¬ãƒ™ãƒ«'] = self.df['å ´å'].map(
            lambda x: self.track_hierarchy.get(x, {}).get('level', 0)
        )
        self.df['ç«¶é¦¬å ´ã‚¿ã‚¤ãƒ—'] = self.df['å ´å'].map(
            lambda x: self.track_hierarchy.get(x, {}).get('type', 'ä¸æ˜')
        )
        self.df['ç«¶é¦¬å ´ã‚«ãƒ†ã‚´ãƒª'] = self.df['å ´å'].map(
            lambda x: self.track_hierarchy.get(x, {}).get('category', 'ä¸æ˜')
        )
        
        # ç«¶é¦¬å ´ã®é‡ã¿ä»˜ã‘ãƒã‚¤ãƒ³ãƒˆæƒ…å ±ã®è¿½åŠ ï¼ˆå¾Œã§é¦¬ã”ã¨ã«é›†è¨ˆï¼‰
        self.df['ç«¶é¦¬å ´é‡ã¿ä»˜ã‘ãƒã‚¤ãƒ³ãƒˆ'] = self.df['å ´å'].map(
            lambda x: self.track_hierarchy.get(x, {}).get('weight_points', 0)
        )
        self.df['ç«¶é¦¬å ´ã‚°ãƒ¬ãƒ¼ãƒ‰é‡ã¿'] = self.df['å ´å'].map(
            lambda x: self.track_hierarchy.get(x, {}).get('grade_weight', 0)
        )
        self.df['ç«¶é¦¬å ´å¨ä¿¡åº¦é‡ã¿'] = self.df['å ´å'].map(
            lambda x: self.track_hierarchy.get(x, {}).get('prestige_weight', 0)
        )
        self.df['ç«¶é¦¬å ´è¨­å‚™é‡ã¿'] = self.df['å ´å'].map(
            lambda x: self.track_hierarchy.get(x, {}).get('facility_weight', 0)
        )
        
        # å¹´ã®å‡¦ç†ï¼ˆãƒ‡ãƒ¼ã‚¿ã«å¹´ãŒã‚ã‚‹ã‹ãƒã‚§ãƒƒã‚¯ï¼‰
        self._process_year_data()
        
        # ãƒ‡ãƒ¼ã‚¿ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°
        before_count = len(self.df)
        self.df = self.df.dropna(subset=['é¦¬å', 'å ´å', 'ç€é †'])
        self.df = self.df[self.df['ç«¶é¦¬å ´ãƒ¬ãƒ™ãƒ«'] > 0]  # æœªå®šç¾©ç«¶é¦¬å ´ã‚’é™¤å¤–
        after_count = len(self.df)
        
        logger.info(f"ãƒ‡ãƒ¼ã‚¿ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°: {before_count}è¡Œ â†’ {after_count}è¡Œ")
        logger.info(f"å¯¾è±¡ç«¶é¦¬å ´: {sorted(self.df['å ´å'].unique())}")
        
        return self.df
    
    def _process_year_data(self):
        """å¹´ãƒ‡ãƒ¼ã‚¿ã®å‡¦ç†"""
        # å¹´ã‚«ãƒ©ãƒ ã®æ¤œå‡º
        year_columns = [col for col in self.df.columns if 'å¹´' in col.lower() or 'year' in col.lower()]
        date_columns = [col for col in self.df.columns if 'æ—¥ä»˜' in col or 'date' in col.lower() or 'é–‹å‚¬æ—¥' in col]
        
        if year_columns:
            self.df['å¹´'] = pd.to_numeric(self.df[year_columns[0]], errors='coerce')
            logger.info(f"å¹´ã‚«ãƒ©ãƒ ã‚’æ¤œå‡ºã—ã¾ã—ãŸ: {year_columns[0]}")
        elif date_columns:
            try:
                # æ—¥ä»˜ã‚«ãƒ©ãƒ ã‹ã‚‰å¹´ã‚’æŠ½å‡º
                date_col = date_columns[0]
                self.df['å¹´'] = pd.to_datetime(self.df[date_col], errors='coerce').dt.year
                logger.info(f"æ—¥ä»˜ã‚«ãƒ©ãƒ ã‹ã‚‰å¹´ã‚’æŠ½å‡ºã—ã¾ã—ãŸ: {date_col}")
            except:
                logger.warning("æ—¥ä»˜ã‚«ãƒ©ãƒ ã‹ã‚‰ã®å¹´æŠ½å‡ºã«å¤±æ•—ã—ã¾ã—ãŸ")
                self.df['å¹´'] = None
        else:
            logger.warning("å¹´ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚å…¨æœŸé–“ã§ã®åˆ†æã‚’å®Ÿè¡Œã—ã¾ã™ã€‚")
            self.df['å¹´'] = None
    
    def _calculate_horse_weights(self, df_period):
        """é¦¬ã”ã¨ã®é‡ã¿ä»˜ã‘ãƒã‚¤ãƒ³ãƒˆè¨ˆç®—ï¼ˆå¾“æ¥é€šã‚Šå…¨å‡ºèµ°ã§è¨ˆç®—ï¼‰"""
        # é¦¬ã”ã¨ã®é‡ã¿ä»˜ã‘ãƒã‚¤ãƒ³ãƒˆå¹³å‡ã‚’è¨ˆç®—
        horse_weights = df_period.groupby('é¦¬å').agg({
            'ç«¶é¦¬å ´é‡ã¿ä»˜ã‘ãƒã‚¤ãƒ³ãƒˆ': 'mean',
            'ç«¶é¦¬å ´ã‚°ãƒ¬ãƒ¼ãƒ‰é‡ã¿': 'mean',
            'ç«¶é¦¬å ´å¨ä¿¡åº¦é‡ã¿': 'mean',
            'ç«¶é¦¬å ´è¨­å‚™é‡ã¿': 'mean',
            'å‹åˆ©': ['count', 'sum', 'mean'],
            'è¤‡å‹': ['sum', 'mean'],  # è¤‡å‹å›æ•°ã¨è¤‡å‹ç‡ã‚’è¿½åŠ 
            'ç€é †': 'mean'
        }).round(4)
        
        # ã‚«ãƒ©ãƒ åã‚’æ•´ç†
        horse_weights.columns = [
            'å¹³å‡é‡ã¿ä»˜ã‘ãƒã‚¤ãƒ³ãƒˆ', 'å¹³å‡ã‚°ãƒ¬ãƒ¼ãƒ‰é‡ã¿', 'å¹³å‡å¨ä¿¡åº¦é‡ã¿', 'å¹³å‡è¨­å‚™é‡ã¿',
            'å‡ºèµ°æ•°', 'å‹åˆ©æ•°', 'å‹ç‡', 'è¤‡å‹å›æ•°', 'è¤‡å‹ç‡', 'å¹³å‡ç€é †'
        ]
        
        # è¤‡åˆé‡ã¿ä»˜ã‘ãƒã‚¤ãƒ³ãƒˆï¼ˆé¦¬ã”ã¨ï¼‰
        horse_weights['è¤‡åˆé‡ã¿ãƒã‚¤ãƒ³ãƒˆ'] = (
            horse_weights['å¹³å‡ã‚°ãƒ¬ãƒ¼ãƒ‰é‡ã¿'] * 0.4 +
            horse_weights['å¹³å‡å¨ä¿¡åº¦é‡ã¿'] * 0.3 +
            horse_weights['å¹³å‡è¨­å‚™é‡ã¿'] * 0.3
        )
        
        # ãƒ‡ãƒ¼ã‚¿ã®æ¤œè¨¼ãƒ­ã‚°
        logger.info(f"é¦¬ã”ã¨çµ±è¨ˆ:")
        logger.info(f"  - å‹ç‡0.0ã®é¦¬: {(horse_weights['å‹ç‡'] == 0.0).sum()}é ­")
        logger.info(f"  - å‹åˆ©çµŒé¨“ã®ã‚ã‚‹é¦¬: {(horse_weights['å‹ç‡'] > 0.0).sum()}é ­")
        logger.info(f"  - å¹³å‡å‹ç‡: {horse_weights['å‹ç‡'].mean():.3f}")
        logger.info(f"  - å¹³å‡è¤‡å‹ç‡: {horse_weights['è¤‡å‹ç‡'].mean():.3f}")
        
        return horse_weights
    
    def _calculate_horse_race_point_stats(self, df_period):
        """é¦¬ã”ã¨ã®è¤‡å‹æ™‚é‡ã¿ä»˜ã‘ãƒã‚¤ãƒ³ãƒˆçµ±è¨ˆè¨ˆç®—ï¼ˆè¤‡å‹ã—ãŸå ´åˆã®ã¿ãƒã‚¤ãƒ³ãƒˆåŠ ç®—ï¼‰"""
        horse_stats_list = []
        
        for horse_name in df_period['é¦¬å'].unique():
            horse_data = df_period[df_period['é¦¬å'] == horse_name]
            
            # åŸºæœ¬çµ±è¨ˆ
            total_races = len(horse_data)
            win_count = horse_data['å‹åˆ©'].sum()
            place_count = horse_data['è¤‡å‹'].sum()
            win_rate = win_count / total_races if total_races > 0 else 0
            place_rate = place_count / total_races if total_races > 0 else 0
            avg_rank = horse_data['ç€é †'].mean()
            
            # è¤‡å‹æ™‚ã®ã¿ã®é‡ã¿ä»˜ã‘ãƒã‚¤ãƒ³ãƒˆè¨ˆç®—
            place_races = horse_data[horse_data['è¤‡å‹'] == 1]  # è¤‡å‹ã—ãŸå ´åˆã®ã¿
            
            if len(place_races) > 0:
                # è¤‡å‹æ™‚ã®é‡ã¿ä»˜ã‘ãƒã‚¤ãƒ³ãƒˆå¹³å‡
                avg_point = place_races['ç«¶é¦¬å ´é‡ã¿ä»˜ã‘ãƒã‚¤ãƒ³ãƒˆ'].mean()
                # è¤‡å‹æ™‚ã®ç´¯ç©ãƒã‚¤ãƒ³ãƒˆ
                cumulative_points = place_races['ç«¶é¦¬å ´é‡ã¿ä»˜ã‘ãƒã‚¤ãƒ³ãƒˆ'].sum()
            else:
                # è¤‡å‹çµŒé¨“ãŒãªã„å ´åˆã¯0
                avg_point = 0.0
                cumulative_points = 0.0
            
            horse_stats_list.append({
                'é¦¬å': horse_name,
                'å¹³å‡é‡ã¿ä»˜ã‘ãƒã‚¤ãƒ³ãƒˆ': round(avg_point, 4),
                'ç´¯ç©é‡ã¿ä»˜ã‘ãƒã‚¤ãƒ³ãƒˆ': round(cumulative_points, 4),
                'å‡ºèµ°æ•°': total_races,
                'å‹åˆ©æ•°': win_count,
                'å‹ç‡': round(win_rate, 4),
                'è¤‡å‹å›æ•°': place_count,
                'è¤‡å‹ç‡': round(place_rate, 4),
                'å¹³å‡ç€é †': round(avg_rank, 4)
            })
        
        horse_stats = pd.DataFrame(horse_stats_list).set_index('é¦¬å')
        
        # ãƒ‡ãƒ¼ã‚¿ã®æ¤œè¨¼ãƒ­ã‚°
        logger.info(f"é¦¬ã”ã¨è¤‡å‹æ™‚é‡ã¿ä»˜ã‘ãƒã‚¤ãƒ³ãƒˆçµ±è¨ˆ:")
        logger.info(f"  - è¤‡å‹çµŒé¨“ãªã—ï¼ˆãƒã‚¤ãƒ³ãƒˆ0ï¼‰ã®é¦¬: {(horse_stats['å¹³å‡é‡ã¿ä»˜ã‘ãƒã‚¤ãƒ³ãƒˆ'] == 0.0).sum()}é ­")
        logger.info(f"  - è¤‡å‹çµŒé¨“ã‚ã‚Šï¼ˆãƒã‚¤ãƒ³ãƒˆ>0ï¼‰ã®é¦¬: {(horse_stats['å¹³å‡é‡ã¿ä»˜ã‘ãƒã‚¤ãƒ³ãƒˆ'] > 0.0).sum()}é ­")
        logger.info(f"  - å¹³å‡é‡ã¿ä»˜ã‘ãƒã‚¤ãƒ³ãƒˆç¯„å›²: {horse_stats['å¹³å‡é‡ã¿ä»˜ã‘ãƒã‚¤ãƒ³ãƒˆ'].min():.2f} - {horse_stats['å¹³å‡é‡ã¿ä»˜ã‘ãƒã‚¤ãƒ³ãƒˆ'].max():.2f}")
        logger.info(f"  - å¹³å‡å‹ç‡: {horse_stats['å‹ç‡'].mean():.3f}")
        logger.info(f"  - å¹³å‡è¤‡å‹ç‡: {horse_stats['è¤‡å‹ç‡'].mean():.3f}")
        
        return horse_stats

    def _analyze_race_point_correlation(self, horse_stats):
        """å¹³å‡é‡ã¿ä»˜ã‘ãƒã‚¤ãƒ³ãƒˆã¨å‹ç‡/è¤‡å‹ç‡ã®ç›¸é–¢åˆ†æï¼ˆè¤‡å‹æ™‚ã®ã¿ï¼‰"""
        if len(horse_stats) < 3:
            return {}
        
        results = {}
        
        try:
            # è¤‡å‹çµŒé¨“ã®ã‚ã‚‹é¦¬ã®ã¿ã§ã®åˆ†æï¼ˆãƒã‚¤ãƒ³ãƒˆ>0ï¼‰
            place_experienced_horses = horse_stats[horse_stats['å¹³å‡é‡ã¿ä»˜ã‘ãƒã‚¤ãƒ³ãƒˆ'] > 0.0]
            
            if len(place_experienced_horses) < 3:
                logger.warning("è¤‡å‹çµŒé¨“ã®ã‚ã‚‹é¦¬ãŒ3é ­æœªæº€ã®ãŸã‚ã€ç›¸é–¢åˆ†æã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™")
                return {}
            
            logger.info(f"è¤‡å‹çµŒé¨“é¦¬ã§ã®ç›¸é–¢åˆ†æ: {len(place_experienced_horses)}é ­")
            
            # === å‹åˆ©æ•°å½±éŸ¿é™¤å»ã®ãŸã‚ã®æ­£è¦åŒ–æŒ‡æ¨™è¨ˆç®— ===
            # é©åˆ‡ãªæ­£è¦åŒ–æŒ‡æ¨™ã®è¨ˆç®—
            place_experienced_horses = place_experienced_horses.copy()
            
            # 1. è¤‡å‹æ™‚ã®å¹³å‡ãƒã‚¤ãƒ³ãƒˆï¼ˆã“ã‚Œã¯æ—¢ã«ã‚ã‚‹ï¼‰
            # place_experienced_horses['å¹³å‡é‡ã¿ä»˜ã‘ãƒã‚¤ãƒ³ãƒˆ'] (æ—¢å­˜)
            
            # 2. å‡ºèµ°å›æ•°ã‚ãŸã‚Šã®æœŸå¾…ãƒã‚¤ãƒ³ãƒˆï¼ˆè¤‡å‹ç‡ã‚’è€ƒæ…®ã—ãŸæœŸå¾…å€¤ï¼‰
            place_experienced_horses['æœŸå¾…é‡ã¿ä»˜ã‘ãƒã‚¤ãƒ³ãƒˆ'] = place_experienced_horses['å¹³å‡é‡ã¿ä»˜ã‘ãƒã‚¤ãƒ³ãƒˆ'] * place_experienced_horses['è¤‡å‹ç‡']
            
            # 3. è¤‡å‹çµŒé¨“ãƒ¬ãƒ¼ã‚¹æ•°ã®å½±éŸ¿ã‚’é™¤å»ã™ã‚‹ãŸã‚ã€è¤‡å‹å›æ•°ã®ãƒ©ãƒ³ã‚¯ãƒ™ãƒ¼ã‚¹æ­£è¦åŒ–
            place_experienced_horses['è¤‡å‹å›æ•°ãƒ©ãƒ³ã‚¯'] = place_experienced_horses['è¤‡å‹å›æ•°'].rank(pct=True)
            place_experienced_horses['ç´¯ç©ãƒã‚¤ãƒ³ãƒˆ_è¤‡å‹å›æ•°èª¿æ•´'] = place_experienced_horses['ç´¯ç©é‡ã¿ä»˜ã‘ãƒã‚¤ãƒ³ãƒˆ'] / (place_experienced_horses['è¤‡å‹å›æ•°ãƒ©ãƒ³ã‚¯'] + 0.1)  # 0é™¤ç®—é˜²æ­¢
            
            # 4. æ¨™æº–åŒ–ã•ã‚ŒãŸç´¯ç©ãƒã‚¤ãƒ³ãƒˆï¼ˆZã‚¹ã‚³ã‚¢ï¼‰
            cumulative_mean = place_experienced_horses['ç´¯ç©é‡ã¿ä»˜ã‘ãƒã‚¤ãƒ³ãƒˆ'].mean()
            cumulative_std = place_experienced_horses['ç´¯ç©é‡ã¿ä»˜ã‘ãƒã‚¤ãƒ³ãƒˆ'].std()
            if cumulative_std > 0:
                place_experienced_horses['æ¨™æº–åŒ–ç´¯ç©ãƒã‚¤ãƒ³ãƒˆ'] = (place_experienced_horses['ç´¯ç©é‡ã¿ä»˜ã‘ãƒã‚¤ãƒ³ãƒˆ'] - cumulative_mean) / cumulative_std
            else:
                place_experienced_horses['æ¨™æº–åŒ–ç´¯ç©ãƒã‚¤ãƒ³ãƒˆ'] = 0
            
            # 5. å˜ç´”å‡ºèµ°æ•°æ­£è¦åŒ–ï¼ˆè¤‡å‹ç‡ã¨ç‹¬ç«‹ï¼‰- å‰Šé™¤äºˆå®šã ãŒæ¯”è¼ƒã®ãŸã‚æ®‹ã™
            place_experienced_horses['å‡ºèµ°æ•°æ­£è¦åŒ–ç´¯ç©ãƒã‚¤ãƒ³ãƒˆ'] = place_experienced_horses['ç´¯ç©é‡ã¿ä»˜ã‘ãƒã‚¤ãƒ³ãƒˆ'] / place_experienced_horses['å‡ºèµ°æ•°']
            place_experienced_horses['è¤‡å‹å›æ•°æ­£è¦åŒ–ç´¯ç©ãƒã‚¤ãƒ³ãƒˆ'] = place_experienced_horses['ç´¯ç©é‡ã¿ä»˜ã‘ãƒã‚¤ãƒ³ãƒˆ'] / place_experienced_horses['è¤‡å‹å›æ•°']
            
            # === å¹³å‡é‡ã¿ä»˜ã‘ãƒã‚¤ãƒ³ãƒˆåˆ†æ ===
            # å‹ç‡åˆ†æ
            win_rate_corr, win_rate_p = pearsonr(place_experienced_horses['å¹³å‡é‡ã¿ä»˜ã‘ãƒã‚¤ãƒ³ãƒˆ'], place_experienced_horses['å‹ç‡'])
            
            # è¤‡å‹ç‡åˆ†æ
            place_rate_corr, place_rate_p = pearsonr(place_experienced_horses['å¹³å‡é‡ã¿ä»˜ã‘ãƒã‚¤ãƒ³ãƒˆ'], place_experienced_horses['è¤‡å‹ç‡'])
            
            # ç·šå½¢å›å¸°åˆ†æ
            X_avg = place_experienced_horses[['å¹³å‡é‡ã¿ä»˜ã‘ãƒã‚¤ãƒ³ãƒˆ']].values
            y_win = place_experienced_horses['å‹ç‡'].values
            y_place = place_experienced_horses['è¤‡å‹ç‡'].values
            
            reg_win_avg = LinearRegression()
            reg_win_avg.fit(X_avg, y_win)
            win_r2_avg = reg_win_avg.score(X_avg, y_win)
            
            reg_place_avg = LinearRegression()
            reg_place_avg.fit(X_avg, y_place)
            place_r2_avg = reg_place_avg.score(X_avg, y_place)
            
            # === ç´¯ç©é‡ã¿ä»˜ã‘ãƒã‚¤ãƒ³ãƒˆï¼ˆåˆè¨ˆï¼‰åˆ†æ ===
            # å‹ç‡åˆ†æ
            cumulative_win_rate_corr, cumulative_win_rate_p = pearsonr(place_experienced_horses['ç´¯ç©é‡ã¿ä»˜ã‘ãƒã‚¤ãƒ³ãƒˆ'], place_experienced_horses['å‹ç‡'])
            
            # è¤‡å‹ç‡åˆ†æ
            cumulative_place_rate_corr, cumulative_place_rate_p = pearsonr(place_experienced_horses['ç´¯ç©é‡ã¿ä»˜ã‘ãƒã‚¤ãƒ³ãƒˆ'], place_experienced_horses['è¤‡å‹ç‡'])
            
            # ç·šå½¢å›å¸°åˆ†æ
            X_cumulative = place_experienced_horses[['ç´¯ç©é‡ã¿ä»˜ã‘ãƒã‚¤ãƒ³ãƒˆ']].values
            
            reg_win_cumulative = LinearRegression()
            reg_win_cumulative.fit(X_cumulative, y_win)
            win_r2_cumulative = reg_win_cumulative.score(X_cumulative, y_win)
            
            reg_place_cumulative = LinearRegression()
            reg_place_cumulative.fit(X_cumulative, y_place)
            place_r2_cumulative = reg_place_cumulative.score(X_cumulative, y_place)
            
            # === æ­£è¦åŒ–åˆ†æï¼ˆå‹åˆ©æ•°å½±éŸ¿é™¤å»ï¼‰ ===
            # å‡ºèµ°æ•°æ­£è¦åŒ–ç´¯ç©ãƒã‚¤ãƒ³ãƒˆåˆ†æï¼ˆæ³¨æ„ï¼šè¤‡å‹ç‡ã¨ã®ç›¸é–¢ã¯æ§‹é€ çš„ã«é«˜ããªã‚‹ï¼‰
            normalized_win_rate_corr, normalized_win_rate_p = pearsonr(place_experienced_horses['å‡ºèµ°æ•°æ­£è¦åŒ–ç´¯ç©ãƒã‚¤ãƒ³ãƒˆ'], place_experienced_horses['å‹ç‡'])
            normalized_place_rate_corr, normalized_place_rate_p = pearsonr(place_experienced_horses['å‡ºèµ°æ•°æ­£è¦åŒ–ç´¯ç©ãƒã‚¤ãƒ³ãƒˆ'], place_experienced_horses['è¤‡å‹ç‡'])
            
            # æœŸå¾…é‡ã¿ä»˜ã‘ãƒã‚¤ãƒ³ãƒˆåˆ†æï¼ˆè¤‡å‹ç‡ã‚’è€ƒæ…®ã—ãŸæœŸå¾…å€¤ï¼‰
            expected_win_rate_corr, expected_win_rate_p = pearsonr(place_experienced_horses['æœŸå¾…é‡ã¿ä»˜ã‘ãƒã‚¤ãƒ³ãƒˆ'], place_experienced_horses['å‹ç‡'])
            expected_place_rate_corr, expected_place_rate_p = pearsonr(place_experienced_horses['æœŸå¾…é‡ã¿ä»˜ã‘ãƒã‚¤ãƒ³ãƒˆ'], place_experienced_horses['è¤‡å‹ç‡'])
            
            # è¤‡å‹å›æ•°èª¿æ•´ç´¯ç©ãƒã‚¤ãƒ³ãƒˆåˆ†æ
            adjusted_win_rate_corr, adjusted_win_rate_p = pearsonr(place_experienced_horses['ç´¯ç©ãƒã‚¤ãƒ³ãƒˆ_è¤‡å‹å›æ•°èª¿æ•´'], place_experienced_horses['å‹ç‡'])
            adjusted_place_rate_corr, adjusted_place_rate_p = pearsonr(place_experienced_horses['ç´¯ç©ãƒã‚¤ãƒ³ãƒˆ_è¤‡å‹å›æ•°èª¿æ•´'], place_experienced_horses['è¤‡å‹ç‡'])
            
            # æ¨™æº–åŒ–ç´¯ç©ãƒã‚¤ãƒ³ãƒˆåˆ†æ
            std_win_rate_corr, std_win_rate_p = pearsonr(place_experienced_horses['æ¨™æº–åŒ–ç´¯ç©ãƒã‚¤ãƒ³ãƒˆ'], place_experienced_horses['å‹ç‡'])
            std_place_rate_corr, std_place_rate_p = pearsonr(place_experienced_horses['æ¨™æº–åŒ–ç´¯ç©ãƒã‚¤ãƒ³ãƒˆ'], place_experienced_horses['è¤‡å‹ç‡'])
            
            # è¤‡å‹å›æ•°æ­£è¦åŒ–ç´¯ç©ãƒã‚¤ãƒ³ãƒˆåˆ†æï¼ˆã“ã‚Œã¯å¹³å‡ã¨åŒã˜ã«ãªã‚‹ã¯ãšï¼‰
            place_normalized_win_rate_corr, place_normalized_win_rate_p = pearsonr(place_experienced_horses['è¤‡å‹å›æ•°æ­£è¦åŒ–ç´¯ç©ãƒã‚¤ãƒ³ãƒˆ'], place_experienced_horses['å‹ç‡'])
            place_normalized_place_rate_corr, place_normalized_place_rate_p = pearsonr(place_experienced_horses['è¤‡å‹å›æ•°æ­£è¦åŒ–ç´¯ç©ãƒã‚¤ãƒ³ãƒˆ'], place_experienced_horses['è¤‡å‹ç‡'])
            
            # ç·šå½¢å›å¸°åˆ†æï¼ˆæ­£è¦åŒ–ï¼‰
            X_normalized = place_experienced_horses[['å‡ºèµ°æ•°æ­£è¦åŒ–ç´¯ç©ãƒã‚¤ãƒ³ãƒˆ']].values
            X_expected = place_experienced_horses[['æœŸå¾…é‡ã¿ä»˜ã‘ãƒã‚¤ãƒ³ãƒˆ']].values
            X_adjusted = place_experienced_horses[['ç´¯ç©ãƒã‚¤ãƒ³ãƒˆ_è¤‡å‹å›æ•°èª¿æ•´']].values
            X_std = place_experienced_horses[['æ¨™æº–åŒ–ç´¯ç©ãƒã‚¤ãƒ³ãƒˆ']].values
            
            reg_win_normalized = LinearRegression()
            reg_win_normalized.fit(X_normalized, y_win)
            win_r2_normalized = reg_win_normalized.score(X_normalized, y_win)
            
            reg_place_normalized = LinearRegression()
            reg_place_normalized.fit(X_normalized, y_place)
            place_r2_normalized = reg_place_normalized.score(X_normalized, y_place)
            
            # æœŸå¾…ãƒã‚¤ãƒ³ãƒˆã§ã®å›å¸°
            reg_win_expected = LinearRegression()
            reg_win_expected.fit(X_expected, y_win)
            win_r2_expected = reg_win_expected.score(X_expected, y_win)
            
            reg_place_expected = LinearRegression()
            reg_place_expected.fit(X_expected, y_place)
            place_r2_expected = reg_place_expected.score(X_expected, y_place)
            
            # è¤‡å‹å›æ•°èª¿æ•´ã§ã®å›å¸°
            reg_win_adjusted = LinearRegression()
            reg_win_adjusted.fit(X_adjusted, y_win)
            win_r2_adjusted = reg_win_adjusted.score(X_adjusted, y_win)
            
            reg_place_adjusted = LinearRegression()
            reg_place_adjusted.fit(X_adjusted, y_place)
            place_r2_adjusted = reg_place_adjusted.score(X_adjusted, y_place)
            
            # === éƒ¨åˆ†ç›¸é–¢åˆ†æï¼ˆè¤‡å‹å›æ•°ã®å½±éŸ¿ã‚’çµ±åˆ¶ï¼‰ ===
            from scipy.stats import pearsonr as sp_pearsonr
            import numpy as np
            
            def partial_correlation(x, y, control):
                """éƒ¨åˆ†ç›¸é–¢ä¿‚æ•°ã‚’è¨ˆç®—"""
                # xã¨controlã®ç›¸é–¢
                rx_control, _ = sp_pearsonr(x, control)
                # yã¨controlã®ç›¸é–¢
                ry_control, _ = sp_pearsonr(y, control)
                # xã¨yã®ç›¸é–¢
                rxy, _ = sp_pearsonr(x, y)
                
                # éƒ¨åˆ†ç›¸é–¢ä¿‚æ•°ã®è¨ˆç®—
                numerator = rxy - (rx_control * ry_control)
                denominator = np.sqrt((1 - rx_control**2) * (1 - ry_control**2))
                
                if denominator == 0:
                    return 0, 1  # ç›¸é–¢ä¿‚æ•°ã€på€¤
                
                partial_r = numerator / denominator
                
                # ç°¡æ˜“çš„ãªpå€¤è¨ˆç®—ï¼ˆæ­£ç¢ºã§ã¯ãªã„ãŒè¿‘ä¼¼å€¤ï¼‰
                n = len(x)
                t_stat = partial_r * np.sqrt((n - 3) / (1 - partial_r**2))
                # ç°¡æ˜“çš„ã«på€¤ã‚’æ¨å®šï¼ˆæ­£ç¢ºãªçµ±è¨ˆçš„æ¤œå®šã§ã¯ãªã„ï¼‰
                p_value = 0.05 if abs(t_stat) > 1.96 else 0.1  # è¿‘ä¼¼å€¤
                
                return partial_r, p_value
            
            # ç´¯ç©ãƒã‚¤ãƒ³ãƒˆã¨å‹ç‡ã®é–¢ä¿‚ï¼ˆè¤‡å‹å›æ•°ã‚’çµ±åˆ¶ï¼‰
            partial_cumulative_win_corr, partial_cumulative_win_p = partial_correlation(
                place_experienced_horses['ç´¯ç©é‡ã¿ä»˜ã‘ãƒã‚¤ãƒ³ãƒˆ'],
                place_experienced_horses['å‹ç‡'],
                place_experienced_horses['è¤‡å‹å›æ•°']
            )
            
            # ç´¯ç©ãƒã‚¤ãƒ³ãƒˆã¨è¤‡å‹ç‡ã®é–¢ä¿‚ï¼ˆè¤‡å‹å›æ•°ã‚’çµ±åˆ¶ï¼‰
            partial_cumulative_place_corr, partial_cumulative_place_p = partial_correlation(
                place_experienced_horses['ç´¯ç©é‡ã¿ä»˜ã‘ãƒã‚¤ãƒ³ãƒˆ'],
                place_experienced_horses['è¤‡å‹ç‡'],
                place_experienced_horses['è¤‡å‹å›æ•°']
            )
            
            # === ãƒ­ã‚¸ã‚¹ãƒ†ã‚£ãƒƒã‚¯å›å¸°ï¼ˆç°¡ç•¥ç‰ˆï¼‰ ===
            # å¹³å‡ãƒã‚¤ãƒ³ãƒˆã®ã¿ã§ãƒ­ã‚¸ã‚¹ãƒ†ã‚£ãƒƒã‚¯å›å¸°ã‚’å®Ÿè¡Œ
            logistic_data_avg = []
            for _, row in place_experienced_horses.iterrows():
                point = row['å¹³å‡é‡ã¿ä»˜ã‘ãƒã‚¤ãƒ³ãƒˆ']
                for _ in range(int(row['å‹åˆ©æ•°'])):
                    logistic_data_avg.append([point, 1])
                for _ in range(int(row['å‡ºèµ°æ•°'] - row['å‹åˆ©æ•°'])):
                    logistic_data_avg.append([point, 0])
            
            if len(logistic_data_avg) > 0:
                logistic_df_avg = pd.DataFrame(logistic_data_avg, columns=['å¹³å‡é‡ã¿ä»˜ã‘ãƒã‚¤ãƒ³ãƒˆ', 'å‹åˆ©ãƒ•ãƒ©ã‚°'])
                X_logistic_avg = logistic_df_avg[['å¹³å‡é‡ã¿ä»˜ã‘ãƒã‚¤ãƒ³ãƒˆ']].values
                y_logistic_avg = logistic_df_avg['å‹åˆ©ãƒ•ãƒ©ã‚°'].values
                
                logistic_reg_avg = LogisticRegression()
                logistic_reg_avg.fit(X_logistic_avg, y_logistic_avg)
                
                results['logistic_regression_avg'] = {
                    'model': logistic_reg_avg,
                    'X': X_logistic_avg,
                    'y': y_logistic_avg
                }
            
            # çµæœã®æ ¼ç´ã¨è¿”å´
            results = {
                'place_experienced_horses': place_experienced_horses,  # æ­£è¦åŒ–æŒ‡æ¨™ã‚’å«ã‚€ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ 
                'correlation_analysis': {
                    'avg_point': {
                        'win_rate': {
                            'correlation': win_rate_corr,
                            'p_value': win_rate_p,
                            'r2': win_r2_avg,
                            'regression': reg_win_avg
                        },
                        'place_rate': {
                            'correlation': place_rate_corr,
                            'p_value': place_rate_p,
                            'r2': place_r2_avg,
                            'regression': reg_place_avg
                        }
                    },
                    'cumulative': {
                        'win_rate': {
                            'correlation': cumulative_win_rate_corr,
                            'p_value': cumulative_win_rate_p,
                            'r2': win_r2_cumulative,
                            'regression': reg_win_cumulative
                        },
                        'place_rate': {
                            'correlation': cumulative_place_rate_corr,
                            'p_value': cumulative_place_rate_p,
                            'r2': place_r2_cumulative,
                            'regression': reg_place_cumulative
                        }
                    },
                    'normalized': {
                        'win_rate': {
                            'correlation': normalized_win_rate_corr,
                            'p_value': normalized_win_rate_p,
                            'r2': win_r2_normalized,
                            'regression': reg_win_normalized
                        },
                        'place_rate': {
                            'correlation': normalized_place_rate_corr,
                            'p_value': normalized_place_rate_p,
                            'r2': place_r2_normalized,
                            'regression': reg_place_normalized
                        }
                    },
                    'expected': {
                        'win_rate': {
                            'correlation': expected_win_rate_corr,
                            'p_value': expected_win_rate_p,
                            'r2': win_r2_expected,
                            'regression': reg_win_expected
                        },
                        'place_rate': {
                            'correlation': expected_place_rate_corr,
                            'p_value': expected_place_rate_p,
                            'r2': place_r2_expected,
                            'regression': reg_place_expected
                        }
                    },
                    'adjusted': {
                        'win_rate': {
                            'correlation': adjusted_win_rate_corr,
                            'p_value': adjusted_win_rate_p,
                            'r2': win_r2_adjusted,
                            'regression': reg_win_adjusted
                        },
                        'place_rate': {
                            'correlation': adjusted_place_rate_corr,
                            'p_value': adjusted_place_rate_p,
                            'r2': place_r2_adjusted,
                            'regression': reg_place_adjusted
                        }
                    },
                    'partial_correlation': {
                        'cumulative_vs_win_rate': partial_cumulative_win_corr,
                        'cumulative_vs_place_rate': partial_cumulative_place_corr
                    }
                }
            }
            
            logger.info(f"è¤‡å‹æ™‚é‡ã¿ä»˜ã‘ãƒã‚¤ãƒ³ãƒˆç›¸é–¢åˆ†æ:")
            logger.info(f"  - å¹³å‡ãƒã‚¤ãƒ³ãƒˆ vs å‹ç‡: r={win_rate_corr:.3f}, p={win_rate_p:.3f}, RÂ²={win_r2_avg:.3f}")
            logger.info(f"  - å¹³å‡ãƒã‚¤ãƒ³ãƒˆ vs è¤‡å‹ç‡: r={place_rate_corr:.3f}, p={place_rate_p:.3f}, RÂ²={place_r2_avg:.3f}")
            logger.info(f"  - ç´¯ç©ãƒã‚¤ãƒ³ãƒˆ vs å‹ç‡: r={cumulative_win_rate_corr:.3f}, p={cumulative_win_rate_p:.3f}, RÂ²={win_r2_cumulative:.3f}")
            logger.info(f"  - ç´¯ç©ãƒã‚¤ãƒ³ãƒˆ vs è¤‡å‹ç‡: r={cumulative_place_rate_corr:.3f}, p={cumulative_place_rate_p:.3f}, RÂ²={place_r2_cumulative:.3f}")
            logger.warning(f"âš ï¸  å‡ºèµ°æ•°æ­£è¦åŒ–ç´¯ç©ãƒã‚¤ãƒ³ãƒˆ vs è¤‡å‹ç‡: r={normalized_place_rate_corr:.3f} ï¼ˆæ§‹é€ çš„ã«é«˜ç›¸é–¢ï¼‰")
            logger.info(f"  - æœŸå¾…é‡ã¿ä»˜ã‘ãƒã‚¤ãƒ³ãƒˆ vs å‹ç‡: r={expected_win_rate_corr:.3f}, p={expected_win_rate_p:.3f}, RÂ²={win_r2_expected:.3f}")
            logger.info(f"  - è¤‡å‹å›æ•°èª¿æ•´ç´¯ç©ãƒã‚¤ãƒ³ãƒˆ vs å‹ç‡: r={adjusted_win_rate_corr:.3f}, p={adjusted_win_rate_p:.3f}, RÂ²={win_r2_adjusted:.3f}")
            logger.info(f"  - æ¨™æº–åŒ–ç´¯ç©ãƒã‚¤ãƒ³ãƒˆ vs å‹ç‡: r={std_win_rate_corr:.3f}, p={std_win_rate_p:.3f}")
            logger.info(f"  - éƒ¨åˆ†ç›¸é–¢ï¼ˆè¤‡å‹å›æ•°çµ±åˆ¶ï¼‰ç´¯ç©ãƒã‚¤ãƒ³ãƒˆ vs å‹ç‡: r={partial_cumulative_win_corr:.3f}")
            logger.info(f"  - éƒ¨åˆ†ç›¸é–¢ï¼ˆè¤‡å‹å›æ•°çµ±åˆ¶ï¼‰ç´¯ç©ãƒã‚¤ãƒ³ãƒˆ vs è¤‡å‹ç‡: r={partial_cumulative_place_corr:.3f}")
        
        except Exception as e:
            logger.warning(f"é‡ã¿ä»˜ã‘ãƒã‚¤ãƒ³ãƒˆç›¸é–¢åˆ†æã§ã‚¨ãƒ©ãƒ¼: {e}")
        
        return results

    def analyze_track_win_rates(self):
        """ç«¶é¦¬å ´åˆ¥å‹ç‡åˆ†æï¼ˆ3å¹´é–“éš”ãƒ»è¤‡å‹æ™‚ã®ã¿ãƒã‚¤ãƒ³ãƒˆåŠ ç®—ï¼‰"""
        logger.info("é¦¬ã”ã¨è¤‡å‹æ™‚é‡ã¿ä»˜ã‘ãƒã‚¤ãƒ³ãƒˆåˆ†æé–‹å§‹...")
        
        results = {}
        
        # å¹´ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚‹å ´åˆã¯3å¹´é–“éš”ã§åˆ†æ
        if self.df['å¹´'].notna().any():
            min_year = int(self.df['å¹´'].min())
            max_year = int(self.df['å¹´'].max())
            logger.info(f"å¹´ãƒ‡ãƒ¼ã‚¿ç¯„å›²: {min_year}å¹´ - {max_year}å¹´")
            
            # 3å¹´é–“éš”ã§ã®æœŸé–“è¨­å®š
            periods = []
            for start_year in range(min_year, max_year + 1, 3):
                end_year = min(start_year + 2, max_year)
                periods.append((start_year, end_year))
            
            logger.info(f"åˆ†ææœŸé–“: {periods}")
            
            for start_year, end_year in periods:
                period_name = f"{start_year}-{end_year}"
                logger.info(f"æœŸé–“ {period_name} ã®åˆ†æé–‹å§‹...")
                
                # æœŸé–“ãƒ‡ãƒ¼ã‚¿ã®æŠ½å‡º
                df_period = self.df[
                    (self.df['å¹´'] >= start_year) & (self.df['å¹´'] <= end_year)
                ].copy()
                
                if len(df_period) < self.config['min_races']:
                    logger.warning(f"æœŸé–“ {period_name}: ãƒ‡ãƒ¼ã‚¿ä¸è¶³ã®ãŸã‚ã‚¹ã‚­ãƒƒãƒ— ({len(df_period)}è¡Œ)")
                    continue
                
                # é¦¬ã”ã¨ã®é‡ã¿ä»˜ã‘ãƒã‚¤ãƒ³ãƒˆè¨ˆç®—ï¼ˆå¾“æ¥é€šã‚Šï¼‰
                horse_weights = self._calculate_horse_weights(df_period)
                
                # é¦¬ã”ã¨ã®è¤‡å‹æ™‚é‡ã¿ä»˜ã‘ãƒã‚¤ãƒ³ãƒˆçµ±è¨ˆè¨ˆç®—ï¼ˆæ–°æ©Ÿèƒ½ï¼‰
                horse_race_point_stats = self._calculate_horse_race_point_stats(df_period)
                
                # æœ€å°å‡ºèµ°æ•°ã§ãƒ•ã‚£ãƒ«ã‚¿
                horse_weights_filtered = horse_weights[
                    horse_weights['å‡ºèµ°æ•°'] >= self.config['min_races']
                ]
                
                horse_race_point_filtered = horse_race_point_stats[
                    horse_race_point_stats['å‡ºèµ°æ•°'] >= self.config['min_races']
                ]
                
                if len(horse_weights_filtered) < 3:
                    logger.warning(f"æœŸé–“ {period_name}: åˆ†æå¯¾è±¡é¦¬ãŒä¸è¶³ã®ãŸã‚ã‚¹ã‚­ãƒƒãƒ—")
                    continue
                
                # ç«¶é¦¬å ´åˆ¥çµ±è¨ˆï¼ˆå¾“æ¥é€šã‚Šï¼‰
                track_stats = self._calculate_track_stats(df_period)
                
                # é‡ã¿ä»˜ã‘ãƒã‚¤ãƒ³ãƒˆç›¸é–¢åˆ†æï¼ˆå¾“æ¥é€šã‚Šï¼‰
                weight_analysis = self._analyze_weight_correlation_horses(horse_weights_filtered)
                
                # è¤‡å‹æ™‚é‡ã¿ä»˜ã‘ãƒã‚¤ãƒ³ãƒˆç›¸é–¢åˆ†æï¼ˆæ–°æ©Ÿèƒ½ï¼‰
                race_point_correlation = self._analyze_race_point_correlation(horse_race_point_filtered)
                
                results[period_name] = {
                    'horse_weights': horse_weights_filtered,
                    'horse_race_point_stats': horse_race_point_filtered,
                    'track_stats': track_stats,
                    'weight_analysis': weight_analysis,
                    'race_point_correlation': race_point_correlation,
                    'period': (start_year, end_year),
                    'total_races': len(df_period),
                    'total_horses': len(horse_weights_filtered)
                }
        
        else:
            # å¹´ãƒ‡ãƒ¼ã‚¿ãŒãªã„å ´åˆã¯å…¨æœŸé–“ã§åˆ†æ
            logger.info("å…¨æœŸé–“ã§ã®åˆ†æã‚’å®Ÿè¡Œ...")
            
            # é¦¬ã”ã¨ã®é‡ã¿ä»˜ã‘ãƒã‚¤ãƒ³ãƒˆè¨ˆç®—
            horse_weights = self._calculate_horse_weights(self.df)
            
            # é¦¬ã”ã¨ã®è¤‡å‹æ™‚é‡ã¿ä»˜ã‘ãƒã‚¤ãƒ³ãƒˆçµ±è¨ˆè¨ˆç®—ï¼ˆæ–°æ©Ÿèƒ½ï¼‰
            horse_race_point_stats = self._calculate_horse_race_point_stats(self.df)
            
            # æœ€å°å‡ºèµ°æ•°ã§ãƒ•ã‚£ãƒ«ã‚¿
            horse_weights_filtered = horse_weights[
                horse_weights['å‡ºèµ°æ•°'] >= self.config['min_races']
            ]
            
            horse_race_point_filtered = horse_race_point_stats[
                horse_race_point_stats['å‡ºèµ°æ•°'] >= self.config['min_races']
            ]
            
            # ç«¶é¦¬å ´åˆ¥çµ±è¨ˆ
            track_stats = self._calculate_track_stats(self.df)
            
            # é‡ã¿ä»˜ã‘ãƒã‚¤ãƒ³ãƒˆç›¸é–¢åˆ†æ
            weight_analysis = self._analyze_weight_correlation_horses(horse_weights_filtered)
            
            # è¤‡å‹æ™‚é‡ã¿ä»˜ã‘ãƒã‚¤ãƒ³ãƒˆç›¸é–¢åˆ†æï¼ˆæ–°æ©Ÿèƒ½ï¼‰
            race_point_correlation = self._analyze_race_point_correlation(horse_race_point_filtered)
            
            results['å…¨æœŸé–“'] = {
                'horse_weights': horse_weights_filtered,
                'horse_race_point_stats': horse_race_point_filtered,
                'track_stats': track_stats,
                'weight_analysis': weight_analysis,
                'race_point_correlation': race_point_correlation,
                'period': None,
                'total_races': len(self.df),
                'total_horses': len(horse_weights_filtered)
            }
        
        return results
    
    def _calculate_track_stats(self, df_period):
        """ç«¶é¦¬å ´åˆ¥çµ±è¨ˆè¨ˆç®—"""
        track_stats = df_period.groupby('å ´å').agg({
            'å‹åˆ©': ['count', 'sum', 'mean'],
            'è¤‡å‹': 'mean',
            'ç€é †': 'mean',
            'é¦¬å': 'nunique'
        }).round(4)
        
        track_stats.columns = ['å‡ºèµ°æ•°', 'å‹åˆ©æ•°', 'å‹ç‡', 'è¤‡å‹ç‡', 'å¹³å‡ç€é †', 'å‡ºèµ°é¦¬æ•°']
        
        # ç«¶é¦¬å ´æƒ…å ±ã‚’è¿½åŠ 
        track_stats['ç«¶é¦¬å ´ãƒ¬ãƒ™ãƒ«'] = track_stats.index.map(
            lambda x: self.track_hierarchy.get(x, {}).get('level', 0)
        )
        track_stats['ç«¶é¦¬å ´ã‚¿ã‚¤ãƒ—'] = track_stats.index.map(
            lambda x: self.track_hierarchy.get(x, {}).get('type', 'ä¸æ˜')
        )
        track_stats['é‡ã¿ä»˜ã‘ãƒã‚¤ãƒ³ãƒˆ'] = track_stats.index.map(
            lambda x: self.track_hierarchy.get(x, {}).get('weight_points', 0)
        )
        
        return track_stats
    
    def _analyze_weight_correlation_horses(self, horse_weights):
        """é¦¬ã”ã¨é‡ã¿ä»˜ã‘ãƒã‚¤ãƒ³ãƒˆã¨å‹ç‡ã®ç›¸é–¢åˆ†æï¼ˆå¾“æ¥é€šã‚Šï¼‰"""
        if len(horse_weights) < 3:
            return {}
        
        results = {}
        
        try:
            # å‹åˆ©çµŒé¨“ã®ã‚ã‚‹é¦¬ã®ã¿ã§ã®åˆ†æã‚‚å®Ÿæ–½
            winning_horses = horse_weights[horse_weights['å‹ç‡'] > 0.0]
            logger.info(f"å‹åˆ©çµŒé¨“é¦¬ã§ã®åˆ†æ: {len(winning_horses)}é ­")
            
            # å…¨é¦¬ã§ã®åˆ†æ
            results['all_horses'] = self._perform_correlation_analysis(
                horse_weights, 'å…¨é¦¬', use_placerate=False
            )
            
            # å‹åˆ©çµŒé¨“é¦¬ã®ã¿ã§ã®åˆ†æ
            if len(winning_horses) >= 3:
                results['winning_horses'] = self._perform_correlation_analysis(
                    winning_horses, 'å‹åˆ©çµŒé¨“é¦¬', use_placerate=False
                )
            
            # è¤‡å‹ç‡ã§ã®åˆ†æï¼ˆå…¨é¦¬ï¼‰
            results['placerate_analysis'] = self._perform_correlation_analysis(
                horse_weights, 'è¤‡å‹ç‡åˆ†æ', use_placerate=True
            )
            
            results['horse_weights'] = horse_weights
            results['winning_horses_data'] = winning_horses if len(winning_horses) >= 3 else None
        
        except Exception as e:
            logger.warning(f"é‡ã¿ä»˜ã‘ç›¸é–¢åˆ†æã§ã‚¨ãƒ©ãƒ¼: {e}")
        
        return results
    
    def _perform_correlation_analysis(self, data, analysis_name, use_placerate=False):
        """ç›¸é–¢åˆ†æã®å®Ÿè¡Œ"""
        target_rate = 'è¤‡å‹ç‡' if use_placerate else 'å‹ç‡'
        
        analysis_results = {}
        
        # 1. ãƒ”ã‚¢ã‚½ãƒ³ç›¸é–¢åˆ†æ
        weight_corr, weight_p = pearsonr(data['å¹³å‡é‡ã¿ä»˜ã‘ãƒã‚¤ãƒ³ãƒˆ'], data[target_rate])
        composite_corr, composite_p = pearsonr(data['è¤‡åˆé‡ã¿ãƒã‚¤ãƒ³ãƒˆ'], data[target_rate])
        
        analysis_results['pearson_correlation'] = {
            'weight_win_corr': weight_corr,
            'weight_win_p': weight_p,
            'composite_win_corr': composite_corr,
            'composite_win_p': composite_p,
            'target_rate': target_rate
        }
        
        # 2. ã‚¹ãƒ”ã‚¢ãƒãƒ³ç›¸é–¢åˆ†æ
        weight_spear, weight_spear_p = spearmanr(data['å¹³å‡é‡ã¿ä»˜ã‘ãƒã‚¤ãƒ³ãƒˆ'], data[target_rate])
        composite_spear, composite_spear_p = spearmanr(data['è¤‡åˆé‡ã¿ãƒã‚¤ãƒ³ãƒˆ'], data[target_rate])
        
        analysis_results['spearman_correlation'] = {
            'weight_win_corr': weight_spear,
            'weight_win_p': weight_spear_p,
            'composite_win_corr': composite_spear,
            'composite_win_p': composite_spear_p,
            'target_rate': target_rate
        }
        
        # 3. ç·šå½¢å›å¸°åˆ†æ
        X_weight = data[['å¹³å‡é‡ã¿ä»˜ã‘ãƒã‚¤ãƒ³ãƒˆ']].values
        X_composite = data[['è¤‡åˆé‡ã¿ãƒã‚¤ãƒ³ãƒˆ']].values
        y = data[target_rate].values
        
        reg_weight = LinearRegression()
        reg_weight.fit(X_weight, y)
        weight_r2 = reg_weight.score(X_weight, y)
        
        reg_composite = LinearRegression()
        reg_composite.fit(X_composite, y)
        composite_r2 = reg_composite.score(X_composite, y)
        
        analysis_results['linear_regression'] = {
            'weight': {
                'r2': weight_r2,
                'coefficient': reg_weight.coef_[0],
                'intercept': reg_weight.intercept_
            },
            'composite': {
                'r2': composite_r2,
                'coefficient': reg_composite.coef_[0],
                'intercept': reg_composite.intercept_
            },
            'target_rate': target_rate
        }
        
        logger.info(f"{analysis_name}ï¼ˆ{target_rate}ï¼‰ç›¸é–¢åˆ†æ:")
        logger.info(f"  - ãƒ”ã‚¢ã‚½ãƒ³ç›¸é–¢: r={weight_corr:.3f}, p={weight_p:.3f}")
        logger.info(f"  - æ±ºå®šä¿‚æ•°: RÂ²={weight_r2:.3f}")
        
        return analysis_results
    
    def visualize_results(self, results):
        """çµæœã®å¯è¦–åŒ–ï¼ˆ3å¹´é–“éš”ãƒ»è¤‡å‹æ™‚ã®ã¿ãƒã‚¤ãƒ³ãƒˆåŠ ç®—å¯¾å¿œï¼‰"""
        logger.info("çµæœã®å¯è¦–åŒ–é–‹å§‹...")
        
        output_dir = Path(self.config['output_dir'])
        output_dir.mkdir(parents=True, exist_ok=True)
        
        for period_name, period_results in results.items():
            logger.info(f"æœŸé–“ {period_name} ã®å¯è¦–åŒ–...")
            
            period_output_dir = output_dir / period_name
            period_output_dir.mkdir(parents=True, exist_ok=True)
            
            # ç«¶é¦¬å ´åˆ¥åˆ†æ
            if 'track_stats' in period_results:
                self._plot_track_analysis(period_results, period_output_dir, period_name)
            
            # é¦¬ã”ã¨é‡ã¿ä»˜ã‘ãƒã‚¤ãƒ³ãƒˆåˆ†æï¼ˆå¾“æ¥é€šã‚Šï¼‰
            if 'weight_analysis' in period_results and 'horse_weights' in period_results['weight_analysis']:
                self._plot_horse_weight_analysis(period_results['weight_analysis'], period_output_dir, period_name)
            
            # è¤‡å‹æ™‚é‡ã¿ä»˜ã‘ãƒã‚¤ãƒ³ãƒˆç›¸é–¢åˆ†æï¼ˆæ–°æ©Ÿèƒ½ï¼‰
            if ('horse_race_point_stats' in period_results and 
                'race_point_correlation' in period_results and
                'correlation_analysis' in period_results['race_point_correlation']):
                
                self._plot_race_point_correlation_analysis(
                    period_results['horse_race_point_stats'],
                    period_results['race_point_correlation'],
                    period_output_dir,
                    period_name
                )
        
        logger.info("å¯è¦–åŒ–å®Œäº†")
    
    def _plot_track_analysis(self, period_results, output_dir, period_name):
        """ç«¶é¦¬å ´åˆ†æå¯è¦–åŒ–"""
        track_stats = period_results['track_stats']
        
        # å‡ºèµ°æ•°ã§ãƒ•ã‚£ãƒ«ã‚¿
        track_stats_filtered = track_stats[track_stats['å‡ºèµ°æ•°'] >= self.config['min_races']]
        
        if len(track_stats_filtered) == 0:
            return
        
        fig, axes = plt.subplots(2, 2, figsize=(16, 12))
        fig.suptitle(f'ç«¶é¦¬å ´åˆ¥åˆ†æ ({period_name})', fontsize=16)
        
        # å‹ç‡
        ax1 = axes[0, 0]
        track_sorted = track_stats_filtered.sort_values('å‹ç‡', ascending=True)
        colors = ['red' if x == 'åœ°æ–¹' else 'blue' for x in track_sorted['ç«¶é¦¬å ´ã‚¿ã‚¤ãƒ—']]
        ax1.barh(range(len(track_sorted)), track_sorted['å‹ç‡'], color=colors, alpha=0.7)
        ax1.set_yticks(range(len(track_sorted)))
        ax1.set_yticklabels(track_sorted.index, fontsize=8)
        ax1.set_xlabel('å‹ç‡')
        ax1.set_title('ç«¶é¦¬å ´åˆ¥å‹ç‡')
        ax1.grid(True, alpha=0.3)
        
        # å‡ºèµ°æ•°
        ax2 = axes[0, 1]
        ax2.bar(range(len(track_sorted)), track_sorted['å‡ºèµ°æ•°'], alpha=0.7, color='orange')
        ax2.set_xticks(range(len(track_sorted)))
        ax2.set_xticklabels(track_sorted.index, rotation=45, fontsize=8)
        ax2.set_ylabel('å‡ºèµ°æ•°')
        ax2.set_title('ç«¶é¦¬å ´åˆ¥å‡ºèµ°æ•°')
        ax2.grid(True, alpha=0.3)
        
        # é‡ã¿ä»˜ã‘ãƒã‚¤ãƒ³ãƒˆ vs å‹ç‡
        ax3 = axes[1, 0]
        central_tracks = track_stats_filtered[track_stats_filtered['ç«¶é¦¬å ´ã‚¿ã‚¤ãƒ—'] == 'ä¸­å¤®']
        local_tracks = track_stats_filtered[track_stats_filtered['ç«¶é¦¬å ´ã‚¿ã‚¤ãƒ—'] == 'åœ°æ–¹']
        
        if len(central_tracks) > 0:
            ax3.scatter(central_tracks['é‡ã¿ä»˜ã‘ãƒã‚¤ãƒ³ãƒˆ'], central_tracks['å‹ç‡'], 
                       color='blue', alpha=0.7, label='ä¸­å¤®', s=60)
        if len(local_tracks) > 0:
            ax3.scatter(local_tracks['é‡ã¿ä»˜ã‘ãƒã‚¤ãƒ³ãƒˆ'], local_tracks['å‹ç‡'], 
                       color='red', alpha=0.7, label='åœ°æ–¹', s=60)
        
        ax3.set_xlabel('é‡ã¿ä»˜ã‘ãƒã‚¤ãƒ³ãƒˆ')
        ax3.set_ylabel('å‹ç‡')
        ax3.set_title('ç«¶é¦¬å ´é‡ã¿ä»˜ã‘ãƒã‚¤ãƒ³ãƒˆ vs å‹ç‡')
        ax3.legend()
        ax3.grid(True, alpha=0.3)
        
        # å¹³å‡ç€é †
        ax4 = axes[1, 1]
        ax4.barh(range(len(track_sorted)), track_sorted['å¹³å‡ç€é †'], color=colors, alpha=0.7)
        ax4.set_yticks(range(len(track_sorted)))
        ax4.set_yticklabels(track_sorted.index, fontsize=8)
        ax4.set_xlabel('å¹³å‡ç€é †')
        ax4.set_title('ç«¶é¦¬å ´åˆ¥å¹³å‡ç€é †')
        ax4.grid(True, alpha=0.3)
        
        plt.tight_layout()
        plt.savefig(output_dir / f'ç«¶é¦¬å ´åˆ¥åˆ†æ_{period_name}.png', dpi=300, bbox_inches='tight')
        plt.close()
    
    def _plot_horse_weight_analysis(self, weight_analysis, output_dir, period_name):
        """é¦¬ã”ã¨é‡ã¿ä»˜ã‘ãƒã‚¤ãƒ³ãƒˆåˆ†æå¯è¦–åŒ–ï¼ˆå¾“æ¥é€šã‚Šï¼‰"""
        
        # weight_analysisã®æ§‹é€ ã«å¿œã˜ã¦é©åˆ‡ãªãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
        if 'horse_weights' in weight_analysis:
            horse_weights = weight_analysis['horse_weights']
        else:
            logger.warning(f"æœŸé–“ {period_name}: horse_weightsãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
            return
        
        # main_analysisãŒå­˜åœ¨ã™ã‚‹ã‹ãƒã‚§ãƒƒã‚¯ã€ãªã‘ã‚Œã°all_horsesã‚’ä½¿ç”¨
        if 'main_analysis' in weight_analysis:
            main_analysis = weight_analysis['main_analysis']
        elif 'all_horses' in weight_analysis:
            main_analysis = weight_analysis['all_horses']
        else:
            logger.warning(f"æœŸé–“ {period_name}: ç›¸é–¢åˆ†æãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
            main_analysis = None
        
        # å‹åˆ©çµŒé¨“ã®ã‚ã‚‹é¦¬ã®ã¿ã‚’æŠ½å‡ºï¼ˆãƒ—ãƒ­ãƒƒãƒˆç”¨ï¼‰
        plot_data = horse_weights[horse_weights['å‹åˆ©æ•°'] > 0].copy()
        
        if len(plot_data) == 0:
            logger.warning(f"æœŸé–“ {period_name}: å‹åˆ©çµŒé¨“ã®ã‚ã‚‹é¦¬ãŒã„ãªã„ãŸã‚ã€æ•£å¸ƒå›³ã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™")
            return
        
        # 6ã¤ã®ã‚µãƒ–ãƒ—ãƒ­ãƒƒãƒˆã‚’ä½œæˆ
        fig, axes = plt.subplots(2, 3, figsize=(20, 12))
        
        # 1. å¹³å‡é‡ã¿ä»˜ã‘ãƒã‚¤ãƒ³ãƒˆ vs å‹ç‡
        ax1 = axes[0, 0]
        
        # ãƒ¬ãƒ¼ã‚¹å›æ•°ï¼ˆå‡ºèµ°æ•°ï¼‰ã«åŸºã¥ãã‚µã‚¤ã‚ºè¨­å®šï¼ˆã‚ˆã‚Šæ˜ç¢ºã«ï¼‰
        min_size = 30
        max_size = 200
        race_counts = plot_data['å‡ºèµ°æ•°']
        # ãƒ¬ãƒ¼ã‚¹å›æ•°ã‚’æ­£è¦åŒ–ã—ã¦ã‚µã‚¤ã‚ºã«å¤‰æ›
        normalized_sizes = min_size + (race_counts - race_counts.min()) / (race_counts.max() - race_counts.min()) * (max_size - min_size)
        
        scatter1 = ax1.scatter(plot_data['å¹³å‡é‡ã¿ä»˜ã‘ãƒã‚¤ãƒ³ãƒˆ'], plot_data['å‹ç‡'], 
                             c=plot_data['å‡ºèµ°æ•°'], cmap='viridis', 
                             alpha=0.7, s=normalized_sizes, edgecolors='black', linewidth=0.5)
        
        plt.colorbar(scatter1, ax=ax1, label='å‡ºèµ°æ•°')
        ax1.set_xlabel('å¹³å‡é‡ã¿ä»˜ã‘ãƒã‚¤ãƒ³ãƒˆ')
        ax1.set_ylabel('å‹ç‡')
        ax1.set_title('å¹³å‡é‡ã¿ä»˜ã‘ãƒã‚¤ãƒ³ãƒˆ vs å‹ç‡')
        ax1.grid(True, alpha=0.3)
        
        # 2. ç´¯ç©é‡ã¿ä»˜ã‘ãƒã‚¤ãƒ³ãƒˆ vs å‹ç‡ï¼ˆhorse_weightsã«ç´¯ç©ãƒã‚¤ãƒ³ãƒˆãŒã‚ã‚‹ã‹ãƒã‚§ãƒƒã‚¯ï¼‰
        ax2 = axes[0, 1]
        
        if 'ç´¯ç©é‡ã¿ä»˜ã‘ãƒã‚¤ãƒ³ãƒˆ' in plot_data.columns:
            # ç´¯ç©ãƒã‚¤ãƒ³ãƒˆç”¨ã®ã‚µã‚¤ã‚ºè¨­å®š
            cumulative_counts = plot_data['å‡ºèµ°æ•°']
            normalized_sizes_cum = min_size + (cumulative_counts - cumulative_counts.min()) / (cumulative_counts.max() - cumulative_counts.min()) * (max_size - min_size)
            
            scatter2 = ax2.scatter(plot_data['ç´¯ç©é‡ã¿ä»˜ã‘ãƒã‚¤ãƒ³ãƒˆ'], plot_data['å‹ç‡'], 
                                 c=plot_data['å‡ºèµ°æ•°'], cmap='plasma', 
                                 alpha=0.7, s=normalized_sizes_cum, edgecolors='black', linewidth=0.5)
            
            plt.colorbar(scatter2, ax=ax2, label='å‡ºèµ°æ•°')
            ax2.set_xlabel('ç´¯ç©é‡ã¿ä»˜ã‘ãƒã‚¤ãƒ³ãƒˆ')
            ax2.set_ylabel('å‹ç‡')
            ax2.set_title('ç´¯ç©é‡ã¿ä»˜ã‘ãƒã‚¤ãƒ³ãƒˆ vs å‹ç‡')
        else:
            # ç´¯ç©ãƒã‚¤ãƒ³ãƒˆãŒãªã„å ´åˆã¯ä»£æ›¿ã¨ã—ã¦å¹³å‡ãƒã‚¤ãƒ³ãƒˆÃ—å‡ºèµ°æ•°ã‚’è¡¨ç¤º
            cumulative_proxy = plot_data['å¹³å‡é‡ã¿ä»˜ã‘ãƒã‚¤ãƒ³ãƒˆ'] * plot_data['å‡ºèµ°æ•°']
            cumulative_counts = plot_data['å‡ºèµ°æ•°']
            normalized_sizes_cum = min_size + (cumulative_counts - cumulative_counts.min()) / (cumulative_counts.max() - cumulative_counts.min()) * (max_size - min_size)
            
            scatter2 = ax2.scatter(cumulative_proxy, plot_data['å‹ç‡'], 
                                 c=plot_data['å‡ºèµ°æ•°'], cmap='plasma', 
                                 alpha=0.7, s=normalized_sizes_cum, edgecolors='black', linewidth=0.5)
            
            plt.colorbar(scatter2, ax=ax2, label='å‡ºèµ°æ•°')
            ax2.set_xlabel('æ¨å®šç´¯ç©é‡ã¿ä»˜ã‘ãƒã‚¤ãƒ³ãƒˆï¼ˆå¹³å‡Ã—å‡ºèµ°æ•°ï¼‰')
            ax2.set_ylabel('å‹ç‡')
            ax2.set_title('æ¨å®šç´¯ç©é‡ã¿ä»˜ã‘ãƒã‚¤ãƒ³ãƒˆ vs å‹ç‡')
        ax2.grid(True, alpha=0.3)
        
        # 3. è¤‡åˆé‡ã¿ä»˜ã‘ãƒã‚¤ãƒ³ãƒˆ vs å‹ç‡
        ax3 = axes[0, 2]
        
        # è¤‡åˆãƒã‚¤ãƒ³ãƒˆç”¨ã®ã‚µã‚¤ã‚ºè¨­å®š
        composite_counts = plot_data['å‡ºèµ°æ•°']
        normalized_sizes_comp = min_size + (composite_counts - composite_counts.min()) / (composite_counts.max() - composite_counts.min()) * (max_size - min_size)
        
        scatter3 = ax3.scatter(plot_data['è¤‡åˆé‡ã¿ãƒã‚¤ãƒ³ãƒˆ'], plot_data['å‹ç‡'], 
                             c=plot_data['å‡ºèµ°æ•°'], cmap='coolwarm', 
                             alpha=0.7, s=normalized_sizes_comp, edgecolors='black', linewidth=0.5)
        
        plt.colorbar(scatter3, ax=ax3, label='å‡ºèµ°æ•°')
        ax3.set_xlabel('è¤‡åˆé‡ã¿ä»˜ã‘ãƒã‚¤ãƒ³ãƒˆ')
        ax3.set_ylabel('å‹ç‡')
        ax3.set_title('è¤‡åˆé‡ã¿ä»˜ã‘ãƒã‚¤ãƒ³ãƒˆ vs å‹ç‡')
        ax3.grid(True, alpha=0.3)
        
        # 4. å‡ºèµ°æ•° vs å‹ç‡ï¼ˆé‡ã¿ä»˜ã‘ãƒã‚¤ãƒ³ãƒˆåˆ¥ï¼‰
        ax4 = axes[1, 0]
        
        # å‡ºèµ°æ•°vså‹ç‡ç”¨ã®ã‚µã‚¤ã‚ºè¨­å®šï¼ˆå¹³å‡é‡ã¿ä»˜ã‘ãƒã‚¤ãƒ³ãƒˆã«åŸºã¥ãï¼‰
        point_based_sizes = min_size + (plot_data['å¹³å‡é‡ã¿ä»˜ã‘ãƒã‚¤ãƒ³ãƒˆ'] - plot_data['å¹³å‡é‡ã¿ä»˜ã‘ãƒã‚¤ãƒ³ãƒˆ'].min()) / (plot_data['å¹³å‡é‡ã¿ä»˜ã‘ãƒã‚¤ãƒ³ãƒˆ'].max() - plot_data['å¹³å‡é‡ã¿ä»˜ã‘ãƒã‚¤ãƒ³ãƒˆ'].min()) * (max_size - min_size)
        
        scatter4 = ax4.scatter(plot_data['å‡ºèµ°æ•°'], plot_data['å‹ç‡'], 
                             c=plot_data['å¹³å‡é‡ã¿ä»˜ã‘ãƒã‚¤ãƒ³ãƒˆ'], cmap='viridis', 
                             alpha=0.7, s=point_based_sizes, edgecolors='black', linewidth=0.5)
        
        plt.colorbar(scatter4, ax=ax4, label='å¹³å‡é‡ã¿ä»˜ã‘ãƒã‚¤ãƒ³ãƒˆ')
        ax4.set_xlabel('å‡ºèµ°æ•°')
        ax4.set_ylabel('å‹ç‡')
        ax4.set_title('å‡ºèµ°æ•° vs å‹ç‡ï¼ˆé‡ã¿ä»˜ã‘ãƒã‚¤ãƒ³ãƒˆåˆ¥ï¼‰')
        ax4.grid(True, alpha=0.3)
        
        # 5. ç›¸é–¢ä¿‚æ•°æ¯”è¼ƒ
        ax5 = axes[1, 1]
        
        if main_analysis and 'pearson_correlation' in main_analysis and 'spearman_correlation' in main_analysis:
            pearson_data = [
                main_analysis['pearson_correlation']['weight_win_corr'],
                main_analysis['pearson_correlation']['composite_win_corr']
            ]
            spearman_data = [
                main_analysis['spearman_correlation']['weight_win_corr'],
                main_analysis['spearman_correlation']['composite_win_corr']
            ]
            
            x_pos = np.arange(2)
            width = 0.35
            
            ax5.bar(x_pos - width/2, pearson_data, width, label='ãƒ”ã‚¢ã‚½ãƒ³ç›¸é–¢', alpha=0.7)
            ax5.bar(x_pos + width/2, spearman_data, width, label='ã‚¹ãƒ”ã‚¢ãƒãƒ³ç›¸é–¢', alpha=0.7)
            
            ax5.set_xlabel('é‡ã¿ä»˜ã‘ã‚¿ã‚¤ãƒ—')
            ax5.set_ylabel('ç›¸é–¢ä¿‚æ•°')
            ax5.set_title('ç›¸é–¢ä¿‚æ•°æ¯”è¼ƒ')
            ax5.set_xticks(x_pos)
            ax5.set_xticklabels(['å¹³å‡é‡ã¿ä»˜ã‘', 'è¤‡åˆé‡ã¿ä»˜ã‘'])
            ax5.legend()
            ax5.grid(True, alpha=0.3)
        else:
            # ç›¸é–¢åˆ†æãƒ‡ãƒ¼ã‚¿ãŒãªã„å ´åˆã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
            ax5.text(0.5, 0.5, 'ç›¸é–¢åˆ†æãƒ‡ãƒ¼ã‚¿ãªã—', 
                    transform=ax5.transAxes, ha='center', va='center',
                    fontsize=14, bbox=dict(boxstyle='round', facecolor='lightgray'))
            ax5.set_title('ç›¸é–¢ä¿‚æ•°æ¯”è¼ƒ')
            ax5.axis('off')
        
        # 6. å‹ç‡åˆ†å¸ƒ
        ax6 = axes[1, 2]
        ax6.hist(horse_weights['å‹ç‡'], bins=20, alpha=0.7, color='skyblue', edgecolor='black', label='å…¨é¦¬')
        if len(plot_data) < len(horse_weights):  # å‹åˆ©çµŒé¨“é¦¬ã®ã¿ã®å ´åˆ
            ax6.hist(plot_data['å‹ç‡'], bins=20, alpha=0.7, color='orange', edgecolor='black', label='å‹åˆ©çµŒé¨“é¦¬')
        
        ax6.set_xlabel('å‹ç‡')
        ax6.set_ylabel('é¦¬æ•°')
        ax6.set_title('å‹ç‡åˆ†å¸ƒ')
        ax6.legend()
        ax6.grid(True, alpha=0.3)
        
        # å…¨ä½“ã®ã‚¿ã‚¤ãƒˆãƒ«ã«å‡ºèµ°æ•°æƒ…å ±ã‚’è¿½åŠ 
        fig.suptitle(f'é¦¬ã”ã¨é‡ã¿ä»˜ã‘åˆ†æ ({period_name})\nå‡ºèµ°æ•°ç¯„å›²: {int(race_counts.min())}ï½{int(race_counts.max())}å› (å¹³å‡: {race_counts.mean():.1f}å›)', 
                    fontsize=16, fontweight='bold')
        
        plt.tight_layout()
        plt.savefig(output_dir / f'é¦¬ã”ã¨é‡ã¿ä»˜ã‘åˆ†æ_{period_name}.png', dpi=300, bbox_inches='tight')
        plt.close()
        
        logger.info(f"é¦¬ã”ã¨é‡ã¿ä»˜ã‘åˆ†æå›³ã‚’ä¿å­˜: {output_dir / f'é¦¬ã”ã¨é‡ã¿ä»˜ã‘åˆ†æ_{period_name}.png'}")
    
    def _plot_race_point_correlation_analysis(self, horse_stats, correlation_results, output_dir, period_name):
        """è¤‡å‹æ™‚é‡ã¿ä»˜ã‘ãƒã‚¤ãƒ³ãƒˆç›¸é–¢åˆ†æã®å¯è¦–åŒ–ï¼ˆæŒ‡å®šãƒ•ã‚¡ã‚¤ãƒ«åï¼‰"""
        if 'correlation_analysis' not in correlation_results:
            return
        
        correlation_data = correlation_results['correlation_analysis']
        place_experienced_horses = correlation_results.get('place_experienced_horses', horse_stats)
        
        # === å¹³å‡é‡ã¿ä»˜ã‘ãƒã‚¤ãƒ³ãƒˆåˆ†æ ===
        # 1. é‡ã¿ä»˜ã‘ãƒã‚¤ãƒ³ãƒˆï¼ˆå¹³å‡ï¼‰ã¨å‹ç‡ã®é–¢ä¿‚ï¼ˆè¤‡å‹çµŒé¨“é¦¬ã®ã¿ï¼‰
        self._plot_correlation_scatter(
            place_experienced_horses, 
            'é‡ã¿ä»˜ã‘ãƒã‚¤ãƒ³ãƒˆï¼ˆå¹³å‡ï¼‰ã¨å‹ç‡ã®é–¢ä¿‚',
            'å¹³å‡é‡ã¿ä»˜ã‘ãƒã‚¤ãƒ³ãƒˆ',
            'å‹ç‡',
            correlation_data['avg_point']['win_rate'],
            output_dir / f'é‡ã¿ä»˜ã‘ãƒã‚¤ãƒ³ãƒˆï¼ˆå¹³å‡ï¼‰ã¨å‹ç‡ã®é–¢ä¿‚_correlation.png'
        )
        
        # 2. é‡ã¿ä»˜ã‘ãƒã‚¤ãƒ³ãƒˆï¼ˆå¹³å‡ï¼‰ã¨è¤‡å‹ç‡ã®é–¢ä¿‚ï¼ˆè¤‡å‹çµŒé¨“é¦¬ã®ã¿ï¼‰
        self._plot_correlation_scatter(
            place_experienced_horses,
            'é‡ã¿ä»˜ã‘ãƒã‚¤ãƒ³ãƒˆï¼ˆå¹³å‡ï¼‰ã¨è¤‡å‹ç‡ã®é–¢ä¿‚', 
            'å¹³å‡é‡ã¿ä»˜ã‘ãƒã‚¤ãƒ³ãƒˆ',
            'è¤‡å‹ç‡',
            correlation_data['avg_point']['place_rate'],
            output_dir / f'é‡ã¿ä»˜ã‘ãƒã‚¤ãƒ³ãƒˆï¼ˆå¹³å‡ï¼‰ã¨è¤‡å‹ç‡ã®é–¢ä¿‚_correlation.png'
        )
        
        # === ç´¯ç©é‡ã¿ä»˜ã‘ãƒã‚¤ãƒ³ãƒˆï¼ˆåˆè¨ˆï¼‰åˆ†æ ===
        # 3. é‡ã¿ä»˜ã‘ãƒã‚¤ãƒ³ãƒˆï¼ˆåˆè¨ˆï¼‰ã¨å‹ç‡ã®é–¢ä¿‚ï¼ˆè¤‡å‹çµŒé¨“é¦¬ã®ã¿ï¼‰
        self._plot_correlation_scatter(
            place_experienced_horses,
            'é‡ã¿ä»˜ã‘ãƒã‚¤ãƒ³ãƒˆï¼ˆåˆè¨ˆï¼‰ã¨å‹ç‡ã®é–¢ä¿‚',
            'ç´¯ç©é‡ã¿ä»˜ã‘ãƒã‚¤ãƒ³ãƒˆ',
            'å‹ç‡',
            correlation_data['cumulative']['win_rate'],
            output_dir / f'é‡ã¿ä»˜ã‘ãƒã‚¤ãƒ³ãƒˆï¼ˆåˆè¨ˆï¼‰ã¨å‹ç‡ã®é–¢ä¿‚_correlation.png'
        )
        
        # 4. é‡ã¿ä»˜ã‘ãƒã‚¤ãƒ³ãƒˆï¼ˆåˆè¨ˆï¼‰ã¨è¤‡å‹ç‡ã®é–¢ä¿‚ï¼ˆè¤‡å‹çµŒé¨“é¦¬ã®ã¿ï¼‰
        self._plot_correlation_scatter(
            place_experienced_horses,
            'é‡ã¿ä»˜ã‘ãƒã‚¤ãƒ³ãƒˆï¼ˆåˆè¨ˆï¼‰ã¨è¤‡å‹ç‡ã®é–¢ä¿‚',
            'ç´¯ç©é‡ã¿ä»˜ã‘ãƒã‚¤ãƒ³ãƒˆ',
            'è¤‡å‹ç‡',
            correlation_data['cumulative']['place_rate'],
            output_dir / f'é‡ã¿ä»˜ã‘ãƒã‚¤ãƒ³ãƒˆï¼ˆåˆè¨ˆï¼‰ã¨è¤‡å‹ç‡ã®é–¢ä¿‚_correlation.png'
        )
        
        # === æ­£è¦åŒ–åˆ†æï¼ˆå‹åˆ©æ•°å½±éŸ¿é™¤å»ï¼‰ ===
        # 5. å‡ºèµ°æ•°æ­£è¦åŒ–é‡ã¿ä»˜ã‘ãƒã‚¤ãƒ³ãƒˆã¨å‹ç‡ã®é–¢ä¿‚
        self._plot_correlation_scatter(
            place_experienced_horses,
            'æœŸå¾…é‡ã¿ä»˜ã‘ãƒã‚¤ãƒ³ãƒˆã¨å‹ç‡ã®é–¢ä¿‚ï¼ˆè¤‡å‹ç‡è€ƒæ…®ï¼‰',
            'æœŸå¾…é‡ã¿ä»˜ã‘ãƒã‚¤ãƒ³ãƒˆ',
            'å‹ç‡',
            correlation_data['expected']['win_rate'],
            output_dir / f'æœŸå¾…é‡ã¿ä»˜ã‘ãƒã‚¤ãƒ³ãƒˆã¨å‹ç‡ã®é–¢ä¿‚_correlation.png'
        )
        
        # 6. å‡ºèµ°æ•°æ­£è¦åŒ–é‡ã¿ä»˜ã‘ãƒã‚¤ãƒ³ãƒˆã¨è¤‡å‹ç‡ã®é–¢ä¿‚ï¼ˆè­¦å‘Šä»˜ãï¼‰
        self._plot_correlation_scatter_with_warning(
            place_experienced_horses,
            'å‡ºèµ°æ•°æ­£è¦åŒ–é‡ã¿ä»˜ã‘ãƒã‚¤ãƒ³ãƒˆã¨è¤‡å‹ç‡ã®é–¢ä¿‚ï¼ˆâš ï¸æ§‹é€ çš„é«˜ç›¸é–¢ï¼‰',
            'å‡ºèµ°æ•°æ­£è¦åŒ–ç´¯ç©ãƒã‚¤ãƒ³ãƒˆ',
            'è¤‡å‹ç‡',
            correlation_data['normalized']['place_rate'],
            output_dir / f'å‡ºèµ°æ•°æ­£è¦åŒ–é‡ã¿ä»˜ã‘ãƒã‚¤ãƒ³ãƒˆã¨è¤‡å‹ç‡ã®é–¢ä¿‚_correlation.png'
        )
        
        # 7. è¤‡å‹å›æ•°èª¿æ•´ç´¯ç©ãƒã‚¤ãƒ³ãƒˆã¨å‹ç‡ã®é–¢ä¿‚
        self._plot_correlation_scatter(
            place_experienced_horses,
            'è¤‡å‹å›æ•°èª¿æ•´ç´¯ç©ãƒã‚¤ãƒ³ãƒˆã¨å‹ç‡ã®é–¢ä¿‚ï¼ˆãƒã‚¤ã‚¢ã‚¹é™¤å»ï¼‰',
            'ç´¯ç©ãƒã‚¤ãƒ³ãƒˆ_è¤‡å‹å›æ•°èª¿æ•´',
            'å‹ç‡',
            correlation_data['adjusted']['win_rate'],
            output_dir / f'è¤‡å‹å›æ•°èª¿æ•´ç´¯ç©ãƒã‚¤ãƒ³ãƒˆã¨å‹ç‡ã®é–¢ä¿‚_correlation.png'
        )
        
        # === ãƒ­ã‚¸ã‚¹ãƒ†ã‚£ãƒƒã‚¯å›å¸°æ›²ç·š ===
        # 8. å¹³å‡ãƒã‚¤ãƒ³ãƒˆã§ã®ãƒ­ã‚¸ã‚¹ãƒ†ã‚£ãƒƒã‚¯å›å¸°æ›²ç·š
        if 'logistic_regression_avg' in correlation_results:
            self._plot_logistic_regression_curve(
                correlation_results['logistic_regression_avg'],
                output_dir / f'é‡ã¿ä»˜ã‘ãƒã‚¤ãƒ³ãƒˆï¼ˆå¹³å‡ï¼‰ã¨å‹ç‡ã®é–¢ä¿‚ï¼ˆãƒ­ã‚¸ã‚¹ãƒ†ã‚£ãƒƒã‚¯å›å¸°ï¼‰_logistic_regression_curve.png'
            )
        
        # 9. ç´¯ç©ãƒã‚¤ãƒ³ãƒˆã§ã®ãƒ­ã‚¸ã‚¹ãƒ†ã‚£ãƒƒã‚¯å›å¸°æ›²ç·š
        if 'logistic_regression_cumulative' in correlation_results:
            self._plot_logistic_regression_curve(
                correlation_results['logistic_regression_cumulative'],
                output_dir / f'é‡ã¿ä»˜ã‘ãƒã‚¤ãƒ³ãƒˆï¼ˆåˆè¨ˆï¼‰ã¨å‹ç‡ã®é–¢ä¿‚ï¼ˆãƒ­ã‚¸ã‚¹ãƒ†ã‚£ãƒƒã‚¯å›å¸°ï¼‰_logistic_regression_curve.png'
            )
        
        # 10. æ­£è¦åŒ–ãƒã‚¤ãƒ³ãƒˆã§ã®ãƒ­ã‚¸ã‚¹ãƒ†ã‚£ãƒƒã‚¯å›å¸°æ›²ç·š
        if 'logistic_regression_normalized' in correlation_results:
            self._plot_logistic_regression_curve(
                correlation_results['logistic_regression_normalized'],
                output_dir / f'å‡ºèµ°æ•°æ­£è¦åŒ–é‡ã¿ä»˜ã‘ãƒã‚¤ãƒ³ãƒˆã¨å‹ç‡ã®é–¢ä¿‚ï¼ˆãƒ­ã‚¸ã‚¹ãƒ†ã‚£ãƒƒã‚¯å›å¸°ï¼‰_logistic_regression_curve.png'
            )

    def _plot_correlation_scatter(self, horse_stats, title, x_col, y_col, correlation_data, output_path):
        """ç›¸é–¢æ•£å¸ƒå›³ã®æç”»ï¼ˆè¤‡å‹çµŒé¨“é¦¬ã®ã¿ï¼‰"""
        fig, ax = plt.subplots(figsize=(12, 8))
        
        # ãƒ‡ãƒ¼ã‚¿ã®æº–å‚™
        x = horse_stats[x_col]
        y = horse_stats[y_col]
        
        # ãƒ¬ãƒ¼ã‚¹å›æ•°ï¼ˆå‡ºèµ°æ•°ï¼‰ã«åŸºã¥ãã‚µã‚¤ã‚ºè¨­å®šï¼ˆã‚ˆã‚Šæ˜ç¢ºã«ï¼‰
        min_size = 30
        max_size = 300
        race_counts = horse_stats['å‡ºèµ°æ•°']
        # ãƒ¬ãƒ¼ã‚¹å›æ•°ã‚’æ­£è¦åŒ–ã—ã¦ã‚µã‚¤ã‚ºã«å¤‰æ›
        normalized_sizes = min_size + (race_counts - race_counts.min()) / (race_counts.max() - race_counts.min()) * (max_size - min_size)
        
        # æ•£å¸ƒå›³
        scatter = ax.scatter(x, y, c=horse_stats['å‡ºèµ°æ•°'], s=normalized_sizes, alpha=0.6, 
                           cmap='viridis', edgecolors='black', linewidth=0.5)
        
        # ã‚«ãƒ©ãƒ¼ãƒãƒ¼
        cbar = plt.colorbar(scatter, ax=ax)
        cbar.set_label('å‡ºèµ°æ•°', fontsize=12)
        
        # å›å¸°ç›´ç·š
        regression = correlation_data['regression']
        x_range = np.linspace(x.min(), x.max(), 100)
        y_pred = regression.predict(x_range.reshape(-1, 1))
        ax.plot(x_range, y_pred, 'r--', linewidth=2, 
               label=f'å›å¸°ç›´ç·š (RÂ² = {correlation_data["r2"]:.3f})')
        
        # çµ±è¨ˆæƒ…å ±ã®è¡¨ç¤º
        corr = correlation_data['correlation']
        p_val = correlation_data['p_value']
        
        stats_text = f'ç›¸é–¢ä¿‚æ•°: {corr:.3f}\n'
        stats_text += f'på€¤: {p_val:.3f}\n' 
        stats_text += f'æœ‰æ„æ€§: {"æœ‰æ„" if p_val < 0.05 else "éæœ‰æ„"}\n'
        stats_text += f'å¯¾è±¡: è¤‡å‹çµŒé¨“é¦¬ã®ã¿ ({len(horse_stats)}é ­)'
        
        ax.text(0.05, 0.95, stats_text, transform=ax.transAxes,
               verticalalignment='top', fontsize=12,
               bbox=dict(boxstyle='round', facecolor='lightblue', alpha=0.8))
        
        # ãƒ¬ãƒ¼ã‚¹å›æ•°ã®ã‚µã‚¤ã‚ºå‡¡ä¾‹ã‚’è¿½åŠ 
        sizes_for_legend = [race_counts.min(), race_counts.quantile(0.5), race_counts.max()]
        labels_for_legend = [f'{int(size)}å›' for size in sizes_for_legend]
        
        # ã‚µã‚¤ã‚ºå‡¡ä¾‹ç”¨ã®ãƒãƒ¼ã‚«ãƒ¼ã‚µã‚¤ã‚ºã‚’è¨ˆç®—
        legend_sizes = []
        for size in sizes_for_legend:
            normalized_size = min_size + (size - race_counts.min()) / (race_counts.max() - race_counts.min()) * (max_size - min_size)
            legend_sizes.append(normalized_size)
        
        # ã‚µã‚¤ã‚ºå‡¡ä¾‹ã®ä½œæˆ
        legend_elements = []
        for size, label, marker_size in zip(sizes_for_legend, labels_for_legend, legend_sizes):
            legend_elements.append(plt.scatter([], [], s=marker_size, c='gray', alpha=0.6, 
                                             edgecolors='black', linewidth=0.5, label=label))
        
        # æ—¢å­˜ã®å‡¡ä¾‹ã¨çµ„ã¿åˆã‚ã›
        legend1 = plt.legend(handles=legend_elements, title="å‡ºèµ°æ•°ï¼ˆç‚¹ã®ã‚µã‚¤ã‚ºï¼‰", 
                           loc='upper left', bbox_to_anchor=(0, 0.85), frameon=True, fancybox=True, shadow=True)
        plt.gca().add_artist(legend1)
        
        # å›å¸°ç›´ç·šã®å‡¡ä¾‹
        legend2 = plt.legend(loc='upper right', frameon=True, fancybox=True, shadow=True)
        
        # ã‚°ãƒ©ãƒ•å·¦ä¸‹ã«å‡ºèµ°æ•°ã®ç¯„å›²æƒ…å ±ã‚’è¿½åŠ 
        info_text = f"å‡ºèµ°æ•°ç¯„å›²: {int(race_counts.min())}ï½{int(race_counts.max())}å›\nå¹³å‡: {race_counts.mean():.1f}å›"
        ax.text(0.02, 0.02, info_text, transform=ax.transAxes, 
                bbox=dict(boxstyle='round', facecolor='lightgray', alpha=0.8),
                verticalalignment='bottom', fontsize=10)
        
        # ãƒ©ãƒ™ãƒ«ã¨ã‚¿ã‚¤ãƒˆãƒ«
        ax.set_xlabel(f'{x_col} â€»è¤‡å‹ã—ãŸå ´åˆã®ã¿ãƒã‚¤ãƒ³ãƒˆåŠ ç®—', fontsize=12)
        ax.set_ylabel(y_col, fontsize=12)
        ax.set_title(f'{title}ï¼ˆè¤‡å‹çµŒé¨“é¦¬ã®ã¿ï¼‰', fontsize=14, fontweight='bold')
        ax.grid(True, alpha=0.3)
        
        plt.tight_layout()
        plt.savefig(output_path, dpi=300, bbox_inches='tight')
        plt.close()
        
        logger.info(f"ç›¸é–¢å›³ã‚’ä¿å­˜: {output_path}")

    def _plot_logistic_regression_curve(self, logistic_data, output_path):
        """ãƒ­ã‚¸ã‚¹ãƒ†ã‚£ãƒƒã‚¯å›å¸°æ›²ç·šã®æç”»ï¼ˆè¤‡å‹çµŒé¨“é¦¬ã®ã¿ï¼‰"""
        fig, ax = plt.subplots(figsize=(12, 8))
        
        model = logistic_data['model']
        X = logistic_data['X']
        y = logistic_data['y']
        
        # å®Ÿãƒ‡ãƒ¼ã‚¿ã®æ•£å¸ƒå›³ï¼ˆã‚¸ãƒƒã‚¿ãƒ¼ä»˜ãï¼‰
        x_vals = X.flatten()
        y_jittered = y + np.random.normal(0, 0.02, len(y))  # ã‚¸ãƒƒã‚¿ãƒ¼è¿½åŠ 
        
        # å‹åˆ©ãƒ»æ•—åŒ—ã§è‰²åˆ†ã‘
        win_mask = y == 1
        lose_mask = y == 0
        
        ax.scatter(x_vals[win_mask], y_jittered[win_mask], 
                  color='red', alpha=0.4, s=20, label='å®Ÿãƒ‡ãƒ¼ã‚¿ï¼ˆèµ¤:å‹, é’:æ•—ï¼‰')
        ax.scatter(x_vals[lose_mask], y_jittered[lose_mask], 
                  color='blue', alpha=0.4, s=20)
        
        # ãƒ­ã‚¸ã‚¹ãƒ†ã‚£ãƒƒã‚¯å›å¸°æ›²ç·š
        x_range = np.linspace(x_vals.min(), x_vals.max(), 100)
        y_prob = model.predict_proba(x_range.reshape(-1, 1))[:, 1]
        
        ax.plot(x_range, y_prob, 'g-', linewidth=3, label='ãƒ­ã‚¸ã‚¹ãƒ†ã‚£ãƒƒã‚¯å›å¸°æ›²ç·š')
        
        # 50%ãƒ©ã‚¤ãƒ³
        ax.axhline(y=0.5, color='orange', linestyle='--', alpha=0.7, label='50%ãƒ©ã‚¤ãƒ³')
        
        # äºˆæ¸¬æ›²ç·šã®èª¬æ˜
        ax.text(0.05, 0.95, 'è¤‡å‹çµŒé¨“é¦¬ã®ã¿ã®äºˆæ¸¬æ›²ç·š', transform=ax.transAxes,
               verticalalignment='top', fontsize=12,
               bbox=dict(boxstyle='round', facecolor='lightgreen', alpha=0.8))
        
        # ãƒ©ãƒ™ãƒ«ã¨ã‚¿ã‚¤ãƒˆãƒ«
        ax.set_xlabel('é‡ã¿ä»˜ã‘ãƒã‚¤ãƒ³ãƒˆï¼ˆè¤‡å‹æ™‚ã®ã¿ï¼‰', fontsize=12)
        ax.set_ylabel('å‹åˆ©ç¢ºç‡', fontsize=12)
        ax.set_title('ãƒ­ã‚¸ã‚¹ãƒ†ã‚£ãƒƒã‚¯å›å¸°åˆ†æ\nè¤‡å‹çµŒé¨“é¦¬ã®é‡ã¿ä»˜ã‘ãƒã‚¤ãƒ³ãƒˆã¨å‹åˆ©ç¢ºç‡', fontsize=14, fontweight='bold')
        ax.legend()
        ax.grid(True, alpha=0.3)
        ax.set_ylim(-0.1, 1.1)
        
        plt.tight_layout()
        plt.savefig(output_path, dpi=300, bbox_inches='tight')
        plt.close()
        
        logger.info(f"ãƒ­ã‚¸ã‚¹ãƒ†ã‚£ãƒƒã‚¯å›å¸°æ›²ç·šã‚’ä¿å­˜: {output_path}")

    def generate_report(self, results):
        """åˆ†æãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆï¼ˆ3å¹´é–“éš”ãƒ»è¤‡å‹æ™‚ã®ã¿ãƒã‚¤ãƒ³ãƒˆåŠ ç®—å¯¾å¿œï¼‰"""
        logger.info("åˆ†æãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆé–‹å§‹...")
        
        output_dir = Path(self.config['output_dir'])
        
        # å…¨ä½“ãƒ¬ãƒãƒ¼ãƒˆ
        main_report_path = output_dir / 'é¦¬ã”ã¨è¤‡å‹æ™‚é‡ã¿ä»˜ã‘ãƒã‚¤ãƒ³ãƒˆåˆ†æãƒ¬ãƒãƒ¼ãƒˆ.md'
        
        with open(main_report_path, 'w', encoding='utf-8') as f:
            f.write("# é¦¬ã”ã¨è¤‡å‹æ™‚é‡ã¿ä»˜ã‘ãƒã‚¤ãƒ³ãƒˆåˆ†æãƒ¬ãƒãƒ¼ãƒˆ\n\n")
            f.write(f"ç”Ÿæˆæ—¥æ™‚: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n\n")
            
            f.write("## ğŸ¯ åˆ†ææ¦‚è¦\n\n")
            f.write("**è¤‡å‹ã—ãŸå ´åˆã®ã¿**é‡ã¿ä»˜ã‘ãƒã‚¤ãƒ³ãƒˆã‚’åŠ ç®—ã—ã€é¦¬ã®å‹ç‡ã¨ã®é–¢ä¿‚ã‚’åˆ†æã—ã¾ã—ãŸã€‚\n")
            f.write("ã“ã‚Œã«ã‚ˆã‚Šã€å®Ÿéš›ã«å¥½æˆç¸¾ã‚’æ®‹ã—ãŸç«¶é¦¬å ´ã®æ ¼å¼åº¦ã¨å‹ç‡ã®é–¢ä¿‚ãŒã‚ˆã‚Šæ˜ç¢ºã«ãªã‚Šã¾ã™ã€‚\n")
            f.write("3å¹´é–“éš”ã§ã®æ™‚ç³»åˆ—åˆ†æã«ã‚ˆã‚Šã€å‚¾å‘ã®å¤‰åŒ–ã‚‚æŠŠæ¡ã§ãã¾ã™ã€‚\n\n")
            f.write("**å¹³å‡é‡ã¿ä»˜ã‘ãƒã‚¤ãƒ³ãƒˆ**ã¨**ç´¯ç©é‡ã¿ä»˜ã‘ãƒã‚¤ãƒ³ãƒˆï¼ˆåˆè¨ˆï¼‰**ã®ä¸¡æ–¹ã§åˆ†æã‚’å®Ÿæ–½ã—ã€\n")
            f.write("é¦¬ã®è³ªï¼ˆæ ¼å¼é«˜ã„ç«¶é¦¬å ´ã§ã®å®‰å®šã—ãŸæˆç¸¾ï¼‰ã¨é‡ï¼ˆç·å®Ÿç¸¾ãƒã‚¤ãƒ³ãƒˆï¼‰ã®ä¸¡é¢ã‹ã‚‰è©•ä¾¡ã—ã¦ã„ã¾ã™ã€‚\n\n")
            f.write("### ğŸ” åˆ†ææ‰‹æ³•ã®æ”¹å–„\n")
            f.write("ç´¯ç©ãƒã‚¤ãƒ³ãƒˆåˆ†æã§ã¯**å‹åˆ©æ•°ã®å½±éŸ¿ã«ã‚ˆã‚‹åã‚Š**ã‚’é™¤å»ã™ã‚‹ãŸã‚ã€ä»¥ä¸‹ã®è£œæ­£åˆ†æã‚’å®Ÿæ–½ï¼š\n")
            f.write("- **å‡ºèµ°æ•°æ­£è¦åŒ–åˆ†æ**: ç´¯ç©ãƒã‚¤ãƒ³ãƒˆã‚’å‡ºèµ°æ•°ã§å‰²ã£ãŸå€¤ã§ã®ç›¸é–¢åˆ†æ\n")
            f.write("- **éƒ¨åˆ†ç›¸é–¢åˆ†æ**: è¤‡å‹å›æ•°ã®å½±éŸ¿ã‚’çµ±è¨ˆçš„ã«çµ±åˆ¶ã—ãŸç›¸é–¢åˆ†æ\n")
            f.write("ã“ã‚Œã«ã‚ˆã‚Šã€å˜ãªã‚‹ã€Œè¤‡å‹å›æ•°ã®å¤šã•ã€ã§ã¯ãªã„ã€çœŸã®ç«¶é¦¬å ´æ ¼å¼åº¦ã¨æˆç¸¾ã®é–¢ä¿‚ã‚’è©•ä¾¡ã—ã¾ã™ã€‚\n\n")
            
            f.write("## ğŸ“Š åˆ†ææœŸé–“ä¸€è¦§\n\n")
            f.write("| æœŸé–“ | å¯¾è±¡é¦¬æ•° | ç·ãƒ¬ãƒ¼ã‚¹æ•° | è¤‡å‹çµŒé¨“é¦¬æ•° | ä¸»è¦çµ±è¨ˆ |\n")
            f.write("|------|----------|-----------|-------------|----------|\n")
            
            for period_name, period_results in results.items():
                total_horses = period_results.get('total_horses', 0)
                total_races = period_results.get('total_races', 0)
                
                # è¤‡å‹çµŒé¨“é¦¬æ•°
                if 'race_point_correlation' in period_results and 'place_experienced_horses' in period_results['race_point_correlation']:
                    place_exp_horses = len(period_results['race_point_correlation']['place_experienced_horses'])
                else:
                    place_exp_horses = 0
                
                # ä¸»è¦çµ±è¨ˆ
                if ('race_point_correlation' in period_results and 
                    'correlation_analysis' in period_results['race_point_correlation']):
                    corr_data = period_results['race_point_correlation']['correlation_analysis']
                    main_stat = f"r={corr_data['avg_point']['win_rate']['correlation']:.3f}"
                else:
                    main_stat = "ãƒ‡ãƒ¼ã‚¿ä¸è¶³"
                
                f.write(f"| {period_name} | {total_horses:,}é ­ | {total_races:,}ãƒ¬ãƒ¼ã‚¹ | {place_exp_horses:,}é ­ | {main_stat} |\n")
            
            # å„æœŸé–“ã®è©³ç´°
            for period_name, period_results in results.items():
                f.write(f"\n## ğŸ“ˆ æœŸé–“: {period_name}\n\n")
                
                if ('race_point_correlation' in period_results and 
                    'correlation_analysis' in period_results['race_point_correlation']):
                    corr_analysis = period_results['race_point_correlation']['correlation_analysis']
                    place_exp_horses = period_results['race_point_correlation'].get('place_experienced_horses')
                    
                    if place_exp_horses is not None and len(place_exp_horses) >= 3:
                        f.write(f"### è¤‡å‹æ™‚é‡ã¿ä»˜ã‘ãƒã‚¤ãƒ³ãƒˆç›¸é–¢åˆ†æï¼ˆè¤‡å‹çµŒé¨“é¦¬ {len(place_exp_horses)}é ­ï¼‰\n\n")
                        
                        # å¹³å‡ãƒã‚¤ãƒ³ãƒˆåˆ†æçµæœ
                        avg_win_corr = corr_analysis['avg_point']['win_rate']['correlation']
                        avg_win_p = corr_analysis['avg_point']['win_rate']['p_value']
                        avg_win_r2 = corr_analysis['avg_point']['win_rate']['r2']
                        
                        avg_place_corr = corr_analysis['avg_point']['place_rate']['correlation']
                        avg_place_p = corr_analysis['avg_point']['place_rate']['p_value']
                        avg_place_r2 = corr_analysis['avg_point']['place_rate']['r2']
                        
                        # ç´¯ç©ãƒã‚¤ãƒ³ãƒˆåˆ†æçµæœ
                        cum_win_corr = corr_analysis['cumulative']['win_rate']['correlation']
                        cum_win_p = corr_analysis['cumulative']['win_rate']['p_value']
                        cum_win_r2 = corr_analysis['cumulative']['win_rate']['r2']
                        
                        cum_place_corr = corr_analysis['cumulative']['place_rate']['correlation']
                        cum_place_p = corr_analysis['cumulative']['place_rate']['p_value']
                        cum_place_r2 = corr_analysis['cumulative']['place_rate']['r2']
                        
                        f.write("#### ç›¸é–¢åˆ†æçµæœ\n\n")
                        f.write("**å¹³å‡é‡ã¿ä»˜ã‘ãƒã‚¤ãƒ³ãƒˆåˆ†æ**\n")
                        f.write(f"- **è¤‡å‹æ™‚å¹³å‡ãƒã‚¤ãƒ³ãƒˆ vs å‹ç‡**: r = {avg_win_corr:.3f}, p = {avg_win_p:.3f}, RÂ² = {avg_win_r2:.3f}")
                        f.write(f" ({'æœ‰æ„' if avg_win_p < 0.05 else 'éæœ‰æ„'})\n")
                        f.write(f"- **è¤‡å‹æ™‚å¹³å‡ãƒã‚¤ãƒ³ãƒˆ vs è¤‡å‹ç‡**: r = {avg_place_corr:.3f}, p = {avg_place_p:.3f}, RÂ² = {avg_place_r2:.3f}")
                        f.write(f" ({'æœ‰æ„' if avg_place_p < 0.05 else 'éæœ‰æ„'})\n\n")
                        
                        f.write("**ç´¯ç©é‡ã¿ä»˜ã‘ãƒã‚¤ãƒ³ãƒˆï¼ˆåˆè¨ˆï¼‰åˆ†æ**\n")
                        f.write(f"- **è¤‡å‹æ™‚ç´¯ç©ãƒã‚¤ãƒ³ãƒˆ vs å‹ç‡**: r = {cum_win_corr:.3f}, p = {cum_win_p:.3f}, RÂ² = {cum_win_r2:.3f}")
                        f.write(f" ({'æœ‰æ„' if cum_win_p < 0.05 else 'éæœ‰æ„'})\n")
                        f.write(f"- **è¤‡å‹æ™‚ç´¯ç©ãƒã‚¤ãƒ³ãƒˆ vs è¤‡å‹ç‡**: r = {cum_place_corr:.3f}, p = {cum_place_p:.3f}, RÂ² = {cum_place_r2:.3f}")
                        f.write(f" ({'æœ‰æ„' if cum_place_p < 0.05 else 'éæœ‰æ„'})\n\n")
                        
                        # ä¸Šä½é¦¬ã®åˆ†æï¼ˆå¹³å‡ãƒã‚¤ãƒ³ãƒˆï¼‰
                        f.write("#### è¤‡å‹æ™‚å¹³å‡é‡ã¿ä»˜ã‘ãƒã‚¤ãƒ³ãƒˆä¸Šä½5é ­\n")
                        f.write("| é †ä½ | é¦¬å | å¹³å‡ãƒã‚¤ãƒ³ãƒˆ | ç´¯ç©ãƒã‚¤ãƒ³ãƒˆ | å‹ç‡ | è¤‡å‹ç‡ | è¤‡å‹å›æ•° | å‡ºèµ°æ•° |\n")
                        f.write("|------|------|-------------|-------------|------|--------|----------|--------|\n")
                        
                        top_horses_avg = place_exp_horses.nlargest(5, 'å¹³å‡é‡ã¿ä»˜ã‘ãƒã‚¤ãƒ³ãƒˆ')
                        for i, (horse_name, row) in enumerate(top_horses_avg.iterrows(), 1):
                            f.write(f"| {i} | {horse_name} | {row['å¹³å‡é‡ã¿ä»˜ã‘ãƒã‚¤ãƒ³ãƒˆ']:.1f} | {row['ç´¯ç©é‡ã¿ä»˜ã‘ãƒã‚¤ãƒ³ãƒˆ']:.1f} | {row['å‹ç‡']:.3f} | "
                                   f"{row['è¤‡å‹ç‡']:.3f} | {row['è¤‡å‹å›æ•°']} | {row['å‡ºèµ°æ•°']} |\n")
                        
                        # ä¸Šä½é¦¬ã®åˆ†æï¼ˆç´¯ç©ãƒã‚¤ãƒ³ãƒˆï¼‰
                        f.write("\n#### è¤‡å‹æ™‚ç´¯ç©é‡ã¿ä»˜ã‘ãƒã‚¤ãƒ³ãƒˆä¸Šä½5é ­\n")
                        f.write("| é †ä½ | é¦¬å | ç´¯ç©ãƒã‚¤ãƒ³ãƒˆ | å¹³å‡ãƒã‚¤ãƒ³ãƒˆ | å‹ç‡ | è¤‡å‹ç‡ | è¤‡å‹å›æ•° | å‡ºèµ°æ•° |\n")
                        f.write("|------|------|-------------|-------------|------|--------|----------|--------|\n")
                        
                        top_horses_cumulative = place_exp_horses.nlargest(5, 'ç´¯ç©é‡ã¿ä»˜ã‘ãƒã‚¤ãƒ³ãƒˆ')
                        for i, (horse_name, row) in enumerate(top_horses_cumulative.iterrows(), 1):
                            f.write(f"| {i} | {horse_name} | {row['ç´¯ç©é‡ã¿ä»˜ã‘ãƒã‚¤ãƒ³ãƒˆ']:.1f} | {row['å¹³å‡é‡ã¿ä»˜ã‘ãƒã‚¤ãƒ³ãƒˆ']:.1f} | {row['å‹ç‡']:.3f} | "
                                   f"{row['è¤‡å‹ç‡']:.3f} | {row['è¤‡å‹å›æ•°']} | {row['å‡ºèµ°æ•°']} |\n")
                        
                        # æ­£è¦åŒ–åˆ†æçµæœï¼ˆå‹åˆ©æ•°å½±éŸ¿é™¤å»ï¼‰
                        if 'normalized_point' in corr_analysis:
                            norm_win_corr = corr_analysis['normalized_point']['win_rate']['correlation']
                            norm_win_p = corr_analysis['normalized_point']['win_rate']['p_value']
                            norm_win_r2 = corr_analysis['normalized_point']['win_rate']['r2']
                            
                            norm_place_corr = corr_analysis['normalized_point']['place_rate']['correlation']
                            norm_place_p = corr_analysis['normalized_point']['place_rate']['p_value']
                            norm_place_r2 = corr_analysis['normalized_point']['place_rate']['r2']
                            
                            f.write("**å‡ºèµ°æ•°æ­£è¦åŒ–é‡ã¿ä»˜ã‘ãƒã‚¤ãƒ³ãƒˆåˆ†æï¼ˆå‹åˆ©æ•°å½±éŸ¿é™¤å»ï¼‰**\n")
                            f.write(f"- **æ­£è¦åŒ–ç´¯ç©ãƒã‚¤ãƒ³ãƒˆ vs å‹ç‡**: r = {norm_win_corr:.3f}, p = {norm_win_p:.3f}, RÂ² = {norm_win_r2:.3f}")
                            f.write(f" ({'æœ‰æ„' if norm_win_p < 0.05 else 'éæœ‰æ„'})\n")
                            f.write(f"- **æ­£è¦åŒ–ç´¯ç©ãƒã‚¤ãƒ³ãƒˆ vs è¤‡å‹ç‡**: r = {norm_place_corr:.3f}, p = {norm_place_p:.3f}, RÂ² = {norm_place_r2:.3f}")
                            f.write(f" ({'æœ‰æ„' if norm_place_p < 0.05 else 'éæœ‰æ„'})\n\n")
                        
                        # éƒ¨åˆ†ç›¸é–¢åˆ†æçµæœ
                        if 'partial_correlation' in corr_analysis:
                            partial_win_corr = corr_analysis['partial_correlation']['cumulative_vs_win_rate']
                            partial_place_corr = corr_analysis['partial_correlation']['cumulative_vs_place_rate']
                            
                            f.write("**éƒ¨åˆ†ç›¸é–¢åˆ†æï¼ˆè¤‡å‹å›æ•°ã®å½±éŸ¿ã‚’çµ±åˆ¶ï¼‰**\n")
                            f.write(f"- **ç´¯ç©ãƒã‚¤ãƒ³ãƒˆ vs å‹ç‡ï¼ˆè¤‡å‹å›æ•°çµ±åˆ¶ï¼‰**: r = {partial_win_corr:.3f}\n")
                            f.write(f"- **ç´¯ç©ãƒã‚¤ãƒ³ãƒˆ vs è¤‡å‹ç‡ï¼ˆè¤‡å‹å›æ•°çµ±åˆ¶ï¼‰**: r = {partial_place_corr:.3f}\n\n")
                            
                            f.write("âš ï¸ **é‡è¦ãªåˆ†æãƒã‚¤ãƒ³ãƒˆ**\n")
                            f.write("- ç´¯ç©ãƒã‚¤ãƒ³ãƒˆã¨è¤‡å‹ç‡ã®é«˜ã„ç›¸é–¢ã¯ã€è¤‡å‹å›æ•°ãŒå¤šã„ã»ã©ç´¯ç©ãƒã‚¤ãƒ³ãƒˆã‚‚è¤‡å‹ç‡ã‚‚é«˜ããªã‚‹æ§‹é€ çš„è¦å› \n")
                            f.write("- å‡ºèµ°æ•°æ­£è¦åŒ–ã‚„éƒ¨åˆ†ç›¸é–¢ã«ã‚ˆã‚Šã€çœŸã®ç«¶é¦¬å ´æ ¼å¼åº¦ã¨æˆç¸¾ã®é–¢ä¿‚ã‚’è©•ä¾¡\n")
                            f.write("- æ­£è¦åŒ–åˆ†æã«ã‚ˆã‚Šå‹åˆ©æ•°ã®åã‚Šã®å½±éŸ¿ã‚’é™¤å»ã—ãŸã€ã‚ˆã‚Šé©åˆ‡ãªè©•ä¾¡ãŒå¯èƒ½\n\n")
                    else:
                        f.write("ã“ã®æœŸé–“ã¯è¤‡å‹çµŒé¨“é¦¬ãŒ3é ­æœªæº€ã®ãŸã‚ã€ç›¸é–¢åˆ†æã‚’å®Ÿè¡Œã§ãã¾ã›ã‚“ã§ã—ãŸã€‚\n")
                else:
                    f.write("ã“ã®æœŸé–“ã¯ãƒ‡ãƒ¼ã‚¿ãŒä¸è¶³ã—ã¦ã„ã‚‹ãŸã‚ã€çµ±è¨ˆåˆ†æã‚’å®Ÿè¡Œã§ãã¾ã›ã‚“ã§ã—ãŸã€‚\n")
            
            # å…¨ä½“çš„ãªå‚¾å‘
            f.write("\n## ğŸ’¡ å…¨ä½“çš„ãªå‚¾å‘ã¨çŸ¥è¦‹\n\n")
            
            # æœŸé–“åˆ¥ã®ç›¸é–¢ä¿‚æ•°å¤‰åŒ–
            correlations_by_period = []
            for period_name, period_results in results.items():
                if ('race_point_correlation' in period_results and 
                    'correlation_analysis' in period_results['race_point_correlation']):
                    corr = period_results['race_point_correlation']['correlation_analysis']['avg_point']['win_rate']['correlation']
                    correlations_by_period.append((period_name, corr))
            
            if len(correlations_by_period) > 1:
                f.write("### æ™‚ç³»åˆ—å¤‰åŒ–\n")
                f.write("| æœŸé–“ | ç›¸é–¢ä¿‚æ•°ï¼ˆè¤‡å‹æ™‚ãƒã‚¤ãƒ³ãƒˆ vs å‹ç‡ï¼‰ | å‚¾å‘ |\n")
                f.write("|------|---------------------------|------|\n")
                
                for i, (period, corr) in enumerate(correlations_by_period):
                    if i > 0:
                        prev_corr = correlations_by_period[i-1][1]
                        trend = "ä¸Šæ˜‡" if corr > prev_corr else "ä¸‹é™"
                    else:
                        trend = "åŸºæº–"
                    f.write(f"| {period} | {corr:.3f} | {trend} |\n")
            
            f.write("\n### è¤‡å‹æ™‚é‡ã¿ä»˜ã‘ãƒã‚¤ãƒ³ãƒˆã®ç‰¹å¾´\n")
            f.write("- **è¤‡å‹ã—ãŸå ´åˆã®ã¿ãƒã‚¤ãƒ³ãƒˆåŠ ç®—**ã«ã‚ˆã‚Šã€å®Ÿéš›ã®æˆç¸¾ã¨ç«¶é¦¬å ´æ ¼å¼ã®é–¢ä¿‚ãŒã‚ˆã‚Šæ˜ç¢ºã«ãªã‚Šã¾ã™\n")
            f.write("- è¤‡å‹çµŒé¨“ãŒãªã„é¦¬ã¯é‡ã¿ä»˜ã‘ãƒã‚¤ãƒ³ãƒˆ0ã¨ãªã‚Šã€æˆç¸¾ã¨ã®ç›¸é–¢ãŒã‚ˆã‚Šç´”ç²‹ã«è©•ä¾¡ã§ãã¾ã™\n")
            f.write("- é«˜æ ¼å¼ç«¶é¦¬å ´ã§ã®è¤‡å‹çµŒé¨“ã¯ã€ãã®é¦¬ã®å®ŸåŠ›ã®è¨¼æ˜ã¨ã—ã¦æ©Ÿèƒ½ã—ã¾ã™\n")
            f.write("- **å¹³å‡ãƒã‚¤ãƒ³ãƒˆ**: é¦¬ã®è³ªï¼ˆã©ã‚Œã ã‘æ ¼å¼é«˜ã„ç«¶é¦¬å ´ã§å‹ã£ã¦ã„ã‚‹ã‹ï¼‰ã‚’è¡¨ã™\n")
            f.write("- **ç´¯ç©ãƒã‚¤ãƒ³ãƒˆ**: é¦¬ã®é‡ï¼ˆã©ã‚Œã ã‘å¤šãã®å®Ÿç¸¾ã‚’ç©ã‚“ã§ã„ã‚‹ã‹ï¼‰ã‚’è¡¨ã™\n")
            
            f.write("\n### å®Ÿç”¨çš„ç¤ºå”†\n")
            f.write("- è¤‡å‹æ™‚é‡ã¿ä»˜ã‘ãƒã‚¤ãƒ³ãƒˆã¯ã€é¦¬ã®ã€Œå®Ÿè¨¼æ¸ˆã¿æ ¼ã€ã‚’è¡¨ã™æŒ‡æ¨™ã¨ã—ã¦æœ‰åŠ¹ã§ã™\n")
            f.write("- é«˜ãƒã‚¤ãƒ³ãƒˆã‚’æŒã¤é¦¬ã¯ã€æ ¼å¼ã®é«˜ã„ç«¶é¦¬å ´ã§å®Ÿéš›ã«çµæœã‚’æ®‹ã—ãŸçµŒé¨“ãŒã‚ã‚Šã¾ã™\n")
            f.write("- **å¹³å‡ãƒã‚¤ãƒ³ãƒˆ**ã¯æ–°é¦¬ã‚„çµŒé¨“ã®æµ…ã„é¦¬ã®å®ŸåŠ›è©•ä¾¡ã«æœ‰åŠ¹\n")
            f.write("- **ç´¯ç©ãƒã‚¤ãƒ³ãƒˆ**ã¯å¤é¦¬ã‚„çµŒé¨“è±Šå¯Œãªé¦¬ã®ç·åˆåŠ›è©•ä¾¡ã«æœ‰åŠ¹\n")
            f.write("- ã“ã®æŒ‡æ¨™ã¯é¦¬åˆ¸è³¼å…¥æ™‚ã®åˆ¤æ–­ææ–™ã¨ã—ã¦æ´»ç”¨ã§ãã¾ã™\n")
        
        logger.info(f"ãƒ¡ã‚¤ãƒ³ãƒ¬ãƒãƒ¼ãƒˆä¿å­˜: {main_report_path}")

    def _plot_correlation_scatter_with_warning(self, horse_stats, title, x_col, y_col, correlation_data, output_path):
        """ç›¸é–¢æ•£å¸ƒå›³ã®æç”»ï¼ˆè­¦å‘Šä»˜ãï¼‰"""
        fig, ax = plt.subplots(figsize=(12, 8))
        
        # ãƒ‡ãƒ¼ã‚¿ã®æº–å‚™
        x = horse_stats[x_col]
        y = horse_stats[y_col]
        
        # ãƒ¬ãƒ¼ã‚¹å›æ•°ï¼ˆå‡ºèµ°æ•°ï¼‰ã«åŸºã¥ãã‚µã‚¤ã‚ºè¨­å®šï¼ˆã‚ˆã‚Šæ˜ç¢ºã«ï¼‰
        min_size = 30
        max_size = 300
        race_counts = horse_stats['å‡ºèµ°æ•°']
        # ãƒ¬ãƒ¼ã‚¹å›æ•°ã‚’æ­£è¦åŒ–ã—ã¦ã‚µã‚¤ã‚ºã«å¤‰æ›
        normalized_sizes = min_size + (race_counts - race_counts.min()) / (race_counts.max() - race_counts.min()) * (max_size - min_size)
        
        # æ•£å¸ƒå›³
        scatter = ax.scatter(x, y, c=horse_stats['å‡ºèµ°æ•°'], s=normalized_sizes, alpha=0.6, 
                           cmap='viridis', edgecolors='black', linewidth=0.5)
        
        # ã‚«ãƒ©ãƒ¼ãƒãƒ¼
        cbar = plt.colorbar(scatter, ax=ax)
        cbar.set_label('å‡ºèµ°æ•°', fontsize=12)
        
        # å›å¸°ç›´ç·š
        regression = correlation_data['regression']
        x_range = np.linspace(x.min(), x.max(), 100)
        y_pred = regression.predict(x_range.reshape(-1, 1))
        ax.plot(x_range, y_pred, 'r--', linewidth=2, 
               label=f'å›å¸°ç›´ç·š (RÂ² = {correlation_data["r2"]:.3f})')
        
        # çµ±è¨ˆæƒ…å ±ã®è¡¨ç¤ºï¼ˆè­¦å‘Šä»˜ãï¼‰
        corr = correlation_data['correlation']
        p_val = correlation_data['p_value']
        
        stats_text = f'ç›¸é–¢ä¿‚æ•°: {corr:.3f}\n'
        stats_text += f'på€¤: {p_val:.3f}\n' 
        stats_text += f'æœ‰æ„æ€§: {"æœ‰æ„" if p_val < 0.05 else "éæœ‰æ„"}\n'
        stats_text += f'å¯¾è±¡: è¤‡å‹çµŒé¨“é¦¬ã®ã¿ ({len(horse_stats)}é ­)\n\n'
        stats_text += 'âš ï¸ è­¦å‘Š:\n'
        stats_text += 'ã“ã®æŒ‡æ¨™ã¯æ§‹é€ çš„ã«é«˜ã„ç›¸é–¢ã‚’\n'
        stats_text += 'ç¤ºã™ãŸã‚ã€è§£é‡ˆã«æ³¨æ„ãŒå¿…è¦ã§ã™'
        
        ax.text(0.05, 0.95, stats_text, transform=ax.transAxes,
               verticalalignment='top', fontsize=11,
               bbox=dict(boxstyle='round', facecolor='orange', alpha=0.8))
        
        # ãƒ¬ãƒ¼ã‚¹å›æ•°ã®ã‚µã‚¤ã‚ºå‡¡ä¾‹ã‚’è¿½åŠ 
        sizes_for_legend = [race_counts.min(), race_counts.quantile(0.5), race_counts.max()]
        labels_for_legend = [f'{int(size)}å›' for size in sizes_for_legend]
        
        # ã‚µã‚¤ã‚ºå‡¡ä¾‹ç”¨ã®ãƒãƒ¼ã‚«ãƒ¼ã‚µã‚¤ã‚ºã‚’è¨ˆç®—
        legend_sizes = []
        for size in sizes_for_legend:
            normalized_size = min_size + (size - race_counts.min()) / (race_counts.max() - race_counts.min()) * (max_size - min_size)
            legend_sizes.append(normalized_size)
        
        # ã‚µã‚¤ã‚ºå‡¡ä¾‹ã®ä½œæˆ
        legend_elements = []
        for size, label, marker_size in zip(sizes_for_legend, labels_for_legend, legend_sizes):
            legend_elements.append(plt.scatter([], [], s=marker_size, c='gray', alpha=0.6, 
                                             edgecolors='black', linewidth=0.5, label=label))
        
        # æ—¢å­˜ã®å‡¡ä¾‹ã¨çµ„ã¿åˆã‚ã›
        legend1 = plt.legend(handles=legend_elements, title="å‡ºèµ°æ•°ï¼ˆç‚¹ã®ã‚µã‚¤ã‚ºï¼‰", 
                           loc='upper left', bbox_to_anchor=(0, 0.75), frameon=True, fancybox=True, shadow=True)
        plt.gca().add_artist(legend1)
        
        # å›å¸°ç›´ç·šã®å‡¡ä¾‹
        legend2 = plt.legend(loc='upper right', frameon=True, fancybox=True, shadow=True)
        
        # ã‚°ãƒ©ãƒ•å·¦ä¸‹ã«å‡ºèµ°æ•°ã®ç¯„å›²æƒ…å ±ã‚’è¿½åŠ 
        info_text = f"å‡ºèµ°æ•°ç¯„å›²: {int(race_counts.min())}ï½{int(race_counts.max())}å›\nå¹³å‡: {race_counts.mean():.1f}å›"
        ax.text(0.02, 0.02, info_text, transform=ax.transAxes, 
                bbox=dict(boxstyle='round', facecolor='lightgray', alpha=0.8),
                verticalalignment='bottom', fontsize=10)
        
        # ãƒ©ãƒ™ãƒ«ã¨ã‚¿ã‚¤ãƒˆãƒ«
        ax.set_xlabel(f'{x_col} â€»è¤‡å‹ã—ãŸå ´åˆã®ã¿ãƒã‚¤ãƒ³ãƒˆåŠ ç®—', fontsize=12)
        ax.set_ylabel(y_col, fontsize=12)
        ax.set_title(f'{title}ï¼ˆè¤‡å‹çµŒé¨“é¦¬ã®ã¿ï¼‰', fontsize=14, fontweight='bold')
        ax.grid(True, alpha=0.3)
        
        plt.tight_layout()
        plt.savefig(output_path, dpi=300, bbox_inches='tight')
        plt.close()
        
        logger.warning(f"âš ï¸  è­¦å‘Šä»˜ãç›¸é–¢å›³ã‚’ä¿å­˜: {output_path}")

    def compare_random_vs_original_weights(self):
        """ã‚ªãƒªã‚¸ãƒŠãƒ«é‡ã¿ä»˜ã‘ã¨ãƒ©ãƒ³ãƒ€ãƒ é‡ã¿ä»˜ã‘ã®æ¯”è¼ƒåˆ†æ"""
        logger.info("ğŸ”„ ã‚ªãƒªã‚¸ãƒŠãƒ« vs ãƒ©ãƒ³ãƒ€ãƒ é‡ã¿ä»˜ã‘æ¯”è¼ƒåˆ†æã‚’é–‹å§‹...")
        
        # ãƒ‡ãƒ¼ã‚¿ã®å‰å‡¦ç†
        self.df = self.preprocess_data()
        
        comparison_results = {}
        
        # åˆ†ææœŸé–“ã®è¨­å®š
        if self.df['å¹´'].notna().any():
            years = sorted(self.df['å¹´'].dropna().unique())
            if len(years) >= 6:
                periods = [
                    ('2022-2024', years[-3:]),
                    ('2019-2021', years[-6:-3]),
                    ('å…¨æœŸé–“', years)
                ]
            else:
                periods = [('å…¨æœŸé–“', years)]
        else:
            periods = [('å…¨æœŸé–“', None)]
        
        for period_name, period_years in periods:
            logger.info(f"\nğŸ“Š æœŸé–“: {period_name}")
            
            # æœŸé–“ãƒ‡ãƒ¼ã‚¿ã®æŠ½å‡º
            if period_years:
                df_period = self.df[self.df['å¹´'].isin(period_years)]
            else:
                df_period = self.df.copy()
            
            df_period = df_period[df_period.groupby('é¦¬å')['é¦¬å'].transform('count') >= self.config['min_races']]
            
            if len(df_period) == 0:
                logger.warning(f"æœŸé–“ {period_name} ã«ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“")
                continue
            
            # 1. ã‚ªãƒªã‚¸ãƒŠãƒ«é‡ã¿ä»˜ã‘ã§ã®åˆ†æ
            logger.info("ğŸ“Š ã‚ªãƒªã‚¸ãƒŠãƒ«é‡ã¿ä»˜ã‘ã§ã®åˆ†æ...")
            original_horse_stats = self._calculate_horse_race_point_stats(df_period)
            original_correlation = self._analyze_race_point_correlation(original_horse_stats)
            
            # 2. ãƒ©ãƒ³ãƒ€ãƒ é‡ã¿ä»˜ã‘ã«å¤‰æ›´
            self._apply_random_weights()
            
            # ãƒ‡ãƒ¼ã‚¿ã‚’å†è¨ˆç®—ï¼ˆç«¶é¦¬å ´é‡ã¿ä»˜ã‘ãƒã‚¤ãƒ³ãƒˆã‚’æ›´æ–°ï¼‰
            df_period_random = df_period.copy()
            df_period_random['ç«¶é¦¬å ´é‡ã¿ä»˜ã‘ãƒã‚¤ãƒ³ãƒˆ'] = df_period_random['å ´å'].map(
                lambda x: self.track_hierarchy.get(x, {}).get('weight_points', 0)
            )
            
            # 3. ãƒ©ãƒ³ãƒ€ãƒ é‡ã¿ä»˜ã‘ã§ã®åˆ†æ
            logger.info("ğŸ² ãƒ©ãƒ³ãƒ€ãƒ é‡ã¿ä»˜ã‘ã§ã®åˆ†æ...")
            random_horse_stats = self._calculate_horse_race_point_stats(df_period_random)
            random_correlation = self._analyze_race_point_correlation(random_horse_stats)
            
            # 4. çµæœã®æ¯”è¼ƒ
            comparison_results[period_name] = {
                'original': {
                    'horse_stats': original_horse_stats,
                    'correlation': original_correlation
                },
                'random': {
                    'horse_stats': random_horse_stats,  
                    'correlation': random_correlation
                },
                'period_years': period_years,
                'total_horses': len(df_period['é¦¬å'].unique()),
                'total_races': len(df_period)
            }
            
            # ã‚ªãƒªã‚¸ãƒŠãƒ«é‡ã¿ä»˜ã‘ã«æˆ»ã™
            self.track_hierarchy = copy.deepcopy(self.original_track_hierarchy)
            
        return comparison_results
    
    def visualize_comparison_results(self, comparison_results):
        """æ¯”è¼ƒåˆ†æçµæœã®å¯è¦–åŒ–"""
        output_dir = Path(self.config['output_dir'])
        comparison_dir = output_dir / 'random_vs_original_comparison'
        comparison_dir.mkdir(parents=True, exist_ok=True)
        
        for period_name, results in comparison_results.items():
            period_dir = comparison_dir / period_name.replace('/', '_')
            period_dir.mkdir(parents=True, exist_ok=True)
            
            # æ¯”è¼ƒãƒãƒ£ãƒ¼ãƒˆã®ä½œæˆ
            self._plot_comparison_charts(results, period_dir, period_name)
            
            logger.info(f"ğŸ“Š æ¯”è¼ƒçµæœä¿å­˜: {period_dir}")
    
    def _plot_comparison_charts(self, results, output_dir, period_name):
        """æ¯”è¼ƒãƒãƒ£ãƒ¼ãƒˆã®æç”»"""
        
        original_results = results['original']
        random_results = results['random']
        
        # è¤‡å‹çµŒé¨“é¦¬ã®ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
        original_experienced = original_results['correlation']['place_experienced_horses']
        random_experienced = random_results['correlation']['place_experienced_horses']
        
        # ç›¸é–¢çµæœã‚’å–å¾—
        original_corr = original_results['correlation']
        random_corr = random_results['correlation']
        
        # å‡ºèµ°æ•°æ­£è¦åŒ–ç´¯ç©ãƒã‚¤ãƒ³ãƒˆã‚«ãƒ©ãƒ ãŒå­˜åœ¨ã—ãªã„å ´åˆã¯ä½œæˆ
        if 'å‡ºèµ°æ•°æ­£è¦åŒ–ç´¯ç©ãƒã‚¤ãƒ³ãƒˆ' not in original_experienced.columns:
            original_experienced = original_experienced.copy()
            original_experienced['å‡ºèµ°æ•°æ­£è¦åŒ–ç´¯ç©ãƒã‚¤ãƒ³ãƒˆ'] = original_experienced['ç´¯ç©é‡ã¿ä»˜ã‘ãƒã‚¤ãƒ³ãƒˆ'] / original_experienced['å‡ºèµ°æ•°']
        
        if 'å‡ºèµ°æ•°æ­£è¦åŒ–ç´¯ç©ãƒã‚¤ãƒ³ãƒˆ' not in random_experienced.columns:
            random_experienced = random_experienced.copy()
            random_experienced['å‡ºèµ°æ•°æ­£è¦åŒ–ç´¯ç©ãƒã‚¤ãƒ³ãƒˆ'] = random_experienced['ç´¯ç©é‡ã¿ä»˜ã‘ãƒã‚¤ãƒ³ãƒˆ'] / random_experienced['å‡ºèµ°æ•°']
        
        # === 1. å¹³å‡é‡ã¿ä»˜ã‘ãƒã‚¤ãƒ³ãƒˆ vs è¤‡å‹ç‡ã®æ¯”è¼ƒãƒãƒ£ãƒ¼ãƒˆ ===
        self._create_single_comparison_chart(
            original_experienced, random_experienced,
            original_corr, random_corr,
            'å¹³å‡é‡ã¿ä»˜ã‘ãƒã‚¤ãƒ³ãƒˆ', 'è¤‡å‹ç‡',
            'avg_point', 'place_rate',
            f'å¹³å‡é‡ã¿ä»˜ã‘ãƒã‚¤ãƒ³ãƒˆ vs è¤‡å‹ç‡æ¯”è¼ƒ ({period_name})',
            output_dir / f'å¹³å‡é‡ã¿ä»˜ã‘ãƒã‚¤ãƒ³ãƒˆã¨è¤‡å‹ç‡ã®é–¢ä¿‚æ¯”è¼ƒ_{period_name}.png'
        )
        
        # === 2. å‡ºèµ°æ•°æ­£è¦åŒ–ç´¯ç©ãƒã‚¤ãƒ³ãƒˆ vs è¤‡å‹ç‡ã®æ¯”è¼ƒãƒãƒ£ãƒ¼ãƒˆ ===
        self._create_single_comparison_chart(
            original_experienced, random_experienced,
            original_corr, random_corr,
            'å‡ºèµ°æ•°æ­£è¦åŒ–ç´¯ç©ãƒã‚¤ãƒ³ãƒˆ', 'è¤‡å‹ç‡',
            'normalized', 'place_rate',
            f'å‡ºèµ°æ•°æ­£è¦åŒ–ç´¯ç©ãƒã‚¤ãƒ³ãƒˆ vs è¤‡å‹ç‡æ¯”è¼ƒ ({period_name})',
            output_dir / f'å‡ºèµ°æ•°æ­£è¦åŒ–ç´¯ç©ãƒã‚¤ãƒ³ãƒˆã¨è¤‡å‹ç‡ã®é–¢ä¿‚æ¯”è¼ƒ_{period_name}.png'
        )
        
        # === 3. 4è±¡é™ç·åˆæ¯”è¼ƒãƒãƒ£ãƒ¼ãƒˆï¼ˆå¾“æ¥ç‰ˆã‚’ç¶­æŒï¼‰ ===
        fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(16, 12))
        
        # ã‚ªãƒªã‚¸ãƒŠãƒ«é‡ã¿ä»˜ã‘æ•£å¸ƒå›³
        x_orig = original_experienced['å‡ºèµ°æ•°æ­£è¦åŒ–ç´¯ç©ãƒã‚¤ãƒ³ãƒˆ']
        y_orig = original_experienced['è¤‡å‹ç‡']
        
        # ãƒ¬ãƒ¼ã‚¹å›æ•°ï¼ˆå‡ºèµ°æ•°ï¼‰ã«åŸºã¥ãã‚µã‚¤ã‚ºè¨­å®š
        min_size = 30
        max_size = 150
        race_counts_orig = original_experienced['å‡ºèµ°æ•°']
        normalized_sizes_orig = min_size + (race_counts_orig - race_counts_orig.min()) / (race_counts_orig.max() - race_counts_orig.min()) * (max_size - min_size)
        
        scatter_orig = ax1.scatter(x_orig, y_orig, alpha=0.6, c=race_counts_orig, s=normalized_sizes_orig, 
                                 cmap='Blues', edgecolors='black', linewidth=0.5)
        
        # ã‚«ãƒ©ãƒ¼ãƒãƒ¼
        cbar1 = plt.colorbar(scatter_orig, ax=ax1)
        cbar1.set_label('å‡ºèµ°æ•°', fontsize=10)
        
        # ç›¸é–¢æƒ…å ±ã®å–å¾—
        if ('correlation_analysis' in original_corr and 
            'normalized' in original_corr['correlation_analysis'] and
            'place_rate' in original_corr['correlation_analysis']['normalized']):
            orig_corr_val = original_corr['correlation_analysis']['normalized']['place_rate']['correlation']
            orig_p_val = original_corr['correlation_analysis']['normalized']['place_rate']['p_value']
            orig_regression = original_corr['correlation_analysis']['normalized']['place_rate']['regression']
        else:
            from scipy.stats import pearsonr
            from sklearn.linear_model import LinearRegression
            orig_corr_val, orig_p_val = pearsonr(x_orig, y_orig)
            # å›å¸°ç›´ç·šã‚’è¨ˆç®—
            orig_regression = LinearRegression()
            orig_regression.fit(x_orig.values.reshape(-1, 1), y_orig.values)
        
        # ã‚ªãƒªã‚¸ãƒŠãƒ«ã®å›å¸°ç›´ç·šã‚’æç”»
        x_range_orig = np.linspace(x_orig.min(), x_orig.max(), 100)
        y_pred_orig = orig_regression.predict(x_range_orig.reshape(-1, 1))
        ax1.plot(x_range_orig, y_pred_orig, 'r--', linewidth=2, 
               label=f'å›å¸°ç›´ç·š (r = {orig_corr_val:.3f})')
        
        ax1.set_title(f'ã‚ªãƒªã‚¸ãƒŠãƒ«é‡ã¿ä»˜ã‘\nr = {orig_corr_val:.3f}, p = {orig_p_val:.3f}', fontsize=12)
        ax1.set_xlabel('å‡ºèµ°æ•°æ­£è¦åŒ–ç´¯ç©ãƒã‚¤ãƒ³ãƒˆ')
        ax1.set_ylabel('è¤‡å‹ç‡')
        ax1.legend()
        ax1.grid(True, alpha=0.3)
        
        # ãƒ©ãƒ³ãƒ€ãƒ é‡ã¿ä»˜ã‘æ•£å¸ƒå›³
        x_rand = random_experienced['å‡ºèµ°æ•°æ­£è¦åŒ–ç´¯ç©ãƒã‚¤ãƒ³ãƒˆ']
        y_rand = random_experienced['è¤‡å‹ç‡']
        
        # ãƒ©ãƒ³ãƒ€ãƒ é‡ã¿ä»˜ã‘ç”¨ã®ã‚µã‚¤ã‚ºè¨­å®š
        race_counts_rand = random_experienced['å‡ºèµ°æ•°']
        normalized_sizes_rand = min_size + (race_counts_rand - race_counts_rand.min()) / (race_counts_rand.max() - race_counts_rand.min()) * (max_size - min_size)
        
        scatter_rand = ax2.scatter(x_rand, y_rand, alpha=0.6, c=race_counts_rand, s=normalized_sizes_rand, 
                                 cmap='Reds', edgecolors='black', linewidth=0.5)
        
        # ã‚«ãƒ©ãƒ¼ãƒãƒ¼
        cbar2 = plt.colorbar(scatter_rand, ax=ax2)
        cbar2.set_label('å‡ºèµ°æ•°', fontsize=10)
        
        if ('correlation_analysis' in random_corr and 
            'normalized' in random_corr['correlation_analysis'] and
            'place_rate' in random_corr['correlation_analysis']['normalized']):
            rand_corr_val = random_corr['correlation_analysis']['normalized']['place_rate']['correlation']
            rand_p_val = random_corr['correlation_analysis']['normalized']['place_rate']['p_value']
            rand_regression = random_corr['correlation_analysis']['normalized']['place_rate']['regression']
        else:
            from scipy.stats import pearsonr
            from sklearn.linear_model import LinearRegression
            rand_corr_val, rand_p_val = pearsonr(x_rand, y_rand)
            # å›å¸°ç›´ç·šã‚’è¨ˆç®—
            rand_regression = LinearRegression()
            rand_regression.fit(x_rand.values.reshape(-1, 1), y_rand.values)
        
        # ãƒ©ãƒ³ãƒ€ãƒ ã®å›å¸°ç›´ç·šã‚’æç”»
        x_range_rand = np.linspace(x_rand.min(), x_rand.max(), 100)
        y_pred_rand = rand_regression.predict(x_range_rand.reshape(-1, 1))
        ax2.plot(x_range_rand, y_pred_rand, 'b--', linewidth=2, 
               label=f'å›å¸°ç›´ç·š (r = {rand_corr_val:.3f})')
        
        ax2.set_title(f'ãƒ©ãƒ³ãƒ€ãƒ é‡ã¿ä»˜ã‘\nr = {rand_corr_val:.3f}, p = {rand_p_val:.3f}', fontsize=12)
        ax2.set_xlabel('å‡ºèµ°æ•°æ­£è¦åŒ–ç´¯ç©ãƒã‚¤ãƒ³ãƒˆ')
        ax2.set_ylabel('è¤‡å‹ç‡')
        ax2.legend()
        ax2.grid(True, alpha=0.3)
        
        # ç›¸é–¢ä¿‚æ•°æ¯”è¼ƒæ£’ã‚°ãƒ©ãƒ•
        categories = ['ã‚ªãƒªã‚¸ãƒŠãƒ«', 'ãƒ©ãƒ³ãƒ€ãƒ ']
        correlations = [orig_corr_val, rand_corr_val]
        colors = ['blue', 'red']
        
        bars = ax3.bar(categories, correlations, color=colors, alpha=0.7)
        ax3.set_title('ç›¸é–¢ä¿‚æ•°æ¯”è¼ƒ', fontsize=12)
        ax3.set_ylabel('ç›¸é–¢ä¿‚æ•°')
        ax3.set_ylim(-1, 1)
        ax3.grid(True, alpha=0.3)
        
        # å€¤ã‚’ãƒãƒ¼ã®ä¸Šã«è¡¨ç¤º
        for bar, corr in zip(bars, correlations):
            height = bar.get_height()
            ax3.text(bar.get_x() + bar.get_width()/2., height + 0.01,
                    f'{corr:.3f}', ha='center', va='bottom')
        
        # å·®ã®å¯è¦–åŒ–
        diff = abs(orig_corr_val) - abs(rand_corr_val)
        
        # å‡ºèµ°æ•°çµ±è¨ˆæƒ…å ±ã‚’è¿½åŠ 
        orig_race_stats = f"å‡ºèµ°æ•°ç¯„å›²: {int(race_counts_orig.min())}ï½{int(race_counts_orig.max())}å›\nå¹³å‡: {race_counts_orig.mean():.1f}å›"
        rand_race_stats = f"å‡ºèµ°æ•°ç¯„å›²: {int(race_counts_rand.min())}ï½{int(race_counts_rand.max())}å›\nå¹³å‡: {race_counts_rand.mean():.1f}å›"
        
        ax4.text(0.5, 0.7, f'ç›¸é–¢ä¿‚æ•°ã®å·®\nï¼ˆçµ¶å¯¾å€¤ï¼‰:\n{diff:.3f}', 
                transform=ax4.transAxes, ha='center', va='center',
                fontsize=14, bbox=dict(boxstyle='round', facecolor='lightgray'))
        
        ax4.text(0.5, 0.4, f'ã‚ªãƒªã‚¸ãƒŠãƒ«é‡ã¿ä»˜ã‘\n{orig_race_stats}', 
                transform=ax4.transAxes, ha='center', va='center',
                fontsize=10, bbox=dict(boxstyle='round', facecolor='lightblue', alpha=0.7))
        
        ax4.text(0.5, 0.1, f'ãƒ©ãƒ³ãƒ€ãƒ é‡ã¿ä»˜ã‘\n{rand_race_stats}', 
                transform=ax4.transAxes, ha='center', va='center',
                fontsize=10, bbox=dict(boxstyle='round', facecolor='lightcoral', alpha=0.7))
        
        ax4.set_xlim(0, 1)
        ax4.set_ylim(0, 1)
        ax4.axis('off')
        
        plt.suptitle(f'ç·åˆæ¯”è¼ƒ: å‡ºèµ°æ•°æ­£è¦åŒ–ç´¯ç©ãƒã‚¤ãƒ³ãƒˆ vs è¤‡å‹ç‡ ({period_name})', fontsize=16, fontweight='bold')
        plt.tight_layout()
        plt.savefig(output_dir / f'ç·åˆæ¯”è¼ƒ_å‡ºèµ°æ•°æ­£è¦åŒ–ç´¯ç©ãƒã‚¤ãƒ³ãƒˆ_{period_name}.png', dpi=300, bbox_inches='tight')
        plt.close()
        
        logger.info(f"ç·åˆæ¯”è¼ƒãƒãƒ£ãƒ¼ãƒˆä¿å­˜: {output_dir / f'ç·åˆæ¯”è¼ƒ_å‡ºèµ°æ•°æ­£è¦åŒ–ç´¯ç©ãƒã‚¤ãƒ³ãƒˆ_{period_name}.png'}")

    def _create_single_comparison_chart(self, original_data, random_data, 
                                      original_corr, random_corr,
                                      x_col, y_col, corr_type, target_type,
                                      title, output_path):
        """å˜ä¸€ã®æ¯”è¼ƒãƒãƒ£ãƒ¼ãƒˆä½œæˆ"""
        fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(16, 12))
        
        # ã‚ªãƒªã‚¸ãƒŠãƒ«é‡ã¿ä»˜ã‘æ•£å¸ƒå›³
        x_orig = original_data[x_col]
        y_orig = original_data[y_col]
        
        # ãƒ¬ãƒ¼ã‚¹å›æ•°ï¼ˆå‡ºèµ°æ•°ï¼‰ã«åŸºã¥ãã‚µã‚¤ã‚ºè¨­å®š
        min_size = 30
        max_size = 150
        race_counts_orig = original_data['å‡ºèµ°æ•°']
        normalized_sizes_orig = min_size + (race_counts_orig - race_counts_orig.min()) / (race_counts_orig.max() - race_counts_orig.min()) * (max_size - min_size)
        
        scatter_orig = ax1.scatter(x_orig, y_orig, alpha=0.6, c=race_counts_orig, s=normalized_sizes_orig, 
                                 cmap='Blues', edgecolors='black', linewidth=0.5)
        
        # ã‚«ãƒ©ãƒ¼ãƒãƒ¼
        cbar1 = plt.colorbar(scatter_orig, ax=ax1)
        cbar1.set_label('å‡ºèµ°æ•°', fontsize=10)
        
        # ç›¸é–¢æƒ…å ±ã®å–å¾—ï¼ˆã‚ªãƒªã‚¸ãƒŠãƒ«ï¼‰
        if ('correlation_analysis' in original_corr and 
            corr_type in original_corr['correlation_analysis'] and
            target_type in original_corr['correlation_analysis'][corr_type]):
            orig_corr_val = original_corr['correlation_analysis'][corr_type][target_type]['correlation']
            orig_p_val = original_corr['correlation_analysis'][corr_type][target_type]['p_value']
            orig_regression = original_corr['correlation_analysis'][corr_type][target_type]['regression']
        else:
            from scipy.stats import pearsonr
            from sklearn.linear_model import LinearRegression
            orig_corr_val, orig_p_val = pearsonr(x_orig, y_orig)
            # å›å¸°ç›´ç·šã‚’è¨ˆç®—
            orig_regression = LinearRegression()
            orig_regression.fit(x_orig.values.reshape(-1, 1), y_orig.values)
        
        # ã‚ªãƒªã‚¸ãƒŠãƒ«ã®å›å¸°ç›´ç·šã‚’æç”»
        x_range_orig = np.linspace(x_orig.min(), x_orig.max(), 100)
        y_pred_orig = orig_regression.predict(x_range_orig.reshape(-1, 1))
        ax1.plot(x_range_orig, y_pred_orig, 'r--', linewidth=2, 
               label=f'å›å¸°ç›´ç·š (r = {orig_corr_val:.3f})')
        
        ax1.set_title(f'ã‚ªãƒªã‚¸ãƒŠãƒ«é‡ã¿ä»˜ã‘\nr = {orig_corr_val:.3f}, p = {orig_p_val:.3f}', fontsize=12)
        ax1.set_xlabel(x_col)
        ax1.set_ylabel(y_col)
        ax1.legend()
        ax1.grid(True, alpha=0.3)
        
        # ãƒ©ãƒ³ãƒ€ãƒ é‡ã¿ä»˜ã‘æ•£å¸ƒå›³
        x_rand = random_data[x_col]
        y_rand = random_data[y_col]
        
        # ãƒ©ãƒ³ãƒ€ãƒ é‡ã¿ä»˜ã‘ç”¨ã®ã‚µã‚¤ã‚ºè¨­å®š
        race_counts_rand = random_data['å‡ºèµ°æ•°']
        normalized_sizes_rand = min_size + (race_counts_rand - race_counts_rand.min()) / (race_counts_rand.max() - race_counts_rand.min()) * (max_size - min_size)
        
        scatter_rand = ax2.scatter(x_rand, y_rand, alpha=0.6, c=race_counts_rand, s=normalized_sizes_rand, 
                                 cmap='Reds', edgecolors='black', linewidth=0.5)
        
        # ã‚«ãƒ©ãƒ¼ãƒãƒ¼
        cbar2 = plt.colorbar(scatter_rand, ax=ax2)
        cbar2.set_label('å‡ºèµ°æ•°', fontsize=10)
        
        # ç›¸é–¢æƒ…å ±ã®å–å¾—ï¼ˆãƒ©ãƒ³ãƒ€ãƒ ï¼‰
        if ('correlation_analysis' in random_corr and 
            corr_type in random_corr['correlation_analysis'] and
            target_type in random_corr['correlation_analysis'][corr_type]):
            rand_corr_val = random_corr['correlation_analysis'][corr_type][target_type]['correlation']
            rand_p_val = random_corr['correlation_analysis'][corr_type][target_type]['p_value']
            rand_regression = random_corr['correlation_analysis'][corr_type][target_type]['regression']
        else:
            from scipy.stats import pearsonr
            from sklearn.linear_model import LinearRegression
            rand_corr_val, rand_p_val = pearsonr(x_rand, y_rand)
            # å›å¸°ç›´ç·šã‚’è¨ˆç®—
            rand_regression = LinearRegression()
            rand_regression.fit(x_rand.values.reshape(-1, 1), y_rand.values)
        
        # ãƒ©ãƒ³ãƒ€ãƒ ã®å›å¸°ç›´ç·šã‚’æç”»
        x_range_rand = np.linspace(x_rand.min(), x_rand.max(), 100)
        y_pred_rand = rand_regression.predict(x_range_rand.reshape(-1, 1))
        ax2.plot(x_range_rand, y_pred_rand, 'b--', linewidth=2, 
               label=f'å›å¸°ç›´ç·š (r = {rand_corr_val:.3f})')
        
        ax2.set_title(f'ãƒ©ãƒ³ãƒ€ãƒ é‡ã¿ä»˜ã‘\nr = {rand_corr_val:.3f}, p = {rand_p_val:.3f}', fontsize=12)
        ax2.set_xlabel(x_col)
        ax2.set_ylabel(y_col)
        ax2.legend()
        ax2.grid(True, alpha=0.3)
        
        # ç›¸é–¢ä¿‚æ•°æ¯”è¼ƒæ£’ã‚°ãƒ©ãƒ•
        categories = ['ã‚ªãƒªã‚¸ãƒŠãƒ«', 'ãƒ©ãƒ³ãƒ€ãƒ ']
        correlations = [orig_corr_val, rand_corr_val]
        colors = ['blue', 'red']
        
        bars = ax3.bar(categories, correlations, color=colors, alpha=0.7)
        ax3.set_title('ç›¸é–¢ä¿‚æ•°æ¯”è¼ƒ', fontsize=12)
        ax3.set_ylabel('ç›¸é–¢ä¿‚æ•°')
        ax3.set_ylim(-1, 1)
        ax3.grid(True, alpha=0.3)
        
        # å€¤ã‚’ãƒãƒ¼ã®ä¸Šã«è¡¨ç¤º
        for bar, corr in zip(bars, correlations):
            height = bar.get_height()
            ax3.text(bar.get_x() + bar.get_width()/2., height + 0.01,
                    f'{corr:.3f}', ha='center', va='bottom')
        
        # å·®ã®å¯è¦–åŒ–ã¨è©•ä¾¡
        diff = abs(orig_corr_val) - abs(rand_corr_val)
        
        # è©•ä¾¡çµæœ
        if diff > 0.1:
            verdict = "âœ… ã‚ªãƒªã‚¸ãƒŠãƒ«æ˜ã‚‰ã‹ã«å„ªç§€"
            color = 'lightgreen'
        elif diff > 0:
            verdict = "â• ã‚ªãƒªã‚¸ãƒŠãƒ«ãŒã‚ãšã‹ã«å„ªç§€"
            color = 'lightblue'
        elif diff > -0.1:
            verdict = "â– ã»ã¼åŒç­‰"
            color = 'lightyellow'
        else:
            verdict = "âŒ ãƒ©ãƒ³ãƒ€ãƒ ãŒå„ªç§€"
            color = 'lightcoral'
        
        ax4.text(0.5, 0.7, f'ç›¸é–¢ä¿‚æ•°ã®å·®\nï¼ˆçµ¶å¯¾å€¤ï¼‰:\n{diff:.3f}', 
                transform=ax4.transAxes, ha='center', va='center',
                fontsize=14, bbox=dict(boxstyle='round', facecolor='lightgray'))
        
        ax4.text(0.5, 0.5, verdict, 
                transform=ax4.transAxes, ha='center', va='center',
                fontsize=12, bbox=dict(boxstyle='round', facecolor=color))
        
        # å›å¸°ä¿‚æ•°æƒ…å ±ã‚‚è¿½åŠ 
        orig_slope = orig_regression.coef_[0]
        rand_slope = rand_regression.coef_[0]
        
        regression_text = f"å›å¸°ä¿‚æ•°:\nã‚ªãƒªã‚¸ãƒŠãƒ«: {orig_slope:.4f}\nãƒ©ãƒ³ãƒ€ãƒ : {rand_slope:.4f}"
        ax4.text(0.5, 0.3, regression_text, 
                transform=ax4.transAxes, ha='center', va='center',
                fontsize=10, bbox=dict(boxstyle='round', facecolor='lightcyan', alpha=0.8))
        
        # çµ±è¨ˆæƒ…å ±
        orig_race_stats = f"ã‚ªãƒªã‚¸ãƒŠãƒ«å‡ºèµ°æ•°: {int(race_counts_orig.min())}ï½{int(race_counts_orig.max())}å›"
        rand_race_stats = f"ãƒ©ãƒ³ãƒ€ãƒ å‡ºèµ°æ•°: {int(race_counts_rand.min())}ï½{int(race_counts_rand.max())}å›"
        
        ax4.text(0.5, 0.1, f'{orig_race_stats}\n{rand_race_stats}', 
                transform=ax4.transAxes, ha='center', va='center',
                fontsize=9, bbox=dict(boxstyle='round', facecolor='lightgray', alpha=0.7))
        
        ax4.set_xlim(0, 1)
        ax4.set_ylim(0, 1)
        ax4.axis('off')
        
        plt.suptitle(title, fontsize=16, fontweight='bold')
        plt.tight_layout()
        plt.savefig(output_path, dpi=300, bbox_inches='tight')
        plt.close()
        
        logger.info(f"æ¯”è¼ƒãƒãƒ£ãƒ¼ãƒˆä¿å­˜: {output_path}")

    def generate_comparison_report(self, comparison_results):
        """æ¯”è¼ƒåˆ†æãƒ¬ãƒãƒ¼ãƒˆã®ç”Ÿæˆ"""
        output_dir = Path(self.config['output_dir'])
        comparison_dir = output_dir / 'random_vs_original_comparison'
        comparison_dir.mkdir(parents=True, exist_ok=True)
        
        report_path = comparison_dir / 'é‡ã¿ä»˜ã‘æ¯”è¼ƒåˆ†æãƒ¬ãƒãƒ¼ãƒˆ.md'
        
        with open(report_path, 'w', encoding='utf-8') as f:
            f.write("# ç«¶é¦¬å ´é‡ã¿ä»˜ã‘æ¯”è¼ƒåˆ†æãƒ¬ãƒãƒ¼ãƒˆ\n\n")
            f.write("## æ¦‚è¦\n")
            f.write("ç«¶é¦¬å ´ã®é‡ã¿ä»˜ã‘ãƒã‚¤ãƒ³ãƒˆã‚’è«–ç†çš„ãªè¨­å®šï¼ˆã‚ªãƒªã‚¸ãƒŠãƒ«ï¼‰ã¨ãƒ©ãƒ³ãƒ€ãƒ ãªè¨­å®šã§æ¯”è¼ƒã—ã€\n")
            f.write("ã©ã¡ã‚‰ãŒè¤‡å‹ç‡ã¨ã®ç›¸é–¢ãŒå¼·ã„ã‹ã‚’æ¤œè¨¼ã—ãŸçµæœã§ã™ã€‚\n\n")
            
            f.write("## æ¤œè¨¼æ–¹æ³•\n")
            f.write("1. **ã‚ªãƒªã‚¸ãƒŠãƒ«é‡ã¿ä»˜ã‘**: ç«¶é¦¬å ´ã®æ ¼å¼ãƒ»å¨ä¿¡åº¦ãƒ»è¨­å‚™ç­‰ã‚’è€ƒæ…®ã—ãŸè«–ç†çš„ãªé‡ã¿ä»˜ã‘\n")
            f.write("2. **ãƒ©ãƒ³ãƒ€ãƒ é‡ã¿ä»˜ã‘**: ã‚ªãƒªã‚¸ãƒŠãƒ«ã®é‡ã¿ä»˜ã‘å€¤ã‚’ãƒ©ãƒ³ãƒ€ãƒ ã«ç«¶é¦¬å ´ã«å†é…åˆ†\n")
            f.write("3. ä¸¡æ–¹å¼ã§ã€Œå‡ºèµ°æ•°æ­£è¦åŒ–ç´¯ç©ãƒã‚¤ãƒ³ãƒˆã€ã¨ã€Œè¤‡å‹ç‡ã€ã®ç›¸é–¢ä¿‚æ•°ã‚’è¨ˆç®—\n")
            f.write("4. ç›¸é–¢ã®å¼·ã•ã‚’æ¯”è¼ƒã—ã¦é‡ã¿ä»˜ã‘ã‚·ã‚¹ãƒ†ãƒ ã®æœ‰åŠ¹æ€§ã‚’è©•ä¾¡\n\n")
            
            f.write("## æœŸå¾…ã•ã‚Œã‚‹çµæœ\n")
            f.write("- **ã‚ªãƒªã‚¸ãƒŠãƒ«é‡ã¿ä»˜ã‘ãŒå„ªç§€ãªå ´åˆ**: è«–ç†çš„ãªé‡ã¿ä»˜ã‘ãŒç«¶é¦¬ã®å®Ÿæ…‹ã‚’æ­£ã—ãåæ˜ \n")
            f.write("- **ãƒ©ãƒ³ãƒ€ãƒ é‡ã¿ä»˜ã‘ã¨åŒç­‰ã®å ´åˆ**: é‡ã¿ä»˜ã‘ã‚·ã‚¹ãƒ†ãƒ ã«æ”¹å–„ã®ä½™åœ°ã‚ã‚Š\n")
            f.write("- **ãƒ©ãƒ³ãƒ€ãƒ é‡ã¿ä»˜ã‘ãŒå„ªç§€ãªå ´åˆ**: è«–ç†çš„é‡ã¿ä»˜ã‘ã«æ ¹æœ¬çš„ãªå•é¡Œã‚ã‚Š\n\n")
            
            f.write("## åˆ†æçµæœ\n\n")
            
            summary_table = []
            overall_orig_better = 0
            overall_total = 0
            
            for period_name, results in comparison_results.items():
                f.write(f"### {period_name}\n\n")
                
                # åŸºæœ¬æƒ…å ±
                total_horses = results['total_horses']
                total_races = results['total_races']
                f.write(f"- **å¯¾è±¡ãƒ‡ãƒ¼ã‚¿**: {total_horses:,}é ­, {total_races:,}ãƒ¬ãƒ¼ã‚¹\n")
                
                # ã‚ªãƒªã‚¸ãƒŠãƒ«çµæœ
                orig_corr = results['original']['correlation']
                orig_experienced = results['original']['horse_stats'][
                    results['original']['horse_stats']['å¹³å‡é‡ã¿ä»˜ã‘ãƒã‚¤ãƒ³ãƒˆ'] > 0.0]
                
                # å‡ºèµ°æ•°æ­£è¦åŒ–ç´¯ç©ãƒã‚¤ãƒ³ãƒˆã‚«ãƒ©ãƒ ãŒå­˜åœ¨ã—ãªã„å ´åˆã¯ä½œæˆ
                if 'å‡ºèµ°æ•°æ­£è¦åŒ–ç´¯ç©ãƒã‚¤ãƒ³ãƒˆ' not in orig_experienced.columns:
                    orig_experienced = orig_experienced.copy()
                    orig_experienced['å‡ºèµ°æ•°æ­£è¦åŒ–ç´¯ç©ãƒã‚¤ãƒ³ãƒˆ'] = orig_experienced['ç´¯ç©é‡ã¿ä»˜ã‘ãƒã‚¤ãƒ³ãƒˆ'] / orig_experienced['å‡ºèµ°æ•°']
                
                if ('correlation_analysis' in orig_corr and 
                    'normalized' in orig_corr['correlation_analysis'] and
                    'place_rate' in orig_corr['correlation_analysis']['normalized']):
                    orig_r = orig_corr['correlation_analysis']['normalized']['place_rate']['correlation']
                    orig_p = orig_corr['correlation_analysis']['normalized']['place_rate']['p_value']
                else:
                    from scipy.stats import pearsonr
                    x_orig = orig_experienced['å‡ºèµ°æ•°æ­£è¦åŒ–ç´¯ç©ãƒã‚¤ãƒ³ãƒˆ']
                    y_orig = orig_experienced['è¤‡å‹ç‡']
                    orig_r, orig_p = pearsonr(x_orig, y_orig)
                
                # ãƒ©ãƒ³ãƒ€ãƒ çµæœ
                rand_corr = results['random']['correlation']
                rand_experienced = results['random']['horse_stats'][
                    results['random']['horse_stats']['å¹³å‡é‡ã¿ä»˜ã‘ãƒã‚¤ãƒ³ãƒˆ'] > 0.0]
                
                # å‡ºèµ°æ•°æ­£è¦åŒ–ç´¯ç©ãƒã‚¤ãƒ³ãƒˆã‚«ãƒ©ãƒ ãŒå­˜åœ¨ã—ãªã„å ´åˆã¯ä½œæˆ
                if 'å‡ºèµ°æ•°æ­£è¦åŒ–ç´¯ç©ãƒã‚¤ãƒ³ãƒˆ' not in rand_experienced.columns:
                    rand_experienced = rand_experienced.copy()
                    rand_experienced['å‡ºèµ°æ•°æ­£è¦åŒ–ç´¯ç©ãƒã‚¤ãƒ³ãƒˆ'] = rand_experienced['ç´¯ç©é‡ã¿ä»˜ã‘ãƒã‚¤ãƒ³ãƒˆ'] / rand_experienced['å‡ºèµ°æ•°']
                
                if ('correlation_analysis' in rand_corr and 
                    'normalized' in rand_corr['correlation_analysis'] and
                    'place_rate' in rand_corr['correlation_analysis']['normalized']):
                    rand_r = rand_corr['correlation_analysis']['normalized']['place_rate']['correlation']
                    rand_p = rand_corr['correlation_analysis']['normalized']['place_rate']['p_value']
                else:
                    from scipy.stats import pearsonr
                    x_rand = rand_experienced['å‡ºèµ°æ•°æ­£è¦åŒ–ç´¯ç©ãƒã‚¤ãƒ³ãƒˆ']
                    y_rand = rand_experienced['è¤‡å‹ç‡']
                    rand_r, rand_p = pearsonr(x_rand, y_rand)
                
                f.write(f"- **è¤‡å‹çµŒé¨“é¦¬**: ã‚ªãƒªã‚¸ãƒŠãƒ« {len(orig_experienced)}é ­, ãƒ©ãƒ³ãƒ€ãƒ  {len(rand_experienced)}é ­\n\n")
                
                f.write("#### ç›¸é–¢åˆ†æçµæœ\n\n")
                f.write("| é‡ã¿ä»˜ã‘æ–¹å¼ | ç›¸é–¢ä¿‚æ•° | på€¤ | æœ‰æ„æ€§ |\n")
                f.write("|-------------|---------|-----|--------|\n")
                f.write(f"| ã‚ªãƒªã‚¸ãƒŠãƒ« | {orig_r:.3f} | {orig_p:.3f} | {'æœ‰æ„' if orig_p < 0.05 else 'éæœ‰æ„'} |\n")
                f.write(f"| ãƒ©ãƒ³ãƒ€ãƒ  | {rand_r:.3f} | {rand_p:.3f} | {'æœ‰æ„' if rand_p < 0.05 else 'éæœ‰æ„'} |\n\n")
                
                # å·®ã®è¨ˆç®—ã¨è©•ä¾¡
                diff = abs(orig_r) - abs(rand_r)
                f.write(f"#### è©•ä¾¡\n")
                f.write(f"- **ç›¸é–¢ä¿‚æ•°ã®å·®ï¼ˆçµ¶å¯¾å€¤ï¼‰**: {diff:.3f}\n")
                
                if diff > 0.1:
                    verdict = "âœ… **ã‚ªãƒªã‚¸ãƒŠãƒ«é‡ã¿ä»˜ã‘ãŒæ˜ã‚‰ã‹ã«å„ªç§€**"
                    explanation = "è«–ç†çš„é‡ã¿ä»˜ã‘ãŒç«¶é¦¬ã®å®Ÿæ…‹ã‚’æ­£ç¢ºã«åæ˜ ã—ã¦ã„ã‚‹"
                    orig_better = True
                elif diff > 0:
                    verdict = "â• **ã‚ªãƒªã‚¸ãƒŠãƒ«é‡ã¿ä»˜ã‘ãŒã‚ãšã‹ã«å„ªç§€**"
                    explanation = "è«–ç†çš„é‡ã¿ä»˜ã‘ã«ä¸€å®šã®åŠ¹æœãŒã‚ã‚‹"
                    orig_better = True
                elif diff > -0.1:
                    verdict = "â– **ã»ã¼åŒç­‰**"
                    explanation = "é‡ã¿ä»˜ã‘ã‚·ã‚¹ãƒ†ãƒ ã®æ”¹å–„ä½™åœ°ãŒã‚ã‚‹"
                    orig_better = False
                else:
                    verdict = "âŒ **ãƒ©ãƒ³ãƒ€ãƒ é‡ã¿ä»˜ã‘ãŒå„ªç§€**"
                    explanation = "è«–ç†çš„é‡ã¿ä»˜ã‘ã«æ ¹æœ¬çš„ãªå•é¡ŒãŒã‚ã‚‹å¯èƒ½æ€§"
                    orig_better = False
                
                f.write(f"- {verdict}\n")
                f.write(f"- **è§£é‡ˆ**: {explanation}\n\n")
                
                # ã‚µãƒãƒªãƒ¼ç”¨ãƒ‡ãƒ¼ã‚¿
                summary_table.append({
                    'period': period_name,
                    'orig_r': orig_r,
                    'rand_r': rand_r,
                    'diff': diff,
                    'orig_better': orig_better
                })
                
                if orig_better:
                    overall_orig_better += 1
                overall_total += 1
            
            # å…¨ä½“ã‚µãƒãƒªãƒ¼
            f.write("## ç·åˆè©•ä¾¡\n\n")
            f.write("### æœŸé–“åˆ¥çµæœä¸€è¦§\n\n")
            f.write("| æœŸé–“ | ã‚ªãƒªã‚¸ãƒŠãƒ«ç›¸é–¢ | ãƒ©ãƒ³ãƒ€ãƒ ç›¸é–¢ | å·® | è©•ä¾¡ |\n")
            f.write("|------|---------------|-------------|----|---------|\n")
            
            for result in summary_table:
                status = "ğŸŸ¢ å„ªç§€" if result['orig_better'] else "ğŸ”´ åŠ£å‹¢"
                f.write(f"| {result['period']} | {result['orig_r']:.3f} | {result['rand_r']:.3f} | {result['diff']:.3f} | {status} |\n")
            
            f.write(f"\n### æœ€çµ‚çµè«–\n")
            success_rate = (overall_orig_better / overall_total) * 100 if overall_total > 0 else 0
            f.write(f"- **ã‚ªãƒªã‚¸ãƒŠãƒ«é‡ã¿ä»˜ã‘ãŒå„ªç§€ãªæœŸé–“**: {overall_orig_better}/{overall_total} ({success_rate:.1f}%)\n")
            
            if success_rate >= 80:
                final_verdict = "ğŸ‰ **è«–ç†çš„é‡ã¿ä»˜ã‘ã‚·ã‚¹ãƒ†ãƒ ã¯éå¸¸ã«æœ‰åŠ¹**"
                recommendation = "ç¾åœ¨ã®é‡ã¿ä»˜ã‘ã‚·ã‚¹ãƒ†ãƒ ã‚’ç¶™ç¶šä½¿ç”¨ã™ã‚‹ã“ã¨ã‚’æ¨å¥¨"
            elif success_rate >= 60:
                final_verdict = "ğŸ‘ **è«–ç†çš„é‡ã¿ä»˜ã‘ã‚·ã‚¹ãƒ†ãƒ ã¯æ¦‚ã­æœ‰åŠ¹**"
                recommendation = "ç´°éƒ¨ã®èª¿æ•´ã«ã‚ˆã‚Šã€ã•ã‚‰ãªã‚‹æ”¹å–„ãŒæœŸå¾…ã§ãã‚‹"
            elif success_rate >= 40:
                final_verdict = "âš ï¸ **è«–ç†çš„é‡ã¿ä»˜ã‘ã‚·ã‚¹ãƒ†ãƒ ã¯éƒ¨åˆ†çš„ã«æœ‰åŠ¹**"
                recommendation = "é‡ã¿ä»˜ã‘ãƒ­ã‚¸ãƒƒã‚¯ã®è¦‹ç›´ã—ãŒå¿…è¦"
            else:
                final_verdict = "âŒ **è«–ç†çš„é‡ã¿ä»˜ã‘ã‚·ã‚¹ãƒ†ãƒ ã«å•é¡Œã‚ã‚Š**"
                recommendation = "é‡ã¿ä»˜ã‘ã‚·ã‚¹ãƒ†ãƒ ã®æ ¹æœ¬çš„ãªå†è¨­è¨ˆãŒå¿…è¦"
            
            f.write(f"- {final_verdict}\n")
            f.write(f"- **æ¨å¥¨**: {recommendation}\n\n")
            
            f.write("### çµ±è¨ˆçš„æ„ç¾©\n")
            f.write("ã“ã®æ¯”è¼ƒæ¤œè¨¼ã«ã‚ˆã‚Šã€ä»¥ä¸‹ãŒç¢ºèªã§ãã¾ã™ï¼š\n")
            f.write("1. **é‡ã¿ä»˜ã‘ã‚·ã‚¹ãƒ†ãƒ ã®æœ‰åŠ¹æ€§**: è«–ç†çš„é‡ã¿ä»˜ã‘ãŒãƒ©ãƒ³ãƒ€ãƒ ã‚ˆã‚Šå„ªç§€ã‹ã©ã†ã‹\n")
            f.write("2. **ç«¶é¦¬å ´æ ¼å¼ã®å¦¥å½“æ€§**: è¨­å®šã—ãŸç«¶é¦¬å ´æ ¼å¼ãŒå®Ÿæ…‹ã¨åˆè‡´ã—ã¦ã„ã‚‹ã‹\n")
            f.write("3. **äºˆæ¸¬ãƒ¢ãƒ‡ãƒ«ã®ä¿¡é ¼æ€§**: ã“ã®ã‚·ã‚¹ãƒ†ãƒ ãŒå®Ÿç”¨çš„ãªäºˆæ¸¬ã«ä½¿ãˆã‚‹ã‹\n\n")
            
            f.write("### æ³¨æ„äº‹é …\n")
            f.write("- ã“ã®åˆ†æã¯è¤‡å‹çµŒé¨“ã®ã‚ã‚‹é¦¬ã®ã¿ã‚’å¯¾è±¡ã¨ã—ã¦ã„ã¾ã™\n")
            f.write("- ãƒ©ãƒ³ãƒ€ãƒ é‡ã¿ä»˜ã‘ã¯1å›ã®å®Ÿè¡Œçµæœã§ã‚ã‚Šã€è¤‡æ•°å›ã®å¹³å‡ã§ã¯ã‚ã‚Šã¾ã›ã‚“\n")
            f.write("- ç›¸é–¢ä¿‚æ•°ãŒé«˜ãã¦ã‚‚å› æœé–¢ä¿‚ã‚’ä¿è¨¼ã™ã‚‹ã‚‚ã®ã§ã¯ã‚ã‚Šã¾ã›ã‚“\n")
            f.write("- å®Ÿéš›ã®é¦¬åˆ¸è³¼å…¥æ™‚ã¯ä»–ã®è¦å› ã‚‚ç·åˆçš„ã«æ¤œè¨ã—ã¦ãã ã•ã„\n")
        
        logger.info(f"ğŸ“‹ æ¯”è¼ƒåˆ†æãƒ¬ãƒãƒ¼ãƒˆä¿å­˜: {report_path}")
        return report_path

def validate_args(args):
    """ã‚³ãƒãƒ³ãƒ‰ãƒ©ã‚¤ãƒ³å¼•æ•°ã®æ¤œè¨¼"""
    input_path = Path(args.input_path)
    if not input_path.exists():
        raise FileNotFoundError(f"æŒ‡å®šã•ã‚ŒãŸãƒ‘ã‚¹ãŒå­˜åœ¨ã—ã¾ã›ã‚“: {input_path}")
    
    if args.min_races < 1:
        raise ValueError("æœ€å°ãƒ¬ãƒ¼ã‚¹æ•°ã¯1ä»¥ä¸Šã‚’æŒ‡å®šã—ã¦ãã ã•ã„")
    
    return args

def main():
    """ãƒ¡ã‚¤ãƒ³å‡¦ç†"""
    parser = argparse.ArgumentParser(
        description='é¦¬ã”ã¨è¤‡å‹æ™‚é‡ã¿ä»˜ã‘ãƒã‚¤ãƒ³ãƒˆåˆ†æã‚’3å¹´é–“éš”ã§å®Ÿè¡Œã—ã¾ã™',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ä½¿ç”¨ä¾‹:
  python analyze_winning_track_level.py export/with_bias
  python analyze_winning_track_level.py export/with_bias --output-dir results/place_point_analysis
  python analyze_winning_track_level.py export/with_bias --compare-random  # ãƒ©ãƒ³ãƒ€ãƒ é‡ã¿ä»˜ã‘æ¯”è¼ƒ
  
åˆ†æå†…å®¹:
  - é¦¬ã”ã¨ã®è¤‡å‹æ™‚é‡ã¿ä»˜ã‘ãƒã‚¤ãƒ³ãƒˆè¨ˆç®—ï¼ˆè¤‡å‹ã—ãŸå ´åˆã®ã¿ãƒã‚¤ãƒ³ãƒˆåŠ ç®—ï¼‰
  - 3å¹´é–“éš”ã§ã®æ™‚ç³»åˆ—åˆ†æ
  - è¤‡å‹çµŒé¨“é¦¬ã®ã¿ã§ã®ç›¸é–¢åˆ†æ
  - å®Ÿè¨¼æ¸ˆã¿æ ¼å¼åº¦ã¨å‹ç‡ã®é–¢ä¿‚åˆ†æ
  - ã‚ªãƒ—ã‚·ãƒ§ãƒ³: ãƒ©ãƒ³ãƒ€ãƒ é‡ã¿ä»˜ã‘ã¨ã®æ¯”è¼ƒåˆ†æ
        """
    )
    parser.add_argument('input_path', help='å…¥åŠ›ãƒ•ã‚¡ã‚¤ãƒ«ã¾ãŸã¯ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®ãƒ‘ã‚¹')
    parser.add_argument('--output-dir', default='export/place_point_analysis', 
                       help='å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®ãƒ‘ã‚¹')
    parser.add_argument('--min-races', type=int, default=5,  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã‚’5å›ã«å¤‰æ›´
                       help='åˆ†æå¯¾è±¡ã¨ã™ã‚‹æœ€å°ãƒ¬ãƒ¼ã‚¹æ•°ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 5ï¼‰')
    parser.add_argument('--encoding', default='utf-8', 
                       help='å…¥åŠ›ãƒ•ã‚¡ã‚¤ãƒ«ã®ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°')
    parser.add_argument('--compare-random', action='store_true',
                       help='ãƒ©ãƒ³ãƒ€ãƒ é‡ã¿ä»˜ã‘ã¨ã®æ¯”è¼ƒåˆ†æã‚’å®Ÿè¡Œ')
    
    try:
        args = parser.parse_args()
        args = validate_args(args)
        
        # è¨­å®šã®ä½œæˆ
        config = {
            'input_path': args.input_path,
            'output_dir': args.output_dir,
            'min_races': args.min_races,
            'encoding': args.encoding,
            'random_weights': False  # é€šå¸¸ã¯ False
        }
        
        if args.compare_random:
            logger.info("ğŸ² ãƒ©ãƒ³ãƒ€ãƒ é‡ã¿ä»˜ã‘æ¯”è¼ƒåˆ†æãƒ¢ãƒ¼ãƒ‰ã§å®Ÿè¡Œã—ã¾ã™...")
            logger.info(f"ğŸ“ å…¥åŠ›ãƒ‘ã‚¹: {args.input_path}")
            logger.info(f"ğŸ“Š å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª: {args.output_dir}")
            logger.info(f"ğŸ¯ æœ€å°ãƒ¬ãƒ¼ã‚¹æ•°: {args.min_races}")
            logger.info("ğŸ”„ ã‚ªãƒªã‚¸ãƒŠãƒ« vs ãƒ©ãƒ³ãƒ€ãƒ é‡ã¿ä»˜ã‘ã®æ¯”è¼ƒã‚’å®Ÿè¡Œ")
            
            # æ¯”è¼ƒåˆ†æã®å®Ÿè¡Œ
            analyzer = TrackWinRateAnalyzer(config)
            
            logger.info("ğŸ“– ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ä¸­...")
            analyzer.df = analyzer.load_data()
            
            logger.info("ğŸ”„ æ¯”è¼ƒåˆ†æå®Ÿè¡Œä¸­...")
            comparison_results = analyzer.compare_random_vs_original_weights()
            
            logger.info("ğŸ“Š æ¯”è¼ƒçµæœå¯è¦–åŒ–ä¸­...")
            analyzer.visualize_comparison_results(comparison_results)
            
            logger.info("ğŸ“ æ¯”è¼ƒåˆ†æãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆä¸­...")
            analyzer.generate_comparison_report(comparison_results)
            
            # æ¯”è¼ƒçµæœã®ã‚µãƒãƒªãƒ¼è¡¨ç¤º
            logger.info("\n" + "="*60)
            logger.info("ğŸ‰ æ¯”è¼ƒåˆ†æå®Œäº†ï¼çµæœ:")
            logger.info("="*60)
            
            for period_name, results in comparison_results.items():
                logger.info(f"ğŸ“Š æœŸé–“ {period_name}:")
                
                # ã‚ªãƒªã‚¸ãƒŠãƒ«çµæœ
                orig_corr = results['original']['correlation']
                if ('correlation_analysis' in orig_corr and 
                    'normalized' in orig_corr['correlation_analysis'] and
                    'place_rate' in orig_corr['correlation_analysis']['normalized']):
                    orig_r = orig_corr['correlation_analysis']['normalized']['place_rate']['correlation']
                    orig_p = orig_corr['correlation_analysis']['normalized']['place_rate']['p_value']
                    logger.info(f"   ğŸ“ˆ ã‚ªãƒªã‚¸ãƒŠãƒ«é‡ã¿ä»˜ã‘: r={orig_r:.3f}, p={orig_p:.3f}")
                
                # ãƒ©ãƒ³ãƒ€ãƒ çµæœ
                rand_corr = results['random']['correlation']
                if ('correlation_analysis' in rand_corr and 
                    'normalized' in rand_corr['correlation_analysis'] and
                    'place_rate' in rand_corr['correlation_analysis']['normalized']):
                    rand_r = rand_corr['correlation_analysis']['normalized']['place_rate']['correlation']
                    rand_p = rand_corr['correlation_analysis']['normalized']['place_rate']['p_value']
                    logger.info(f"   ğŸ² ãƒ©ãƒ³ãƒ€ãƒ é‡ã¿ä»˜ã‘: r={rand_r:.3f}, p={rand_p:.3f}")
                    
                    # å·®ã®è¨ˆç®—ã¨è©•ä¾¡
                    diff = abs(orig_r) - abs(rand_r)
                    if diff > 0.1:
                        logger.info(f"   âœ… ã‚ªãƒªã‚¸ãƒŠãƒ«ãŒæ˜ã‚‰ã‹ã«å„ªç§€ (å·®: {diff:.3f})")
                    elif diff > 0:
                        logger.info(f"   â• ã‚ªãƒªã‚¸ãƒŠãƒ«ãŒã‚ãšã‹ã«å„ªç§€ (å·®: {diff:.3f})")
                    elif diff > -0.1:
                        logger.info(f"   â– ã»ã¼åŒç­‰ (å·®: {diff:.3f})")
                    else:
                        logger.info(f"   âŒ ãƒ©ãƒ³ãƒ€ãƒ ãŒå„ªç§€ï¼Ÿ (å·®: {diff:.3f})")
                
                logger.info(f"   ğŸ“Š å¯¾è±¡: {results['total_horses']:,}é ­, {results['total_races']:,}ãƒ¬ãƒ¼ã‚¹")
            
            logger.info("="*60)
            logger.info(f"âœ… æ¯”è¼ƒçµæœã¯ {args.output_dir}/random_vs_original_comparison ã«ä¿å­˜ã•ã‚Œã¾ã—ãŸã€‚")
            
        else:
            logger.info("ğŸ‡ é¦¬ã”ã¨è¤‡å‹æ™‚é‡ã¿ä»˜ã‘ãƒã‚¤ãƒ³ãƒˆåˆ†æã‚’é–‹å§‹ã—ã¾ã™...")
            logger.info(f"ğŸ“ å…¥åŠ›ãƒ‘ã‚¹: {args.input_path}")
            logger.info(f"ğŸ“Š å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª: {args.output_dir}")
            logger.info(f"ğŸ¯ æœ€å°ãƒ¬ãƒ¼ã‚¹æ•°: {args.min_races}")
            logger.info("âœ¨ ç‰¹å¾´: è¤‡å‹ã—ãŸå ´åˆã®ã¿ãƒã‚¤ãƒ³ãƒˆåŠ ç®—")
            
            # é€šå¸¸ã®åˆ†æã®å®Ÿè¡Œ
            analyzer = TrackWinRateAnalyzer(config)
            
            logger.info("ğŸ“– ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ä¸­...")
            analyzer.df = analyzer.load_data()
            
            logger.info("ğŸ”§ ãƒ‡ãƒ¼ã‚¿å‰å‡¦ç†ä¸­...")
            analyzer.df = analyzer.preprocess_data()
            
            logger.info("ğŸ“Š é¦¬ã”ã¨è¤‡å‹æ™‚é‡ã¿ä»˜ã‘ãƒã‚¤ãƒ³ãƒˆåˆ†æå®Ÿè¡Œä¸­...")
            results = analyzer.analyze_track_win_rates()
            
            logger.info("ğŸ“Š å¯è¦–åŒ–ç”Ÿæˆä¸­...")
            analyzer.visualize_results(results)
            
            logger.info("ğŸ“ ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆä¸­...")
            analyzer.generate_report(results)
            
            # åˆ†æçµæœã®ã‚µãƒãƒªãƒ¼è¡¨ç¤º
            logger.info("\n" + "="*60)
            logger.info("ğŸ‰ åˆ†æå®Œäº†ï¼ä¸»è¦ãªçµæœ:")
            logger.info("="*60)
            
            for period_name, period_results in results.items():
                total_horses = period_results.get('total_horses', 0)
                total_races = period_results.get('total_races', 0)
                
                logger.info(f"ğŸ“Š æœŸé–“ {period_name}: {total_horses:,}é ­, {total_races:,}ãƒ¬ãƒ¼ã‚¹")
                
                if ('race_point_correlation' in period_results and 
                    'correlation_analysis' in period_results['race_point_correlation']):
                    corr_analysis = period_results['race_point_correlation']['correlation_analysis']
                    place_exp_horses = period_results['race_point_correlation'].get('place_experienced_horses')
                    
                    if place_exp_horses is not None:
                        win_corr = corr_analysis['avg_point']['win_rate']['correlation']
                        win_p = corr_analysis['avg_point']['win_rate']['p_value']
                        win_r2 = corr_analysis['avg_point']['win_rate']['r2']
                        
                        logger.info(f"   ğŸ“ˆ è¤‡å‹æ™‚ãƒã‚¤ãƒ³ãƒˆç›¸é–¢ï¼ˆè¤‡å‹çµŒé¨“é¦¬ {len(place_exp_horses)}é ­ï¼‰: r={win_corr:.3f}, p={win_p:.3f}")
                        logger.info(f"   ğŸ“Š å›å¸°RÂ²: {win_r2:.3f}")
                    else:
                        logger.info(f"   âš ï¸  è¤‡å‹çµŒé¨“é¦¬ä¸è¶³ã®ãŸã‚ç›¸é–¢åˆ†æãªã—")
            
            logger.info("="*60)
            logger.info(f"âœ… å…¨ã¦ã®çµæœã¯ {args.output_dir} ã«ä¿å­˜ã•ã‚Œã¾ã—ãŸã€‚")
            logger.info("ğŸ“‹ ç”Ÿæˆã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«:")
            logger.info("  - é¦¬ã”ã¨è¤‡å‹æ™‚é‡ã¿ä»˜ã‘ãƒã‚¤ãƒ³ãƒˆåˆ†æãƒ¬ãƒãƒ¼ãƒˆ.md")
            logger.info("  - å„æœŸé–“ãƒ•ã‚©ãƒ«ãƒ€å†…ã®åˆ†æçµæœPNG")
            logger.info("  â€» è¤‡å‹çµŒé¨“ã®ãªã„é¦¬ã¯é‡ã¿ä»˜ã‘ãƒã‚¤ãƒ³ãƒˆ0ã¨ã—ã¦è¡¨ç¤ºã•ã‚Œã¾ã™")
            logger.info("ğŸ’¡ ãƒ’ãƒ³ãƒˆ: --compare-random ã‚ªãƒ—ã‚·ãƒ§ãƒ³ã§ãƒ©ãƒ³ãƒ€ãƒ é‡ã¿ä»˜ã‘ã¨ã®æ¯”è¼ƒã‚‚å¯èƒ½ã§ã™")
        
        return 0
        
    except FileNotFoundError as e:
        logger.error(f"âŒ ãƒ•ã‚¡ã‚¤ãƒ«ã‚¨ãƒ©ãƒ¼: {str(e)}")
        return 1
    except ValueError as e:
        logger.error(f"âŒ å…¥åŠ›å€¤ã‚¨ãƒ©ãƒ¼: {str(e)}")
        return 1
    except Exception as e:
        logger.error(f"âŒ äºˆæœŸã›ã¬ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")
        logger.error("è©³ç´°ãªã‚¨ãƒ©ãƒ¼æƒ…å ±:", exc_info=True)
        return 1

if __name__ == '__main__':
    sys.exit(main()) 