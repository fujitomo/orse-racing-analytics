#!/usr/bin/env python
"""
ç«¶é¦¬ãƒ¬ãƒ¼ã‚¹åˆ†æã‚³ãƒãƒ³ãƒ‰ãƒ©ã‚¤ãƒ³ãƒ„ãƒ¼ãƒ«
ãƒ¬ãƒ¼ã‚¹ãƒ¬ãƒ™ãƒ«ã®åˆ†æã‚’å®Ÿè¡Œã—ã¾ã™ã€‚
3å¹´é–“éš”ã§ã®æ™‚ç³»åˆ—åˆ†æã«ã‚‚å¯¾å¿œã€‚
"""

import argparse
from pathlib import Path
from datetime import datetime
import logging
import sys
from horse_racing.base.analyzer import AnalysisConfig
from horse_racing.analyzers.race_level_analyzer import RaceLevelAnalyzer

# ãƒ¡ã‚¤ãƒ³ãƒ­ã‚¬ãƒ¼ã®è¨­å®š
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

def validate_date(date_str: str) -> datetime:
    """æ—¥ä»˜æ–‡å­—åˆ—ã®ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³"""
    try:
        return datetime.strptime(date_str, '%Y%m%d')
    except ValueError:
        raise ValueError(f"ç„¡åŠ¹ãªæ—¥ä»˜å½¢å¼ã§ã™: {date_str}ã€‚YYYYMMDDå½¢å¼ã§æŒ‡å®šã—ã¦ãã ã•ã„ã€‚")

def validate_args(args):
    """ã‚³ãƒãƒ³ãƒ‰ãƒ©ã‚¤ãƒ³å¼•æ•°ã®æ¤œè¨¼"""
    input_path = Path(args.input_path)
    if not input_path.exists():
        raise FileNotFoundError(f"æŒ‡å®šã•ã‚ŒãŸãƒ‘ã‚¹ãŒå­˜åœ¨ã—ã¾ã›ã‚“: {input_path}")
    
    if args.min_races < 1:
        raise ValueError("æœ€å°ãƒ¬ãƒ¼ã‚¹æ•°ã¯1ä»¥ä¸Šã‚’æŒ‡å®šã—ã¦ãã ã•ã„")
    
    # æ—¥ä»˜ç¯„å›²ã®ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³
    if args.start_date:
        start_date = validate_date(args.start_date)
    else:
        start_date = None
        
    if args.end_date:
        end_date = validate_date(args.end_date)
        if start_date and end_date < start_date:
            raise ValueError("çµ‚äº†æ—¥ã¯é–‹å§‹æ—¥ä»¥é™ã‚’æŒ‡å®šã—ã¦ãã ã•ã„")
    else:
        end_date = None
    
    return args

def analyze_by_periods(analyzer, periods, base_output_dir):
    """æœŸé–“åˆ¥ã«åˆ†æã‚’å®Ÿè¡Œ"""
    all_results = {}
    
    for period_name, start_year, end_year in periods:
        logger.info(f"æœŸé–“ {period_name} ã®åˆ†æé–‹å§‹...")
        
        try:
            # æœŸé–“åˆ¥ã®è¨­å®šã‚’ä½œæˆ
            period_config = AnalysisConfig(
                input_path=analyzer.config.input_path,
                min_races=analyzer.config.min_races,
                output_dir=str(base_output_dir / period_name),
                date_str=analyzer.config.date_str,
                start_date=f"{start_year}0101" if start_year else None,
                end_date=f"{end_year}1231" if end_year else None
            )
            
            logger.info(f"  ğŸ“… æœŸé–“è¨­å®š: {start_year}å¹´ - {end_year}å¹´")
            logger.info(f"  ğŸ“ å‡ºåŠ›å…ˆ: {period_config.output_dir}")
            
            # æœŸé–“åˆ¥ã‚¢ãƒŠãƒ©ã‚¤ã‚¶ãƒ¼ã‚’ä½œæˆ
            period_analyzer = RaceLevelAnalyzer(period_config, enable_time_analysis=analyzer.enable_time_analysis)
            
            # æœŸé–“åˆ¥åˆ†æã®å®Ÿè¡Œ
            logger.info(f"  ğŸ“– ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ä¸­...")
            period_analyzer.df = period_analyzer.load_data()
            
            logger.info(f"  ğŸ”§ å‰å‡¦ç†ä¸­...")
            period_analyzer.df = period_analyzer.preprocess_data()
            
            # ãƒ‡ãƒ¼ã‚¿ãŒååˆ†ã«ã‚ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
            if len(period_analyzer.df) < analyzer.config.min_races:
                logger.warning(f"æœŸé–“ {period_name}: ãƒ‡ãƒ¼ã‚¿ä¸è¶³ã®ãŸã‚ã‚¹ã‚­ãƒƒãƒ— ({len(period_analyzer.df)}è¡Œ)")
                continue
            
            logger.info(f"  ğŸ“Š å¯¾è±¡ãƒ‡ãƒ¼ã‚¿: {len(period_analyzer.df)}è¡Œ")
            logger.info(f"  ğŸ å¯¾è±¡é¦¬æ•°: {len(period_analyzer.df['é¦¬å'].unique())}é ­")
            
            logger.info(f"  ğŸ§® ç‰¹å¾´é‡è¨ˆç®—ä¸­...")
            period_analyzer.df = period_analyzer.calculate_feature()
            
            logger.info(f"  ğŸ“ˆ åˆ†æå®Ÿè¡Œä¸­...")
            results = period_analyzer.analyze()
            
            # çµæœã®å¯è¦–åŒ–
            logger.info(f"  ğŸ“Š å¯è¦–åŒ–ç”Ÿæˆä¸­...")
            period_analyzer.stats = results
            period_analyzer.visualize()
            
            # æœŸé–“æƒ…å ±ã‚’çµæœã«è¿½åŠ 
            results['period_info'] = {
                'name': period_name,
                'start_year': start_year,
                'end_year': end_year,
                'total_races': len(period_analyzer.df),
                'total_horses': len(period_analyzer.df['é¦¬å'].unique())
            }
            
            all_results[period_name] = results
            logger.info(f"æœŸé–“ {period_name} ã®åˆ†æå®Œäº†: {results['period_info']['total_races']}ãƒ¬ãƒ¼ã‚¹, {results['period_info']['total_horses']}é ­")
            
        except Exception as e:
            logger.error(f"æœŸé–“ {period_name} ã®åˆ†æã§ã‚¨ãƒ©ãƒ¼: {str(e)}")
            logger.error("è©³ç´°ãªã‚¨ãƒ©ãƒ¼æƒ…å ±:", exc_info=True)
            continue
    
    return all_results

def generate_period_summary_report(all_results, output_dir):
    """æœŸé–“åˆ¥åˆ†æã®ç·åˆãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆ"""
    report_path = output_dir / 'ãƒ¬ãƒ¼ã‚¹ãƒ¬ãƒ™ãƒ«åˆ†æ_æœŸé–“åˆ¥ç·åˆãƒ¬ãƒãƒ¼ãƒˆ.md'
    
    with open(report_path, 'w', encoding='utf-8') as f:
        f.write("# ãƒ¬ãƒ¼ã‚¹ãƒ¬ãƒ™ãƒ«åˆ†æ æœŸé–“åˆ¥ç·åˆãƒ¬ãƒãƒ¼ãƒˆ\n\n")
        f.write(f"ç”Ÿæˆæ—¥æ™‚: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n\n")
        
        f.write("## ğŸ“Š åˆ†ææœŸé–“ä¸€è¦§\n\n")
        f.write("| æœŸé–“ | å¯¾è±¡é¦¬æ•° | ç·ãƒ¬ãƒ¼ã‚¹æ•° | å¹³å‡ãƒ¬ãƒ™ãƒ«ç›¸é–¢ | æœ€é«˜ãƒ¬ãƒ™ãƒ«ç›¸é–¢ |\n")
        f.write("|------|----------|-----------|---------------|---------------|\n")
        
        for period_name, results in all_results.items():
            period_info = results.get('period_info', {})
            correlation_stats = results.get('correlation_stats', {})
            
            total_horses = period_info.get('total_horses', 0)
            total_races = period_info.get('total_races', 0)
            
            # ç›¸é–¢ä¿‚æ•°ã®å–å¾—
            corr_avg = correlation_stats.get('correlation_place_avg', 0.0)
            corr_max = correlation_stats.get('correlation_place_max', 0.0)
            
            f.write(f"| {period_name} | {total_horses:,}é ­ | {total_races:,}ãƒ¬ãƒ¼ã‚¹ | {corr_avg:.3f} | {corr_max:.3f} |\n")
        
        # å„æœŸé–“ã®è©³ç´°
        for period_name, results in all_results.items():
            f.write(f"\n## ğŸ“ˆ æœŸé–“: {period_name}\n\n")
            
            period_info = results.get('period_info', {})
            correlation_stats = results.get('correlation_stats', {})
            
            f.write(f"### åŸºæœ¬æƒ…å ±\n")
            f.write(f"- **åˆ†ææœŸé–“**: {period_info.get('start_year', 'ä¸æ˜')}å¹´ - {period_info.get('end_year', 'ä¸æ˜')}å¹´\n")
            f.write(f"- **å¯¾è±¡é¦¬æ•°**: {period_info.get('total_horses', 0):,}é ­\n")
            f.write(f"- **ç·ãƒ¬ãƒ¼ã‚¹æ•°**: {period_info.get('total_races', 0):,}ãƒ¬ãƒ¼ã‚¹\n\n")
            
            f.write(f"### ç›¸é–¢åˆ†æçµæœ\n")
            if correlation_stats:
                # å¹³å‡ãƒ¬ãƒ™ãƒ«åˆ†æ
                corr_place_avg = correlation_stats.get('correlation_place_avg', 0.0)
                r2_place_avg = correlation_stats.get('r2_place_avg', 0.0)
                
                # æœ€é«˜ãƒ¬ãƒ™ãƒ«åˆ†æ
                corr_place_max = correlation_stats.get('correlation_place_max', 0.0)
                r2_place_max = correlation_stats.get('r2_place_max', 0.0)
                
                f.write(f"**å¹³å‡ãƒ¬ãƒ¼ã‚¹ãƒ¬ãƒ™ãƒ« vs è¤‡å‹ç‡**\n")
                f.write(f"- ç›¸é–¢ä¿‚æ•°: {corr_place_avg:.3f}\n")
                f.write(f"- æ±ºå®šä¿‚æ•° (RÂ²): {r2_place_avg:.3f}\n\n")
                
                f.write(f"**æœ€é«˜ãƒ¬ãƒ¼ã‚¹ãƒ¬ãƒ™ãƒ« vs è¤‡å‹ç‡**\n")
                f.write(f"- ç›¸é–¢ä¿‚æ•°: {corr_place_max:.3f}\n")
                f.write(f"- æ±ºå®šä¿‚æ•° (RÂ²): {r2_place_max:.3f}\n\n")
            else:
                f.write("- ç›¸é–¢åˆ†æãƒ‡ãƒ¼ã‚¿ãªã—\n\n")
        
        f.write("\n## ğŸ’¡ ç·åˆçš„ãªå‚¾å‘ã¨çŸ¥è¦‹\n\n")
        
        # æœŸé–“åˆ¥ã®ç›¸é–¢ä¿‚æ•°å¤‰åŒ–
        if len(all_results) > 1:
            f.write("### æ™‚ç³»åˆ—å¤‰åŒ–\n")
            f.write("å¹³å‡ãƒ¬ãƒ¼ã‚¹ãƒ¬ãƒ™ãƒ«ã¨è¤‡å‹ç‡ã®ç›¸é–¢ä¿‚æ•°ã®å¤‰åŒ–ï¼š\n")
            
            correlations_by_period = []
            for period_name, results in all_results.items():
                correlation_stats = results.get('correlation_stats', {})
                corr = correlation_stats.get('correlation_place_avg', 0.0)
                correlations_by_period.append((period_name, corr))
            
            for i, (period, corr) in enumerate(correlations_by_period):
                if i > 0:
                    prev_corr = correlations_by_period[i-1][1]
                    change = corr - prev_corr
                    trend = "ä¸Šæ˜‡" if change > 0.05 else "ä¸‹é™" if change < -0.05 else "æ¨ªã°ã„"
                    f.write(f"- {period}: {corr:.3f} ({trend})\n")
                else:
                    f.write(f"- {period}: {corr:.3f} (åŸºæº–)\n")
        
        f.write("\n### ãƒ¬ãƒ¼ã‚¹ãƒ¬ãƒ™ãƒ«åˆ†æã®ç‰¹å¾´\n")
        f.write("- ãƒ¬ãƒ¼ã‚¹ãƒ¬ãƒ™ãƒ«ã¯ç«¶é¦¬å ´ã®æ ¼å¼åº¦ã¨å®ŸåŠ›ã®é–¢ä¿‚ã‚’æ•°å€¤åŒ–\n")
        f.write("- å¹³å‡ãƒ¬ãƒ™ãƒ«ï¼šé¦¬ã®ç¶™ç¶šçš„ãªå®ŸåŠ›ã‚’è¡¨ã™æŒ‡æ¨™\n")
        f.write("- æœ€é«˜ãƒ¬ãƒ™ãƒ«ï¼šé¦¬ã®ãƒ”ãƒ¼ã‚¯æ™‚ã®å®ŸåŠ›ã‚’è¡¨ã™æŒ‡æ¨™\n")
        f.write("- æ™‚ç³»åˆ—åˆ†æã«ã‚ˆã‚Šã€ç«¶é¦¬ç•Œã®æ ¼å¼ä½“ç³»ã®å¤‰åŒ–ã‚’æŠŠæ¡å¯èƒ½\n")
    
    logger.info(f"æœŸé–“åˆ¥ç·åˆãƒ¬ãƒãƒ¼ãƒˆä¿å­˜: {report_path}")

def main():
    """ãƒ¡ã‚¤ãƒ³å‡¦ç†"""
    parser = argparse.ArgumentParser(
        description='ãƒ¬ãƒ¼ã‚¹ãƒ¬ãƒ™ãƒ«åˆ†æã‚’å®Ÿè¡Œã—ã¾ã™ï¼ˆ3å¹´é–“éš”åˆ†æå¯¾å¿œã€RunningTimeåˆ†æå¯¾å¿œï¼‰',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ä½¿ç”¨ä¾‹:
  python analyze_race_level.py export/with_bias
  python analyze_race_level.py export/with_bias --output-dir results/race_level_analysis
  python analyze_race_level.py export/with_bias --three-year-periods  # 3å¹´é–“éš”åˆ†æ
  python analyze_race_level.py export/with_bias --enable-time-analysis  # RunningTimeåˆ†æ
  
åˆ†æå†…å®¹:
  - ãƒ¬ãƒ¼ã‚¹ãƒ¬ãƒ™ãƒ«ï¼ˆã‚°ãƒ¬ãƒ¼ãƒ‰ãƒ»è³é‡‘ãƒ»è·é›¢ã«ã‚ˆã‚‹æ ¼ä»˜ã‘ï¼‰ã®è¨ˆç®—
  - ãƒ¬ãƒ¼ã‚¹ãƒ¬ãƒ™ãƒ«ã¨å‹ç‡ãƒ»è¤‡å‹ç‡ã®ç›¸é–¢åˆ†æ
  - ã‚ªãƒ—ã‚·ãƒ§ãƒ³: 3å¹´é–“éš”ã§ã®æ™‚ç³»åˆ—åˆ†æ
  - ã‚ªãƒ—ã‚·ãƒ§ãƒ³: èµ°ç ´ã‚¿ã‚¤ãƒ å› æœé–¢ä¿‚åˆ†æï¼ˆè«–æ–‡ä»®èª¬H1, H4æ¤œè¨¼ï¼‰
        """
    )
    parser.add_argument('input_path', help='å…¥åŠ›ãƒ•ã‚¡ã‚¤ãƒ«ã¾ãŸã¯ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®ãƒ‘ã‚¹')
    parser.add_argument('--output-dir', default='export/race_level_analysis', help='å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®ãƒ‘ã‚¹')
    parser.add_argument('--min-races', type=int, default=6, help='åˆ†æå¯¾è±¡ã¨ã™ã‚‹æœ€å°ãƒ¬ãƒ¼ã‚¹æ•°')
    parser.add_argument('--encoding', default='utf-8', help='å…¥åŠ›ãƒ•ã‚¡ã‚¤ãƒ«ã®ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°')
    parser.add_argument('--start-date', help='åˆ†æé–‹å§‹æ—¥ï¼ˆYYYYMMDDå½¢å¼ï¼‰')
    parser.add_argument('--end-date', help='åˆ†æçµ‚äº†æ—¥ï¼ˆYYYYMMDDå½¢å¼ï¼‰')
    parser.add_argument('--three-year-periods', action='store_true',
                       help='3å¹´é–“éš”ã§ã®æœŸé–“åˆ¥åˆ†æã‚’å®Ÿè¡Œï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã¯å…¨æœŸé–“åˆ†æï¼‰')
    parser.add_argument('--enable-time-analysis', action='store_true',
                       help='èµ°ç ´ã‚¿ã‚¤ãƒ å› æœé–¢ä¿‚åˆ†æã‚’å®Ÿè¡Œï¼ˆè«–æ–‡ä»®èª¬H1, H4æ¤œè¨¼ï¼‰')
    
    try:
        args = parser.parse_args()
        args = validate_args(args)

        # å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®ä½œæˆ
        output_dir = Path(args.output_dir)
        output_dir.mkdir(parents=True, exist_ok=True)

        logger.info(f"ğŸ‡ ãƒ¬ãƒ¼ã‚¹ãƒ¬ãƒ™ãƒ«åˆ†æã‚’é–‹å§‹ã—ã¾ã™...")
        logger.info(f"ğŸ“ å…¥åŠ›ãƒ‘ã‚¹: {args.input_path}")
        logger.info(f"ğŸ“Š å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª: {args.output_dir}")
        logger.info(f"ğŸ¯ æœ€å°ãƒ¬ãƒ¼ã‚¹æ•°: {args.min_races}")
        if args.start_date:
            logger.info(f"ğŸ“… åˆ†æé–‹å§‹æ—¥: {args.start_date}")
        if args.end_date:
            logger.info(f"ğŸ“… åˆ†æçµ‚äº†æ—¥: {args.end_date}")
        if args.enable_time_analysis:
            logger.info(f"ğŸƒ RunningTimeåˆ†æ: æœ‰åŠ¹")
        else:
            logger.info(f"ğŸƒ RunningTimeåˆ†æ: ç„¡åŠ¹ï¼ˆ--enable-time-analysisã§æœ‰åŠ¹åŒ–ï¼‰")

        if args.three_year_periods:
            logger.info("ğŸ“Š 3å¹´é–“éš”ã§ã®æœŸé–“åˆ¥åˆ†æã‚’å®Ÿè¡Œã—ã¾ã™...")
            
            # åˆæœŸãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ã§å¹´ãƒ‡ãƒ¼ã‚¿ç¯„å›²ã‚’ç¢ºèª
            temp_config = AnalysisConfig(
                input_path=args.input_path,
                min_races=args.min_races,
                output_dir=str(output_dir),
                date_str=datetime.now().strftime('%Y%m%d'),
                start_date=args.start_date,
                end_date=args.end_date
            )
            
            # ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ã¨åŸºæœ¬çš„ãªå‰å‡¦ç†ï¼ˆæœŸé–“ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ãªã—ï¼‰
            temp_analyzer = RaceLevelAnalyzer(temp_config, enable_time_analysis=args.enable_time_analysis)
            logger.info("ğŸ“– å…¨ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ä¸­...")
            temp_df = temp_analyzer.load_data()
            
            logger.info(f"ğŸ“Š èª­ã¿è¾¼ã‚“ã ãƒ‡ãƒ¼ã‚¿ä»¶æ•°: {len(temp_df):,}ä»¶")
            
            # å¹´ãƒ‡ãƒ¼ã‚¿ãŒå­˜åœ¨ã™ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
            if 'å¹´' in temp_df.columns and temp_df['å¹´'].notna().any():
                min_year = int(temp_df['å¹´'].min())
                max_year = int(temp_df['å¹´'].max())
                logger.info(f"ğŸ“Š å¹´ãƒ‡ãƒ¼ã‚¿ç¯„å›²: {min_year}å¹´ - {max_year}å¹´")
                
                # 3å¹´é–“éš”ã§ã®æœŸé–“è¨­å®š
                periods = []
                for start_year in range(min_year, max_year + 1, 3):
                    end_year = min(start_year + 2, max_year)
                    period_name = f"{start_year}-{end_year}"
                    
                    # æœŸé–“å†…ã«ãƒ‡ãƒ¼ã‚¿ãŒå­˜åœ¨ã™ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
                    period_data = temp_df[
                        (temp_df['å¹´'] >= start_year) & (temp_df['å¹´'] <= end_year)
                    ]
                    
                    if len(period_data) >= args.min_races:
                        periods.append((period_name, start_year, end_year))
                        logger.info(f"  ğŸ“Š æœŸé–“ {period_name}: {len(period_data):,}ä»¶ã®ãƒ‡ãƒ¼ã‚¿")
                    else:
                        logger.warning(f"  âš ï¸  æœŸé–“ {period_name}: ãƒ‡ãƒ¼ã‚¿ä¸è¶³ ({len(period_data)}ä»¶)")
                
                if periods:
                    logger.info(f"ğŸ“Š æœ‰åŠ¹ãªåˆ†ææœŸé–“: {[p[0] for p in periods]}")
                    
                    # æœŸé–“åˆ¥åˆ†æã®å®Ÿè¡Œ
                    all_results = analyze_by_periods(temp_analyzer, periods, output_dir)
                    
                    if all_results:
                        # ç·åˆãƒ¬ãƒãƒ¼ãƒˆã®ç”Ÿæˆ
                        generate_period_summary_report(all_results, output_dir)
                        
                        logger.info("\n" + "="*60)
                        logger.info("ğŸ‰ 3å¹´é–“éš”åˆ†æå®Œäº†ï¼çµæœ:")
                        logger.info("="*60)
                        
                        for period_name, results in all_results.items():
                            period_info = results.get('period_info', {})
                            correlation_stats = results.get('correlation_stats', {})
                            
                            total_horses = period_info.get('total_horses', 0)
                            total_races = period_info.get('total_races', 0)
                            corr_avg = correlation_stats.get('correlation_place_avg', 0.0)
                            
                            logger.info(f"ğŸ“Š æœŸé–“ {period_name}: {total_horses:,}é ­, {total_races:,}ãƒ¬ãƒ¼ã‚¹")
                            logger.info(f"   ğŸ“ˆ å¹³å‡ãƒ¬ãƒ™ãƒ« vs è¤‡å‹ç‡ç›¸é–¢: r={corr_avg:.3f}")
                        
                        logger.info("="*60)
                        logger.info(f"âœ… å…¨ã¦ã®çµæœã¯ {args.output_dir} ã«ä¿å­˜ã•ã‚Œã¾ã—ãŸã€‚")
                        logger.info("ğŸ“‹ ç”Ÿæˆã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«:")
                        logger.info("  - ãƒ¬ãƒ¼ã‚¹ãƒ¬ãƒ™ãƒ«åˆ†æ_æœŸé–“åˆ¥ç·åˆãƒ¬ãƒãƒ¼ãƒˆ.md")
                        logger.info("  - å„æœŸé–“ãƒ•ã‚©ãƒ«ãƒ€å†…ã®åˆ†æçµæœPNG")
                    else:
                        logger.warning("âš ï¸  æœ‰åŠ¹ãªæœŸé–“åˆ¥åˆ†æçµæœãŒã‚ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
                else:
                    logger.warning("âš ï¸  ååˆ†ãªãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚‹æœŸé–“ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚å…¨æœŸé–“ã§ã®åˆ†æã«åˆ‡ã‚Šæ›¿ãˆã¾ã™ã€‚")
                    args.three_year_periods = False
            else:
                logger.warning("âš ï¸  å¹´ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚å…¨æœŸé–“ã§ã®åˆ†æã«åˆ‡ã‚Šæ›¿ãˆã¾ã™ã€‚")
                args.three_year_periods = False
        
        if not args.three_year_periods:
            logger.info("ğŸ“Š å…¨æœŸé–“ã§ã®åˆ†æã‚’å®Ÿè¡Œã—ã¾ã™...")
            
            # è¨­å®šã®ä½œæˆ
            date_str = datetime.now().strftime('%Y%m%d')
            config = AnalysisConfig(
                input_path=args.input_path,
                min_races=args.min_races,
                output_dir=str(output_dir),
                date_str=date_str,
                start_date=args.start_date,
                end_date=args.end_date
            )

            # åˆ†æã®å®Ÿè¡Œ
            analyzer = RaceLevelAnalyzer(config, enable_time_analysis=args.enable_time_analysis)
            analyzer.df = analyzer.load_data()
            analyzer.df = analyzer.preprocess_data()
            analyzer.df = analyzer.calculate_feature()
            results = analyzer.analyze()
            
            # çµæœã®å¯è¦–åŒ–
            analyzer.stats = results
            analyzer.visualize()

            logger.info(f"âœ… åˆ†æãŒå®Œäº†ã—ã¾ã—ãŸã€‚çµæœã¯ {output_dir} ã«ä¿å­˜ã•ã‚Œã¾ã—ãŸã€‚")

        return 0

    except FileNotFoundError as e:
        logger.error(f"âŒ ãƒ•ã‚¡ã‚¤ãƒ«ã‚¨ãƒ©ãƒ¼: {str(e)}")
        return 1
    except ValueError as e:
        logger.error(f"âŒ å…¥åŠ›å€¤ã‚¨ãƒ©ãƒ¼: {str(e)}")
        return 1
    except Exception as e:
        logger.error(f"âŒ äºˆæœŸã›ã¬ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")
        logger.error("è©³ç´°ãªã‚¨ãƒ©ãƒ¼æƒ…å ±:", exc_info=True)
        return 1

if __name__ == '__main__':
    sys.exit(main())