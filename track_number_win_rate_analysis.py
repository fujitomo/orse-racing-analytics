import os
import glob
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from datetime import datetime
import japanize_matplotlib
from scipy import stats
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import r2_score
import statsmodels.api as sm
import warnings
warnings.filterwarnings('ignore')

class TrackNumberWinRateAnalyzer:
    """
    ç«¶é¦¬å ´åˆ¥é¦¬ç•ªã¨å‹ç‡ã®é–¢ä¿‚ã‚’åˆ†æã™ã‚‹ã‚¯ãƒ©ã‚¹
    """
    
    def __init__(self, data_folder="export/with_bias", output_folder="results/track_number_analysis", turf_only=False):
        """
        åˆæœŸåŒ–
        
        Args:
            data_folder (str): ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚©ãƒ«ãƒ€ã®ãƒ‘ã‚¹
            output_folder (str): çµæœå‡ºåŠ›å…ˆãƒ•ã‚©ãƒ«ãƒ€ã®ãƒ‘ã‚¹
            turf_only (bool): èŠãƒ¬ãƒ¼ã‚¹ã®ã¿ã«çµã‚‹ã‹ã©ã†ã‹
        """
        self.data_folder = data_folder
        self.output_folder = output_folder
        self.df = None
        self.turf_only = turf_only  # èŠãƒ¬ãƒ¼ã‚¹ã®ã¿ã«çµã‚‹ã‹ã©ã†ã‹
        
        # æ—¥æœ¬èªãƒ•ã‚©ãƒ³ãƒˆè¨­å®š
        self._setup_japanese_font()
        
    def _setup_japanese_font(self):
        """
        æ—¥æœ¬èªãƒ•ã‚©ãƒ³ãƒˆã®ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ï¼ˆæ”¹è‰¯ç‰ˆï¼‰
        """
        import matplotlib
        import matplotlib.font_manager as fm
        import platform
        import os
        
        try:
            print("æ—¥æœ¬èªãƒ•ã‚©ãƒ³ãƒˆè¨­å®šã‚’é–‹å§‹ï¼ˆæ”¹è‰¯ç‰ˆï¼‰...")
            
            if platform.system() == 'Windows':
                # Windowsãƒ•ã‚©ãƒ³ãƒˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
                windows_fonts_dir = r'C:\Windows\Fonts'
                
                # åˆ©ç”¨å¯èƒ½ãªæ—¥æœ¬èªãƒ•ã‚©ãƒ³ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç›´æ¥æŒ‡å®š
                font_candidates = [
                    (os.path.join(windows_fonts_dir, 'YuGothM.ttc'), 'Yu Gothic Medium'),
                    (os.path.join(windows_fonts_dir, 'YuGothB.ttc'), 'Yu Gothic Bold'),
                    (os.path.join(windows_fonts_dir, 'yugothm.ttf'), 'Yu Gothic Medium'),
                    (os.path.join(windows_fonts_dir, 'msgothic.ttc'), 'MS Gothic'),
                    (os.path.join(windows_fonts_dir, 'meiryo.ttc'), 'Meiryo'),
                    (os.path.join(windows_fonts_dir, 'msmincho.ttc'), 'MS Mincho'),
                ]
                
                font_found = False
                
                # ãƒ•ã‚©ãƒ³ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã®å­˜åœ¨ç¢ºèªã¨è¨­å®š
                for font_path, font_name in font_candidates:
                    if os.path.exists(font_path):
                        try:
                            # ãƒ•ã‚©ãƒ³ãƒˆãƒ—ãƒ­ãƒ‘ãƒ†ã‚£ã‚’ä½œæˆ
                            prop = fm.FontProperties(fname=font_path)
                            
                            # ãƒ•ã‚©ãƒ³ãƒˆã‚’ç™»éŒ²
                            fm.fontManager.addfont(font_path)
                            
                            # matplotlibã®è¨­å®šã‚’æ›´æ–°
                            matplotlib.rcParams['font.family'] = [font_name, 'DejaVu Sans', 'sans-serif']
                            
                            # ãƒ†ã‚¹ãƒˆæç”»
                            fig, ax = plt.subplots(figsize=(2, 1))
                            ax.text(0.5, 0.5, 'é¦¬ç•ªå‹ç‡ãƒ†ã‚¹ãƒˆ', ha='center', va='center', fontproperties=prop)
                            plt.close(fig)
                            
                            print(f"ãƒ•ã‚©ãƒ³ãƒˆè¨­å®šæˆåŠŸ: {font_name} ({font_path})")
                            font_found = True
                            break
                            
                        except Exception as e:
                            print(f"ãƒ•ã‚©ãƒ³ãƒˆ {font_name} ã®è¨­å®šã«å¤±æ•—: {e}")
                            continue
                
                if not font_found:
                    print("Windowsãƒ•ã‚©ãƒ³ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ã®è¨­å®šã«å¤±æ•—ã—ã¾ã—ãŸã€‚ã‚·ã‚¹ãƒ†ãƒ ãƒ•ã‚©ãƒ³ãƒˆã‚’è©¦è¡Œ...")
                    # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: ã‚·ã‚¹ãƒ†ãƒ ç™»éŒ²ãƒ•ã‚©ãƒ³ãƒˆ
                    font_list = [f.name for f in fm.fontManager.ttflist]
                    japanese_fonts = ['Yu Gothic UI', 'Yu Gothic', 'MS Gothic', 'MS PGothic', 'Meiryo UI', 'Meiryo']
                    
                    for font in japanese_fonts:
                        if font in font_list:
                            matplotlib.rcParams['font.family'] = [font, 'DejaVu Sans']
                            print(f"ã‚·ã‚¹ãƒ†ãƒ ãƒ•ã‚©ãƒ³ãƒˆè¨­å®š: {font}")
                            font_found = True
                            break
                    
                    if not font_found:
                        print("æ—¥æœ¬èªãƒ•ã‚©ãƒ³ãƒˆãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚è‹±èªè¡¨ç¤ºã«ãªã‚Šã¾ã™ã€‚")
                        matplotlib.rcParams['font.family'] = ['DejaVu Sans']
            else:
                # Windowsä»¥å¤–ã®OS
                matplotlib.rcParams['font.family'] = ['Hiragino Sans', 'Yu Gothic', 'Meiryo', 'DejaVu Sans']
                print("éWindowsç’°å¢ƒã§ã®æ—¥æœ¬èªãƒ•ã‚©ãƒ³ãƒˆè¨­å®š")
            
            # å…±é€šè¨­å®š
            matplotlib.rcParams['axes.unicode_minus'] = False
            matplotlib.rcParams['figure.figsize'] = (12, 8)
            matplotlib.rcParams['font.size'] = 10
            matplotlib.rcParams['axes.titlesize'] = 12
            matplotlib.rcParams['axes.labelsize'] = 10
            matplotlib.rcParams['legend.fontsize'] = 10
            
            # è¨­å®šç¢ºèªã®ãŸã‚ã®ãƒ†ã‚¹ãƒˆ
            current_font = matplotlib.rcParams['font.family']
            print(f"æœ€çµ‚ãƒ•ã‚©ãƒ³ãƒˆè¨­å®š: {current_font}")
            
        except Exception as e:
            print(f"ãƒ•ã‚©ãƒ³ãƒˆè¨­å®šã‚¨ãƒ©ãƒ¼: {e}")
            print("ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆè¨­å®šã‚’ä½¿ç”¨ã—ã¾ã™ã€‚")
            # æœ€ä½é™ã®è¨­å®š
            try:
                matplotlib.rcParams['axes.unicode_minus'] = False
                matplotlib.rcParams['font.family'] = ['DejaVu Sans']
            except:
                pass
        
    def load_sed_data(self):
        """
        SEDãƒ•ã‚¡ã‚¤ãƒ«ç¾¤ã‹ã‚‰ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã‚€
        
        Returns:
            bool: èª­ã¿è¾¼ã¿æˆåŠŸæ™‚Trueã€å¤±æ•—æ™‚False
        """
        print("SEDãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã‚“ã§ã„ã¾ã™...")
        
        # SEDãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’æ¤œç´¢
        sed_files = glob.glob(os.path.join(self.data_folder, "SED*_formatted_with_bias.csv"))
        
        if not sed_files:
            print(f"ã‚¨ãƒ©ãƒ¼: {self.data_folder} ã«SEDãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")
            return False
        
        print(f"è¦‹ã¤ã‹ã£ãŸSEDãƒ•ã‚¡ã‚¤ãƒ«: {len(sed_files)}å€‹")
        
        data_list = []
        
        for file_path in sed_files:
            try:
                # ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã‚’è©¦è¡ŒéŒ¯èª¤ã§èª­ã¿è¾¼ã¿
                for encoding in ['utf-8', 'shift-jis', 'cp932']:
                    try:
                        df = pd.read_csv(file_path, encoding=encoding)
                        print(f"èª­ã¿è¾¼ã¿æˆåŠŸ: {os.path.basename(file_path)} ({len(df)}è¡Œ)")
                        data_list.append(df)
                        break
                    except UnicodeDecodeError:
                        continue
                    except Exception as e:
                        print(f"ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {file_path} - {e}")
                        break
            except Exception as e:
                print(f"ãƒ•ã‚¡ã‚¤ãƒ« {file_path} ã®å‡¦ç†ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿ: {e}")
        
        if not data_list:
            print("ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸã€‚")
            return False
        
        # ãƒ‡ãƒ¼ã‚¿ã‚’çµåˆ
        self.df = pd.concat(data_list, ignore_index=True)
        print(f"ç·ãƒ‡ãƒ¼ã‚¿æ•°: {len(self.df)}è¡Œ")
        
        return True
    
    def preprocess_data(self):
        """
        ãƒ‡ãƒ¼ã‚¿ã®å‰å‡¦ç†ã‚’å®Ÿè¡Œ
        
        Returns:
            bool: å‰å‡¦ç†æˆåŠŸæ™‚Trueã€å¤±æ•—æ™‚False
        """
        print("ãƒ‡ãƒ¼ã‚¿ã®å‰å‡¦ç†ã‚’å®Ÿè¡Œä¸­...")
        
        if self.df is None:
            print("ã‚¨ãƒ©ãƒ¼: ãƒ‡ãƒ¼ã‚¿ãŒèª­ã¿è¾¼ã¾ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
            return False
        
        # å¿…è¦ãªã‚«ãƒ©ãƒ ã®å­˜åœ¨ç¢ºèª
        required_columns = ['å ´ã‚³ãƒ¼ãƒ‰', 'å¹´', 'é¦¬ç•ª', 'ç€é †']
        missing_columns = [col for col in required_columns if col not in self.df.columns]
        
        if missing_columns:
            print(f"ã‚¨ãƒ©ãƒ¼: å¿…è¦ãªã‚«ãƒ©ãƒ ãŒä¸è¶³ã—ã¦ã„ã¾ã™: {missing_columns}")
            return False
        
        # ãƒ‡ãƒ¼ã‚¿å‹ã®å¤‰æ›
        self.df['å¹´'] = pd.to_numeric(self.df['å¹´'], errors='coerce')
        self.df['é¦¬ç•ª'] = pd.to_numeric(self.df['é¦¬ç•ª'], errors='coerce')
        self.df['ç€é †'] = pd.to_numeric(self.df['ç€é †'], errors='coerce')
        
        # å‹åˆ©ãƒ•ãƒ©ã‚°ã®ä½œæˆï¼ˆ1ä½ãªã‚‰1ã€ãã‚Œä»¥å¤–ã¯0ï¼‰
        self.df['å‹åˆ©'] = (self.df['ç€é †'] == 1).astype(int)
        
        # ç„¡åŠ¹ãªãƒ‡ãƒ¼ã‚¿ã‚’é™¤å»
        before_count = len(self.df)
        self.df = self.df.dropna(subset=['å¹´', 'é¦¬ç•ª', 'ç€é †'])
        after_count = len(self.df)
        
        print(f"ãƒ‡ãƒ¼ã‚¿ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°: {before_count}è¡Œ â†’ {after_count}è¡Œ")
        
        # èŠãƒ¬ãƒ¼ã‚¹ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
        if self.turf_only:
            if not self._filter_turf_races():
                print("èŠãƒ¬ãƒ¼ã‚¹ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã«å¤±æ•—ã—ã¾ã—ãŸã€‚")
                return False
        
        # åŸºæœ¬çµ±è¨ˆæƒ…å ±ã®è¡¨ç¤º
        print("\n=== ãƒ‡ãƒ¼ã‚¿æ¦‚è¦ ===")
        print(f"å¹´ã®ç¯„å›²: {self.df['å¹´'].min()} - {self.df['å¹´'].max()}")
        print(f"é¦¬ç•ªã®ç¯„å›²: {self.df['é¦¬ç•ª'].min()} - {self.df['é¦¬ç•ª'].max()}")
        print(f"ç«¶é¦¬å ´æ•°: {self.df['å ´å'].nunique()}")
        print(f"ç«¶é¦¬å ´: {list(self.df['å ´å'].unique())}")
        
        return True
    
    def _filter_turf_races(self):
        """
        èŠãƒ¬ãƒ¼ã‚¹ã®ã¿ã«ãƒ‡ãƒ¼ã‚¿ã‚’ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
        
        Returns:
            bool: ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°æˆåŠŸæ™‚Trueã€å¤±æ•—æ™‚False
        """
        print("ğŸŒ± èŠãƒ¬ãƒ¼ã‚¹ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ä¸­...")
        
        # ã‚³ãƒ¼ã‚¹ç¨®åˆ¥ã®åˆ—ã‚’ç‰¹å®š
        turf_column = None
        possible_columns = ['èŠãƒ€éšœå®³ã‚³ãƒ¼ãƒ‰', 'ã‚³ãƒ¼ã‚¹ç¨®åˆ¥', 'èŠãƒ€ãƒ¼ãƒˆ', 'ãƒˆãƒ©ãƒƒã‚¯ç¨®åˆ¥']
        
        for col in possible_columns:
            if col in self.df.columns:
                turf_column = col
                print(f"ã‚³ãƒ¼ã‚¹ç¨®åˆ¥åˆ—ã‚’ç™ºè¦‹: {col}")
                break
        
        if turf_column is None:
            print("è­¦å‘Š: ã‚³ãƒ¼ã‚¹ç¨®åˆ¥ã‚’è¡¨ã™åˆ—ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")
            print(f"åˆ©ç”¨å¯èƒ½ãªåˆ—: {list(self.df.columns)}")
            return False
        
        # ãƒ‡ãƒ¼ã‚¿ã®å†…å®¹ã‚’ç¢ºèª
        unique_values = self.df[turf_column].dropna().unique()
        print(f"ã‚³ãƒ¼ã‚¹ç¨®åˆ¥ã®å€¤: {unique_values}")
        
        # èŠãƒ¬ãƒ¼ã‚¹ã®åˆ¤å®šæ¡ä»¶
        before_count = len(self.df)
        
        if turf_column == 'èŠãƒ€éšœå®³ã‚³ãƒ¼ãƒ‰':
            # ãƒ‡ãƒ¼ã‚¿ã®å€¤ã‚’ç¢ºèªã—ã¦é©åˆ‡ãªæ¡ä»¶ã‚’è¨­å®š
            if self.df[turf_column].dtype == 'object':
                # æ–‡å­—åˆ—ã®å ´åˆ
                turf_condition = self.df[turf_column] == 'èŠ'
            else:
                # æ•°å€¤ã‚³ãƒ¼ãƒ‰ã®å ´åˆ: 1=èŠã€2=ãƒ€ãƒ¼ãƒˆã€3=éšœå®³ï¼ˆä¸€èˆ¬çš„ãªè¨­å®šï¼‰
                turf_condition = self.df[turf_column] == 1
        else:
            # æ–‡å­—åˆ—ã®å ´åˆ
            turf_condition = self.df[turf_column].str.contains('èŠ', na=False)
        
        self.df = self.df[turf_condition].copy()
        after_count = len(self.df)
        
        print(f"èŠãƒ¬ãƒ¼ã‚¹ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°çµæœ: {before_count}è¡Œ â†’ {after_count}è¡Œ")
        print(f"å‰Šæ¸›ã•ã‚ŒãŸãƒ¬ãƒ¼ã‚¹æ•°: {before_count - after_count}è¡Œ ({((before_count - after_count) / before_count * 100):.1f}%)")
        
        if after_count == 0:
            print("ã‚¨ãƒ©ãƒ¼: èŠãƒ¬ãƒ¼ã‚¹ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°æ¡ä»¶ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
            return False
        
        return True
    
    def get_period_ranges(self, period_years=3):
        """
        åˆ†ææœŸé–“ã®ç¯„å›²ã‚’å–å¾—
        
        Args:
            period_years (int): 1æœŸé–“ã®å¹´æ•°
            
        Returns:
            list: æœŸé–“ã®ç¯„å›²ã®ãƒªã‚¹ãƒˆ [(é–‹å§‹å¹´, çµ‚äº†å¹´), ...]
        """
        min_year = self.df['å¹´'].min()
        max_year = self.df['å¹´'].max()
        
        if pd.isna(min_year) or pd.isna(max_year):
            print("ã‚¨ãƒ©ãƒ¼: å¹´ãƒ‡ãƒ¼ã‚¿ãŒä¸æ­£ã§ã™ã€‚")
            return []
        
        periods = []
        start_year = min_year
        
        while start_year <= max_year:
            end_year = min(start_year + period_years - 1, max_year)
            periods.append((int(start_year), int(end_year)))
            start_year = end_year + 1
        
        print(f"åˆ†ææœŸé–“: {periods}")
        return periods
    
    def calculate_win_rate_by_number(self, data):
        """
        é¦¬ç•ªåˆ¥ã®å‹ç‡ã‚’è¨ˆç®—
        
        Args:
            data (DataFrame): åˆ†æå¯¾è±¡ãƒ‡ãƒ¼ã‚¿
            
        Returns:
            DataFrame: é¦¬ç•ªåˆ¥å‹ç‡ãƒ‡ãƒ¼ã‚¿
        """
        # é¦¬ç•ªåˆ¥ã®å‹ç‡é›†è¨ˆ
        number_stats = data.groupby('é¦¬ç•ª').agg({
            'å‹åˆ©': ['count', 'sum', 'mean'],
            'ç€é †': 'mean'
        }).round(4)
        
        # ã‚«ãƒ©ãƒ åã‚’æ•´ç†
        number_stats.columns = ['ç·ãƒ¬ãƒ¼ã‚¹æ•°', 'å‹åˆ©æ•°', 'å‹ç‡', 'å¹³å‡ç€é †']
        number_stats = number_stats.reset_index()
        
        # å‹ç‡ã‚’ãƒ‘ãƒ¼ã‚»ãƒ³ãƒ†ãƒ¼ã‚¸ã«å¤‰æ›
        number_stats['å‹ç‡_percent'] = number_stats['å‹ç‡'] * 100
        
        return number_stats
    
    def perform_statistical_analysis(self, data, track_name, period_name):
        """
        çµ±è¨ˆåˆ†æã‚’å®Ÿè¡Œ
        
        Args:
            data (DataFrame): åˆ†æå¯¾è±¡ãƒ‡ãƒ¼ã‚¿
            track_name (str): ç«¶é¦¬å ´å
            period_name (str): æœŸé–“å
            
        Returns:
            dict: åˆ†æçµæœ
        """
        # é¦¬ç•ªåˆ¥å‹ç‡ã‚’è¨ˆç®—
        win_rate_data = self.calculate_win_rate_by_number(data)
        
        # ååˆ†ãªãƒ‡ãƒ¼ã‚¿ãŒãªã„å ´åˆã¯ã‚¹ã‚­ãƒƒãƒ—
        if len(win_rate_data) < 3:
            return None
        
        # ç›¸é–¢åˆ†æ
        correlation_coef = win_rate_data['é¦¬ç•ª'].corr(win_rate_data['å‹ç‡'])
        
        # ãƒ”ã‚¢ã‚½ãƒ³ç›¸é–¢ã®på€¤ã‚’è¨ˆç®—
        correlation_pvalue = stats.pearsonr(win_rate_data['é¦¬ç•ª'], win_rate_data['å‹ç‡'])[1]
        
        # ç·šå½¢å›å¸°
        X = win_rate_data['é¦¬ç•ª'].values.reshape(-1, 1)
        y = win_rate_data['å‹ç‡'].values
        
        # scikit-learnã§ã®ç·šå½¢å›å¸°
        from sklearn.linear_model import LinearRegression
        linear_model = LinearRegression()
        linear_model.fit(X, y)
        
        # RÂ²å€¤
        r2 = linear_model.score(X, y)
        
        # ãƒ­ã‚¸ã‚¹ãƒ†ã‚£ãƒƒã‚¯å›å¸°ï¼ˆå€‹åˆ¥ãƒ¬ãƒ¼ã‚¹çµæœã§ã®åˆ†æï¼‰
        logistic_X = data['é¦¬ç•ª'].values.reshape(-1, 1)
        logistic_y = data['å‹åˆ©'].values
        
        logistic_model = LogisticRegression(max_iter=1000)
        try:
            logistic_model.fit(logistic_X, logistic_y)
            logistic_coef = logistic_model.coef_[0][0]
            logistic_intercept = logistic_model.intercept_[0]
        except:
            logistic_coef = np.nan
            logistic_intercept = np.nan
        
        # çµæœã‚’ã¾ã¨ã‚ã‚‹
        results = {
            'track_name': track_name,
            'period_name': period_name,
            'sample_size': len(data),
            'horse_numbers': len(win_rate_data),
            'correlation_coefficient': correlation_coef,
            'correlation_pvalue': correlation_pvalue,
            'linear_r2': r2,
            'linear_slope': linear_model.coef_[0],
            'linear_intercept': linear_model.intercept_,
            'logistic_coefficient': logistic_coef,
            'logistic_intercept': logistic_intercept,
            'win_rate_data': win_rate_data
        }
        
        return results
    
    def create_visualizations(self, results, output_dir):
        """
        å¯è¦–åŒ–ã‚°ãƒ©ãƒ•ã‚’ä½œæˆï¼ˆç¢ºå®Ÿãªãƒ•ã‚©ãƒ³ãƒˆè¨­å®šç‰ˆï¼‰
        
        Args:
            results (dict): åˆ†æçµæœ
            output_dir (str): å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
        """
        import matplotlib.font_manager as fm
        import matplotlib.pyplot as plt
        import platform
        import os
        
        # æ—¥æœ¬èªãƒ•ã‚©ãƒ³ãƒˆãƒ—ãƒ­ãƒ‘ãƒ†ã‚£ã‚’æº–å‚™
        font_prop = None
        try:
            if platform.system() == 'Windows':
                # Windowsãƒ•ã‚©ãƒ³ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç›´æ¥æŒ‡å®š
                windows_fonts_dir = r'C:\Windows\Fonts'
                font_candidates = [
                    os.path.join(windows_fonts_dir, 'YuGothM.ttc'),
                    os.path.join(windows_fonts_dir, 'msgothic.ttc'),
                    os.path.join(windows_fonts_dir, 'meiryo.ttc'),
                ]
                
                for font_path in font_candidates:
                    if os.path.exists(font_path):
                        font_prop = fm.FontProperties(fname=font_path)
                        print(f"å¯è¦–åŒ–ç”¨ãƒ•ã‚©ãƒ³ãƒˆè¨­å®š: {font_path}")
                        break
            
            if font_prop is None:
                # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
                font_prop = fm.FontProperties(family=['Yu Gothic', 'MS Gothic', 'Meiryo', 'DejaVu Sans'])
                
        except Exception as e:
            print(f"ãƒ•ã‚©ãƒ³ãƒˆãƒ—ãƒ­ãƒ‘ãƒ†ã‚£è¨­å®šã‚¨ãƒ©ãƒ¼: {e}")
            font_prop = fm.FontProperties()
        
        track_name = results['track_name']
        period_name = results['period_name']
        win_rate_data = results['win_rate_data']
        
        # å›³ã®ã‚µã‚¤ã‚ºã‚’è¨­å®š
        plt.style.use('default')
        
        # 1. æ•£å¸ƒå›³ã¨å›å¸°ç›´ç·š
        fig, axes = plt.subplots(2, 2, figsize=(15, 12))
        
        # ã‚¿ã‚¤ãƒˆãƒ«è¨­å®šï¼ˆãƒ•ã‚©ãƒ³ãƒˆãƒ—ãƒ­ãƒ‘ãƒ†ã‚£æŒ‡å®šï¼‰
        title_text = f'{track_name} - {period_name}æœŸé–“ é¦¬ç•ªã¨å‹ç‡ã®é–¢ä¿‚åˆ†æ'
        fig.suptitle(title_text, fontsize=16, fontproperties=font_prop)
        
        # æ•£å¸ƒå›³
        ax1 = axes[0, 0]
        ax1.scatter(win_rate_data['é¦¬ç•ª'], win_rate_data['å‹ç‡_percent'], alpha=0.7, s=50)
        
        # å›å¸°ç›´ç·š
        x_range = np.linspace(win_rate_data['é¦¬ç•ª'].min(), win_rate_data['é¦¬ç•ª'].max(), 100)
        y_pred = results['linear_slope'] * x_range + results['linear_intercept']
        ax1.plot(x_range, y_pred * 100, 'r-', linewidth=2, label='å›å¸°ç›´ç·š')
        
        ax1.set_xlabel('é¦¬ç•ª', fontproperties=font_prop)
        ax1.set_ylabel('å‹ç‡ (%)', fontproperties=font_prop)
        ax1.set_title('æ•£å¸ƒå›³ã¨å›å¸°ç›´ç·š', fontproperties=font_prop)
        ax1.legend(prop=font_prop)
        ax1.grid(True, alpha=0.3)
        
        # é¦¬ç•ªåˆ¥å‹ç‡æ£’ã‚°ãƒ©ãƒ•
        ax2 = axes[0, 1]
        bars = ax2.bar(win_rate_data['é¦¬ç•ª'], win_rate_data['å‹ç‡_percent'], alpha=0.7)
        ax2.set_xlabel('é¦¬ç•ª', fontproperties=font_prop)
        ax2.set_ylabel('å‹ç‡ (%)', fontproperties=font_prop)
        ax2.set_title('é¦¬ç•ªåˆ¥å‹ç‡', fontproperties=font_prop)
        ax2.grid(True, alpha=0.3)
        
        # çµ±è¨ˆæƒ…å ±ãƒ†ã‚­ã‚¹ãƒˆ
        ax3 = axes[1, 0]
        ax3.axis('off')
        
        # çµ±è¨ˆæƒ…å ±ï¼ˆç¢ºå®Ÿãªãƒ•ã‚©ãƒ³ãƒˆæŒ‡å®šï¼‰
        stats_text = f"""çµ±è¨ˆåˆ†æçµæœ:

ç›¸é–¢ä¿‚æ•°: {results['correlation_coefficient']:.4f}
på€¤: {results['correlation_pvalue']:.4f}
æ±ºå®šä¿‚æ•°(RÂ²): {results['linear_r2']:.4f}

ç·šå½¢å›å¸°:
  å‚¾ã: {results['linear_slope']:.6f}
  åˆ‡ç‰‡: {results['linear_intercept']:.6f}

ãƒ­ã‚¸ã‚¹ãƒ†ã‚£ãƒƒã‚¯å›å¸°:
  ä¿‚æ•°: {results['logistic_coefficient']:.6f}
  åˆ‡ç‰‡: {results['logistic_intercept']:.6f}

ã‚µãƒ³ãƒ—ãƒ«æ•°:
  ç·ãƒ¬ãƒ¼ã‚¹æ•°: {results['sample_size']:,}
  é¦¬ç•ªæ•°: {results['horse_numbers']}
        """
        
        ax3.text(0.1, 0.9, stats_text, transform=ax3.transAxes, fontsize=11,
                verticalalignment='top', fontproperties=font_prop)
        
        # é¦¬ç•ªåˆ¥ãƒ¬ãƒ¼ã‚¹æ•°
        ax4 = axes[1, 1]
        ax4.bar(win_rate_data['é¦¬ç•ª'], win_rate_data['ç·ãƒ¬ãƒ¼ã‚¹æ•°'], alpha=0.7, color='orange')
        ax4.set_xlabel('é¦¬ç•ª', fontproperties=font_prop)
        ax4.set_ylabel('ãƒ¬ãƒ¼ã‚¹æ•°', fontproperties=font_prop)
        ax4.set_title('é¦¬ç•ªåˆ¥ãƒ¬ãƒ¼ã‚¹æ•°', fontproperties=font_prop)
        ax4.grid(True, alpha=0.3)
        
        plt.tight_layout()
        
        # ãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜
        filename = f"{track_name}_{period_name}_é¦¬ç•ªå‹ç‡åˆ†æ_ç¢ºå®Ÿç‰ˆ.png"
        filepath = os.path.join(output_dir, filename)
        plt.savefig(filepath, dpi=300, bbox_inches='tight')
        plt.close()
        
        print(f"ç¢ºå®Ÿç‰ˆã‚°ãƒ©ãƒ•ã‚’ä¿å­˜ã—ã¾ã—ãŸ: {filepath}")
    
    def analyze_track_number_winrate(self, period_years=3, min_races=100):
        """
        ç«¶é¦¬å ´åˆ¥é¦¬ç•ªã¨å‹ç‡ã®é–¢ä¿‚ã‚’åˆ†æ
        
        Args:
            period_years (int): æœŸé–“å¹´æ•°
            min_races (int): åˆ†æã«å¿…è¦ãªæœ€å°ãƒ¬ãƒ¼ã‚¹æ•°
            
        Returns:
            list: åˆ†æçµæœã®ãƒªã‚¹ãƒˆ
        """
        surface_label = "ã€èŠãƒ¬ãƒ¼ã‚¹é™å®šã€‘" if self.turf_only else "ã€èŠãƒ»ãƒ€ãƒ¼ãƒˆå…¨ãƒ¬ãƒ¼ã‚¹ã€‘"
        print(f"{surface_label} ç«¶é¦¬å ´åˆ¥é¦¬ç•ªã¨å‹ç‡ã®é–¢ä¿‚åˆ†æã‚’é–‹å§‹ã—ã¾ã™ï¼ˆæœŸé–“: {period_years}å¹´ï¼‰")
        
        # å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®ä½œæˆ
        output_dir = os.path.join(self.output_folder, f"period_{period_years}years")
        if not os.path.exists(output_dir):
            os.makedirs(output_dir)
        
        # æœŸé–“ç¯„å›²ã‚’å–å¾—
        periods = self.get_period_ranges(period_years)
        if not periods:
            return []
        
        # åˆ†æçµæœã‚’ä¿å­˜ã™ã‚‹ãƒªã‚¹ãƒˆ
        all_results = []
        
        # ç«¶é¦¬å ´åˆ¥ã«åˆ†æ
        tracks = self.df['å ´å'].unique()
        
        for track in tracks:
            print(f"\n=== {track}ç«¶é¦¬å ´ã®åˆ†æ ===")
            track_data = self.df[self.df['å ´å'] == track]
            
            for period_start, period_end in periods:
                period_name = f"{period_start}-{period_end}"
                period_data = track_data[
                    (track_data['å¹´'] >= period_start) & 
                    (track_data['å¹´'] <= period_end)
                ]
                
                # ãƒ‡ãƒ¼ã‚¿ãŒååˆ†ã«ãªã„å ´åˆã¯ã‚¹ã‚­ãƒƒãƒ—
                if len(period_data) < min_races:
                    print(f"  {period_name}: ãƒ‡ãƒ¼ã‚¿ä¸è¶³ã®ãŸã‚ã‚¹ã‚­ãƒƒãƒ— ({len(period_data)}ãƒ¬ãƒ¼ã‚¹ < {min_races})")
                    continue
                
                print(f"  {period_name}: {len(period_data)}ãƒ¬ãƒ¼ã‚¹ã‚’åˆ†æä¸­...")
                
                # çµ±è¨ˆåˆ†æã‚’å®Ÿè¡Œ
                results = self.perform_statistical_analysis(period_data, track, period_name)
                
                if results is None:
                    print(f"    åˆ†æå¤±æ•—: ååˆ†ãªãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“")
                    continue
                
                # å¯è¦–åŒ–
                self.create_visualizations(results, output_dir)
                
                # çµæœã‚’ä¿å­˜
                all_results.append(results)
                
                # çµæœã‚’ã‚³ãƒ³ã‚½ãƒ¼ãƒ«ã«è¡¨ç¤º
                print(f"    ç›¸é–¢ä¿‚æ•°: {results['correlation_coefficient']:.4f}")
                print(f"    på€¤: {results['correlation_pvalue']:.4f}")
                print(f"    æ±ºå®šä¿‚æ•°: {results['linear_r2']:.4f}")
        
        return all_results
    
    def generate_summary_report(self, all_results, period_years):
        """
        ç·åˆãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆ
        
        Args:
            all_results (list): å…¨åˆ†æçµæœ
            period_years (int): æœŸé–“å¹´æ•°
        """
        output_dir = os.path.join(self.output_folder, f"period_{period_years}years")
        report_path = os.path.join(output_dir, f"é¦¬ç•ªå‹ç‡åˆ†æãƒ¬ãƒãƒ¼ãƒˆ_{period_years}å¹´.md")
        
        # èŠãƒ¬ãƒ¼ã‚¹é™å®šã®åˆ¤å®š
        surface_type = "èŠãƒ¬ãƒ¼ã‚¹é™å®š" if self.turf_only else "å…¨ãƒ¬ãƒ¼ã‚¹ï¼ˆèŠãƒ»ãƒ€ãƒ¼ãƒˆï¼‰"
        
        # Windowsç’°å¢ƒã§ã®æ–‡å­—åŒ–ã‘ã‚’é˜²ããŸã‚UTF-8 BOMä»˜ãã§ä¿å­˜
        with open(report_path, 'w', encoding='utf-8-sig') as f:
            f.write(f"# ç«¶é¦¬å ´åˆ¥é¦¬ç•ªã¨å‹ç‡ã®é–¢ä¿‚åˆ†æãƒ¬ãƒãƒ¼ãƒˆï¼ˆ{period_years}å¹´æœŸé–“ãƒ»{surface_type}ï¼‰\n\n")
            f.write(f"ç”Ÿæˆæ—¥æ™‚: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n\n")
            
            f.write("## æ¦‚è¦\n\n")
            f.write(f"å„ç«¶é¦¬å ´ã«ãŠã„ã¦ã€é¦¬ç•ªã¨å‹ç‡ã®é–¢ä¿‚ã‚’{period_years}å¹´æœŸé–“ã”ã¨ã«åˆ†æã—ã¾ã—ãŸã€‚\n")
            f.write(f"å¯¾è±¡ãƒ¬ãƒ¼ã‚¹: **{surface_type}**\n")
            f.write("çµ±è¨ˆçš„æ‰‹æ³•ã¨ã—ã¦ç›¸é–¢åˆ†æã€ç·šå½¢å›å¸°ã€ãƒ­ã‚¸ã‚¹ãƒ†ã‚£ãƒƒã‚¯å›å¸°ã‚’ä½¿ç”¨ã—ã¦ã„ã¾ã™ã€‚\n\n")
            
            f.write("## åˆ†æçµæœä¸€è¦§\n\n")
            f.write("| ç«¶é¦¬å ´ | æœŸé–“ | ç›¸é–¢ä¿‚æ•° | på€¤ | æ±ºå®šä¿‚æ•°(RÂ²) | ç·šå½¢å›å¸°å‚¾ã | ãƒ­ã‚¸ã‚¹ãƒ†ã‚£ãƒƒã‚¯å›å¸°ä¿‚æ•° | ãƒ¬ãƒ¼ã‚¹æ•° |\n")
            f.write("|--------|------|----------|-----|-------------|-------------|---------------------|----------|\n")
            
            for result in all_results:
                f.write(f"| {result['track_name']} | {result['period_name']} | "
                       f"{result['correlation_coefficient']:.4f} | "
                       f"{result['correlation_pvalue']:.4f} | "
                       f"{result['linear_r2']:.4f} | "
                       f"{result['linear_slope']:.6f} | "
                       f"{result['logistic_coefficient']:.6f} | "
                       f"{result['sample_size']:,} |\n")
            
            f.write("\n## çµ±è¨ˆçš„è§£é‡ˆ\n\n")
            f.write("### ç›¸é–¢ä¿‚æ•°ã«ã¤ã„ã¦\n")
            f.write("- -1 â‰¤ r â‰¤ 1 ã®ç¯„å›²ã§ã€0ã«è¿‘ã„ã»ã©ç„¡ç›¸é–¢\n")
            f.write("- |r| > 0.3 ã§å¼±ã„ç›¸é–¢ã€|r| > 0.5 ã§ä¸­ç¨‹åº¦ã®ç›¸é–¢\n\n")
            
            f.write("### på€¤ã«ã¤ã„ã¦\n")
            f.write("- p < 0.05 ã§çµ±è¨ˆçš„ã«æœ‰æ„ï¼ˆ95%ä¿¡é ¼æ°´æº–ï¼‰\n")
            f.write("- p < 0.01 ã§é«˜åº¦ã«æœ‰æ„ï¼ˆ99%ä¿¡é ¼æ°´æº–ï¼‰\n\n")
            
            f.write("### æ±ºå®šä¿‚æ•°(RÂ²)ã«ã¤ã„ã¦\n")
            f.write("- 0 â‰¤ RÂ² â‰¤ 1 ã®ç¯„å›²ã§ã€1ã«è¿‘ã„ã»ã©å›å¸°ãƒ¢ãƒ‡ãƒ«ã®èª¬æ˜åŠ›ãŒé«˜ã„\n")
            f.write("- RÂ² > 0.1 ã§å®Ÿç”¨çš„ãªèª¬æ˜åŠ›ãŒã‚ã‚‹ã¨è€ƒãˆã‚‰ã‚Œã‚‹\n\n")
            
            # æœ‰æ„ãªçµæœã®è¦ç´„
            significant_results = [r for r in all_results if r['correlation_pvalue'] < 0.05]
            
            f.write(f"### çµ±è¨ˆçš„ã«æœ‰æ„ãªçµæœï¼ˆp < 0.05ï¼‰\n\n")
            if significant_results:
                f.write(f"å…¨{len(all_results)}ä»¶ä¸­{len(significant_results)}ä»¶ã§çµ±è¨ˆçš„ã«æœ‰æ„ãªé–¢ä¿‚ãŒæ¤œå‡ºã•ã‚Œã¾ã—ãŸã€‚\n\n")
                
                for result in significant_results:
                    correlation_strength = "å¼·ã„" if abs(result['correlation_coefficient']) > 0.5 else \
                                         "ä¸­ç¨‹åº¦" if abs(result['correlation_coefficient']) > 0.3 else "å¼±ã„"
                    direction = "æ­£ã®" if result['correlation_coefficient'] > 0 else "è² ã®"
                    
                    f.write(f"- **{result['track_name']}ï¼ˆ{result['period_name']}ï¼‰**: "
                           f"{direction}{correlation_strength}ç›¸é–¢ (r={result['correlation_coefficient']:.4f}, "
                           f"p={result['correlation_pvalue']:.4f})\n")
                f.write("\n")
            else:
                f.write("çµ±è¨ˆçš„ã«æœ‰æ„ãªé–¢ä¿‚ã¯æ¤œå‡ºã•ã‚Œã¾ã›ã‚“ã§ã—ãŸã€‚\n\n")
        
        print(f"ãƒ¬ãƒãƒ¼ãƒˆã‚’ä¿å­˜ã—ã¾ã—ãŸ: {report_path}")
        
        # PowerShellç”¨ã®Shift-JISç‰ˆã‚‚ä½œæˆ
        report_path_sjis = os.path.join(output_dir, f"é¦¬ç•ªå‹ç‡åˆ†æãƒ¬ãƒãƒ¼ãƒˆ_{period_years}å¹´_SJIS.md")
        try:
            with open(report_path_sjis, 'w', encoding='shift-jis', errors='replace') as f:
                f.write(f"# ç«¶é¦¬å ´åˆ¥é¦¬ç•ªã¨å‹ç‡ã®é–¢ä¿‚åˆ†æãƒ¬ãƒãƒ¼ãƒˆï¼ˆ{period_years}å¹´æœŸé–“ãƒ»{surface_type}ï¼‰\n\n")
                f.write(f"ç”Ÿæˆæ—¥æ™‚: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n\n")
                
                f.write("## æ¦‚è¦\n\n")
                f.write(f"å„ç«¶é¦¬å ´ã«ãŠã„ã¦ã€é¦¬ç•ªã¨å‹ç‡ã®é–¢ä¿‚ã‚’{period_years}å¹´æœŸé–“ã”ã¨ã«åˆ†æã—ã¾ã—ãŸã€‚\n")
                f.write(f"å¯¾è±¡ãƒ¬ãƒ¼ã‚¹: **{surface_type}**\n")
                f.write("çµ±è¨ˆçš„æ‰‹æ³•ã¨ã—ã¦ç›¸é–¢åˆ†æã€ç·šå½¢å›å¸°ã€ãƒ­ã‚¸ã‚¹ãƒ†ã‚£ãƒƒã‚¯å›å¸°ã‚’ä½¿ç”¨ã—ã¦ã„ã¾ã™ã€‚\n\n")
                
                f.write("## åˆ†æçµæœä¸€è¦§\n\n")
                f.write("| ç«¶é¦¬å ´ | æœŸé–“ | ç›¸é–¢ä¿‚æ•° | på€¤ | æ±ºå®šä¿‚æ•°(RÂ²) | ç·šå½¢å›å¸°å‚¾ã | ãƒ­ã‚¸ã‚¹ãƒ†ã‚£ãƒƒã‚¯å›å¸°ä¿‚æ•° | ãƒ¬ãƒ¼ã‚¹æ•° |\n")
                f.write("|--------|------|----------|-----|-------------|-------------|---------------------|----------|\n")
                
                for result in all_results:
                    f.write(f"| {result['track_name']} | {result['period_name']} | "
                           f"{result['correlation_coefficient']:.4f} | "
                           f"{result['correlation_pvalue']:.4f} | "
                           f"{result['linear_r2']:.4f} | "
                           f"{result['linear_slope']:.6f} | "
                           f"{result['logistic_coefficient']:.6f} | "
                           f"{result['sample_size']:,} |\n")
                
                f.write("\n## çµ±è¨ˆçš„è§£é‡ˆ\n\n")
                f.write("### ç›¸é–¢ä¿‚æ•°ã«ã¤ã„ã¦\n")
                f.write("- -1 â‰¤ r â‰¤ 1 ã®ç¯„å›²ã§ã€0ã«è¿‘ã„ã»ã©ç„¡ç›¸é–¢\n")
                f.write("- |r| > 0.3 ã§å¼±ã„ç›¸é–¢ã€|r| > 0.5 ã§ä¸­ç¨‹åº¦ã®ç›¸é–¢\n\n")
                
                f.write("### på€¤ã«ã¤ã„ã¦\n")
                f.write("- p < 0.05 ã§çµ±è¨ˆçš„ã«æœ‰æ„ï¼ˆ95%ä¿¡é ¼æ°´æº–ï¼‰\n")
                f.write("- p < 0.01 ã§é«˜åº¦ã«æœ‰æ„ï¼ˆ99%ä¿¡é ¼æ°´æº–ï¼‰\n\n")
                
                f.write("### æ±ºå®šä¿‚æ•°(RÂ²)ã«ã¤ã„ã¦\n")
                f.write("- 0 â‰¤ RÂ² â‰¤ 1 ã®ç¯„å›²ã§ã€1ã«è¿‘ã„ã»ã©å›å¸°ãƒ¢ãƒ‡ãƒ«ã®èª¬æ˜åŠ›ãŒé«˜ã„\n")
                f.write("- RÂ² > 0.1 ã§å®Ÿç”¨çš„ãªèª¬æ˜åŠ›ãŒã‚ã‚‹ã¨è€ƒãˆã‚‰ã‚Œã‚‹\n\n")
                
                f.write(f"### çµ±è¨ˆçš„ã«æœ‰æ„ãªçµæœï¼ˆp < 0.05ï¼‰\n\n")
                if significant_results:
                    f.write(f"å…¨{len(all_results)}ä»¶ä¸­{len(significant_results)}ä»¶ã§çµ±è¨ˆçš„ã«æœ‰æ„ãªé–¢ä¿‚ãŒæ¤œå‡ºã•ã‚Œã¾ã—ãŸã€‚\n\n")
                    
                    for result in significant_results:
                        correlation_strength = "å¼·ã„" if abs(result['correlation_coefficient']) > 0.5 else \
                                             "ä¸­ç¨‹åº¦" if abs(result['correlation_coefficient']) > 0.3 else "å¼±ã„"
                        direction = "æ­£ã®" if result['correlation_coefficient'] > 0 else "è² ã®"
                        
                        f.write(f"- **{result['track_name']}ï¼ˆ{result['period_name']}ï¼‰**: "
                               f"{direction}{correlation_strength}ç›¸é–¢ (r={result['correlation_coefficient']:.4f}, "
                               f"p={result['correlation_pvalue']:.4f})\n")
                    f.write("\n")
                else:
                    f.write("çµ±è¨ˆçš„ã«æœ‰æ„ãªé–¢ä¿‚ã¯æ¤œå‡ºã•ã‚Œã¾ã›ã‚“ã§ã—ãŸã€‚\n\n")
            
            print(f"PowerShellç”¨ãƒ¬ãƒãƒ¼ãƒˆã‚’ä¿å­˜ã—ã¾ã—ãŸ: {report_path_sjis}")
        except Exception as e:
            print(f"Shift-JISç‰ˆã®ä½œæˆã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")

def main():
    """
    ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•°
    """
    import argparse
    
    parser = argparse.ArgumentParser(description='ç«¶é¦¬å ´åˆ¥é¦¬ç•ªã¨å‹ç‡ã®é–¢ä¿‚åˆ†æ')
    parser.add_argument('--period', type=int, default=3, 
                       help='åˆ†ææœŸé–“ã®å¹´æ•°ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 3å¹´ï¼‰')
    parser.add_argument('--min-races', type=int, default=100,
                       help='åˆ†æã«å¿…è¦ãªæœ€å°ãƒ¬ãƒ¼ã‚¹æ•°ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 100ï¼‰')
    parser.add_argument('--data-folder', type=str, default="export/with_bias",
                       help='ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚©ãƒ«ãƒ€ã®ãƒ‘ã‚¹')
    parser.add_argument('--output-folder', type=str, default="results/track_number_analysis",
                       help='çµæœå‡ºåŠ›å…ˆãƒ•ã‚©ãƒ«ãƒ€ã®ãƒ‘ã‚¹')
    parser.add_argument('--turf-only', action='store_true',
                       help='èŠãƒ¬ãƒ¼ã‚¹ã®ã¿ã«é™å®šã™ã‚‹')
    
    args = parser.parse_args()
    
    # èŠãƒ¬ãƒ¼ã‚¹é™å®šã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼ˆã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ãƒ†ã‚£ãƒ–ç‰ˆï¼‰
    if not args.turf_only:
        turf_only_choice = input("èŠãƒ¬ãƒ¼ã‚¹ã®ã¿ã«é™å®šã—ã¾ã™ã‹ï¼Ÿ (y/n): ").strip().lower()
        turf_only = turf_only_choice in ['y', 'yes', 'ã¯ã„', '1']
    else:
        turf_only = True
    
    # å‡ºåŠ›ãƒ•ã‚©ãƒ«ãƒ€ã‚’èª¿æ•´
    output_folder = args.output_folder
    if turf_only:
        output_folder = output_folder.replace("track_number_analysis", "track_number_analysis_turf_only")
        print("ğŸŒ± èŠãƒ¬ãƒ¼ã‚¹é™å®šãƒ¢ãƒ¼ãƒ‰ã§é¦¬ç•ªå‹ç‡åˆ†æã‚’å®Ÿè¡Œã—ã¾ã™ã€‚")
    else:
        print("ğŸ‡ å…¨ãƒ¬ãƒ¼ã‚¹ï¼ˆèŠãƒ»ãƒ€ãƒ¼ãƒˆï¼‰ã§é¦¬ç•ªå‹ç‡åˆ†æã‚’å®Ÿè¡Œã—ã¾ã™ã€‚")
    
    # åˆ†æå™¨ã‚’åˆæœŸåŒ–
    analyzer = TrackNumberWinRateAnalyzer(
        data_folder=args.data_folder,
        output_folder=output_folder,
        turf_only=turf_only
    )
    
    # ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
    if not analyzer.load_sed_data():
        print("ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸã€‚")
        return
    
    # ãƒ‡ãƒ¼ã‚¿å‰å‡¦ç†
    if not analyzer.preprocess_data():
        print("ãƒ‡ãƒ¼ã‚¿å‰å‡¦ç†ã«å¤±æ•—ã—ã¾ã—ãŸã€‚")
        return
    
    # åˆ†æå®Ÿè¡Œ
    all_results = analyzer.analyze_track_number_winrate(
        period_years=args.period,
        min_races=args.min_races
    )
    
    if not all_results:
        print("åˆ†æçµæœãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
        return
    
    # ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
    analyzer.generate_summary_report(all_results, args.period)
    
    print(f"\n=== é¦¬ç•ªå‹ç‡åˆ†æå®Œäº† ===")
    surface_label = "ã€èŠãƒ¬ãƒ¼ã‚¹é™å®šã€‘" if turf_only else "ã€èŠãƒ»ãƒ€ãƒ¼ãƒˆå…¨ãƒ¬ãƒ¼ã‚¹ã€‘"
    print(f"{surface_label} åˆ†æä»¶æ•°: {len(all_results)}ä»¶")
    print(f"çµæœä¿å­˜å…ˆ: {output_folder}")
    
    if turf_only:
        print("ğŸŒ± èŠãƒ¬ãƒ¼ã‚¹é™å®šã®é¦¬ç•ªå‹ç‡åˆ†æã«ã‚ˆã‚Šã€èŠãƒ¬ãƒ¼ã‚¹ç‰¹æœ‰ã®å‚¾å‘ãŒæŠ½å‡ºã•ã‚Œã¾ã—ãŸã€‚")
        print("ğŸŒ± ãƒ€ãƒ¼ãƒˆãƒ¬ãƒ¼ã‚¹ã®å½±éŸ¿ã‚’é™¤å»ã—ã€ã‚ˆã‚Šç²¾å¯†ãªèŠé¦¬å ´ã§ã®é¦¬ç•ªåŠ¹æœã‚’åˆ†æã§ãã¾ã™ã€‚")

if __name__ == "__main__":
    main() 